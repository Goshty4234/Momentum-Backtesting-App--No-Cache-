# NO_CACHE VERSION - All @st.cache_data decorators removed for reliability (with full MA Filter support)
import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import os
import diskcache as dc

# Initialize API call counter
if 'api_call_count' not in st.session_state:
    st.session_state.api_call_count = 0

# Yahoo Finance Cache Functions
def get_ticker_with_cache(ticker_symbol: str):
    """Get yf.Ticker object with 4-hour cache"""
    try:
        cache_key = f"ticker_obj_{ticker_symbol}"
        cache_dir = '.streamlit/ticker_cache'
        if not os.path.exists(cache_dir):
            os.makedirs(cache_dir, exist_ok=True)
        
        disk_cache = dc.Cache(cache_dir)
        cached_result = disk_cache.get(cache_key)
        if cached_result is not None:
            return cached_result
        
        ticker = yf.Ticker(ticker_symbol)
        st.session_state.api_call_count += 1
        disk_cache.set(cache_key, ticker, expire=14400)  # 4 hours
        return ticker
    except Exception:
        return yf.Ticker(ticker_symbol)

def get_ticker_history_with_cache(ticker_symbol: str, period: str = "max", auto_adjust: bool = False, 
                                 columns: list = None):
    """Get ticker historical data with 4-hour cache"""
    try:
        cache_key = f"history_{ticker_symbol}_{period}_{auto_adjust}_{columns}"
        cache_dir = '.streamlit/ticker_cache'
        if not os.path.exists(cache_dir):
            os.makedirs(cache_dir, exist_ok=True)
        
        disk_cache = dc.Cache(cache_dir)
        cached_result = disk_cache.get(cache_key)
        if cached_result is not None:
            return cached_result
        
        ticker = yf.Ticker(ticker_symbol)
        st.session_state.api_call_count += 1
        hist = ticker.history(period=period, auto_adjust=auto_adjust)
        
        if columns and not hist.empty:
            available_columns = [col for col in columns if col in hist.columns]
            if available_columns:
                hist = hist[available_columns]
        
        disk_cache.set(cache_key, hist, expire=14400)  # 4 hours
        return hist
    except Exception:
        ticker = yf.Ticker(ticker_symbol)
        hist = ticker.history(period=period, auto_adjust=auto_adjust)
        if columns and not hist.empty:
            available_columns = [col for col in columns if col in hist.columns]
            if available_columns:
                hist = hist[available_columns]
        return hist

def get_ticker_info_with_cache(ticker_symbol: str):
    """Get ticker info with 4-hour cache"""
    try:
        cache_key = f"info_{ticker_symbol}"
        cache_dir = '.streamlit/ticker_info_cache'
        if not os.path.exists(cache_dir):
            os.makedirs(cache_dir, exist_ok=True)
        
        disk_cache = dc.Cache(cache_dir)
        cached_result = disk_cache.get(cache_key)
        if cached_result is not None:
            return cached_result
        
        ticker = yf.Ticker(ticker_symbol)
        st.session_state.api_call_count += 1
        info = ticker.info
        disk_cache.set(cache_key, info, expire=14400)  # 4 hours
        return info
    except Exception:
        return {}

def get_batch_download_with_cache(ticker_list: list, period: str = "max", 
                                 auto_adjust: bool = False, **kwargs):
    """Get batch download data with 4-hour cache"""
    try:
        cache_key = f"batch_{sorted(ticker_list)}_{period}_{auto_adjust}_{kwargs}"
        cache_dir = '.streamlit/ticker_cache'
        if not os.path.exists(cache_dir):
            os.makedirs(cache_dir, exist_ok=True)
        
        disk_cache = dc.Cache(cache_dir)
        cached_result = disk_cache.get(cache_key)
        if cached_result is not None:
            return cached_result
        
        batch_data = yf.download(ticker_list, period=period, auto_adjust=auto_adjust, **kwargs)
        st.session_state.api_call_count += 1
        disk_cache.set(cache_key, batch_data, expire=14400)  # 4 hours
        return batch_data
    except Exception:
        return yf.download(ticker_list, period=period, auto_adjust=auto_adjust, **kwargs)

def clear_all_yahoo_caches():
    """Clear all Yahoo Finance caches"""
    total_cleared = 0
    
    cache_dir = '.streamlit/ticker_cache'
    if os.path.exists(cache_dir):
        disk_cache = dc.Cache(cache_dir)
        cache_size = len(disk_cache)
        disk_cache.clear()
        total_cleared += cache_size
    
    info_cache_dir = '.streamlit/ticker_info_cache'
    if os.path.exists(info_cache_dir):
        info_cache = dc.Cache(info_cache_dir)
        info_cache_size = len(info_cache)
        info_cache.clear()
        total_cleared += info_cache_size
    
    return total_cleared
import json
import io
import re
import time
from numba import jit
import concurrent.futures
# lru_cache removed for NO_CACHE version
import os
import signal
import sys
import threading
import logging
import warnings
import multiprocessing as mp
import diskcache as dc

# Suppress specific Streamlit threading warnings
warnings.filterwarnings('ignore')
warnings.filterwarnings('ignore', message='.*ScriptRunContext.*')
warnings.filterwarnings('ignore', message='.*missing ScriptRunContext.*')
logging.getLogger("streamlit.runtime.scriptrunner.script_runner").setLevel(logging.ERROR)
logging.getLogger("streamlit.runtime.scriptrunner").setLevel(logging.ERROR)
logging.getLogger("streamlit.runtime.scriptrunner.script_runner").propagate = False

# Set pandas options for handling large dataframes
pd.set_option("styler.render.max_elements", 1000000)  # Allow up to 1M cells for styling

# =============================================================================
# HARD KILL FUNCTIONS
# =============================================================================
def hard_kill_process():
    """Completely kill the current process and all background threads"""
    try:
        # Kill all background threads
        for thread in threading.enumerate():
            if thread != threading.current_thread():
                thread.join(timeout=0.1)

        # Force garbage collection
        import gc
        gc.collect()

        # On Windows, use os._exit for immediate termination
        if os.name == 'nt':
            os._exit(1)
        else:
            # On Unix-like systems, use os.kill
            os.kill(os.getpid(), signal.SIGTERM)
    except Exception:
        # Last resort - force exit
        os._exit(1)

def check_kill_request():
    """Check if user has requested a hard kill"""
    if st.session_state.get('hard_kill_requested', False):
        st.error("üõë **HARD KILL REQUESTED** - Terminating all processes...")
        st.stop()

def emergency_kill():
    """Emergency kill function that stops backtest without crashing the app"""
    st.error("üõë **EMERGENCY KILL** - Forcing immediate backtest termination...")
    st.session_state.hard_kill_requested = True
    st.rerun()

# Note: Signal handler removed to prevent Streamlit errors
# Interrupt handling is now done through the existing hard_kill_requested mechanism

# =============================================================================
# TICKER ALIASES FUNCTIONS
# =============================================================================

def get_ticker_aliases():
    """Define ticker aliases for easier entry"""
    return {
        # Stock Market Indices
        'SPX': '^GSPC',           # S&P 500 (price only, no dividends) - 1927+
        'SPXTR': '^SP500TR',      # S&P 500 Total Return (with dividends) - 1988+
        'SP500': '^GSPC',         # S&P 500 (price only, no dividends) - 1927+
        'SP500TR': '^SP500TR',    # S&P 500 Total Return (with dividends) - 1988+
        'SPYTR': '^SP500TR',      # S&P 500 Total Return (with dividends) - 1988+
        'NASDAQ': '^IXIC',        # NASDAQ Composite (price only, no dividends) - 1971+
        'NDX': '^NDX',           # NASDAQ 100 (price only, no dividends) - 1985+
        'QQQTR': 'QQQ',          # NASDAQ-100 (with dividends) - 1999+
        'DOW': '^DJI',           # Dow Jones Industrial Average (price only, no dividends) - 1992+
        
        # Treasury Yield Indices (LONGEST HISTORY - 1960s+)
        'TNX': '^TNX',           # 10-Year Treasury Yield (1962+) - Price only, no coupons
        'TYX': '^TYX',           # 30-Year Treasury Yield (1977+) - Price only, no coupons
        'FVX': '^FVX',           # 5-Year Treasury Yield (1962+) - Price only, no coupons
        'IRX': '^IRX',           # 3-Month Treasury Yield (1960+) - Price only, no coupons
        
        # Treasury Bond ETFs (MODERN - WITH COUPONS/DIVIDENDS)
        'TLTETF': 'TLT',         # 20+ Year Treasury Bond ETF (2002+) - With coupons
        'IEFETF': 'IEF',         # 7-10 Year Treasury Bond ETF (2002+) - With coupons
        'SHY': 'SHY',            # 1-3 Year Treasury Bond ETF (2002+) - With coupons
        'BIL': 'BIL',            # 1-3 Month T-Bill ETF (2007+) - With coupons
        'GOVT': 'GOVT',          # US Treasury Bond ETF (2012+) - With coupons
        'SPTL': 'SPTL',          # Long Term Treasury ETF (2007+) - With coupons
        'SPTS': 'SPTS',          # Short Term Treasury ETF (2011+) - With coupons
        'SPTI': 'SPTI',          # Intermediate Term Treasury ETF (2007+) - With coupons
        
        # Cash/Zero Return
        'ZEROX': 'ZEROX',        # Cash doing nothing - zero return
        
        # Gold & Commodities
        'GOLDX': 'GOLDX',        # Fidelity Gold Fund (1994+) - With dividends
        'GLD': 'GLD',            # SPDR Gold Trust ETF (2004+) - With dividends
        'IAU': 'IAU',            # iShares Gold Trust ETF (2005+) - With dividends
        'GOLDF': 'GC=F',         # Gold Futures (2000+) - No dividends
        'GOLD50': 'GOLD_COMPLETE',  # Complete Gold Dataset (1975+) - Historical + GLD
        'ZROZ50': 'ZROZ_COMPLETE',  # Complete ZROZ Dataset (1962+) - Historical + ZROZ
        'TLT50': 'TLT_COMPLETE',  # Complete TLT Dataset (1962+) - Historical + TLT
        'BTC50': 'BTC_COMPLETE',  # Complete Bitcoin Dataset (2010+) - Historical + BTC-USD
        'IEF50': 'IEF_COMPLETE',  # Complete IEF Dataset (1962+) - Historical + IEF
        'KMLM50': 'KMLM_COMPLETE',  # Complete KMLM Dataset (1992+) - Historical + KMLM
        'DBMF50': 'DBMF_COMPLETE',  # Complete DBMF Dataset (2000+) - Historical + DBMF
        'TBILL50': 'TBILL_COMPLETE',  # Complete TBILL Dataset (1948+) - Historical + SGOV
        # New short aliases for complete tickers (ordered by asset class)
        'TBILL': 'TBILL_COMPLETE',  # Complete TBILL Dataset (1948+) - Historical + SGOV
        'IEFTR': 'IEF_COMPLETE',  # Complete IEF Dataset (1962+) - Historical + IEF
        'TLTTR': 'TLT_COMPLETE',  # Complete TLT Dataset (1962+) - Historical + TLT
        'ZROZX': 'ZROZ_COMPLETE',  # Complete ZROZ Dataset (1962+) - Historical + ZROZ
        'GOLDX': 'GOLD_COMPLETE',  # Complete Gold Dataset (1975+) - Historical + GLD
        'KMLMX': 'KMLM_COMPLETE',  # Complete KMLM Dataset (1992+) - Historical + KMLM
        'DBMFX': 'DBMF_COMPLETE',  # Complete DBMF Dataset (2000+) - Historical + DBMF
        'BITCOINX': 'BTC_COMPLETE',  # Complete Bitcoin Dataset (2010+) - Historical + BTC-USD
        'SPYSIM': 'SPYSIM_COMPLETE',  # Complete S&P 500 Simulation (1885+) - Historical + SPYTR
        'GOLDSIM': 'GOLDSIM_COMPLETE',  # Complete Gold Simulation (1968+) - New Historical + GOLDX
        'SILVER': 'SI=F',        # Silver Futures (2000+) - No dividends
        'OIL': 'CL=F',           # Crude Oil Futures (2000+) - No dividends
        'NATGAS': 'NG=F',        # Natural Gas Futures (2000+) - No dividends
        'CORN': 'ZC=F',          # Corn Futures (2000+) - No dividends
        'SOYBEAN': 'ZS=F',       # Soybean Futures (2000+) - No dividends
        'COFFEE': 'KC=F',        # Coffee Futures (2000+) - No dividends
        'SUGAR': 'SB=F',         # Sugar Futures (2000+) - No dividends
        'COTTON': 'CT=F',        # Cotton Futures (2000+) - No dividends
        'COPPER': 'HG=F',        # Copper Futures (2000+) - No dividends
        'PLATINUM': 'PL=F',      # Platinum Futures (1997+) - No dividends
        'PALLADIUM': 'PA=F',     # Palladium Futures (1998+) - No dividends
        
        # Cryptocurrency
        'BITCOIN': 'BTC-USD',    # Bitcoin (2014+) - No dividends
        
        # Leveraged & Inverse ETFs (Synthetic Aliases) - NASDAQ-100 versions
        'TQQQND': '^NDX?L=3?E=0.95',     # 3x NASDAQ-100 (price only) - 1985+
        'QLDND': '^NDX?L=2?E=0.95',      # 2x NASDAQ-100 (price only) - 1985+
        'PSQND': '^NDX?L=-1?E=0.95',     # -1x NASDAQ-100 (price only, no dividends) - 1985+
        'QIDND': '^NDX?L=-2?E=0.95',     # -2x NASDAQ-100 (price only, no dividends) - 1985+
        'SQQQND': '^NDX?L=-3?E=0.95',    # -3x NASDAQ-100 (price only, no dividends) - 1985+
        
        # Leveraged & Inverse ETFs (Synthetic Aliases) - NASDAQ Composite versions (longer history)
        'TQQQIXIC': '^IXIC?L=3?E=0.95',  # 3x NASDAQ Composite (price only) - 1971+ ‚ö†Ô∏è Different from real TQQQ
        'QLDIXIC': '^IXIC?L=2?E=0.95',   # 2x NASDAQ Composite (price only) - 1971+ ‚ö†Ô∏è Different from real QLD
        'PSQIXIC': '^IXIC?L=-1?E=0.95',  # -1x NASDAQ Composite (price only, no dividends) - 1971+ ‚ö†Ô∏è Different from real PSQ
        'QIDIXIC': '^IXIC?L=-2?E=0.95',  # -2x NASDAQ Composite (price only, no dividends) - 1971+ ‚ö†Ô∏è Different from real QID
        'SQQQIXIC': '^IXIC?L=-3?E=0.95', # -3x NASDAQ Composite (price only, no dividends) - 1971+ ‚ö†Ô∏è Different from real SQQQ
        
        # S&P 500 leveraged/inverse (unchanged)
        'SPXLTR': '^SP500TR?L=3?E=1.00', # 3x S&P 500 (with dividends) - 1988+
        'UPROTR': '^SP500TR?L=3?E=0.91', # 3x S&P 500 (with dividends) - 1988+
        'SSOTR': '^SP500TR?L=2?E=0.91',  # 2x S&P 500 (with dividends) - 1988+
        'SHND': '^GSPC?L=-1?E=0.89',     # -1x S&P 500 (price only, no dividends) - 1927+
        'SDSND': '^GSPC?L=-2?E=0.91',    # -2x S&P 500 (price only, no dividends) - 1927+
        'SPXUND': '^GSPC?L=-3?E=1.00',   # -3x S&P 500 (price only, no dividends) - 1927+
        
        # Legacy aliases (kept for backward compatibility)
        'TQQQTR': '^NDX?L=3?E=0.95',     # Legacy - 3x NASDAQ-100 (price only) - 1985+
        'QLDTR': '^NDX?L=2?E=0.95',      # Legacy - 2x NASDAQ-100 (price only) - 1985+
        'SHTR': '^GSPC?L=-1?E=0.89',     # Legacy - -1x S&P 500 (price only, no dividends) - 1927+
        'PSQTR': '^NDX?L=-1?E=0.95',     # Legacy - -1x NASDAQ-100 (price only, no dividends) - 1985+
        'SDSTR': '^GSPC?L=-2?E=0.91',    # Legacy - -2x S&P 500 (price only, no dividends) - 1927+
        'QIDTR': '^NDX?L=-2?E=0.95',     # Legacy - -2x NASDAQ-100 (price only, no dividends) - 1985+
        'SPXUTR': '^GSPC?L=-3?E=1.00',   # Legacy - -3x S&P 500 (price only, no dividends) - 1927+
        'SQQQTR': '^NDX?L=-3?E=0.95',    # Legacy - -3x NASDAQ-100 (price only, no dividends) - 1985+
        
        # Special Dynamic Portfolio Tickers
        'SP500TOP20': 'SP500TOP20',  # Dynamic S&P 500 Top 20 (rebalances yearly based on historical data)
        
        # Additional mappings for new aliases
        'SPYND': '^GSPC',         # S&P 500 (price only, no dividends) - 1927+
        'QQQND': '^IXIC',         # NASDAQ Composite (price only, no dividends) - 1971+
        
        # Sector Indices (No Dividends) - Using GICS codes
        'XLKND': '^SP500-45',    # S&P 500 Information Technology (1990+)
        'XLVND': '^SP500-35',    # S&P 500 Health Care (1990+)
        'XLPND': '^SP500-30',    # S&P 500 Consumer Staples (1990+)
        'XLFND': '^SP500-40',    # S&P 500 Financials (1990+)
        'XLEND': '^SP500-10',    # S&P 500 Energy (1990+)
        'XLIND': '^SP500-20',    # S&P 500 Industrials (1990+)
        'XLYND': '^SP500-25',    # S&P 500 Consumer Discretionary (1990+)
        'XLBND': '^SP500-15',    # S&P 500 Materials (1990+)
        'XLUND': '^SP500-55',    # S&P 500 Utilities (1990+)
        'XLREND': '^SP500-60',   # S&P 500 Real Estate (1990+)
        'XLCND': '^SP500-50',    # S&P 500 Communication Services (1990+)
    }

def resolve_ticker_alias(ticker):
    """Resolve ticker alias to actual ticker symbol"""
    aliases = get_ticker_aliases()
    upper_ticker = ticker.upper()
    
    # Special conversion for Berkshire Hathaway tickers for Yahoo Finance compatibility
    if upper_ticker == 'BRK.B':
        upper_ticker = 'BRK-B'
    elif upper_ticker == 'BRK.A':
        upper_ticker = 'BRK-A'
    
    return aliases.get(upper_ticker, upper_ticker)

def parse_raw_sp500_csv():
    """Parse the raw S&P 500 CSV data into a structured DataFrame"""
    try:
        import pandas as pd
        
        st.write("üîç DEBUG: Starting to parse raw S&P 500 CSV")
        
        # Read the raw CSV file
        df = pd.read_csv('TOP 20 S&P 500 compagnies over time.csv', header=None)
        
        st.write(f"üîç DEBUG: Raw CSV has {len(df)} rows")
        st.write(f"üîç DEBUG: First 10 rows: {df.head(10).values.tolist()}")
        
        # The data is structured as: value, company, value, company, etc.
        # We need to parse it into Year, Rank, Company, Ticker, Market_Cap_Billions format
        
        parsed_data = []
        current_year = 1989  # Starting year
        rank = 1
        
        i = 0
        while i < len(df):
            row = df.iloc[i, 0]
            
            # Check if this is a year (numeric value)
            if pd.isna(row) or row == '':
                i += 1
                continue
                
            try:
                # Try to convert to float to see if it's a market cap value
                market_cap = float(row)
                
                # If we have a market cap, the next row should be the company name
                if i + 1 < len(df):
                    company = str(df.iloc[i + 1, 0])
                    
                    # Skip if company name is empty or NaN
                    if company and company != '' and company != 'nan':
                        # Extract ticker from company name
                        ticker = extract_ticker_from_company(company)
                        
                        parsed_data.append({
                            'Year': current_year,
                            'Rank': rank,
                            'Company': company,
                            'Ticker': ticker,
                            'Market_Cap_Billions': market_cap
                        })
                        
                        # Debug output for first few entries
                        if len(parsed_data) <= 25:  # First year + some of second year
                            st.write(f"üîç DEBUG: Parsed {company} -> {ticker} (Rank {rank}, Year {current_year})")
                        
                        rank += 1
                        if rank > 20:  # Reset for next year
                            st.write(f"üîç DEBUG: Completed year {current_year}, moving to {current_year + 1}")
                            rank = 1
                            current_year += 1
                
                i += 2  # Skip both market cap and company name
                
            except (ValueError, TypeError):
                # If conversion fails, it might be a year or other data
                i += 1
                continue
        
        if parsed_data:
            return pd.DataFrame(parsed_data)
        else:
            return None
            
    except Exception as e:
        print(f"Error parsing S&P 500 CSV: {e}")
        return None

def extract_ticker_from_company(company_name):
    """Extract ticker symbol from company name - simplified mapping"""
    # This is a simplified mapping - you may need to expand this
    ticker_mapping = {
        'Apple': 'AAPL',
        'Microsoft': 'MSFT',
        'Amazon': 'AMZN',
        'Alphabet': 'GOOGL',
        'Tesla': 'TSLA',
        'Meta/Facebook': 'META',
        'Meta Platforms': 'META',
        'NVIDIA': 'NVDA',
        'Berkshire Hathaway': 'BRK-B',
        'Exxon Mobil': 'XOM',
        'Johnson & Johnson': 'JNJ',
        'JPMorgan Chase': 'JPM',
        'Visa': 'V',
        'Procter & Gamble': 'PG',
        'UnitedHealth': 'UNH',
        'Mastercard': 'MA',
        'Walmart': 'WMT',
        'Chevron': 'CVX',
        'Home Depot': 'HD',
        'Pfizer': 'PFE',
        'Bank of America': 'BAC',
        'Coca-Cola': 'KO',
        'Merck': 'MRK',
        'PepsiCo': 'PEP',
        'Wells Fargo': 'WFC',
        'Intel': 'INTC',
        'Cisco Systems': 'CSCO',
        'Verizon': 'VZ',
        'AT&T': 'T',
        'General Electric': 'GE',
        'IBM': 'IBM',
        'Oracle': 'ORCL',
        'Boeing': 'BA',
        '3M': 'MMM',
        'McDonald\'s': 'MCD',
        'Walt Disney': 'DIS',
        'AIG': 'AIG',
        'Bristol-Myers Squibb': 'BMY',
        'Eli Lilly': 'LLY',
        'Schlumberger': 'SLB',
        'Altria Group': 'MO',
        'Fannie Mae': 'FNMA',
        'Kellogg\'s': 'K',
        'Citigroup': 'C',
        'Qualcomm': 'QCOM',
        'UPS': 'UPS',
        'Netflix': 'NFLX',
        'AbbVie': 'ABBV',
        'Palantir Technologies': 'PLTR'
    }
    
    return ticker_mapping.get(company_name, company_name.replace(' ', '').upper()[:4])

def is_special_dynamic_ticker(ticker):
    """Check if ticker is a special dynamic portfolio ticker"""
    special_tickers = ['SP500TOP20', 'ZROX']
    return ticker.upper() in special_tickers

def get_dynamic_portfolio_data(ticker):
    """Get dynamic portfolio data for special tickers"""
    if ticker.upper() == 'SP500TOP20':
        try:
            import pandas as pd
            # Try to read the template CSV first
            try:
                df = pd.read_csv('TOP_20_SP500_COMPLETE_TEMPLATE.csv')
            except:
                # If template doesn't exist, parse the raw CSV
                df = parse_raw_sp500_csv()
            
            if df is not None:
                # Get all unique tickers that need to be downloaded
                all_tickers = df['Ticker'].unique()
                start_year = df['Year'].min()
                end_year = df['Year'].max()
                
                return {
                    'type': 'dynamic_portfolio',
                    'name': f'Dynamic S&P 500 Top 20 ({start_year}-{end_year})',
                    'tickers': all_tickers.tolist(),
                    'historical_data': df.to_dict('records')
                }
        except Exception as e:
            print(f"Error getting dynamic portfolio data: {e}")
            return None
    return None

# =============================================================================
# RISK-FREE RATE FUNCTIONS
# =============================================================================

def _get_default_risk_free_rate(dates):
    """Get default risk-free rate when all other methods fail."""
    default_daily = (1 + 0.02) ** (1 / 365.25) - 1
    result = pd.Series(default_daily, index=pd.to_datetime(dates))
    # Ensure the result is timezone-naive
    if getattr(result.index, "tz", None) is not None:
        result.index = result.index.tz_convert(None)
    return result

def get_risk_free_rate_robust(dates):
    """Simple risk-free rate fetcher using Yahoo Finance treasury data."""
    try:
        dates = pd.to_datetime(dates)
        if isinstance(dates, pd.DatetimeIndex):
            if getattr(dates, "tz", None) is not None:
                dates = dates.tz_convert(None)
        
        # Get treasury data - use ^IRX (13-week treasury) as primary for leverage calculations
        # Fallback hierarchy: ^IRX ‚Üí ^FVX ‚Üí ^TNX ‚Üí ^TYX
        symbols = ["^IRX", "^FVX", "^TNX", "^TYX"]
        ticker = None
        for symbol in symbols:
            try:
                ticker = get_ticker_with_cache(symbol)
                st.session_state.api_call_count += 1
                hist = ticker.history(period="max", auto_adjust=False)
                if hist is not None and not hist.empty and 'Close' in hist.columns:
                    break
            except Exception:
                continue
        
        if ticker is None:
            # Final fallback to ^TNX
            ticker = get_ticker_with_cache("^TNX")
            st.session_state.api_call_count += 1
        hist = ticker.history(period="max", auto_adjust=False)
        
        if hist is not None and not hist.empty and 'Close' in hist.columns:
            # Filter valid data
            valid_data = hist[hist['Close'].notnull() & (hist['Close'] > 0)]
            
            if not valid_data.empty:
                # Convert annual percentage to daily rate
                annual_rates = valid_data['Close'] / 100.0
                daily_rates = (1 + annual_rates) ** (1 / 365.25) - 1.0
                
                # Create series with timezone-naive index
                daily_rate_series = pd.Series(daily_rates.values, index=daily_rates.index)
                if getattr(daily_rate_series.index, "tz", None) is not None:
                    daily_rate_series.index = daily_rate_series.index.tz_convert(None)
                
                # For each target date, use the most recent available rate
                result = pd.Series(index=dates, dtype=float)
                
                for i, target_date in enumerate(dates):
                    # Find the most recent treasury date <= target_date
                    valid_dates = daily_rate_series.index[daily_rate_series.index <= target_date]
                    
                    if len(valid_dates) > 0:
                        closest_date = valid_dates.max()
                        result.iloc[i] = daily_rate_series.loc[closest_date]
                    else:
                        # If no data before target date, use the earliest available
                        result.iloc[i] = daily_rate_series.iloc[0]
                
                # Handle any remaining NaN values
                if result.isna().any():
                    result = result.fillna(method='ffill').fillna(method='bfill')
                    if result.isna().any():
                        result = result.fillna(0.000105)  # Default daily rate
                
                return result
        
        # Fallback to default if all else fails
        return _get_default_risk_free_rate(dates)
        
    except Exception:
        return _get_default_risk_free_rate(dates)
import contextlib
from datetime import datetime, timedelta, date, time
import warnings
import os
import plotly.io as pio
warnings.filterwarnings('ignore')

# =============================================================================
# PERFORMANCE OPTIMIZATION: NO CACHING VERSION
# =============================================================================

# =============================================================================
# STANDALONE LEVERAGE FUNCTIONS (Independent from Backtest_Engine)
# =============================================================================

def _ensure_naive_index(obj: pd.DataFrame | pd.Series) -> pd.DataFrame | pd.Series:
    """Return a copy of obj with a tz-naive DatetimeIndex."""
    if not isinstance(obj.index, pd.DatetimeIndex):
        return obj
    idx = obj.index
    if getattr(idx, "tz", None) is not None:
        obj = obj.copy()
        obj.index = idx.tz_convert(None)
    return obj

def _get_default_risk_free_rate(dates):
    """Get default risk-free rate when all other methods fail."""
    default_daily = (1 + 0.02) ** (1 / 365.25) - 1
    result = pd.Series(default_daily, index=pd.to_datetime(dates))
    # Ensure the result is timezone-naive
    if getattr(result.index, "tz", None) is not None:
        result.index = result.index.tz_convert(None)
    return result

def get_risk_free_rate_robust(dates):
    """Simple risk-free rate fetcher using Yahoo Finance treasury data."""
    try:
        dates = pd.to_datetime(dates)
        if isinstance(dates, pd.DatetimeIndex):
            if getattr(dates, "tz", None) is not None:
                dates = dates.tz_convert(None)
        
        # Get treasury data - use ^IRX (13-week treasury) as primary for leverage calculations
        # Fallback hierarchy: ^IRX ‚Üí ^FVX ‚Üí ^TNX ‚Üí ^TYX
        symbols = ["^IRX", "^FVX", "^TNX", "^TYX"]
        ticker = None
        for symbol in symbols:
            try:
                ticker = get_ticker_with_cache(symbol)
                st.session_state.api_call_count += 1
                hist = ticker.history(period="max", auto_adjust=False)
                if hist is not None and not hist.empty and 'Close' in hist.columns:
                    break
            except Exception:
                continue
        
        if ticker is None:
            # Final fallback to ^TNX
            ticker = get_ticker_with_cache("^TNX")
            st.session_state.api_call_count += 1
        hist = ticker.history(period="max", auto_adjust=False)
        
        if hist is not None and not hist.empty and 'Close' in hist.columns:
            # Filter valid data
            valid_data = hist[hist['Close'].notnull() & (hist['Close'] > 0)]
            
            if not valid_data.empty:
                # Convert annual percentage to daily rate
                annual_rates = valid_data['Close'] / 100.0
                daily_rates = (1 + annual_rates) ** (1 / 365.25) - 1.0
                
                # Create series with timezone-naive index
                daily_rate_series = pd.Series(daily_rates.values, index=daily_rates.index)
                if getattr(daily_rate_series.index, "tz", None) is not None:
                    daily_rate_series.index = daily_rate_series.index.tz_convert(None)
                
                # For each target date, use the most recent available rate
                result = pd.Series(index=dates, dtype=float)
                
                for i, target_date in enumerate(dates):
                    # Find the most recent treasury date <= target_date
                    valid_dates = daily_rate_series.index[daily_rate_series.index <= target_date]
                    
                    if len(valid_dates) > 0:
                        closest_date = valid_dates.max()
                        result.iloc[i] = daily_rate_series.loc[closest_date]
                    else:
                        # If no data before target date, use the earliest available
                        result.iloc[i] = daily_rate_series.iloc[0]
                
                # Handle any remaining NaN values
                if result.isna().any():
                    result = result.fillna(method='ffill').fillna(method='bfill')
                    if result.isna().any():
                        result = result.fillna(0.000105)  # Default daily rate
                
                return result
        
        # Fallback to default if all else fails
        return _get_default_risk_free_rate(dates)
        
    except Exception:
        return _get_default_risk_free_rate(dates)

def parse_ticker_parameters(ticker_symbol: str) -> tuple[str, float, float]:
    """
    Parse ticker symbol to extract base ticker, leverage multiplier, and expense ratio.
    
    Args:
        ticker_symbol: Ticker symbol with optional parameters (e.g., "SPY?L=3?E=0.84")
        
    Returns:
        tuple: (base_ticker, leverage_multiplier, expense_ratio)
        
    Examples:
        "SPY" -> ("SPY", 1.0, 0.0)
        "SPY?L=3" -> ("SPY", 3.0, 0.0)
        "QQQ?E=1" -> ("QQQ", 1.0, 1.0)  # 1% expense ratio
        "QQQ?L=3?E=0.84" -> ("QQQ", 3.0, 0.84)
        "QQQ?E=1?L=2" -> ("QQQ", 2.0, 1.0)  # Order doesn't matter
    """
    # Convert commas to dots for decimal separators
    ticker_symbol = ticker_symbol.replace(",", ".")
    
    base_ticker = ticker_symbol
    leverage = 1.0
    expense_ratio = 0.0
    
    # Parse leverage parameter
    if "?L=" in base_ticker:
        try:
            parts = base_ticker.split("?L=", 1)
            base_ticker = parts[0]
            leverage_part = parts[1]
            
            # Check if there are more parameters after leverage
            if "?" in leverage_part:
                leverage_str, remaining = leverage_part.split("?", 1)
                leverage = float(leverage_str)
                base_ticker += "?" + remaining  # Add back remaining parameters
            else:
                leverage = float(leverage_part)
            
            # Leverage validation removed - allow any leverage value for testing
                
        except (ValueError, IndexError) as e:
            # If parsing fails, treat as regular ticker with no leverage
            leverage = 1.0
    
    # Parse expense ratio parameter
    if "?E=" in base_ticker:
        try:
            parts = base_ticker.split("?E=", 1)
            base_ticker = parts[0]
            expense_part = parts[1]
            
            # Check if there are more parameters after expense ratio
            if "?" in expense_part:
                expense_str, remaining = expense_part.split("?", 1)
                expense_ratio = float(expense_str)
                base_ticker += "?" + remaining  # Add back remaining parameters
            else:
                expense_ratio = float(expense_part)
            
            # Expense ratio validation removed - allow any expense ratio value for testing
                
        except (ValueError, IndexError) as e:
            # If parsing fails, treat as regular ticker with no expense ratio
            expense_ratio = 0.0
    
    return base_ticker.strip(), leverage, expense_ratio

def parse_leverage_ticker(ticker_symbol: str) -> tuple[str, float]:
    """
    Parse ticker symbol to extract base ticker and leverage multiplier.
    This is a backward compatibility wrapper for the new parameter parsing function.
    
    Args:
        ticker_symbol: Ticker symbol, potentially with leverage (e.g., "SPY?L=3")
        
    Returns:
        tuple: (base_ticker, leverage_multiplier)
        
    Examples:
        "SPY" -> ("SPY", 1.0)
        "SPY?L=3" -> ("SPY", 3.0)
        "QQQ?E=1" -> ("QQQ", 1.0)  # E=1 is expense ratio, not leverage
    """
    base_ticker, leverage, _ = parse_ticker_parameters(ticker_symbol)
    return base_ticker, leverage

def apply_daily_leverage(price_data: pd.DataFrame, leverage: float, expense_ratio: float = 0.0) -> pd.DataFrame:
    """
    Apply daily leverage multiplier and expense ratio to price data, simulating leveraged ETF behavior.
    
    Leveraged ETFs reset daily, so we apply the leverage to daily returns and then
    compound the results to get the leveraged price series. Includes daily cost drag
    equivalent to (leverage - 1) √ó risk_free_rate plus daily expense ratio drag.
    
    Args:
        price_data: DataFrame with 'Close' column containing price data
        leverage: Leverage multiplier (e.g., 3.0 for 3x leverage)
        expense_ratio: Annual expense ratio in percentage (e.g., 1.0 for 1% annual expense)
        
    Returns:
        DataFrame with leveraged price data including cost drag and expense ratio drag
    """
    if leverage == 1.0 and expense_ratio == 0.0:
        return price_data.copy()
    
    # Create a copy to avoid modifying original data
    leveraged_data = price_data.copy()
    
    # Get time-varying risk-free rates for the entire period
    try:
        risk_free_rates = get_risk_free_rate_robust(price_data.index)
        # Ensure risk-free rates are timezone-naive to match price_data
        if getattr(risk_free_rates.index, "tz", None) is not None:
            risk_free_rates.index = risk_free_rates.index.tz_localize(None)
    except Exception as e:
        raise
    
    # Calculate daily cost drag: (leverage - 1) √ó risk_free_rate
    # risk_free_rates is already in daily format, so we don't need to divide by 365.25
    try:
        daily_cost_drag = (leverage - 1) * risk_free_rates
    except Exception as e:
        raise
    
    # Calculate daily expense ratio drag: expense_ratio / 100 / 365.25 (annual to daily)
    daily_expense_drag = expense_ratio / 100.0 / 365.25
    
    # VECTORIZED APPROACH - 100-1000x faster than for loop!
    # Calculate daily returns using vectorized operations
    prices = price_data['Close'].values  # Convert to NumPy array for speed
    daily_returns = np.zeros(len(prices))
    daily_returns[1:] = prices[1:] / prices[:-1] - 1  # Vectorized returns calculation
    
    # Apply leverage to returns and subtract cost drag
    leveraged_returns = (daily_returns * leverage) - daily_cost_drag.values - daily_expense_drag
    leveraged_returns[0] = 0  # First day has no return
    
    # Compound the leveraged returns to get prices (cumulative product)
    # Using np.cumprod for vectorized compounding
    leveraged_prices = prices[0] * np.cumprod(1 + leveraged_returns)
    
    # Convert back to pandas Series with proper index
    leveraged_prices = pd.Series(leveraged_prices, index=price_data.index)
    
    # Update the Close price with leveraged prices
    leveraged_data['Close'] = leveraged_prices
    
    # Recalculate price changes with the new leveraged prices
    leveraged_data['Price_change'] = leveraged_data['Close'].pct_change(fill_method=None)
    
    # IMPORTANT: Preserve all other columns (like Dividend_per_share) from original data
    # The dividends should remain at their original values (not leveraged) for leveraged ETFs
    # This is correct behavior - leveraged ETFs don't multiply dividends
    
    return leveraged_data

def get_ticker_aliases():
    """Define ticker aliases for easier entry"""
    return {
        # Stock Market Indices
        'SPX': '^GSPC',           # S&P 500 (price only, no dividends) - 1927+
        'SPXTR': '^SP500TR',      # S&P 500 Total Return (with dividends) - 1988+
        'SP500': '^GSPC',         # S&P 500 (price only, no dividends) - 1927+
        'SP500TR': '^SP500TR',    # S&P 500 Total Return (with dividends) - 1988+
        'SPYTR': '^SP500TR',      # S&P 500 Total Return (with dividends) - 1988+
        'NASDAQ': '^IXIC',        # NASDAQ Composite (price only, no dividends) - 1971+
        'NDX': '^NDX',           # NASDAQ 100 (price only, no dividends) - 1985+
        'QQQTR': 'QQQ',          # NASDAQ-100 (with dividends) - 1999+
        'DOW': '^DJI',           # Dow Jones Industrial Average (price only, no dividends) - 1992+
        
        # Treasury Yield Indices (LONGEST HISTORY - 1960s+)
        'TNX': '^TNX',           # 10-Year Treasury Yield (1962+) - Price only, no coupons
        'TYX': '^TYX',           # 30-Year Treasury Yield (1977+) - Price only, no coupons
        'FVX': '^FVX',           # 5-Year Treasury Yield (1962+) - Price only, no coupons
        'IRX': '^IRX',           # 3-Month Treasury Yield (1960+) - Price only, no coupons
        
        # Treasury Bond ETFs (MODERN - WITH COUPONS/DIVIDENDS)
        'TLTETF': 'TLT',         # 20+ Year Treasury Bond ETF (2002+) - With coupons
        'IEFETF': 'IEF',         # 7-10 Year Treasury Bond ETF (2002+) - With coupons
        'SHY': 'SHY',            # 1-3 Year Treasury Bond ETF (2002+) - With coupons
        'BIL': 'BIL',            # 1-3 Month T-Bill ETF (2007+) - With coupons
        'GOVT': 'GOVT',          # US Treasury Bond ETF (2012+) - With coupons
        'SPTL': 'SPTL',          # Long Term Treasury ETF (2007+) - With coupons
        'SPTS': 'SPTS',          # Short Term Treasury ETF (2011+) - With coupons
        'SPTI': 'SPTI',          # Intermediate Term Treasury ETF (2007+) - With coupons
        
        # Cash/Zero Return
        'ZEROX': 'ZEROX',        # Cash doing nothing - zero return
        
        # Gold & Commodities
        'GOLDX': 'GOLDX',        # Fidelity Gold Fund (1994+) - With dividends
        'GLD': 'GLD',            # SPDR Gold Trust ETF (2004+) - With dividends
        'IAU': 'IAU',            # iShares Gold Trust ETF (2005+) - With dividends
        'GOLDF': 'GC=F',         # Gold Futures (2000+) - No dividends
        'GOLD50': 'GOLD_COMPLETE',  # Complete Gold Dataset (1975+) - Historical + GLD
        'ZROZ50': 'ZROZ_COMPLETE',  # Complete ZROZ Dataset (1962+) - Historical + ZROZ
        'TLT50': 'TLT_COMPLETE',  # Complete TLT Dataset (1962+) - Historical + TLT
        'BTC50': 'BTC_COMPLETE',  # Complete Bitcoin Dataset (2010+) - Historical + BTC-USD
        'IEF50': 'IEF_COMPLETE',  # Complete IEF Dataset (1962+) - Historical + IEF
        'KMLM50': 'KMLM_COMPLETE',  # Complete KMLM Dataset (1992+) - Historical + KMLM
        'DBMF50': 'DBMF_COMPLETE',  # Complete DBMF Dataset (2000+) - Historical + DBMF
        'TBILL50': 'TBILL_COMPLETE',  # Complete TBILL Dataset (1948+) - Historical + SGOV
        # New short aliases for complete tickers (ordered by asset class)
        'TBILL': 'TBILL_COMPLETE',  # Complete TBILL Dataset (1948+) - Historical + SGOV
        'IEFTR': 'IEF_COMPLETE',  # Complete IEF Dataset (1962+) - Historical + IEF
        'TLTTR': 'TLT_COMPLETE',  # Complete TLT Dataset (1962+) - Historical + TLT
        'ZROZX': 'ZROZ_COMPLETE',  # Complete ZROZ Dataset (1962+) - Historical + ZROZ
        'GOLDX': 'GOLD_COMPLETE',  # Complete Gold Dataset (1975+) - Historical + GLD
        'KMLMX': 'KMLM_COMPLETE',  # Complete KMLM Dataset (1992+) - Historical + KMLM
        'DBMFX': 'DBMF_COMPLETE',  # Complete DBMF Dataset (2000+) - Historical + DBMF
        'BITCOINX': 'BTC_COMPLETE',  # Complete Bitcoin Dataset (2010+) - Historical + BTC-USD
        'SPYSIM': 'SPYSIM_COMPLETE',  # Complete S&P 500 Simulation (1885+) - Historical + SPYTR
        'GOLDSIM': 'GOLDSIM_COMPLETE',  # Complete Gold Simulation (1968+) - New Historical + GOLDX
        'SILVER': 'SI=F',        # Silver Futures (2000+) - No dividends
        'OIL': 'CL=F',           # Crude Oil Futures (2000+) - No dividends
        'NATGAS': 'NG=F',        # Natural Gas Futures (2000+) - No dividends
        'CORN': 'ZC=F',          # Corn Futures (2000+) - No dividends
        'SOYBEAN': 'ZS=F',       # Soybean Futures (2000+) - No dividends
        'COFFEE': 'KC=F',        # Coffee Futures (2000+) - No dividends
        'SUGAR': 'SB=F',         # Sugar Futures (2000+) - No dividends
        'COTTON': 'CT=F',        # Cotton Futures (2000+) - No dividends
        'COPPER': 'HG=F',        # Copper Futures (2000+) - No dividends
        'PLATINUM': 'PL=F',      # Platinum Futures (1997+) - No dividends
        'PALLADIUM': 'PA=F',     # Palladium Futures (1998+) - No dividends
        
        # Cryptocurrency
        'BITCOIN': 'BTC-USD',    # Bitcoin (2014+) - No dividends
        
        # Leveraged & Inverse ETFs (Synthetic Aliases) - NASDAQ-100 versions
        'TQQQND': '^NDX?L=3?E=0.95',     # 3x NASDAQ-100 (price only) - 1985+
        'QLDND': '^NDX?L=2?E=0.95',      # 2x NASDAQ-100 (price only) - 1985+
        'PSQND': '^NDX?L=-1?E=0.95',     # -1x NASDAQ-100 (price only, no dividends) - 1985+
        'QIDND': '^NDX?L=-2?E=0.95',     # -2x NASDAQ-100 (price only, no dividends) - 1985+
        'SQQQND': '^NDX?L=-3?E=0.95',    # -3x NASDAQ-100 (price only, no dividends) - 1985+
        
        # Leveraged & Inverse ETFs (Synthetic Aliases) - NASDAQ Composite versions (longer history)
        'TQQQIXIC': '^IXIC?L=3?E=0.95',  # 3x NASDAQ Composite (price only) - 1971+ ‚ö†Ô∏è Different from real TQQQ
        'QLDIXIC': '^IXIC?L=2?E=0.95',   # 2x NASDAQ Composite (price only) - 1971+ ‚ö†Ô∏è Different from real QLD
        'PSQIXIC': '^IXIC?L=-1?E=0.95',  # -1x NASDAQ Composite (price only, no dividends) - 1971+ ‚ö†Ô∏è Different from real PSQ
        'QIDIXIC': '^IXIC?L=-2?E=0.95',  # -2x NASDAQ Composite (price only, no dividends) - 1971+ ‚ö†Ô∏è Different from real QID
        'SQQQIXIC': '^IXIC?L=-3?E=0.95', # -3x NASDAQ Composite (price only, no dividends) - 1971+ ‚ö†Ô∏è Different from real SQQQ
        
        # S&P 500 leveraged/inverse (unchanged)
        'SPXLTR': '^SP500TR?L=3?E=1.00', # 3x S&P 500 (with dividends) - 1988+
        'UPROTR': '^SP500TR?L=3?E=0.91', # 3x S&P 500 (with dividends) - 1988+
        'SSOTR': '^SP500TR?L=2?E=0.91',  # 2x S&P 500 (with dividends) - 1988+
        'SHND': '^GSPC?L=-1?E=0.89',     # -1x S&P 500 (price only, no dividends) - 1927+
        'SDSND': '^GSPC?L=-2?E=0.91',    # -2x S&P 500 (price only, no dividends) - 1927+
        'SPXUND': '^GSPC?L=-3?E=1.00',   # -3x S&P 500 (price only, no dividends) - 1927+
        
        # Legacy aliases (kept for backward compatibility)
        'TQQQTR': '^NDX?L=3?E=0.95',     # Legacy - 3x NASDAQ-100 (price only) - 1985+
        'QLDTR': '^NDX?L=2?E=0.95',      # Legacy - 2x NASDAQ-100 (price only) - 1985+
        'SHTR': '^GSPC?L=-1?E=0.89',     # Legacy - -1x S&P 500 (price only, no dividends) - 1927+
        'PSQTR': '^NDX?L=-1?E=0.95',     # Legacy - -1x NASDAQ-100 (price only, no dividends) - 1985+
        'SDSTR': '^GSPC?L=-2?E=0.91',    # Legacy - -2x S&P 500 (price only, no dividends) - 1927+
        'QIDTR': '^NDX?L=-2?E=0.95',     # Legacy - -2x NASDAQ-100 (price only, no dividends) - 1985+
        'SPXUTR': '^GSPC?L=-3?E=1.00',   # Legacy - -3x S&P 500 (price only, no dividends) - 1927+
        'SQQQTR': '^NDX?L=-3?E=0.95',    # Legacy - -3x NASDAQ-100 (price only, no dividends) - 1985+
        
        # Special Dynamic Portfolio Tickers
        'SP500TOP20': 'SP500TOP20',  # Dynamic S&P 500 Top 20 (rebalances yearly based on historical data)
        
        # Additional mappings for new aliases
        'SPYND': '^GSPC',         # S&P 500 (price only, no dividends) - 1927+
        'QQQND': '^IXIC',         # NASDAQ Composite (price only, no dividends) - 1971+
        
        # Sector Indices (No Dividends) - Using GICS codes
        'XLKND': '^SP500-45',    # S&P 500 Information Technology (1990+)
        'XLVND': '^SP500-35',    # S&P 500 Health Care (1990+)
        'XLPND': '^SP500-30',    # S&P 500 Consumer Staples (1990+)
        'XLFND': '^SP500-40',    # S&P 500 Financials (1990+)
        'XLEND': '^SP500-10',    # S&P 500 Energy (1990+)
        'XLIND': '^SP500-20',    # S&P 500 Industrials (1990+)
        'XLYND': '^SP500-25',    # S&P 500 Consumer Discretionary (1990+)
        'XLBND': '^SP500-15',    # S&P 500 Materials (1990+)
        'XLUND': '^SP500-55',    # S&P 500 Utilities (1990+)
        'XLREND': '^SP500-60',   # S&P 500 Real Estate (1990+)
        'XLCND': '^SP500-50',    # S&P 500 Communication Services (1990+)
    }

def resolve_ticker_alias(ticker):
    """Resolve ticker alias to actual ticker symbol"""
    aliases = get_ticker_aliases()
    upper_ticker = ticker.upper()
    
    # Special conversion for Berkshire Hathaway tickers for Yahoo Finance compatibility
    if upper_ticker == 'BRK.B':
        upper_ticker = 'BRK-B'
    elif upper_ticker == 'BRK.A':
        upper_ticker = 'BRK-A'
    
    return aliases.get(upper_ticker, upper_ticker)

def generate_zero_return_data(period="max"):
    """Generate synthetic zero return data for ZEROX ticker"""
    try:
        ref_ticker = get_ticker_with_cache("SPY")
        st.session_state.api_call_count += 1
        ref_hist = ref_ticker.history(period=period)
        if ref_hist.empty:
            end_date = pd.Timestamp.now()
            start_date = end_date - pd.Timedelta(days=365)
            dates = pd.date_range(start=start_date, end=end_date, freq='D')
        else:
            dates = ref_hist.index
        zero_data = pd.DataFrame({
            'Close': [100.0] * len(dates),
            'Dividends': [0.0] * len(dates)
        }, index=dates)
        return zero_data
    except Exception:
        end_date = pd.Timestamp.now()
        start_date = end_date - pd.Timedelta(days=30)
        dates = pd.date_range(start=start_date, end=end_date, freq='D')
        zero_data = pd.DataFrame({
            'Close': [100.0] * len(dates),
            'Dividends': [0.0] * len(dates)
        }, index=dates)
        return zero_data

def get_gold_complete_data(period="max"):
    """Get complete gold data from historical CSV and GLD"""
    try:
        # Load historical data directly
        import pandas as pd
        df = pd.read_csv('Complete_Tickers/Historical CSV/Gold_Futures_Complete.csv')
        
        # Parse dates
        df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%Y')
        df.set_index('Date', inplace=True)
        
        # Rename columns
        df.columns = ['Close', 'Open', 'High', 'Low', 'Volume', 'Change_Percent']
        
        # Get GLD data for recent updates
        gld_ticker = get_ticker_with_cache("GLD")
        st.session_state.api_call_count += 1
        gld_data = gld_ticker.history(period="max", auto_adjust=True)
        
        if not gld_data.empty:
            # Make timezone-naive for comparison
            gld_data.index = gld_data.index.tz_localize(None)
            
            # Scale GLD to match historical data at 2004
            historical_2004_price = df.loc['2004-11-18', 'Close'] if '2004-11-18' in df.index else df.loc[df.index[df.index.year == 2004].max(), 'Close']
            gld_2004_price = gld_data.loc[gld_data.index[gld_data.index.year == 2004].min(), 'Close']
            scaling_factor = historical_2004_price / gld_2004_price
            
            # Scale GLD data
            gld_scaled = gld_data.copy()
            gld_scaled['Close'] = gld_scaled['Close'] * scaling_factor
            gld_scaled['Open'] = gld_scaled['Open'] * scaling_factor
            gld_scaled['High'] = gld_scaled['High'] * scaling_factor
            gld_scaled['Low'] = gld_scaled['Low'] * scaling_factor
            
            # Combine data
            combined_data = pd.concat([df, gld_scaled])
            combined_data = combined_data[~combined_data.index.duplicated(keep='last')]
            combined_data = combined_data.sort_index()
        else:
            combined_data = df
        
        # Convert to expected format
        result = pd.DataFrame({
            'Close': combined_data['Close'],
            'Dividends': [0.0] * len(combined_data)
        }, index=combined_data.index)
        
        return result
        
    except Exception as e:
        # Fallback to GLD
        try:
            ticker = get_ticker_with_cache("GLD")
            st.session_state.api_call_count += 1
            return ticker.history(period=period, auto_adjust=True)[["Close", "Dividends"]]
        except:
            return pd.DataFrame()

def get_zroz_complete_data(period="max"):
    """Get complete ZROZ data from our custom ZROZ ticker"""
    try:
        # Import our ZROZ ticker
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
        
        from Complete_Tickers.ZROZ_COMPLETE_TICKER import create_safe_zroz_ticker
        
        # Get the complete ZROZ data
        zroz_data = create_safe_zroz_ticker()
        
        if zroz_data is None:
            # Fallback to ZROZ if our custom ticker fails
            ticker = get_ticker_with_cache("ZROZ")
            st.session_state.api_call_count += 1
            return ticker.history(period=period, auto_adjust=True)[["Close", "Dividends"]]
        
        # Convert to the expected format
        result = pd.DataFrame({
            'Close': zroz_data['Close'],
            'Dividends': [0.0] * len(zroz_data)  # ZROZ doesn't pay dividends
        }, index=zroz_data.index)
        
        return result
    except Exception as e:
        # Fallback to ZROZ if anything fails
        try:
            ticker = get_ticker_with_cache("ZROZ")
            st.session_state.api_call_count += 1
            return ticker.history(period=period, auto_adjust=True)[["Close", "Dividends"]]
        except:
            return pd.DataFrame()

def get_tlt_complete_data(period="max"):
    """Get complete TLT data from our custom TLT ticker"""
    try:
        # Import our TLT ticker
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
        
        from Complete_Tickers.TLT_COMPLETE_TICKER import create_safe_tlt_ticker
        
        # Get the complete TLT data
        tlt_data = create_safe_tlt_ticker()
        
        if tlt_data is None:
            # Fallback to TLT if our custom ticker fails
            ticker = get_ticker_with_cache("TLT")
            st.session_state.api_call_count += 1
            return ticker.history(period=period, auto_adjust=True)[["Close", "Dividends"]]
        
        # Convert to the expected format
        result = pd.DataFrame({
            'Close': tlt_data['Close'],
            'Dividends': [0.0] * len(tlt_data)  # TLT doesn't pay dividends
        }, index=tlt_data.index)
        
        return result
    except Exception as e:
        # Fallback to TLT if anything fails
        try:
            ticker = get_ticker_with_cache("TLT")
            st.session_state.api_call_count += 1
            return ticker.history(period=period, auto_adjust=True)[["Close", "Dividends"]]
        except:
            return pd.DataFrame()

def get_bitcoin_complete_data(period="max"):
    """Get complete Bitcoin data from our custom Bitcoin ticker"""
    try:
        # Import our Bitcoin ticker
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
        
        from Complete_Tickers.BITCOIN_COMPLETE_TICKER import create_bitcoin_complete_ticker
        
        # Get the complete Bitcoin data
        bitcoin_data = create_bitcoin_complete_ticker()
        
        if bitcoin_data is None:
            # Fallback to BTC-USD if our custom ticker fails
            ticker = get_ticker_with_cache("BTC-USD")
            st.session_state.api_call_count += 1
            return ticker.history(period=period, auto_adjust=True)[["Close", "Dividends"]]
        
        # Convert to the expected format
        result = pd.DataFrame({
            'Close': bitcoin_data['Close'],
            'Dividends': [0.0] * len(bitcoin_data)  # Bitcoin doesn't pay dividends
        }, index=bitcoin_data.index)
        
        return result
    except Exception as e:
        # Fallback to BTC-USD if anything fails
        try:
            ticker = get_ticker_with_cache("BTC-USD")
            st.session_state.api_call_count += 1
            return ticker.history(period=period, auto_adjust=True)[["Close", "Dividends"]]
        except:
            return pd.DataFrame()

def get_ief_complete_data(period="max"):
    """Get complete IEF data from our custom IEF ticker"""
    try:
        from Complete_Tickers.IEF_COMPLETE_TICKER import create_ief_complete_ticker
        ief_data = create_ief_complete_ticker()
        if ief_data is not None and not ief_data.empty:
            result = pd.DataFrame({
                'Close': ief_data['Close'],
                'Dividends': [0.0] * len(ief_data)
            }, index=ief_data.index)
            return result
        else:
            return None
    except Exception as e:
        try:
            ticker = get_ticker_with_cache("IEF")
            st.session_state.api_call_count += 1
            return ticker.history(period=period, auto_adjust=True)[["Close", "Dividends"]]
        except:
            return pd.DataFrame()

def get_kmlm_complete_data(period="max"):
    """Get complete KMLM data from our custom KMLM ticker"""
    try:
        from Complete_Tickers.KMLM_COMPLETE_TICKER import create_kmlm_complete_ticker
        kmlm_data = create_kmlm_complete_ticker()
        if kmlm_data is not None and not kmlm_data.empty:
            result = pd.DataFrame({
                'Close': kmlm_data['Close'],
                'Dividends': [0.0] * len(kmlm_data)
            }, index=kmlm_data.index)
            return result
        else:
            return None
    except Exception as e:
        try:
            ticker = get_ticker_with_cache("KMLM")
            return ticker.history(period=period, auto_adjust=True)[["Close", "Dividends"]]
        except:
            return pd.DataFrame()

def get_dbmf_complete_data(period="max"):
    """Get complete DBMF data from our custom DBMF ticker"""
    try:
        from Complete_Tickers.DBMF_COMPLETE_TICKER import create_dbmf_complete_ticker
        dbmf_data = create_dbmf_complete_ticker()
        if dbmf_data is not None and not dbmf_data.empty:
            result = pd.DataFrame({
                'Close': dbmf_data['Close'],
                'Dividends': [0.0] * len(dbmf_data)
            }, index=dbmf_data.index)
            return result
        else:
            return None
    except Exception as e:
        try:
            ticker = get_ticker_with_cache("DBMF")
            return ticker.history(period=period, auto_adjust=True)[["Close", "Dividends"]]
        except:
            return pd.DataFrame()

def get_tbill_complete_data(period="max"):
    """Get complete TBILL data from our custom TBILL ticker"""
    try:
        from Complete_Tickers.TBILL_COMPLETE_TICKER import create_tbill_complete_ticker
        tbill_data = create_tbill_complete_ticker()
        if tbill_data is not None and not tbill_data.empty:
            result = pd.DataFrame({
                'Close': tbill_data['Close'],
                'Dividends': [0.0] * len(tbill_data)
            }, index=tbill_data.index)
            return result
        else:
            return None
    except Exception as e:
        try:
            ticker = get_ticker_with_cache("SGOV")
            return ticker.history(period=period, auto_adjust=True)[["Close", "Dividends"]]
        except:
            return pd.DataFrame()

def get_spysim_complete_data(period="max"):
    """Get complete SPYSIM data from our custom SPYSIM ticker"""
    try:
        from Complete_Tickers.SPYSIM_COMPLETE_TICKER import create_spysim_complete_ticker
        spysim_data = create_spysim_complete_ticker()
        if spysim_data is not None and not spysim_data.empty:
            # Handle both DataFrame and Series
            close_data = spysim_data['Close'] if isinstance(spysim_data, pd.DataFrame) else spysim_data
            result = pd.DataFrame({
                'Close': close_data,
                'Dividends': [0.0] * len(spysim_data)
            }, index=spysim_data.index)
            return result
        else:
            return None
    except Exception as e:
        try:
            ticker = get_ticker_with_cache("^SP500TR")
            return ticker.history(period=period, auto_adjust=True)[["Close", "Dividends"]]
        except:
            return pd.DataFrame()

def get_goldsim_complete_data(period="max"):
    """Get complete GOLDSIM data from our custom GOLDSIM ticker"""
    try:
        # Try importing the GOLDSIM ticker
        from Complete_Tickers.GOLDSIM_COMPLETE_TICKER import create_goldsim_complete_ticker
        goldsim_data = create_goldsim_complete_ticker()
        
        if goldsim_data is not None and not goldsim_data.empty:
            # Handle both DataFrame and Series
            close_data = goldsim_data['Close'] if isinstance(goldsim_data, pd.DataFrame) else goldsim_data
            result = pd.DataFrame({
                'Close': close_data,
                'Dividends': [0.0] * len(goldsim_data)
            }, index=goldsim_data.index)
            return result
        else:
            print("‚ö†Ô∏è WARNING: GOLDSIM ticker returned empty data, falling back to GLD")
            # Fallback to GLD if GOLDSIM fails
            ticker = get_ticker_with_cache("GLD")
            st.session_state.api_call_count += 1
            return ticker.history(period=period, auto_adjust=True)[["Close", "Dividends"]]
            
    except ImportError as e:
        print(f"‚ö†Ô∏è WARNING: GOLDSIM import error: {e}, falling back to GLD")
        # Fallback to GLD if import fails
        ticker = get_ticker_with_cache("GLD")
        return ticker.history(period=period, auto_adjust=True)[["Close", "Dividends"]]
    except Exception as e:
        print(f"‚ö†Ô∏è WARNING: GOLDSIM function error: {e}, falling back to GLD")
        # Fallback to GLD if everything fails
        try:
            ticker = get_ticker_with_cache("GLD")
            st.session_state.api_call_count += 1
            return ticker.history(period=period, auto_adjust=True)[["Close", "Dividends"]]
        except:
            return pd.DataFrame()

def get_multiple_tickers_info_batch(ticker_list):
    """
    TRUE BATCH download ticker info for multiple tickers using yahooquery.
    
    Args:
        ticker_list: List of ticker symbols
        
    Returns:
        dict: {ticker: {info_dict}} for each ticker
    """
    results = {}
    
    # Initialize API call counter if not exists
    if 'api_call_count' not in st.session_state:
        st.session_state.api_call_count = 0
    
    # Resolve ticker aliases
    resolved_map = {}
    for ticker_symbol in ticker_list:
        try:
            base_ticker, _ = parse_leverage_ticker(ticker_symbol)
            resolved_ticker = resolve_ticker_alias(base_ticker, for_stats=True)
            resolved_map[ticker_symbol] = resolved_ticker
        except Exception:
            resolved_map[ticker_symbol] = ticker_symbol
    
    # Get unique resolved tickers
    unique_resolved = list(set(resolved_map.values()))
    
    # TRUE BATCH CALL using yahooquery
    try:
        from yahooquery import Ticker as YahooQueryTicker
        
        batch_ticker = YahooQueryTicker(unique_resolved)
        key_stats = batch_ticker.summary_detail
        
        # Count this as 1 API call
        st.session_state.api_call_count += 1
        
        # Process results
        info_results = {}
        for resolved in unique_resolved:
            try:
                if resolved in key_stats and key_stats[resolved]:
                    stats = key_stats[resolved]
                    info_results[resolved] = {
                        'trailingPE': stats.get('trailingPE'),
                        'forwardPE': stats.get('forwardPE'),
                        'priceToBook': stats.get('priceToBook'),
                        'priceToSalesTrailing12Months': stats.get('priceToSalesTrailing12Months'),
                        'enterpriseToRevenue': stats.get('enterpriseToRevenue'),
                        'enterpriseToEbitda': stats.get('enterpriseToEbitda'),
                        'beta': stats.get('beta'),
                        'marketCap': stats.get('marketCap'),
                        'totalCash': stats.get('totalCash'),
                        'totalDebt': stats.get('totalDebt'),
                        'returnOnEquity': stats.get('returnOnEquity'),
                        'returnOnAssets': stats.get('returnOnAssets'),
                        'debtToEquity': stats.get('debtToEquity'),
                        'currentRatio': stats.get('currentRatio'),
                        'quickRatio': stats.get('quickRatio'),
                        'grossMargins': stats.get('grossMargins'),
                        'operatingMargins': stats.get('operatingMargins'),
                        'profitMargins': stats.get('profitMargins'),
                        'revenueGrowth': stats.get('revenueGrowth'),
                        'earningsGrowth': stats.get('earningsGrowth'),
                        'dividendYield': stats.get('dividendYield'),
                        'payoutRatio': stats.get('payoutRatio'),
                        '52WeekHigh': stats.get('fiftyTwoWeekHigh'),
                        '52WeekLow': stats.get('fiftyTwoWeekLow'),
                        'averageVolume': stats.get('averageVolume'),
                        'volume': stats.get('volume'),
                        'regularMarketPrice': stats.get('regularMarketPrice'),
                        'regularMarketPreviousClose': stats.get('regularMarketPreviousClose'),
                        'regularMarketOpen': stats.get('regularMarketOpen'),
                        'regularMarketDayHigh': stats.get('regularMarketDayHigh'),
                        'regularMarketDayLow': stats.get('regularMarketDayLow'),
                        'regularMarketVolume': stats.get('regularMarketVolume'),
                        'currency': stats.get('currency'),
                        'exchange': stats.get('exchange'),
                        'quoteType': stats.get('quoteType'),
                        'longName': stats.get('longName'),
                        'shortName': stats.get('shortName'),
                        'sector': stats.get('sector'),
                        'industry': stats.get('industry'),
                        'fullTimeEmployees': stats.get('fullTimeEmployees'),
                        'website': stats.get('website'),
                        'city': stats.get('city'),
                        'state': stats.get('state'),
                        'country': stats.get('country'),
                        'businessSummary': stats.get('businessSummary'),
                        'maxAge': stats.get('maxAge')
                    }
                else:
                    info_results[resolved] = {}
            except Exception as e:
                print(f"Error processing stats for {resolved}: {e}")
                info_results[resolved] = {}
        
        # Map back to original ticker symbols
        for ticker_symbol in ticker_list:
            resolved = resolved_map[ticker_symbol]
            results[ticker_symbol] = info_results.get(resolved, {})
            
    except ImportError:
        st.error("‚ùå yahooquery not available - PE data will be skipped")
        return {}
    except Exception as e:
        st.error(f"‚ùå yahooquery failed: {e} - PE data will be skipped")
        return {}
    
    return results

def get_multiple_tickers_batch(ticker_list, period="max", auto_adjust=False):
    """
    Smart batch download with fallback to individual downloads + disk cache.
    
    Strategy:
    1. Check disk cache first (4-hour TTL, survives reloads)
    2. Try batch download (fast - 1 API call for all tickers)
    3. If batch fails ‚Üí fallback to individual downloads (reliable)
    4. Invalid tickers are skipped, others continue
    5. Store in disk cache for 4 hours
    
    Args:
        ticker_list: List of ticker symbols (can include leverage format)
        period: Data period
        auto_adjust: Auto-adjust setting
    
    Returns:
        Dict[ticker_symbol, DataFrame]: Data for each ticker
    """
    if not ticker_list:
        return {}
    
    # Initialize disk cache (survives page reloads)
    # Create cache directory if it doesn't exist
    cache_dir = '.streamlit/ticker_cache'
    os.makedirs(cache_dir, exist_ok=True)
    
    # Initialize disk cache with 4-hour TTL
    disk_cache = dc.Cache(cache_dir)
    
    # Check cache first
    results = {}
    cache_hits = 0
    cache_misses = []
    
    # Generate cache keys and check disk cache
    for ticker_symbol in ticker_list:
        cache_key = f"{ticker_symbol}_{period}_{auto_adjust}"
        
        # Try to get from disk cache
        cached_data = disk_cache.get(cache_key)
        
        if cached_data is not None:
            # Data found in disk cache (4h TTL is handled by diskcache)
            try:
                results[ticker_symbol] = cached_data.copy()
                cache_hits += 1
                continue
            except:
                # If deserialization fails, mark as miss
                pass
        
        cache_misses.append(ticker_symbol)
    
    if cache_hits > 0:
        st.write(f"‚úÖ Cache hit: {cache_hits}/{len(ticker_list)} tickers (from cache, < 4h old)")
    
    # If everything was cached, return early
    if not cache_misses:
        return results
    
    if cache_misses:
        st.write(f"üì• Downloading {len(cache_misses)} tickers from Yahoo Finance...")
    
    # Separate tickers into Yahoo-fetchable vs custom
    yahoo_tickers = []
    custom_tickers = {}
    
    for ticker_symbol in ticker_list:
        # Parse parameters
        base_ticker, leverage, expense_ratio = parse_ticker_parameters(ticker_symbol)
        resolved = resolve_ticker_alias(base_ticker)
        
        # Check if it's a custom ticker (local data, no Yahoo call)
        custom_list = ["ZEROX", "GOLD_COMPLETE", "ZROZ_COMPLETE", "TLT_COMPLETE", 
                      "BTC_COMPLETE", "IEF_COMPLETE", "KMLM_COMPLETE", "DBMF_COMPLETE",
                      "TBILL_COMPLETE", "SPYSIM_COMPLETE", "GOLDSIM_COMPLETE"]
        
        if resolved in custom_list:
            # Handle custom tickers individually (they don't use Yahoo)
            custom_tickers[ticker_symbol] = (resolved, leverage, expense_ratio)
        else:
            yahoo_tickers.append((ticker_symbol, resolved, leverage, expense_ratio))
    
    # Process custom tickers first (no Yahoo calls)
    for ticker_symbol, (resolved, leverage, expense_ratio) in custom_tickers.items():
        try:
            results[ticker_symbol] = get_ticker_data(ticker_symbol, period, auto_adjust)
        except:
            results[ticker_symbol] = pd.DataFrame()
    
    # If no Yahoo tickers, return early
    if not yahoo_tickers:
        return results
    
    # Extract just the resolved tickers for batch download
    resolved_list = list(set([resolved for _, resolved, _, _ in yahoo_tickers]))
    
    # CRITICAL: We must use individual downloads, not batch downloads
    # Batch downloads force ALL tickers to have the SAME date range (intersection of all dates)
    # This breaks backtesting because each ticker should have its own unique history
    # Individual downloads preserve each ticker's actual historical data range
    USE_BATCH_DOWNLOAD = True  # Set to True for optimized API calls
    
    try:
        # BATCH DOWNLOAD - Fast path (1 API call for all)
        if USE_BATCH_DOWNLOAD and len(resolved_list) > 1:
            batch_data = get_batch_download_with_cache(
                resolved_list,
                period=period,
                auto_adjust=auto_adjust,
                progress=False,
                group_by='ticker'
            )
            st.session_state.api_call_count += 1
            
            # Process batch data
            if not batch_data.empty:
                for ticker_symbol, resolved, leverage, expense_ratio in yahoo_tickers:
                    try:
                        if len(resolved_list) > 1:
                            # Multi-ticker batch
                            ticker_data = batch_data[resolved][['Close', 'Dividends']] if resolved in batch_data else pd.DataFrame()
                        else:
                            # Single ticker batch
                            ticker_data = batch_data[['Close', 'Dividends']]
                        
                        if not ticker_data.empty:
                            # Apply leverage/expense if needed
                            if leverage != 1.0 or expense_ratio != 0.0:
                                ticker_data = apply_daily_leverage(ticker_data, leverage, expense_ratio)
                            results[ticker_symbol] = ticker_data
                        else:
                            results[ticker_symbol] = pd.DataFrame()
                    except:
                        # Individual ticker failed in batch, will retry below
                        pass
            else:
                raise Exception("Batch download returned empty")
                
    except Exception:
        # FALLBACK - Batch failed, download individually (reliable but slower)
        pass
    
    # Download any missing tickers individually (fallback or single ticker)
    for ticker_symbol, resolved, leverage, expense_ratio in yahoo_tickers:
        if ticker_symbol not in results or results[ticker_symbol].empty:
            try:
                ticker = get_ticker_with_cache(resolved)
                hist = ticker.history(period=period, auto_adjust=auto_adjust)[["Close", "Dividends"]]
                
                if not hist.empty:
                    # Apply leverage/expense if needed
                    if leverage != 1.0 or expense_ratio != 0.0:
                        hist = apply_daily_leverage(hist, leverage, expense_ratio)
                    results[ticker_symbol] = hist
                    
                    # Store in disk cache (4h TTL)
                    cache_key = f"{ticker_symbol}_{period}_{auto_adjust}"
                    disk_cache.set(cache_key, hist.copy(), expire=4*3600)  # 4 hours in seconds
                else:
                    results[ticker_symbol] = pd.DataFrame()
            except:
                results[ticker_symbol] = pd.DataFrame()
    
    if cache_misses and results:
        downloaded_count = len([r for r in results.values() if r is not None and not r.empty])
        st.write(f"üì• Downloaded {downloaded_count} new tickers (cached for 4h)")
    
    return results

def get_ticker_data(ticker_symbol, period="max", auto_adjust=False, _cache_bust=None):
    """Get ticker data (NO_CACHE version - Optimized for backtesting)
    
    Args:
        ticker_symbol: Stock ticker symbol (supports leverage format like SPY?L=3)
        period: Data period
        auto_adjust: Auto-adjust setting
    """
    try:
        # Parse parameters from ticker symbol
        base_ticker, leverage, expense_ratio = parse_ticker_parameters(ticker_symbol)
        
        # Resolve ticker alias if it exists
        resolved_ticker = resolve_ticker_alias(base_ticker)
        
        # Special handling for ZEROX - generate zero return data
        if resolved_ticker == "ZEROX":
            return generate_zero_return_data(period)
        
        # Special handling for GOLD_COMPLETE - use our custom gold ticker
        if resolved_ticker == "GOLD_COMPLETE":
            hist = get_gold_complete_data(period)
            # Apply leverage and/or expense ratio if specified
            if leverage != 1.0 or expense_ratio != 0.0:
                hist = apply_daily_leverage(hist, leverage, expense_ratio)
            return hist
        
        # Special handling for ZROZ_COMPLETE - use our custom ZROZ ticker
        if resolved_ticker == "ZROZ_COMPLETE":
            hist = get_zroz_complete_data(period)
            # Apply leverage and/or expense ratio if specified
            if leverage != 1.0 or expense_ratio != 0.0:
                hist = apply_daily_leverage(hist, leverage, expense_ratio)
            return hist
        
        # Special handling for TLT_COMPLETE - use our custom TLT ticker
        if resolved_ticker == "TLT_COMPLETE":
            hist = get_tlt_complete_data(period)
            # Apply leverage and/or expense ratio if specified
            if leverage != 1.0 or expense_ratio != 0.0:
                hist = apply_daily_leverage(hist, leverage, expense_ratio)
            return hist
        
        # Special handling for BTC_COMPLETE - use our custom Bitcoin ticker
        if resolved_ticker == "BTC_COMPLETE":
            hist = get_bitcoin_complete_data(period)
            # Apply leverage and/or expense ratio if specified
            if leverage != 1.0 or expense_ratio != 0.0:
                hist = apply_daily_leverage(hist, leverage, expense_ratio)
            return hist
        
        # Special handling for IEF_COMPLETE - use our custom IEF ticker
        if resolved_ticker == "IEF_COMPLETE":
            hist = get_ief_complete_data(period)
            # Apply leverage and/or expense ratio if specified
            if leverage != 1.0 or expense_ratio != 0.0:
                hist = apply_daily_leverage(hist, leverage, expense_ratio)
            return hist
        
        # Special handling for KMLM_COMPLETE - use our custom KMLM ticker
        if resolved_ticker == "KMLM_COMPLETE":
            hist = get_kmlm_complete_data(period)
            # Apply leverage and/or expense ratio if specified
            if leverage != 1.0 or expense_ratio != 0.0:
                hist = apply_daily_leverage(hist, leverage, expense_ratio)
            return hist
        
        # Special handling for DBMF_COMPLETE - use our custom DBMF ticker
        if resolved_ticker == "DBMF_COMPLETE":
            hist = get_dbmf_complete_data(period)
            # Apply leverage and/or expense ratio if specified
            if leverage != 1.0 or expense_ratio != 0.0:
                hist = apply_daily_leverage(hist, leverage, expense_ratio)
            return hist
        
        # Special handling for TBILL_COMPLETE - use our custom TBILL ticker
        if resolved_ticker == "TBILL_COMPLETE":
            hist = get_tbill_complete_data(period)
            # Apply leverage and/or expense ratio if specified
            if leverage != 1.0 or expense_ratio != 0.0:
                hist = apply_daily_leverage(hist, leverage, expense_ratio)
            return hist
        
        # Special handling for SPYSIM_COMPLETE - use our custom SPYSIM ticker
        if resolved_ticker == "SPYSIM_COMPLETE":
            hist = get_spysim_complete_data(period)
            # Apply leverage and/or expense ratio if specified
            if leverage != 1.0 or expense_ratio != 0.0:
                hist = apply_daily_leverage(hist, leverage, expense_ratio)
            return hist
        
        # Special handling for GOLDSIM_COMPLETE - use our custom GOLDSIM ticker
        if resolved_ticker == "GOLDSIM_COMPLETE":
            hist = get_goldsim_complete_data(period)
            # Apply leverage and/or expense ratio if specified
            if leverage != 1.0 or expense_ratio != 0.0:
                hist = apply_daily_leverage(hist, leverage, expense_ratio)
            return hist
        
        ticker = get_ticker_with_cache(resolved_ticker)
        hist = ticker.history(period=period, auto_adjust=auto_adjust)[["Close", "Dividends"]]
        
        if hist.empty:
            return hist
            
        # Apply leverage and/or expense ratio if specified
        if leverage != 1.0 or expense_ratio != 0.0:
            hist = apply_daily_leverage(hist, leverage, expense_ratio)
            
        return hist
    except Exception:
        return pd.DataFrame()

def get_ticker_info(ticker_symbol):
    """Get ticker info (NO_CACHE version)"""
    try:
        # Parse leverage from ticker symbol
        base_ticker, leverage = parse_leverage_ticker(ticker_symbol)
        
        # Resolve ticker alias if it exists
        resolved_ticker = resolve_ticker_alias(base_ticker)
        
        ticker = get_ticker_with_cache(resolved_ticker)
        info = ticker.info
        
        return info
    except Exception:
        return {}

# Matplotlib configuration for high-quality PDF generation
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib.patches import Rectangle
import matplotlib.patches as mpatches
plt.style.use('default')
plt.rcParams['figure.dpi'] = 300
plt.rcParams['savefig.dpi'] = 300
plt.rcParams['font.size'] = 10
plt.rcParams['axes.titlesize'] = 12
plt.rcParams['axes.labelsize'] = 10
plt.rcParams['xtick.labelsize'] = 9
plt.rcParams['ytick.labelsize'] = 9
plt.rcParams['legend.fontsize'] = 9
plt.rcParams['figure.titlesize'] = 14

# PDF Generation imports
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak, Table, TableStyle, Image
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.lib import colors as reportlab_colors

def plotly_to_matplotlib_figure(plotly_fig, title="", width_inches=8, height_inches=6):
    """
    Convert a Plotly figure to a matplotlib figure for PDF generation
    """
    try:
        # Extract data from Plotly figure
        fig_data = plotly_fig.data
        
        # Create matplotlib figure
        fig, ax = plt.subplots(figsize=(width_inches, height_inches))
        
        # Set title with wrapping for long titles
        if title:
            # Use textwrap for proper word-based wrapping
            import textwrap
            wrapped_title = textwrap.fill(title, width=40, break_long_words=True, break_on_hyphens=False)
            ax.set_title(wrapped_title, fontsize=14, fontweight='bold', pad=20)
        
        # Define a color palette for different traces
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']
        color_index = 0
        
        # Process each trace
        for trace in fig_data:
            if trace.type == 'scatter':
                x_data = trace.x
                y_data = trace.y
                name = trace.name if hasattr(trace, 'name') and trace.name else f'Trace {color_index}'
                
                # Get color from trace or use palette
                if hasattr(trace, 'line') and hasattr(trace.line, 'color') and trace.line.color:
                    color = trace.line.color
                else:
                    color = colors[color_index % len(colors)]
                
                # Plot the line
                ax.plot(x_data, y_data, label=name, linewidth=2, color=color)
                color_index += 1
                
            elif trace.type == 'bar':
                x_data = trace.x
                y_data = trace.y
                name = trace.name if hasattr(trace, 'name') and trace.name else f'Bar {color_index}'
                
                # Get color from trace or use palette
                if hasattr(trace, 'marker') and hasattr(trace.marker, 'color') and trace.marker.color:
                    color = trace.marker.color
                else:
                    color = colors[color_index % len(colors)]
                
                # Plot the bars
                ax.bar(x_data, y_data, label=name, color=color, alpha=0.7)
                color_index += 1
                
            elif trace.type == 'pie':
                # Handle pie charts - SIMPLE PERFECT CIRCLE SOLUTION
                labels = trace.labels if hasattr(trace, 'labels') else []
                values = trace.values if hasattr(trace, 'values') else []
                
                if labels and values:
                    # Create a slightly wider figure to ensure perfect circle
                    fig_pie, ax_pie = plt.subplots(figsize=(8.5, 8))
                    
                    # Format long titles to break into multiple lines using textwrap
                    import textwrap
                    formatted_title = textwrap.fill(title, width=40, break_long_words=True, break_on_hyphens=False)
                    ax_pie.set_title(formatted_title, fontsize=14, fontweight='bold', pad=40, y=0.95)
                    
                    # Create pie chart with smart percentage display - hide small ones to prevent overlap
                    def smart_autopct(pct):
                        return f'{pct:.1f}%' if pct > 3 else ''  # Only show percentages > 3%
                    
                    wedges, texts, autotexts = ax_pie.pie(
                        values, 
                        labels=labels, 
                        autopct=smart_autopct,  # Use smart percentage display
                        startangle=90, 
                        colors=colors[:len(values)]
                    )
                    
                    # Create legend labels with percentages
                    legend_labels = []
                    for i, label in enumerate(labels):
                        percentage = (values[i] / sum(values)) * 100
                        legend_labels.append(f"{label} ({percentage:.1f}%)")
                    
                    # Add legend with SPECIFIC POSITIONING to prevent overlap
                    ax_pie.legend(wedges, legend_labels, title="Categories", 
                                loc="center left", bbox_to_anchor=(1.15, 0.5))
                    
                    # This is the magic - force perfect circle
                    ax_pie.axis('equal')
                    
                    # Add extra spacing to prevent overlap
                    plt.subplots_adjust(right=0.8)
                    
                    return fig_pie
        
        # Format the plot
        ax.grid(True, alpha=0.3)
        # Don't add legend here - it will be added separately below the plot
        # Extract legend information for separate placement
        if ax.get_legend_handles_labels()[0]:
            handles, labels = ax.get_legend_handles_labels()
            colors = [handle.get_color() if hasattr(handle, 'get_color') else 'black' for handle in handles]
            fig.legend_info = [{'label': label, 'color': color} for label, color in zip(labels, colors)]
            # Remove legend from plot since we'll add it separately
            ax.legend().remove()
        
        # Format x-axis for dates if needed
        if fig_data and len(fig_data) > 0 and hasattr(fig_data[0], 'x') and fig_data[0].x is not None:
            try:
                # Try to parse as dates
                dates = pd.to_datetime(fig_data[0].x)
                ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
                ax.xaxis.set_major_locator(mdates.YearLocator(interval=2))  # Show every 2 years
                plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')
            except:
                pass
        
        # Adjust layout
        plt.tight_layout()
        
        return fig
        
    except Exception as e:
        # Return a simple error figure
        fig, ax = plt.subplots(figsize=(width_inches, height_inches))
        ax.text(0.5, 0.5, f'Error converting plot: {str(e)}', 
                ha='center', va='center', transform=ax.transAxes)
        return fig


def create_legend_figure(legend_info, title="Legend", width_inches=10, height_inches=2):
    """
    Create a separate matplotlib figure for the legend to be placed below the main plot
    """
    try:
        if not legend_info:
            return None
        
        # Process labels to handle long portfolio names
        processed_labels = []
        max_label_length = 0
        
        for item in legend_info:
            label = item['label']
            # If label is very long, wrap it intelligently
            if len(label) > 40:
                # Split long labels at spaces or special characters
                words = label.split()
                if len(words) > 3:
                    # For very long names, create multiple lines
                    if len(words) <= 6:
                        # Split in the middle
                        mid = len(words) // 2
                        wrapped_label = '\n'.join([' '.join(words[:mid]), ' '.join(words[mid:])])
                    else:
                        # Split into thirds for extremely long names
                        third = len(words) // 3
                        wrapped_label = '\n'.join([
                            ' '.join(words[:third]),
                            ' '.join(words[third:2*third]),
                            ' '.join(words[2*third:])
                        ])
                else:
                    wrapped_label = label
            else:
                wrapped_label = label
            
            processed_labels.append(wrapped_label)
            # Calculate max height needed for wrapped labels
            lines = wrapped_label.count('\n') + 1
            max_label_length = max(max_label_length, lines)
        
        # Calculate dynamic height based on number of items and label complexity
        num_items = len(legend_info)
        base_height = 2.5  # Increased from 2.0 to 2.5 for larger text
        height_per_item = max(0.8, max_label_length * 0.25)  # Increased from 0.6/0.2 to 0.8/0.25 for larger text
        legend_height = max(base_height, min(6.0, num_items * height_per_item))  # Increased max from 5.0 to 6.0
        
        fig, ax = plt.subplots(figsize=(width_inches, legend_height))
        ax.axis('off')
        
        # Create legend handles
        handles = []
        
        for item in legend_info:
            # Create a line handle for the legend
            line = plt.Line2D([], [], color=item['color'], linewidth=3)
            handles.append(line)
        
        # Determine optimal number of columns based on content
        if num_items <= 3:
            ncol = num_items
        elif num_items <= 6:
            ncol = min(3, num_items)
        else:
            ncol = min(4, num_items)  # Max 4 columns for many items
        
        # Create legend with specific positioning and better text handling
        legend = ax.legend(handles, processed_labels, 
                           loc='center',
                           ncol=ncol,
                           frameon=True,
                           fancybox=True,
                           shadow=True,
                           fontsize=16,  # Increased from 12 to 16 for better readability
                           columnspacing=2.0,
                           labelspacing=1.2)  # Increased from 1.0 to 1.2 for better spacing
        
        # Add title if provided
        if title:
            ax.set_title(title, fontsize=18, fontweight='bold', pad=15)  # Increased from 14 to 18
        
        plt.tight_layout()
        return fig
        
    except Exception as e:
        # Return a simple error figure
        fig, ax = plt.subplots(figsize=(width_inches, 1))
        ax.text(0.5, 0.5, f'Error creating legend: {str(e)}', 
                ha='center', va='center', transform=ax.transAxes)
        return fig


def create_paginated_legends(legend_info, title="Legend", width_inches=10, max_items_per_page=25):
    """
    Create multiple legend figures if the legend is very long, splitting across pages
    """
    if not legend_info:
        return []
    
    legends = []
    total_items = len(legend_info)
    
    # If legend is short enough, create single legend
    if total_items <= max_items_per_page:
        single_legend = create_legend_figure(legend_info, title, width_inches)
        if single_legend:
            legends.append(single_legend)
        return legends
    
    # Split legend into multiple pages
    num_pages = (total_items + max_items_per_page - 1) // max_items_per_page
    
    for page in range(num_pages):
        start_idx = page * max_items_per_page
        end_idx = min((page + 1) * max_items_per_page, total_items)
        
        page_legend_info = legend_info[start_idx:end_idx]
        page_title = f"{title} (Page {page + 1} of {num_pages})"
        
        # Calculate height for this page
        num_items = len(page_legend_info)
        base_height = 2.5  # Increased from 2.0 to 2.5 for larger text
        height_per_item = 0.8  # Increased from 0.6 to 0.8 for larger text
        page_height = max(base_height, min(6.0, num_items * height_per_item))  # Increased max from 5.0 to 6.0
        
        page_legend = create_legend_figure(page_legend_info, page_title, width_inches, page_height)
        if page_legend:
            legends.append(page_legend)
    
    return legends

def create_matplotlib_table(data, headers, title="", width_inches=10, height_inches=4):
    """
    Create a matplotlib table for PDF generation
    """
    try:
        # Ensure data is properly formatted
        if not data or not headers:
            raise ValueError("Data or headers are empty")
        
        # Convert data to strings and ensure proper format
        formatted_data = []
        for row in data:
            formatted_row = []
            for cell in row:
                if cell is None:
                    formatted_row.append('')
                else:
                    formatted_row.append(str(cell))
            formatted_data.append(formatted_row)
        
        fig, ax = plt.subplots(figsize=(width_inches, height_inches))
        ax.axis('tight')
        ax.axis('off')
        
        # Create table
        table = ax.table(cellText=formatted_data, colLabels=headers, 
                        cellLoc='center', loc='center',
                        bbox=[0, 0, 1, 1])
        
        # Style the table
        table.auto_set_font_size(False)
        table.set_fontsize(9)
        table.scale(1, 2)
        
        # Color header row
        for i in range(len(headers)):
            table[(0, i)].set_facecolor('#4CAF50')
            table[(0, i)].set_text_props(weight='bold', color='white')
        
        # Color alternating rows
        for i in range(1, len(formatted_data) + 1):
            for j in range(len(headers)):
                if i % 2 == 0:
                    table[(i, j)].set_facecolor('#f0f0f0')
        
        # Add title with wrapping for long titles
        if title:
            # Use textwrap for proper word-based wrapping
            import textwrap
            wrapped_title = textwrap.fill(title, width=40, break_long_words=True, break_on_hyphens=False)
            ax.set_title(wrapped_title, fontsize=12, fontweight='bold', pad=20)
        
        plt.tight_layout()
        return fig
        
    except Exception as e:
        # Return a simple error figure
        fig, ax = plt.subplots(figsize=(width_inches, height_inches))
        ax.text(0.5, 0.5, f'Error creating table: {str(e)}', 
                ha='center', va='center', transform=ax.transAxes)
        return fig

def generate_simple_pdf_report(custom_name=""):
    """
    Generate a simple PDF report with exactly 4 sections using existing Streamlit data
    """
    try:
        # Show progress bar for PDF generation
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # Create PDF buffer
        buffer = io.BytesIO()
        
        # Add proper PDF metadata
        if custom_name.strip():
            title = f"Multi Backtest Report - {custom_name.strip()}"
            subject = f"Portfolio Analysis Report: {custom_name.strip()}"
        else:
            title = "Multi Backtest Report"
            subject = "Portfolio Analysis and Performance Report"
        
        doc = SimpleDocTemplate(
            buffer, 
            pagesize=letter,
            title=title,
            author="Portfolio Backtest System",
            subject=subject,
            creator="Multi Backtest Application"
        )
        story = []
        
        # Update progress
        progress_bar.progress(10)
        status_text.text("üìÑ Initializing PDF document...")
        
        # Get styles
        styles = getSampleStyleSheet()
        heading_style = ParagraphStyle(
            'CustomHeading',
            parent=styles['Heading1'],
            fontSize=16,
            spaceAfter=20,
            textColor=reportlab_colors.Color(0.2, 0.4, 0.6)
        )
        subheading_style = ParagraphStyle(
            'CustomSubHeading',
            parent=styles['Heading2'],
            fontSize=14,
            spaceAfter=15,
            textColor=reportlab_colors.Color(0.3, 0.5, 0.7)
        )
        
        # Update progress
        progress_bar.progress(20)
        status_text.text("üìä Adding portfolio configurations...")
        
        # Title page (no page break before)
        title_style = ParagraphStyle(
            'TitlePage',
            parent=styles['Title'],
            fontSize=24,
            spaceAfter=30,
            textColor=reportlab_colors.Color(0.2, 0.4, 0.6),
            alignment=1  # Center alignment
        )
        
        subtitle_style = ParagraphStyle(
            'SubtitlePage',
            parent=styles['Normal'],
            fontSize=16,
            spaceAfter=40,
            textColor=reportlab_colors.Color(0.4, 0.6, 0.8),
            alignment=1  # Center alignment
        )
        
        # Main title - use custom name if provided
        if custom_name.strip():
            main_title = f"Multi Backtest Report - {custom_name.strip()}"
            subtitle = f"Investment Portfolio Analysis: {custom_name.strip()}"
        else:
            main_title = "Multi-Portfolio Backtest Report"
            subtitle = "Comprehensive Investment Portfolio Analysis"
        
        story.append(Paragraph(main_title, title_style))
        story.append(Paragraph(subtitle, subtitle_style))
        
        # Document metadata is set in SimpleDocTemplate creation above
        
        # Report metadata
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        story.append(Paragraph(f"Generated on: {current_time}", styles['Normal']))
        story.append(Spacer(1, 10))
        
        # Get backtest period from data if available
        if 'multi_backtest_snapshot_data' in st.session_state:
            snapshot = st.session_state.multi_backtest_snapshot_data
            raw_data = snapshot.get('raw_data', {})
            if raw_data:
                # Get first and last dates from any available data
                all_dates = []
                for ticker_data in raw_data.values():
                    if isinstance(ticker_data, pd.DataFrame) and 'Close' in ticker_data.columns:
                        all_dates.extend(ticker_data.index.tolist())
                
                if all_dates:
                    start_date = min(all_dates)
                    end_date = max(all_dates)
                    total_days = (end_date - start_date).days
                    
                    story.append(Paragraph(f"Backtest Period: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}", styles['Normal']))
                    story.append(Paragraph(f"Total Days Analyzed: {total_days:,}", styles['Normal']))
                    story.append(Spacer(1, 20))
        
        # Table of contents first (correct order)
        toc_style = ParagraphStyle(
            'TOC',
            parent=styles['Heading2'],
            fontSize=14,
            spaceAfter=15,
            textColor=reportlab_colors.Color(0.3, 0.5, 0.7)
        )
        
        story.append(Paragraph("Table of Contents", toc_style))
        toc_points = [
            "Portfolio Configurations & Parameters",
            "Performance Charts & Analysis", 
            "Final Performance Statistics",
            "Portfolio Allocations & Rebalancing Timers"
        ]
        
        for i, point in enumerate(toc_points, 1):
            story.append(Paragraph(f"{i}. {point}", styles['Normal']))
        
        story.append(Spacer(1, 30))
        
        # Report overview (after TOC, correct order)
        overview_style = ParagraphStyle(
            'Overview',
            parent=styles['Heading2'],
            fontSize=14,
            spaceAfter=15,
            textColor=reportlab_colors.Color(0.3, 0.5, 0.7)
        )
        
        story.append(Paragraph("Report Overview", overview_style))
        story.append(Paragraph("This report provides comprehensive analysis of investment portfolios, including:", styles['Normal']))
        
        # Overview bullet points (non-personal, clear descriptions)
        overview_points = [
            "Detailed portfolio configurations with all parameters and strategies",
            "Performance analysis with value comparison and drawdown charts",
            "Comprehensive performance statistics and risk metrics",
            "Current allocations and rebalancing countdown timers"
        ]
        
        for point in overview_points:
            story.append(Paragraph(f"‚Ä¢ {point}", styles['Normal']))
        
        story.append(PageBreak())
        
        # SECTION 1: Portfolio Configurations & Parameters
        story.append(Paragraph("1. Portfolio Configurations & Parameters", heading_style))
        story.append(Spacer(1, 10))
        
        # Get portfolio configs from session state
        portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
        
        for i, config in enumerate(portfolio_configs):
            # Add page break for all portfolios except the first one
            if i > 0:
                story.append(PageBreak())
            
            story.append(Paragraph(f"Portfolio: {config.get('name', 'Unknown')}", subheading_style))
            story.append(Spacer(1, 5))
            
            # Create configuration table with all parameters
            config_data = [
                ['Parameter', 'Value', 'Description'],
                ['Initial Value', f"${config.get('initial_value', 0):,.2f}", 'Starting portfolio value'],
                ['Added Amount', f"${config.get('added_amount', 0):,.2f}", 'Regular contribution amount'],
                ['Added Frequency', config.get('added_frequency', 'N/A'), 'How often contributions are made'],
                ['Rebalancing Frequency', config.get('rebalancing_frequency', 'N/A'), 'How often portfolio is rebalanced'],
                ['Benchmark', config.get('benchmark_ticker', 'N/A'), 'Performance comparison index'],
                ['Use Momentum', 'Yes' if config.get('use_momentum', False) else 'No', 'Whether momentum strategy is enabled'],
                ['Momentum Strategy', config.get('momentum_strategy', 'N/A'), 'Type of momentum calculation'],
                ['Negative Momentum Strategy', config.get('negative_momentum_strategy', 'N/A'), 'How to handle negative momentum'],
                ['Use Relative Momentum', 'Yes' if config.get('use_relative_momentum', False) else 'No', 'Whether to use relative momentum'],
                ['Equal if All Negative', 'Yes' if config.get('equal_if_all_negative', False) else 'No', 'Equal weight when all momentum is negative'],
                ['Calculate Beta', 'Yes' if config.get('calc_beta', False) else 'No', 'Include beta in momentum weighting'],
                ['Calculate Volatility', 'Yes' if config.get('calc_volatility', False) else 'No', 'Include volatility in momentum weighting'],
                ['Start Strategy', config.get('start_with', 'N/A'), 'Initial allocation strategy'],
                                 ['First Rebalance Strategy', 
                  "rebalancing date" if config.get('first_rebalance_strategy', 'rebalancing_date') == 'rebalancing_date' else "momentum window complete", 
                  'Initial rebalancing approach'],
                ['Collect Dividends as Cash', 'Yes' if config.get('collect_dividends_as_cash', False) else 'No', 'Dividend handling method'],
                ['Beta Lookback', f"{config.get('beta_window_days', 0)} days", 'Days for beta calculation'],
                ['Beta Exclude', f"{config.get('exclude_days_beta', 0)} days", 'Days excluded from beta calculation'],
                ['Volatility Lookback', f"{config.get('vol_window_days', 0)} days", 'Days for volatility calculation'],
                ['Volatility Exclude', f"{config.get('exclude_days_vol', 0)} days", 'Days excluded from volatility calculation'],
                ['Minimal Threshold', f"{config.get('minimal_threshold_percent', 4.0):.1f}%" if config.get('use_minimal_threshold', False) else 'Disabled', 'Minimum allocation percentage threshold'],
                ['Maximum Allocation', f"{config.get('max_allocation_percent', 20.0):.1f}%" if config.get('use_max_allocation', False) else 'Disabled', 'Maximum allocation percentage per stock'],
                ['MA Filter', 'Yes' if config.get('use_sma_filter', False) else 'No', 'Filter assets below moving average'],
                ['MA Type', config.get('ma_type', 'SMA'), 'Type of moving average (SMA or EMA)'],
                ['MA Window', f"{config.get('sma_window', 200)} days", 'Moving average calculation window'],
                ['MA Multiplier', f"{config.get('ma_multiplier', 1.48):.4f}", 'Multiplier to convert market days to calendar days'],
                ['MA Cross Rebalancing', 'Yes' if config.get('ma_cross_rebalance', False) else 'No', 'Immediate rebalancing on MA cross'],
                ['MA Tolerance Band', f"{config.get('ma_tolerance_percent', 2.0):.1f}%" if config.get('ma_cross_rebalance', False) else 'N/A', 'Tolerance band for MA cross detection'],
                ['MA Confirmation Days', f"{config.get('ma_confirmation_days', 3)} days" if config.get('ma_cross_rebalance', False) else 'N/A', 'Confirmation delay for MA cross']
            ]
            
            # Add momentum windows if they exist
            momentum_windows = config.get('momentum_windows', [])
            if momentum_windows:
                for i, window in enumerate(momentum_windows, 1):
                    lookback = window.get('lookback', 0)
                    weight = window.get('weight', 0)
                    config_data.append([
                        f'Momentum Window {i}',
                        f"{lookback} days, {weight:.2f}",
                        f"Lookback: {lookback} days, Weight: {weight:.2f}"
                    ])
            
            # Create tables with proper column widths to prevent text overflow
            config_table = Table(config_data, colWidths=[2.2*inch, 1.8*inch, 2.5*inch])
            config_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), reportlab_colors.Color(0.3, 0.5, 0.7)),
                ('TEXTCOLOR', (0, 0), (-1, 0), reportlab_colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, -1), 8),
                ('GRID', (0, 0), (-1, -1), 1, reportlab_colors.black),
                ('BACKGROUND', (0, 1), (-1, -1), reportlab_colors.Color(0.98, 0.98, 0.98)),
                ('VALIGN', (0, 0), (-1, -1), 'TOP'),
                ('WORDWRAP', (0, 0), (-1, -1), True),
                ('LEFTPADDING', (0, 0), (-1, -1), 6),
                ('RIGHTPADDING', (0, 0), (-1, -1), 6),
                ('TOPPADDING', (0, 0), (-1, -1), 3),
                ('BOTTOMPADDING', (0, 0), (-1, -1), 3)
            ]))
            
            story.append(config_table)
            story.append(PageBreak())
            # Show ticker allocations table, but hide Allocation % column if momentum is enabled
            if not config.get('use_momentum', True):
                story.append(Paragraph("Initial Ticker Allocations (Entered by User):", styles['Heading3']))
                story.append(Paragraph("Note: These are the initial allocations entered by the user, not rebalanced allocations.", styles['Normal']))
                
                # Create full table with conditional columns for non-momentum strategies
                if config.get('use_sma_filter', False):
                    stocks_data = [['Ticker', 'Allocation\n%', 'Include\nDividends', 'Include in\nMA Filter', 'MA Reference\nTicker']]
                    for stock in config['stocks']:
                        include_ma = "‚úì" if stock.get('include_in_sma_filter', True) else "‚úó"
                        ma_ref = stock.get('ma_reference_ticker', '')
                        ma_ref_str = ma_ref if ma_ref else stock['ticker']  # Use own ticker if no custom reference
                        stocks_data.append([
                            stock['ticker'],
                            f"{stock['allocation']*100:.1f}%",
                            "‚úì" if stock['include_dividends'] else "‚úó",
                            include_ma,
                            ma_ref_str
                        ])
                else:
                    stocks_data = [['Ticker', 'Allocation\n%', 'Include\nDividends']]
                    for stock in config['stocks']:
                        stocks_data.append([
                            stock['ticker'],
                            f"{stock['allocation']*100:.1f}%",
                            "‚úì" if stock['include_dividends'] else "‚úó"
                        ])
                
                # Adjust column widths based on number of columns
                if config.get('use_sma_filter', False):
                    stocks_table = Table(stocks_data, colWidths=[1.2*inch, 1.0*inch, 1.2*inch, 1.2*inch, 1.2*inch])
                else:
                    stocks_table = Table(stocks_data, colWidths=[2.0*inch, 1.5*inch, 2.0*inch])
                stocks_table.setStyle(TableStyle([
                    ('BACKGROUND', (0, 0), (-1, 0), reportlab_colors.Color(0.3, 0.5, 0.7)),
                    ('TEXTCOLOR', (0, 0), (-1, 0), reportlab_colors.whitesmoke),
                    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                    ('FONTSIZE', (0, 0), (-1, -1), 10),
                    ('GRID', (0, 0), (-1, -1), 1, reportlab_colors.black),
                    ('BACKGROUND', (0, 1), (-1, -1), reportlab_colors.Color(0.98, 0.98, 0.98)),
                    ('WORDWRAP', (0, 0), (-1, -1), True),
                    ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
                    ('TOPPADDING', (0, 0), (-1, 0), 8),
                    ('BOTTOMPADDING', (0, 0), (-1, 0), 8)
                ]))
                
                story.append(stocks_table)
                story.append(Spacer(1, 15))
            else:
                story.append(Paragraph("Initial Ticker Allocations:", styles['Heading3']))
                story.append(Paragraph("Note: Momentum strategy is enabled - ticker allocations are calculated dynamically based on momentum scores.", styles['Normal']))
                
                # Create modified table with conditional columns for momentum strategies
                if config.get('use_sma_filter', False):
                    stocks_data_momentum = [['Ticker', 'Include\nDividends', 'Max Allocation\n%', 'Include in\nMA Filter', 'MA Reference\nTicker']]
                    for stock in config['stocks']:
                        max_alloc = stock.get('max_allocation_percent')
                        max_alloc_str = f"{max_alloc:.1f}%" if max_alloc is not None else "No limit"
                        include_ma = "‚úì" if stock.get('include_in_sma_filter', True) else "‚úó"
                        ma_ref = stock.get('ma_reference_ticker', '')
                        ma_ref_str = ma_ref if ma_ref else stock['ticker']  # Use own ticker if no custom reference
                        stocks_data_momentum.append([
                            stock['ticker'],
                            "‚úì" if stock['include_dividends'] else "‚úó",
                            max_alloc_str,
                            include_ma,
                            ma_ref_str
                        ])
                else:
                    stocks_data_momentum = [['Ticker', 'Include\nDividends', 'Max Allocation\n%']]
                    for stock in config['stocks']:
                        max_alloc = stock.get('max_allocation_percent')
                        max_alloc_str = f"{max_alloc:.1f}%" if max_alloc is not None else "No limit"
                        stocks_data_momentum.append([
                            stock['ticker'],
                            "‚úì" if stock['include_dividends'] else "‚úó",
                            max_alloc_str
                        ])
                
                # Adjust column widths based on number of columns for momentum table
                if config.get('use_sma_filter', False):
                    stocks_table_momentum = Table(stocks_data_momentum, colWidths=[1.2*inch, 1.2*inch, 1.2*inch, 1.2*inch, 1.2*inch])
                else:
                    stocks_table_momentum = Table(stocks_data_momentum, colWidths=[2.0*inch, 2.0*inch, 2.0*inch])
                stocks_table_momentum.setStyle(TableStyle([
                    ('BACKGROUND', (0, 0), (-1, 0), reportlab_colors.Color(0.3, 0.5, 0.7)),
                    ('TEXTCOLOR', (0, 0), (-1, 0), reportlab_colors.whitesmoke),
                    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                    ('FONTSIZE', (0, 0), (-1, -1), 10),
                    ('GRID', (0, 0), (-1, -1), 1, reportlab_colors.black),
                    ('BACKGROUND', (0, 1), (-1, -1), reportlab_colors.Color(0.98, 0.98, 0.98)),
                    ('WORDWRAP', (0, 0), (-1, -1), True),
                    ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
                    ('TOPPADDING', (0, 0), (-1, 0), 8),
                    ('BOTTOMPADDING', (0, 0), (-1, 0), 8)
                ]))
                
                story.append(stocks_table_momentum)
                story.append(Spacer(1, 15))
        
        # Update progress
        progress_bar.progress(40)
        status_text.text("üìà Adding performance charts...")
        
        # SECTION 2: Portfolio Value and Drawdown Comparison Plots
        story.append(PageBreak())
        story.append(Paragraph("2. Portfolio Value and Drawdown Comparison", heading_style))
        story.append(Spacer(1, 20))
        
        # Get the EXISTING Plotly figures from session state - these are the literal plots from your UI
        if 'fig1' in st.session_state:
            # Convert the existing Plotly figure to matplotlib for PDF
            try:
                fig1 = st.session_state.fig1
                # Convert Plotly figure to matplotlib
                mpl_fig = plotly_to_matplotlib_figure(fig1, title="Portfolio Value Comparison", width_inches=10, height_inches=6)
                
                # Save matplotlib figure to buffer
                img_buffer = io.BytesIO()
                mpl_fig.savefig(img_buffer, format='png', dpi=300, bbox_inches='tight')
                img_buffer.seek(0)
                plt.close(mpl_fig)  # Close to free memory
                
                # Add to PDF
                story.append(Image(img_buffer, width=7.5*inch, height=4.5*inch))  # Full page width
                story.append(Spacer(1, 15))
                
                # Add legend below the plot if available
                if hasattr(mpl_fig, 'legend_info') and mpl_fig.legend_info:
                    try:
                        legend_figures = create_paginated_legends(mpl_fig.legend_info, "Portfolio Legend", width_inches=10)
                        for legend_fig in legend_figures:
                            legend_buffer = io.BytesIO()
                            legend_fig.savefig(legend_buffer, format='png', dpi=300, bbox_inches='tight')
                            legend_buffer.seek(0)
                            plt.close(legend_fig)
                            
                            # Add legend to PDF
                            story.append(Image(legend_buffer, width=7.5*inch, height=2*inch))
                            story.append(Spacer(1, 10))
                    except Exception as e:
                        story.append(Paragraph(f"Error creating legend: {str(e)}", styles['Normal']))
            except Exception as e:
                story.append(Paragraph(f"Error converting performance plot: {str(e)}", styles['Normal']))
        
        # Add Max Drawdown plot
        if 'fig2' in st.session_state:
            try:
                fig2 = st.session_state.fig2
                # Convert Plotly figure to matplotlib
                mpl_fig = plotly_to_matplotlib_figure(fig2, title="Portfolio Drawdown Comparison", width_inches=10, height_inches=6)
                
                # Save matplotlib figure to buffer
                img_buffer = io.BytesIO()
                mpl_fig.savefig(img_buffer, format='png', dpi=300, bbox_inches='tight')
                img_buffer.seek(0)
                plt.close(mpl_fig)  # Close to free memory
                
                # Add to PDF
                story.append(Image(img_buffer, width=7.5*inch, height=4.5*inch))  # Full page width
                story.append(Spacer(1, 15))
                
                # Add legend below the plot if available
                if hasattr(mpl_fig, 'legend_info') and mpl_fig.legend_info:
                    try:
                        legend_figures = create_paginated_legends(mpl_fig.legend_info, "Portfolio Legend", width_inches=10)
                        for legend_fig in legend_figures:
                            legend_buffer = io.BytesIO()
                            legend_fig.savefig(legend_buffer, format='png', dpi=300, bbox_inches='tight')
                            legend_buffer.seek(0)
                            plt.close(legend_fig)
                            
                            # Add legend to PDF
                            story.append(Image(legend_buffer, width=7.5*inch, height=2*inch))
                            story.append(Spacer(1, 10))
                    except Exception as e:
                        story.append(Paragraph(f"Error creating legend: {str(e)}", styles['Normal']))
            except Exception as e:
                story.append(Paragraph(f"Error converting drawdown plot: {str(e)}", styles['Normal']))
        
        # Add Risk-Free Rate plot (Annualized)
        if 'fig4' in st.session_state:
            try:
                fig4 = st.session_state.fig4
                # Convert Plotly figure to matplotlib
                mpl_fig = plotly_to_matplotlib_figure(fig4, title="Annualized Risk-Free Rate (13-Week Treasury)", width_inches=10, height_inches=6)
                
                # Save matplotlib figure to buffer
                img_buffer = io.BytesIO()
                mpl_fig.savefig(img_buffer, format='png', dpi=300, bbox_inches='tight')
                img_buffer.seek(0)
                plt.close(mpl_fig)  # Close to free memory
                
                # Add to PDF
                story.append(Image(img_buffer, width=7.5*inch, height=4.5*inch))
                story.append(Spacer(1, 15))
                
                # Add legend below the plot if available
                if hasattr(mpl_fig, 'legend_info') and mpl_fig.legend_info:
                    try:
                        legend_figures = create_paginated_legends(mpl_fig.legend_info, "Risk-Free Rate Legend", width_inches=10)
                        for legend_fig in legend_figures:
                            legend_buffer = io.BytesIO()
                            legend_fig.savefig(legend_buffer, format='png', dpi=300, bbox_inches='tight')
                            legend_buffer.seek(0)
                            plt.close(legend_fig)
                            
                            # Add legend to PDF
                            story.append(Image(legend_buffer, width=7.5*inch, height=2*inch))
                            story.append(Spacer(1, 10))
                    except Exception as e:
                        story.append(Paragraph(f"Error creating legend: {str(e)}", styles['Normal']))
            except Exception as e:
                story.append(Paragraph(f"Error converting risk-free rate plot: {str(e)}", styles['Normal']))
        
        # Update progress
        progress_bar.progress(60)
        status_text.text("üìã Adding performance statistics...")
        
        # SECTION 3: Final Performance Statistics Table
        story.append(PageBreak())
        story.append(Paragraph("3. Final Performance Statistics", heading_style))
        story.append(Spacer(1, 15))
        
        # GUARANTEED statistics table creation - use multiple data sources
        table_created = False
        
        # Method 1: NUKE APPROACH - Extract from fig_stats with proper data handling
        if 'fig_stats' in st.session_state and not table_created:
            try:
                fig_stats = st.session_state.fig_stats
                if hasattr(fig_stats, 'data') and fig_stats.data:
                    for trace in fig_stats.data:
                        if trace.type == 'table':
                            # Get headers
                            if hasattr(trace, 'header') and trace.header and hasattr(trace.header, 'values'):
                                headers = trace.header.values
                            else:
                                headers = ['Portfolio', 'CAGR (%)', 'Max Drawdown (%)', 'Volatility (%)', 'Sharpe Ratio', 'Sortino Ratio']
                            
                            # Get cell data
                            if hasattr(trace, 'cells') and trace.cells and hasattr(trace.cells, 'values'):
                                cell_data = trace.cells.values
                                if cell_data and len(cell_data) > 0:
                                    # Convert to proper table format with header wrapping
                                    num_rows = len(cell_data[0]) if cell_data[0] else 0
                                    table_rows = []
                                    
                                    # Improved header wrapping with better line breaks and dynamic sizing
                                    wrapped_headers = []
                                    common_words = ['Portfolio', 'Volatility', 'Drawdown', 'Sharpe', 'Sortino', 'Ulcer', 'Index', 'Return', 'Value', 'Money', 'Added', 'Contributions']
                                    
                                    for header in headers:
                                        if len(header) > 8:  # More aggressive wrapping for better readability
                                            # Split on spaces and create multi-line header
                                            words = header.split()
                                            if len(words) > 1:
                                                # Smart splitting: try to balance lines
                                                if len(words) == 2:
                                                    wrapped_header = '\n'.join(words)
                                                elif len(words) == 3:
                                                    wrapped_header = '\n'.join([words[0], ' '.join(words[1:])])
                                                elif len(words) == 4:
                                                    wrapped_header = '\n'.join([' '.join(words[:2]), ' '.join(words[2:])])
                                                else:
                                                    # For longer headers, split more aggressively
                                                    mid = len(words) // 2
                                                    wrapped_header = '\n'.join([' '.join(words[:mid]), ' '.join(words[mid:])])
                                            else:
                                                # Single long word - split more aggressively
                                                if header not in common_words and len(header) > 10:
                                                    mid = len(header) // 2
                                                    wrapped_header = header[:mid] + '\n' + header[mid:]
                                                else:
                                                    wrapped_header = header
                                        else:
                                            wrapped_header = header
                                        wrapped_headers.append(wrapped_header)
                                    
                                    for row_idx in range(num_rows):
                                        row = []
                                        for col_idx in range(len(cell_data)):
                                            if col_idx < len(cell_data) and row_idx < len(cell_data[col_idx]):
                                                value = cell_data[col_idx][row_idx]
                                                # Wrap long portfolio names in the first column
                                                if col_idx == 0 and len(str(value)) > 25:
                                                    # Split long portfolio names at spaces with balanced line breaks
                                                    words = str(value).split()
                                                    if len(words) > 5:
                                                        # For very long names, create 2-3 lines maximum
                                                        if len(words) <= 8:
                                                            # 2 lines: split in the middle
                                                            mid = len(words) // 2
                                                            wrapped_value = '\n'.join([' '.join(words[:mid]), ' '.join(words[mid:])])
                                                        else:
                                                            # 3 lines: split into thirds for extremely long names
                                                            third = len(words) // 3
                                                            wrapped_value = '\n'.join([
                                                                ' '.join(words[:third]),
                                                                ' '.join(words[third:2*third]),
                                                                ' '.join(words[2*third:])
                                                            ])
                                                    elif len(words) > 3:
                                                        # Split in the middle for medium names
                                                        mid = len(words) // 2
                                                        wrapped_value = '\n'.join([' '.join(words[:mid]), ' '.join(words[mid:])])
                                                    else:
                                                        wrapped_value = str(value)
                                                else:
                                                    wrapped_value = str(value) if value is not None else ''
                                                row.append(wrapped_value)
                                            else:
                                                row.append('')
                                        table_rows.append(row)
                                    
                                    # Create table with smart column widths for statistics table - WIDER TABLE WITH MONETARY COLUMNS
                                    page_width = 8.2*inch  # Increased from 7.5 to 8.2 inches for maximum width usage
                                    
                                    # Optimized column width distribution for statistics table - WITH WIDER MONETARY COLUMNS
                                    if len(headers) > 8:  # If we have many columns, use optimized widths
                                        # Portfolio column: increased from 1.4 to 2.1 inches for better text wrapping
                                        # Performance metrics get more space for better readability
                                        portfolio_width = 2.1*inch
                                        remaining_width = page_width - portfolio_width
                                        
                                        # Create custom column widths with wider monetary columns
                                        col_widths = [portfolio_width]
                                        for i, header in enumerate(headers[1:], 1):  # Skip portfolio column
                                            header_lower = header.lower()
                                            # Give extra width to monetary value columns
                                            if any(word in header_lower for word in ['value', 'portfolio', 'money', 'total']):
                                                col_widths.append(1.6 * (remaining_width / (len(headers) - 1)))  # 60% wider for monetary columns
                                            else:
                                                col_widths.append(remaining_width / (len(headers) - 1))
                                        
                                        # Ensure total width equals page_width
                                        total_allocated = sum(col_widths)
                                        if total_allocated > page_width:
                                            # Scale down proportionally
                                            scale_factor = page_width / total_allocated
                                            col_widths = [w * scale_factor for w in col_widths]
                                            
                                    elif len(headers) > 6:  # Medium number of columns
                                        # Portfolio column: 2.3 inches for medium tables
                                        portfolio_width = 2.3*inch
                                        remaining_width = page_width - portfolio_width
                                        
                                        # Create custom column widths with wider monetary columns
                                        col_widths = [portfolio_width]
                                        for i, header in enumerate(headers[1:], 1):  # Skip portfolio column
                                            header_lower = header.lower()
                                            # Give extra width to monetary value columns
                                            if any(word in header_lower for word in ['value', 'portfolio', 'money', 'total']):
                                                col_widths.append(1.7 * (remaining_width / (len(headers) - 1)))  # 70% wider for monetary columns
                                            else:
                                                col_widths.append(remaining_width / (len(headers) - 1))
                                        
                                        # Ensure total width equals page_width
                                        total_allocated = sum(col_widths)
                                        if total_allocated > page_width:
                                            # Scale down proportionally
                                            scale_factor = page_width / total_allocated
                                            col_widths = [w * scale_factor for w in col_widths]
                                            
                                    else:
                                        # Few columns: Portfolio gets 2.0 inches, others share remaining space
                                        portfolio_width = 2.0*inch
                                        remaining_width = page_width - portfolio_width
                                        
                                        # Create custom column widths with wider monetary columns
                                        col_widths = [portfolio_width]
                                        for i, header in enumerate(headers[1:], 1):  # Skip portfolio column
                                            header_lower = header.lower()
                                            # Give extra width to monetary value columns
                                            if any(word in header_lower for word in ['value', 'portfolio', 'total']):
                                                col_widths.append(1.7 * (remaining_width / (len(headers) - 1)))  # 70% wider for monetary columns
                                            else:
                                                col_widths.append(remaining_width / (len(headers) - 1))
                                        
                                        # Ensure total width equals page_width
                                        total_allocated = sum(col_widths)
                                        if total_allocated > page_width:
                                            # Scale down proportionally
                                            scale_factor = page_width / total_allocated
                                            col_widths = [w * scale_factor for w in col_widths]
                                    
                                    stats_table = Table([wrapped_headers] + table_rows, colWidths=col_widths)
                                    # Dynamic font sizing based on number of columns and header complexity
                                    num_columns = len(headers)
                                    max_header_length = max(len(header) for header in headers)
                                    
                                    # More sophisticated font sizing - SLIGHTLY LARGER FOR BETTER READABILITY
                                    if num_columns > 14:
                                        font_size = 5  # Slightly increased from 4
                                    elif num_columns > 12:
                                        font_size = 6  # Slightly increased from 5
                                    elif num_columns > 10:
                                        font_size = 7  # Slightly increased from 6
                                    elif num_columns > 8:
                                        font_size = 8  # Slightly increased from 7
                                    else:
                                        font_size = 9  # Slightly increased from 8
                                    
                                    # Adjust for very long headers - moderate reduction
                                    if max_header_length > 20:
                                        font_size = max(4, font_size - 1)  # Reduce font size moderately
                                    
                                    stats_table.setStyle(TableStyle([
                                        ('BACKGROUND', (0, 0), (-1, 0), reportlab_colors.Color(0.3, 0.5, 0.7)),
                                        ('TEXTCOLOR', (0, 0), (-1, 0), reportlab_colors.whitesmoke),
                                        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                                        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                                        ('FONTSIZE', (0, 0), (-1, 0), font_size),  # Font size for headers
                                        ('FONTSIZE', (0, 1), (-1, -1), font_size + 2),  # Slightly larger font for data rows
                                        ('GRID', (0, 0), (-1, -1), 1, reportlab_colors.black),
                                        ('BACKGROUND', (0, 1), (-1, -1), reportlab_colors.Color(0.98, 0.98, 0.98)),
                                        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
                                        ('LEFTPADDING', (0, 0), (-1, -1), 1),  # Reduced padding to maximize table width usage
                                        ('RIGHTPADDING', (0, 0), (-1, -1), 1),  # Reduced padding to maximize table width usage
                                        ('TOPPADDING', (0, 0), (-1, 0), 4),  # Increased padding for header row for better title visibility
                                        ('BOTTOMPADDING', (0, 0), (-1, 0), 4),  # Increased padding for header row for better title visibility
                                        ('TOPPADDING', (0, 1), (-1, -1), 2),  # Padding for data rows
                                        ('BOTTOMPADDING', (0, 1), (-1, -1), 2),
                                        ('WORDWRAP', (0, 0), (-1, -1), True)
                                    ]))
                                story.append(stats_table)
                                story.append(Spacer(1, 15))
                                table_created = True
                                break
            except Exception as e:
                pass
        
        # Method 2: Try to get from snapshot data
        if not table_created and 'multi_backtest_snapshot_data' in st.session_state:
            try:
                snapshot = st.session_state.multi_backtest_snapshot_data
                all_results = snapshot.get('all_results', {})
                
                if all_results:
                    table_data = []
                    headers = ['Portfolio', 'CAGR (%)', 'Max Drawdown (%)', 'Volatility (%)', 'Sharpe Ratio', 'Sortino Ratio']
                    
                    # Wrap long headers to multiple lines - but don't split common words
                    wrapped_headers = []
                    common_words = ['Portfolio', 'Volatility', 'Drawdown', 'Sharpe', 'Sortino', 'Ulcer', 'Index', 'Return', 'Value', 'Money', 'Added', 'Contributions']
                    
                    for header in headers:
                        if len(header) > 12:  # Only wrap very long headers
                            # Split on spaces and create multi-line header
                            words = header.split()
                            if len(words) > 1:
                                # Try to split in the middle, but avoid splitting common words
                                mid = len(words) // 2
                                wrapped_header = '\n'.join([' '.join(words[:mid]), ' '.join(words[mid:])])
                            else:
                                # Single long word - only split if it's not a common word
                                if header not in common_words:
                                    mid = len(header) // 2
                                    wrapped_header = header[:mid] + '\n' + header[mid:]
                                else:
                                    wrapped_header = header
                        else:
                            wrapped_header = header
                        wrapped_headers.append(wrapped_header)
                    
                    for portfolio_name, result in all_results.items():
                        if isinstance(result, dict) and 'metrics' in result:
                            metrics = result['metrics']
                            # Wrap long portfolio names with balanced line breaks
                            if len(portfolio_name) > 25:
                                words = portfolio_name.split()
                                if len(words) > 5:
                                    # For very long names, create 2-3 lines maximum
                                    if len(words) <= 8:
                                        # 2 lines: split in the middle
                                        mid = len(words) // 2
                                        wrapped_name = '\n'.join([' '.join(words[:mid]), ' '.join(words[mid:])])
                                    else:
                                        # 3 lines: split into thirds for extremely long names
                                        third = len(words) // 3
                                        wrapped_name = '\n'.join([
                                            ' '.join(words[:third]),
                                            ' '.join(words[third:2*third]),
                                            ' '.join(words[2*third:])
                                        ])
                                elif len(words) > 3:
                                    # Split in the middle for medium names
                                    mid = len(words) // 2
                                    wrapped_name = '\n'.join([' '.join(words[:mid]), ' '.join(words[mid:])])
                                else:
                                    wrapped_name = portfolio_name
                            else:
                                wrapped_name = portfolio_name
                            
                            row = [
                                wrapped_name,
                                f"{metrics.get('cagr', 0):.2f}",
                                f"{metrics.get('max_drawdown', 0):.2f}",
                                f"{metrics.get('volatility', 0):.2f}",
                                f"{metrics.get('sharpe_ratio', 0):.2f}",
                                f"{metrics.get('sortino_ratio', 0):.2f}"
                            ]
                            table_data.append(row)
                    
                    if table_data:
                        # Create table with smart formatting for statistics - WIDER TABLE WITH MONETARY COLUMNS
                        page_width = 8.2*inch  # Increased from 7.5 to 8.2 inches for maximum width usage
                        
                        # Optimized column width distribution for statistics table - WITH WIDER MONETARY COLUMNS
                        if len(headers) > 8:  # If we have many columns, use optimized widths
                            # Portfolio column: increased from 1.4 to 2.1 inches for better text wrapping
                            # Performance metrics get more space for better readability
                            portfolio_width = 2.1*inch
                            remaining_width = page_width - portfolio_width
                            
                            # Create custom column widths with wider monetary columns
                            col_widths = [portfolio_width]
                            for i, header in enumerate(headers[1:], 1):  # Skip portfolio column
                                header_lower = header.lower()
                                # Give extra width to monetary value columns
                                if any(word in header_lower for word in ['value', 'portfolio', 'money', 'total']):
                                    col_widths.append(1.5 * (remaining_width / (len(headers) - 1)))  # 50% wider for monetary columns
                                else:
                                    col_widths.append(remaining_width / (len(headers) - 1))
                            
                            # Ensure total width equals page_width
                            total_allocated = sum(col_widths)
                            if total_allocated > page_width:
                                # Scale down proportionally
                                scale_factor = page_width / total_allocated
                                col_widths = [w * scale_factor for w in col_widths]
                                
                        elif len(headers) > 6:  # Medium number of columns
                            # Portfolio column: 2.3 inches for medium tables
                            portfolio_width = 2.3*inch
                            remaining_width = page_width - portfolio_width
                            
                            # Create custom column widths with wider monetary columns
                            col_widths = [portfolio_width]
                            for i, header in enumerate(headers[1:], 1):  # Skip portfolio column
                                header_lower = header.lower()
                                # Give extra width to monetary value columns
                                if any(word in header_lower for word in ['value', 'portfolio', 'money', 'total']):
                                    col_widths.append(1.6 * (remaining_width / (len(headers) - 1)))  # 60% wider for monetary columns
                                else:
                                    col_widths.append(remaining_width / (len(headers) - 1))
                            
                            # Ensure total width equals page_width
                            total_allocated = sum(col_widths)
                            if total_allocated > page_width:
                                # Scale down proportionally
                                scale_factor = page_width / total_allocated
                                col_widths = [w * scale_factor for w in col_widths]
                                
                        else:
                            # Few columns: Portfolio gets 2.0 inches, others share remaining space
                            portfolio_width = 2.0*inch
                            remaining_width = page_width - portfolio_width
                            
                            # Create custom column widths with wider monetary columns
                            col_widths = [portfolio_width]
                            for i, header in enumerate(headers[1:], 1):  # Skip portfolio column
                                header_lower = header.lower()
                                # Give extra width to monetary value columns
                                if any(word in header_lower for word in ['value', 'portfolio', 'total']):
                                    col_widths.append(1.7 * (remaining_width / (len(headers) - 1)))  # 70% wider for monetary columns
                                else:
                                    col_widths.append(remaining_width / (len(headers) - 1))
                            
                            # Ensure total width equals page_width
                            total_allocated = sum(col_widths)
                            if total_allocated > page_width:
                                # Scale down proportionally
                                scale_factor = page_width / total_allocated
                                col_widths = [w * scale_factor for w in col_widths]
                        
                        stats_table = Table([wrapped_headers] + table_data, colWidths=col_widths)
                        
                        # Smart font size based on number of columns - SLIGHTLY LARGER FOR BETTER READABILITY
                        font_size = 4 if len(headers) > 14 else 5 if len(headers) > 12 else 6 if len(headers) > 10 else 7 if len(headers) > 8 else 8
                        
                        stats_table.setStyle(TableStyle([
                            ('BACKGROUND', (0, 0), (-1, 0), reportlab_colors.Color(0.3, 0.5, 0.7)),
                            ('TEXTCOLOR', (0, 0), (-1, 0), reportlab_colors.whitesmoke),
                                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                                ('FONTSIZE', (0, 0), (-1, 0), font_size),  # Font size for headers
                                ('FONTSIZE', (0, 1), (-1, -1), font_size + 2),  # Slightly larger font for data rows
                            ('GRID', (0, 0), (-1, -1), 1, reportlab_colors.black),
                            ('BACKGROUND', (0, 1), (-1, -1), reportlab_colors.Color(0.98, 0.98, 0.98)),
                            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
                            ('LEFTPADDING', (0, 0), (-1, -1), 0),  # Zero padding for maximum space
                            ('RIGHTPADDING', (0, 0), (-1, -1), 0),
                            ('TOPPADDING', (0, 0), (-1, 0), 1),  # Minimal padding for header row
                            ('BOTTOMPADDING', (0, 0), (-1, 0), 1),
                            ('TOPPADDING', (0, 1), (-1, -1), 0.5),  # Minimal padding for data rows
                            ('BOTTOMPADDING', (0, 1), (-1, -1), 0.5),
                            ('WORDWRAP', (0, 0), (-1, -1), True)
                        ]))
                        story.append(stats_table)
                        story.append(Spacer(1, 15))
                        table_created = True
            except Exception as e:
                pass
        
        # Method 3: Fallback - create simple table from any available data
        if not table_created:
            try:
                # Try to get any available portfolio data
                available_data = []
                if 'multi_backtest_snapshot_data' in st.session_state:
                    snapshot = st.session_state.multi_backtest_snapshot_data
                    portfolio_configs = snapshot.get('portfolio_configs', [])
                    if portfolio_configs:
                        headers = ['Portfolio', 'Status']
                        for config in portfolio_configs:
                            name = config.get('name', 'Unknown')
                            # Wrap long portfolio names with balanced line breaks for consistency
                            if len(name) > 25:
                                words = name.split()
                                if len(words) > 5:
                                    # For very long names, create 2-3 lines maximum
                                    if len(words) <= 8:
                                        # 2 lines: split in the middle
                                        mid = len(words) // 2
                                        wrapped_name = '\n'.join([' '.join(words[:mid]), ' '.join(words[mid:])])
                                    else:
                                        # 3 lines: split into thirds for extremely long names
                                        third = len(words) // 3
                                        wrapped_name = '\n'.join([
                                            ' '.join(words[:third]),
                                            ' '.join(words[third:2*third]),
                                            ' '.join(words[2*third:])
                                        ])
                                elif len(words) > 3:
                                    # Split in the middle for medium names
                                    mid = len(words) // 2
                                    wrapped_name = '\n'.join([' '.join(words[:mid]), ' '.join(words[mid:])])
                                else:
                                    wrapped_name = name
                            else:
                                wrapped_name = name
                            available_data.append([wrapped_name, 'Data Available'])
                
                if available_data:
                    fallback_table = Table([headers] + available_data, colWidths=[2.2*inch, 2.8*inch])
                    fallback_table.setStyle(TableStyle([
                        ('BACKGROUND', (0, 0), (-1, 0), reportlab_colors.Color(0.3, 0.5, 0.7)),
                        ('TEXTCOLOR', (0, 0), (-1, 0), reportlab_colors.whitesmoke),
                        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                        ('FONTSIZE', (0, 0), (-1, -1), 9),
                        ('GRID', (0, 0), (-1, -1), 1, reportlab_colors.black)
                    ]))
                    story.append(fallback_table)
                    story.append(Spacer(1, 15))
                    table_created = True
            except Exception as e:
                pass
        
        if not table_created:
            story.append(Paragraph("Statistics data not available. Please run the backtest first.", styles['Normal']))
            story.append(Spacer(1, 15))
        
        # SECTION 3.1: Top 5 Best and Worst Performing Portfolios
        # Extract data from the Final Performance Statistics table that was just created
        if table_created and 'fig_stats' in st.session_state:
            try:
                all_results = st.session_state.multi_all_results
                
                fig_stats = st.session_state.fig_stats
                if hasattr(fig_stats, 'data') and fig_stats.data:
                    for trace in fig_stats.data:
                        if trace.type == 'table':
                            # Get headers and data from the existing table
                            if hasattr(trace, 'header') and trace.header and hasattr(trace.header, 'values'):
                                headers = trace.header.values
                            else:
                                headers = ['Portfolio', 'CAGR (%)', 'Max Drawdown (%)', 'Volatility (%)', 'Sharpe Ratio', 'Sortino Ratio']
                            
                            if hasattr(trace, 'cells') and trace.cells and hasattr(trace.cells, 'values'):
                                cell_data = trace.cells.values
                                if cell_data and len(cell_data) > 0 and len(cell_data[0]) > 0:
                                    # Convert to list of rows for easier processing
                                    num_rows = len(cell_data[0])
                                    table_rows = []
                                    for row_idx in range(num_rows):
                                        row = []
                                        for col_idx in range(len(cell_data)):
                                            if col_idx < len(cell_data) and row_idx < len(cell_data[col_idx]):
                                                value = cell_data[col_idx][row_idx]
                                                row.append(str(value) if value is not None else '')
                                            else:
                                                row.append('')
                                        table_rows.append(row)
                                    
                                    if len(table_rows) > 0:
                                        # Sort by Final Portfolio Value (column 1) to get best and worst performers
                                        # Convert Final Portfolio Value to float for sorting (remove $ and commas)
                                        def get_final_value(row):
                                            try:
                                                value_str = str(row[1]).replace('$', '').replace(',', '')
                                                return float(value_str)
                                            except:
                                                return 0.0
                                        
                                        # Sort by Final Portfolio Value descending (best first)
                                        sorted_rows = sorted(table_rows, key=get_final_value, reverse=True)
                                        
                                        # Get top 10 best and worst
                                        num_portfolios = len(sorted_rows)
                                        top_10_best = sorted_rows[:min(10, num_portfolios)]
                                        
                                        # For worst performers, get the actual worst (lowest final values)
                                        # Sort by final value ascending to get worst first, then take top 10
                                        worst_sorted = sorted(table_rows, key=get_final_value, reverse=False)
                                        top_10_worst = worst_sorted[:min(10, num_portfolios)]
                    
                    # Add page break before the new tables
                    story.append(PageBreak())
                    
                    # Top 10 Best Performing Portfolios
                    story.append(Paragraph("3.1. Top 10 Best Performing Portfolios by Final Value", heading_style))
                    story.append(Spacer(1, 10))
                    
                    if len(top_10_best) > 0:
                        # Create table data with headers - EXACT SAME TEXT WRAPPING AS FINAL PERFORMANCE STATISTICS
                        # Wrap headers for better display
                        wrapped_headers = []
                        common_words = ['Portfolio', 'Volatility', 'Drawdown', 'Sharpe', 'Sortino', 'Ulcer', 'Index', 'Return', 'Value', 'Money', 'Added', 'Contributions']
                        
                        for header in headers:
                            if len(header) > 8:  # More aggressive wrapping for better readability
                                # Split on spaces and create multi-line header
                                words = header.split()
                                if len(words) > 1:
                                    # Smart splitting: try to balance lines
                                    if len(words) == 2:
                                        wrapped_header = '\n'.join(words)
                                    elif len(words) == 3:
                                        wrapped_header = '\n'.join([words[0], ' '.join(words[1:])])
                                    elif len(words) == 4:
                                        wrapped_header = '\n'.join([' '.join(words[:2]), ' '.join(words[2:])])
                                    else:
                                        # For longer headers, split more aggressively
                                        mid = len(words) // 2
                                        wrapped_header = '\n'.join([' '.join(words[:mid]), ' '.join(words[mid:])])
                                else:
                                    # Single long word - split more aggressively
                                    if header not in common_words and len(header) > 10:
                                        mid = len(header) // 2
                                        wrapped_header = header[:mid] + '\n' + header[mid:]
                                    else:
                                        wrapped_header = header
                            else:
                                wrapped_header = header
                            wrapped_headers.append(wrapped_header)
                        
                        # Wrap portfolio names in the first column for best performers
                        wrapped_best_rows = []
                        for row in top_10_best:
                            wrapped_row = row.copy()
                            if len(str(row[0])) > 25:  # Wrap long portfolio names
                                words = str(row[0]).split()
                                if len(words) > 5:
                                    if len(words) <= 8:
                                        mid = len(words) // 2
                                        wrapped_row[0] = '\n'.join([' '.join(words[:mid]), ' '.join(words[mid:])])
                                    else:
                                        third = len(words) // 3
                                        wrapped_row[0] = '\n'.join([
                                            ' '.join(words[:third]),
                                            ' '.join(words[third:2*third]),
                                            ' '.join(words[2*third:])
                                        ])
                                elif len(words) > 3:
                                    mid = len(words) // 2
                                    wrapped_row[0] = '\n'.join([' '.join(words[:mid]), ' '.join(words[mid:])])
                            wrapped_best_rows.append(wrapped_row)
                        
                        # Create table data with wrapped headers and rows
                        best_table_data = [wrapped_headers] + wrapped_best_rows
                        
                        # EXACT SAME COLUMN WIDTH LOGIC AS FINAL PERFORMANCE STATISTICS TABLE
                        page_width = 8.2*inch  # Same as Final Performance Statistics
                        
                        # Optimized column width distribution - EXACT SAME LOGIC
                        if len(headers) > 8:  # If we have many columns, use optimized widths
                            portfolio_width = 2.1*inch
                            remaining_width = page_width - portfolio_width
                            
                            col_widths = [portfolio_width]
                            for i, header in enumerate(headers[1:], 1):  # Skip portfolio column
                                header_lower = header.lower()
                                if any(word in header_lower for word in ['value', 'portfolio', 'money', 'total']):
                                    col_widths.append(1.6 * (remaining_width / (len(headers) - 1)))
                                else:
                                    col_widths.append(remaining_width / (len(headers) - 1))
                            
                            total_allocated = sum(col_widths)
                            if total_allocated > page_width:
                                scale_factor = page_width / total_allocated
                                col_widths = [w * scale_factor for w in col_widths]
                                
                        elif len(headers) > 6:  # Medium number of columns
                            portfolio_width = 2.3*inch
                            remaining_width = page_width - portfolio_width
                            
                            col_widths = [portfolio_width]
                            for i, header in enumerate(headers[1:], 1):
                                header_lower = header.lower()
                                if any(word in header_lower for word in ['value', 'portfolio', 'money', 'total']):
                                    col_widths.append(1.7 * (remaining_width / (len(headers) - 1)))
                                else:
                                    col_widths.append(remaining_width / (len(headers) - 1))
                            
                            total_allocated = sum(col_widths)
                            if total_allocated > page_width:
                                scale_factor = page_width / total_allocated
                                col_widths = [w * scale_factor for w in col_widths]
                                
                        else:  # Few columns
                            portfolio_width = 2.0*inch
                            remaining_width = page_width - portfolio_width
                            
                            col_widths = [portfolio_width]
                            for i, header in enumerate(headers[1:], 1):
                                header_lower = header.lower()
                                if any(word in header_lower for word in ['value', 'portfolio', 'money', 'total']):
                                    col_widths.append(1.7 * (remaining_width / (len(headers) - 1)))
                                else:
                                    col_widths.append(remaining_width / (len(headers) - 1))
                            
                            total_allocated = sum(col_widths)
                            if total_allocated > page_width:
                                scale_factor = page_width / total_allocated
                                col_widths = [w * scale_factor for w in col_widths]
                        
                        # EXACT SAME TABLE CREATION AND STYLING AS FINAL PERFORMANCE STATISTICS
                        best_table = Table(best_table_data, colWidths=col_widths)
                        
                        # Dynamic font sizing - EXACT SAME LOGIC
                        num_columns = len(headers)
                        max_header_length = max(len(header) for header in headers)
                        
                        if num_columns > 14:
                            font_size = 5
                        elif num_columns > 12:
                            font_size = 6
                        elif num_columns > 10:
                            font_size = 7
                        elif num_columns > 8:
                            font_size = 8
                        else:
                            font_size = 9
                        
                        if max_header_length > 20:
                            font_size = max(4, font_size - 1)
                        
                        best_table.setStyle(TableStyle([
                            ('BACKGROUND', (0, 0), (-1, 0), reportlab_colors.Color(0.3, 0.5, 0.7)),
                            ('TEXTCOLOR', (0, 0), (-1, 0), reportlab_colors.whitesmoke),
                            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                            ('FONTSIZE', (0, 0), (-1, 0), font_size),
                            ('FONTSIZE', (0, 1), (-1, -1), font_size + 2),
                            ('GRID', (0, 0), (-1, -1), 1, reportlab_colors.black),
                            ('BACKGROUND', (0, 1), (-1, -1), reportlab_colors.Color(0.98, 0.98, 0.98)),
                            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
                            ('LEFTPADDING', (0, 0), (-1, -1), 1),
                            ('RIGHTPADDING', (0, 0), (-1, -1), 1),
                            ('TOPPADDING', (0, 0), (-1, 0), 4),
                            ('BOTTOMPADDING', (0, 0), (-1, 0), 4),
                            ('TOPPADDING', (0, 1), (-1, -1), 2),
                            ('BOTTOMPADDING', (0, 1), (-1, -1), 2),
                            ('WORDWRAP', (0, 0), (-1, -1), True)
                        ]))
                        story.append(best_table)
                        story.append(Spacer(1, 15))
                    
                    # Top 10 Worst Performing Portfolios
                    story.append(PageBreak())
                    story.append(Paragraph("3.2. Top 10 Worst Performing Portfolios by Final Value", heading_style))
                    story.append(Spacer(1, 10))
                    
                    if len(top_10_worst) > 0:
                        # Create table data with headers - EXACT SAME TEXT WRAPPING AS FINAL PERFORMANCE STATISTICS
                        # Wrap portfolio names in the first column for worst performers
                        wrapped_worst_rows = []
                        for row in top_10_worst:
                            wrapped_row = row.copy()
                            if len(str(row[0])) > 25:  # Wrap long portfolio names
                                words = str(row[0]).split()
                                if len(words) > 5:
                                    if len(words) <= 8:
                                        mid = len(words) // 2
                                        wrapped_row[0] = '\n'.join([' '.join(words[:mid]), ' '.join(words[mid:])])
                                    else:
                                        third = len(words) // 3
                                        wrapped_row[0] = '\n'.join([
                                            ' '.join(words[:third]),
                                            ' '.join(words[third:2*third]),
                                            ' '.join(words[2*third:])
                                        ])
                                elif len(words) > 3:
                                    mid = len(words) // 2
                                    wrapped_row[0] = '\n'.join([' '.join(words[:mid]), ' '.join(words[mid:])])
                            wrapped_worst_rows.append(wrapped_row)
                        
                        worst_table_data = [wrapped_headers] + wrapped_worst_rows
                        
                        # EXACT SAME TABLE CREATION AND STYLING AS FINAL PERFORMANCE STATISTICS
                        worst_table = Table(worst_table_data, colWidths=col_widths)
                        worst_table.setStyle(TableStyle([
                            ('BACKGROUND', (0, 0), (-1, 0), reportlab_colors.Color(0.7, 0.3, 0.3)),  # Red header for worst
                            ('TEXTCOLOR', (0, 0), (-1, 0), reportlab_colors.whitesmoke),
                            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                            ('FONTSIZE', (0, 0), (-1, 0), font_size),
                            ('FONTSIZE', (0, 1), (-1, -1), font_size + 2),
                            ('GRID', (0, 0), (-1, -1), 1, reportlab_colors.black),
                            ('BACKGROUND', (0, 1), (-1, -1), reportlab_colors.Color(0.98, 0.98, 0.98)),
                            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
                            ('LEFTPADDING', (0, 0), (-1, -1), 1),
                            ('RIGHTPADDING', (0, 0), (-1, -1), 1),
                            ('TOPPADDING', (0, 0), (-1, 0), 4),
                            ('BOTTOMPADDING', (0, 0), (-1, 0), 4),
                            ('TOPPADDING', (0, 1), (-1, -1), 2),
                            ('BOTTOMPADDING', (0, 1), (-1, -1), 2),
                            ('WORDWRAP', (0, 0), (-1, -1), True)
                        ]))
                        story.append(worst_table)
                        story.append(Spacer(1, 15))
                    
            except Exception as e:
                story.append(Paragraph(f"Error creating top performers tables: {str(e)}", styles['Normal']))
                story.append(Spacer(1, 15))
        
        # Update progress
        progress_bar.progress(80)
        status_text.text("üéØ Adding allocation charts and timers...")
        
        # SECTION 4: Target Allocation if Rebalanced Today
        story.append(PageBreak())
        current_date_str = datetime.now().strftime("%B %d, %Y")
        story.append(Paragraph(f"4. Target Allocation if Rebalanced Today ({current_date_str})", heading_style))
        story.append(Spacer(1, 10))
        
        # Get the allocation data from your existing UI - fetch the existing allocation data
        if 'multi_backtest_snapshot_data' in st.session_state:
            snapshot = st.session_state.multi_backtest_snapshot_data
            today_weights_map = snapshot.get('today_weights_map', {})
            
            # Process ALL portfolios, not just the active one
            portfolio_count = 0
            for portfolio_name, today_weights in today_weights_map.items():
                if today_weights:
                    # Add page break for all portfolios except the first one
                    if portfolio_count > 0:
                        story.append(PageBreak())
                    
                    portfolio_count += 1
                    
                    # Add portfolio header
                    story.append(Paragraph(f"Portfolio: {portfolio_name}", subheading_style))
                    story.append(Spacer(1, 10))
                    
                    # Create pie chart for this portfolio (since we need ALL portfolios, not just the selected one)
                    try:
                        # Create labels and values for the plot
                        labels_today = [k for k, v in sorted(today_weights.items(), key=lambda x: (-x[1], x[0])) if v > 0]
                        vals_today = [float(today_weights[k]) * 100 for k in labels_today]
                        
                        # Handle case where momentum goes to cash (all assets have negative momentum)
                        # If no labels or all values are very small, show 100% CASH
                        if not labels_today or sum(vals_today) < 0.1:
                            labels_today = ['CASH']
                            vals_today = [100.0]
                        
                        if labels_today and vals_today:
                            # Create matplotlib pie chart (same format as pages 1, 2, 3)
                            fig, ax_target = plt.subplots(1, 1, figsize=(10, 10))
                            
                            # Create pie chart with smart percentage display - hide small ones to prevent overlap
                            def smart_autopct(pct):
                                return f'{pct:.1f}%' if pct > 3 else ''  # Only show percentages > 3%
                            
                            wedges_target, texts_target, autotexts_target = ax_target.pie(vals_today, autopct=smart_autopct, 
                                                                                         startangle=90)
                            
                            # Add ticker names with percentages outside the pie chart slices for allocations > 1.8%
                            for i, (wedge, ticker, alloc) in enumerate(zip(wedges_target, labels_today, vals_today)):
                                # Only show tickers above 1.8%
                                if alloc > 1.8:
                                    # Calculate position for the text (middle of the slice)
                                    angle = (wedge.theta1 + wedge.theta2) / 2
                                    # Convert angle to radians and calculate position
                                    rad = np.radians(angle)
                                    # Position text outside the pie chart at 1.4 radius (farther away)
                                    x = 1.4 * np.cos(rad)
                                    y = 1.4 * np.sin(rad)
                                    
                                    # Add ticker name with percentage under it (e.g., "ORLY 5%")
                                    ax_target.text(x, y, f"{ticker}\n{alloc:.1f}%", ha='center', va='center', 
                                                 fontsize=8, fontweight='bold', 
                                                 bbox=dict(boxstyle="round,pad=0.2", facecolor='white', alpha=0.8))
                                    
                                    # Add leader line from slice edge to label
                                    # Start from edge of pie chart (radius 1.0)
                                    line_start_x = 1.0 * np.cos(rad)
                                    line_start_y = 1.0 * np.sin(rad)
                                    # End at label position
                                    line_end_x = 1.25 * np.cos(rad)
                                    line_end_y = 1.25 * np.sin(rad)
                                    
                                    ax_target.plot([line_start_x, line_end_x], [line_start_y, line_end_y], 
                                                 'k-', linewidth=0.5, alpha=0.6)
                            
                            # Create legend with percentages - positioned farther to the right to avoid overlap
                            legend_labels = [f"{ticker} ({alloc:.1f}%)" for ticker, alloc in zip(labels_today, vals_today)]
                            ax_target.legend(wedges_target, legend_labels, title="Tickers", loc="center left", bbox_to_anchor=(1.15, 0, 0.5, 1), fontsize=10)
                            
                            # Wrap long titles to prevent them from going out of bounds
                            title_text = f'Target Allocation - {portfolio_name}'
                            # Use textwrap for proper word-based wrapping
                            import textwrap
                            wrapped_title = textwrap.fill(title_text, width=40, break_long_words=True, break_on_hyphens=False)
                            ax_target.set_title(wrapped_title, fontsize=14, fontweight='bold', pad=80)
                            # Force perfectly circular shape
                            ax_target.set_aspect('equal')
                            # Use tighter axis limits to make pie chart appear larger within its space
                            ax_target.set_xlim(-1.2, 1.2)
                            ax_target.set_ylim(-1.2, 1.2)
                            
                            # Adjust layout to accommodate legend and title (better spacing to prevent title cutoff)
                            # Use more aggressive spacing like sector/industry charts for bigger pie chart
                            plt.subplots_adjust(left=0.1, right=0.7, top=0.95, bottom=0.05)
                            
                            # Save to buffer
                            target_img_buffer = io.BytesIO()
                            fig.savefig(target_img_buffer, format='png', dpi=300, facecolor='white')
                            target_img_buffer.seek(0)
                            plt.close(fig)
                            
                            # Add to PDF - increased pie chart size for better visibility
                            story.append(Image(target_img_buffer, width=5.5*inch, height=5.5*inch))
                            
                            # Add minimal spacing after pie chart before timer section
                            story.append(Spacer(1, 5))
                            
                            # Add Next Rebalance Timer information - calculate fresh for PDF
                            story.append(Paragraph(f"Next Rebalance Timer - {portfolio_name}", subheading_style))
                            story.append(Spacer(1, 5))
                            
                            # Calculate timer information fresh for PDF using the actual last rebalance date
                            try:
                                # Get portfolio configuration
                                portfolio_cfg = None
                                for cfg in st.session_state.multi_backtest_portfolio_configs:
                                    if cfg.get('name') == portfolio_name:
                                        portfolio_cfg = cfg
                                        break
                                
                                if portfolio_cfg:
                                    rebalancing_frequency = portfolio_cfg.get('rebalancing_frequency', 'Monthly')
                                    initial_value = portfolio_cfg.get('initial_value', 10000)
                                    # Compute current/final portfolio value for display (instead of initial)
                                    display_portfolio_value = initial_value
                                    try:
                                        if 'multi_all_results' in st.session_state and portfolio_name in st.session_state.multi_all_results:
                                            portfolio_results = st.session_state.multi_all_results[portfolio_name]
                                            if isinstance(portfolio_results, dict):
                                                if 'with_additions' in portfolio_results and len(portfolio_results['with_additions']):
                                                    val = portfolio_results['with_additions'].iloc[-1]
                                                    if not pd.isna(val) and float(val) > 0:
                                                        display_portfolio_value = float(val)
                                                elif 'no_additions' in portfolio_results and len(portfolio_results['no_additions']):
                                                    val = portfolio_results['no_additions'].iloc[-1]
                                                    if not pd.isna(val) and float(val) > 0:
                                                        display_portfolio_value = float(val)
                                            elif isinstance(portfolio_results, pd.Series) and len(portfolio_results):
                                                val = portfolio_results.iloc[-1]
                                                if not pd.isna(val) and float(val) > 0:
                                                    display_portfolio_value = float(val)
                                    except Exception:
                                        pass
                                    
                                    # Get last rebalance date from allocation data
                                    all_allocations = st.session_state.get('multi_all_allocations', {})
                                    portfolio_allocations = all_allocations.get(portfolio_name, {})
                                    
                                    if portfolio_allocations:
                                        alloc_dates = sorted(list(portfolio_allocations.keys()))
                                        
                                        # Find the actual last rebalance date by looking at the backtest results
                                        # The last rebalance date should be from the actual rebalancing dates, not just any date
                                        last_rebal_date = None
                                        if 'multi_all_results' in st.session_state and portfolio_name in st.session_state.multi_all_results:
                                            portfolio_results = st.session_state.multi_all_results[portfolio_name]
                                            if isinstance(portfolio_results, dict) and 'with_additions' in portfolio_results:
                                                # Get the simulation index (actual trading days)
                                                sim_index = portfolio_results['with_additions'].index
                                                # Get the rebalancing frequency to calculate actual rebalance dates
                                                rebalancing_frequency = portfolio_cfg.get('rebalancing_frequency', 'none')
                                                # Get actual rebalancing dates
                                                actual_rebal_dates = get_dates_by_freq(rebalancing_frequency, sim_index[0], sim_index[-1], sim_index)
                                                if actual_rebal_dates:
                                                    # Find the most recent actual rebalance date that's in our allocation data
                                                    actual_rebal_dates_sorted = sorted(list(actual_rebal_dates))
                                                    for rebal_date in reversed(actual_rebal_dates_sorted):
                                                        if rebal_date in portfolio_allocations:
                                                            last_rebal_date = rebal_date
                                                            break
                                        
                                        # Fallback to second-to-last date if we couldn't find an actual rebalance date
                                        if last_rebal_date is None:
                                            last_rebal_date = alloc_dates[-2] if len(alloc_dates) > 1 else alloc_dates[-1] if alloc_dates else None
                                        
                                        if last_rebal_date:
                                            # Map frequency to function expectations
                                            frequency_mapping = {
                                                'monthly': 'month',
                                                'weekly': 'week',
                                                'bi-weekly': '2weeks',
                                                'biweekly': '2weeks',
                                                'quarterly': '3months',
                                                'semi-annually': '6months',
                                                'semiannually': '6months',
                                                'annually': 'year',
                                                'yearly': 'year',
                                                'never': 'none',
                                                'none': 'none'
                                            }
                                            mapped_frequency = frequency_mapping.get(rebalancing_frequency.lower(), rebalancing_frequency.lower())
                                            
                                            # Calculate next rebalance date
                                            next_date, time_until, next_rebalance_datetime = calculate_next_rebalance_date(
                                                mapped_frequency, last_rebal_date
                                            )
                                            
                                            if next_date and time_until:
                                                story.append(Paragraph(f"Time Until Next Rebalance: {format_time_until(time_until)}", styles['Normal']))
                                                story.append(Paragraph(f"Target Rebalance Date: {next_date.strftime('%B %d, %Y')}", styles['Normal']))
                                                story.append(Paragraph(f"Rebalancing Frequency: {rebalancing_frequency}", styles['Normal']))
                                                story.append(Paragraph(f"Portfolio Value: ${display_portfolio_value:,.2f}", styles['Normal']))
                                            else:
                                                story.append(Paragraph("Next rebalance date calculation not available", styles['Normal']))
                                        else:
                                            story.append(Paragraph("No rebalancing history available", styles['Normal']))
                                    else:
                                        story.append(Paragraph("No allocation data available for timer calculation", styles['Normal']))
                                else:
                                    story.append(Paragraph("Portfolio configuration not found", styles['Normal']))
                            except Exception as e:
                                story.append(Paragraph(f"Error calculating timer: {str(e)}", styles['Normal']))
                            
                            # Add page break so Allocation Details starts on a new page
                            story.append(PageBreak())
                            
                            # Now add the allocation table on a new page
                            story.append(Paragraph(f"Allocation Details for {portfolio_name}", subheading_style))
                            story.append(Spacer(1, 3))
                            
                            # NUKE APPROACH: Rebuild allocation table from scratch with correct final portfolio values
                            alloc_table_key = f"alloc_table_{portfolio_name}"
                            table_created = False
                            
                            # First, try to get the FINAL portfolio value from backtest results for PDF generation
                            pdf_portfolio_value = 10000  # Default fallback
                            if 'multi_all_results' in st.session_state and st.session_state.multi_all_results:
                                portfolio_results = st.session_state.multi_all_results.get(portfolio_name)
                                if portfolio_results:
                                    try:
                                        if isinstance(portfolio_results, dict) and 'with_additions' in portfolio_results:
                                            final_value = portfolio_results['with_additions'].iloc[-1]
                                            if not pd.isna(final_value) and final_value > 0:
                                                pdf_portfolio_value = float(final_value)
                                        elif isinstance(portfolio_results, dict) and 'no_additions' in portfolio_results:
                                            final_value = portfolio_results['no_additions'].iloc[-1]
                                            if not pd.isna(final_value) and final_value > 0:
                                                pdf_portfolio_value = float(final_value)
                                        elif isinstance(portfolio_results, pd.Series):
                                            latest_value = portfolio_results.iloc[-1]
                                            if not pd.isna(latest_value) and latest_value > 0:
                                                pdf_portfolio_value = float(latest_value)
                                    except (IndexError, ValueError, TypeError):
                                        pass  # Keep default value
                            
                            if alloc_table_key in st.session_state:
                                try:
                                    fig_alloc = st.session_state[alloc_table_key]
                                    
                                    # Method 1: Extract from Plotly figure data structure but recalculate with correct final portfolio value
                                    if hasattr(fig_alloc, 'data') and fig_alloc.data:
                                        for trace in fig_alloc.data:
                                            if trace.type == 'table':
                                                # Get headers
                                                if hasattr(trace, 'header') and trace.header and hasattr(trace.header, 'values'):
                                                    headers = trace.header.values
                                                else:
                                                    headers = ['Asset', 'Allocation %', 'Price ($)', 'Shares', 'Total Value ($)', '% of Portfolio']
                                                
                                                # Get cell data and recalculate with correct final portfolio value
                                                if hasattr(trace, 'cells') and trace.cells and hasattr(trace.cells, 'values'):
                                                    cell_data = trace.cells.values
                                                    if cell_data and len(cell_data) > 0:
                                                        # Recalculate table with correct final portfolio value
                                                        table_rows = []
                                                        
                                                        # Get raw data for price calculations
                                                        raw_data = {}
                                                        if 'multi_backtest_snapshot_data' in st.session_state:
                                                            snapshot = st.session_state.multi_backtest_snapshot_data
                                                            raw_data = snapshot.get('raw_data', {})
                                                        
                                                        # Recalculate each row with correct final portfolio value
                                                        for row_idx in range(len(cell_data[0])):
                                                            asset = cell_data[0][row_idx] if row_idx < len(cell_data[0]) else ''
                                                            if asset and asset != 'TOTAL':
                                                                # Get allocation percentage from stored data
                                                                alloc_pct_str = cell_data[1][row_idx] if row_idx < len(cell_data[1]) else '0%'
                                                                alloc_pct = float(alloc_pct_str.rstrip('%')) / 100.0
                                                                
                                                                # Calculate with correct final portfolio value
                                                                allocation_value = pdf_portfolio_value * alloc_pct
                                                                
                                                                # Get current price
                                                                current_price = None
                                                                shares = 0.0
                                                                if asset != 'CASH' and asset in raw_data:
                                                                    df = raw_data[asset]
                                                                    if isinstance(df, pd.DataFrame) and 'Close' in df.columns and not df['Close'].dropna().empty:
                                                                        try:
                                                                            current_price = float(df['Close'].iloc[-1])
                                                                            if current_price and current_price > 0:
                                                                                shares = round(allocation_value / current_price, 1)
                                                                        except Exception:
                                                                            current_price = None
                                                                
                                                                total_val = shares * current_price if current_price and shares > 0 else allocation_value
                                                                pct_of_port = (total_val / pdf_portfolio_value * 100) if pdf_portfolio_value > 0 else 0
                                                                
                                                                table_rows.append([
                                                                    asset,
                                                                    f"{alloc_pct * 100:.2f}%",
                                                                    f"{current_price:.2f}" if current_price else "N/A",
                                                                    f"{shares:.1f}",
                                                                    f"${total_val:,.2f}",
                                                                    f"{pct_of_port:.2f}%"
                                                                ])
                                                        
                                                        # Calculate total values for summary row
                                                        total_alloc_pct = sum(float(row[1].rstrip('%')) for row in table_rows)
                                                        total_value = sum(float(row[4].replace('$', '').replace(',', '')) for row in table_rows)
                                                        total_port_pct = sum(float(row[5].rstrip('%')) for row in table_rows)

                                                        # Add total row
                                                        total_row = [
                                                            'TOTAL',
                                                            f"{total_alloc_pct:.2f}%",
                                                            '',
                                                            '',
                                                            f"${total_value:,.2f}",
                                                            f"{total_port_pct:.2f}%"
                                                        ]

                                                        # Create table with proper formatting
                                                        page_width = 7.5*inch
                                                        col_widths = [page_width/len(headers)] * len(headers)
                                                        alloc_table = Table([headers] + table_rows + [total_row], colWidths=col_widths)
                                                        alloc_table.setStyle(TableStyle([
                                                            ('BACKGROUND', (0, 0), (-1, 0), reportlab_colors.Color(0.3, 0.5, 0.7)),
                                                            ('TEXTCOLOR', (0, 0), (-1, 0), reportlab_colors.whitesmoke),
                                                            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                                                            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                                                            ('FONTSIZE', (0, 0), (-1, -1), 8),
                                                            ('GRID', (0, 0), (-1, -1), 1, reportlab_colors.black),
                                                            ('BACKGROUND', (0, 1), (-1, -1), reportlab_colors.Color(0.98, 0.98, 0.98)),
                                                            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
                                                            ('LEFTPADDING', (0, 0), (-1, -1), 3),
                                                            ('RIGHTPADDING', (0, 0), (-1, -1), 3),
                                                            ('TOPPADDING', (0, 0), (-1, -1), 2),
                                                            ('BOTTOMPADDING', (0, 0), (-1, -1), 2),
                                                            ('WORDWRAP', (0, 0), (-1, -1), True),
                                                            # Style the total row
                                                            ('BACKGROUND', (0, -1), (-1, -1), reportlab_colors.Color(0.2, 0.4, 0.6)),
                                                            ('TEXTCOLOR', (0, -1), (-1, -1), reportlab_colors.whitesmoke),
                                                            ('FONTNAME', (0, -1), (-1, -1), 'Helvetica-Bold')
                                                        ]))
                                                        story.append(alloc_table)
                                                        story.append(Spacer(1, 5))
                                                        table_created = True
                                                        break
                                except Exception as e:
                                    pass
                            
                            # Method 2: Create table from today_weights directly if stored table not available
                            if not table_created:
                                try:
                                    if today_weights:
                                        headers = ['Asset', 'Allocation %']
                                        table_rows = []
                                        
                                        for asset, weight in today_weights.items():
                                            if float(weight) > 0:
                                                table_rows.append([asset, f"{float(weight)*100:.2f}%"])
                                        
                                        if table_rows:
                                            # Calculate total values for summary row
                                            total_alloc_pct = sum(float(row[1].rstrip('%')) for row in table_rows)

                                            # Add total row
                                            total_row = [
                                                'TOTAL',
                                                f"{total_alloc_pct:.2f}%"
                                            ]

                                            page_width = 7.5*inch
                                            col_widths = [page_width/len(headers)] * len(headers)
                                            alloc_table = Table([headers] + table_rows + [total_row], colWidths=col_widths)
                                            alloc_table.setStyle(TableStyle([
                                                ('BACKGROUND', (0, 0), (-1, 0), reportlab_colors.Color(0.3, 0.5, 0.7)),
                                                ('TEXTCOLOR', (0, 0), (-1, 0), reportlab_colors.whitesmoke),
                                                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                                                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                                                ('FONTSIZE', (0, 0), (-1, -1), 8),
                                                ('GRID', (0, 0), (-1, -1), 1, reportlab_colors.black),
                                                ('BACKGROUND', (0, 1), (-1, -1), reportlab_colors.Color(0.98, 0.98, 0.98)),
                                                ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
                                                ('LEFTPADDING', (0, 0), (-1, -1), 3),
                                                ('RIGHTPADDING', (0, 0), (-1, -1), 3),
                                                ('TOPPADDING', (0, 0), (-1, -1), 2),
                                                ('BOTTOMPADDING', (0, 0), (-1, -1), 2),
                                                ('WORDWRAP', (0, 0), (-1, -1), True),
                                                # Style the total row
                                                ('BACKGROUND', (0, -1), (-1, -1), reportlab_colors.Color(0.2, 0.4, 0.6)),
                                                ('TEXTCOLOR', (0, -1), (-1, -1), reportlab_colors.whitesmoke),
                                                ('FONTNAME', (0, -1), (-1, -1), 'Helvetica-Bold')
                                            ]))
                                            story.append(alloc_table)
                                            story.append(Spacer(1, 3))
                                            table_created = True
                                        else:
                                            story.append(Paragraph("No allocation data available", styles['Normal']))
                                    else:
                                        story.append(Paragraph("No allocation data available", styles['Normal']))
                                except Exception as e2:
                                    story.append(Paragraph(f"Error creating allocation table: {str(e2)}", styles['Normal']))
                            else:
                                # Fallback: simple text representation if table creation fails
                                    story.append(Paragraph("Target Allocation if Rebalanced Today:", styles['Heading4']))
                                    for asset, weight in today_weights.items():
                                        if float(weight) > 0:
                                            story.append(Paragraph(f"{asset}: {float(weight)*100:.1f}%", styles['Normal']))
                            
                            story.append(Spacer(1, 3))
                        else:
                            story.append(Paragraph(f"No allocation data available for {portfolio_name}", styles['Normal']))
                    except Exception as e:
                        story.append(Paragraph(f"Error creating pie chart for {portfolio_name}: {str(e)}", styles['Normal']))
        else:
            story.append(Paragraph("Allocation data not available. Please run the backtest first.", styles['Normal']))
            story.append(Spacer(1, 5))
        
        # Update progress
        progress_bar.progress(95)
        status_text.text("üî® Building PDF document...")
        
        # Build PDF
        doc.build(story)
        buffer.seek(0)
        
        # Complete progress
        progress_bar.progress(100)
        status_text.text("‚úÖ PDF generation complete! Downloading...")
        
        return buffer
        
    except Exception as e:
        st.error(f"Error generating PDF: {str(e)}")
        return None

def check_currency_warning(tickers):
    """
    Check if any tickers are non-USD and display a warning.
    """
    non_usd_suffixes = ['.TO', '.V', '.CN', '.AX', '.L', '.PA', '.AS', '.SW', '.T', '.HK', '.KS', '.TW', '.JP']
    non_usd_tickers = []
    
    for ticker in tickers:
        if any(ticker.endswith(suffix) for suffix in non_usd_suffixes):
            non_usd_tickers.append(ticker)
    
    if non_usd_tickers:
        st.warning(f"‚ö†Ô∏è **Currency Warning**: The following tickers are not in USD: {', '.join(non_usd_tickers)}. "
                  f"Currency conversion is not taken into account, which may affect allocation accuracy. "
                  f"Consider using USD equivalents for more accurate results.")

# Initialize page-specific session state for Multi-Backtest page
if 'multi_backtest_page_initialized' not in st.session_state:
    st.session_state.multi_backtest_page_initialized = True
    # Initialize multi-backtest specific session state
    st.session_state.multi_backtest_portfolio_configs = [
        # 1) Benchmark only (SPY) - yearly rebalancing and yearly additions
        {
            'name': 'Benchmark Only (SPY)',
            'stocks': [
                {'ticker': 'SPY', 'allocation': 1.0, 'include_dividends': True, 'include_in_sma_filter': True, 'max_allocation_percent': None},
            ],
            'benchmark_ticker': '^GSPC',
            'initial_value': 10000,
            'added_amount': 10000,
            'added_frequency': 'Annually',
            'rebalancing_frequency': 'Annually',
            'start_date_user': None,
            'end_date_user': None,
            'start_with': 'first',
            'use_momentum': False,
            'use_relative_momentum': False,
            'equal_if_all_negative': False,
            'momentum_strategy': 'Classic',
            'negative_momentum_strategy': 'Cash',
            'momentum_windows': [],
            'calc_beta': False,
            'calc_volatility': False,
            'beta_window_days': 365,
            'exclude_days_beta': 30,
            'vol_window_days': 365,
            'exclude_days_vol': 30,
            'use_minimal_threshold': False,
            'minimal_threshold_percent': 4.0,
            'use_max_allocation': False,
            'max_allocation_percent': 20.0,
        },
        # 2) Momentum-based portfolio using SPY, QQQ, GLD, TLT
        {
            'name': 'Momentum-Based Portfolio',
            'stocks': [
                {'ticker': 'SPY', 'allocation': 0.25, 'include_dividends': True, 'include_in_sma_filter': True},
                {'ticker': 'QQQ', 'allocation': 0.25, 'include_dividends': True, 'include_in_sma_filter': True},
                {'ticker': 'GLD', 'allocation': 0.25, 'include_dividends': True, 'include_in_sma_filter': True},
                {'ticker': 'TLT', 'allocation': 0.25, 'include_dividends': True, 'include_in_sma_filter': True},
            ],
            'benchmark_ticker': '^GSPC',
            'initial_value': 10000,
            'added_amount': 10000,
            'added_frequency': 'Annually',
            'rebalancing_frequency': 'Annually',
            'start_date_user': None,
            'end_date_user': None,
            'start_with': 'first',
            'use_momentum': True,
            'use_relative_momentum': True,
            'equal_if_all_negative': True,
            'momentum_strategy': 'Classic',
            'negative_momentum_strategy': 'Cash',
            'momentum_windows': [
                {'lookback': 365, 'exclude': 30, 'weight': 0.5},
                {'lookback': 180, 'exclude': 30, 'weight': 0.3},
                {'lookback': 120, 'exclude': 30, 'weight': 0.2},
            ],
            'calc_beta': False,
            'calc_volatility': False,
            'beta_window_days': 365,
            'exclude_days_beta': 30,
            'vol_window_days': 365,
            'exclude_days_vol': 30,
            'use_minimal_threshold': False,
            'minimal_threshold_percent': 4.0,
            'use_max_allocation': False,
            'max_allocation_percent': 20.0,
        },
        # 3) Equal weight (No Momentum) using the same tickers
        {
            'name': 'Equal Weight Portfolio (No Momentum)',
            'stocks': [
                {'ticker': 'SPY', 'allocation': 0.25, 'include_dividends': True, 'include_in_sma_filter': True, 'max_allocation_percent': None},
                {'ticker': 'QQQ', 'allocation': 0.25, 'include_dividends': True, 'include_in_sma_filter': True, 'max_allocation_percent': None},
                {'ticker': 'GLD', 'allocation': 0.25, 'include_dividends': True, 'include_in_sma_filter': True, 'max_allocation_percent': None},
                {'ticker': 'TLT', 'allocation': 0.25, 'include_dividends': True, 'include_in_sma_filter': True, 'max_allocation_percent': None},
            ],
            'benchmark_ticker': '^GSPC',
            'initial_value': 10000,
            'added_amount': 10000,
            'added_frequency': 'Annually',
            'rebalancing_frequency': 'Annually',
            'start_date_user': None,
            'end_date_user': None,
            'start_with': 'first',
            'use_momentum': False,
            'use_relative_momentum': False,
            'equal_if_all_negative': False,
            'momentum_strategy': 'Classic',
            'negative_momentum_strategy': 'Cash',
            'momentum_windows': [],
            'calc_beta': False,
            'calc_volatility': False,
            'beta_window_days': 365,
            'exclude_days_beta': 30,
            'vol_window_days': 365,
            'exclude_days_vol': 30,
            'use_minimal_threshold': False,
            'minimal_threshold_percent': 4.0,
            'use_max_allocation': False,
            'max_allocation_percent': 20.0,
        },
    ]
    st.session_state.multi_backtest_active_portfolio_index = 0
    st.session_state.multi_backtest_rerun_flag = False
    # Clean up any existing portfolio configs to remove unused settings
if 'multi_backtest_portfolio_configs' in st.session_state:
    for config in st.session_state.multi_backtest_portfolio_configs:
        config.pop('use_relative_momentum', None)
        config.pop('equal_if_all_negative', None)
        
        # Ensure all stocks have max_allocation_percent field
        for stock in config.get('stocks', []):
            if 'max_allocation_percent' not in stock:
                stock['max_allocation_percent'] = None

st.set_page_config(layout="wide", page_title="Multi-Portfolio Analysis", page_icon="üìà")

# Initialize global date widgets on page load to maintain state across page navigation
def initialize_global_dates():
    """Initialize global date widgets to maintain state across page navigation"""
    from datetime import date
    if "multi_backtest_start_date" not in st.session_state:
        st.session_state["multi_backtest_start_date"] = date(2010, 1, 1)
    if "multi_backtest_end_date" not in st.session_state:
        st.session_state["multi_backtest_end_date"] = date.today()
    if "multi_backtest_use_custom_dates" not in st.session_state:
        st.session_state["multi_backtest_use_custom_dates"] = False

initialize_global_dates()

# Handle imported values from JSON - MUST BE AT THE VERY BEGINNING
if "_import_start_with" in st.session_state:
    st.session_state["multi_backtest_start_with"] = st.session_state.pop("_import_start_with")
    st.session_state["multi_backtest_start_with_radio"] = st.session_state["multi_backtest_start_with"]
if "_import_first_rebalance_strategy" in st.session_state:
    st.session_state["multi_backtest_first_rebalance_strategy"] = st.session_state.pop("_import_first_rebalance_strategy")
    st.session_state["multi_backtest_first_rebalance_strategy_radio"] = st.session_state["multi_backtest_first_rebalance_strategy"]
st.markdown("""
<style>
    /* Global Styles for the App */
    .st-emotion-cache-1f87s81 {
        padding-top: 2rem;
        padding-bottom: 2rem;
        padding-left: 1rem;
        padding-right: 1rem;
    }
    .st-emotion-cache-1v0bb62 button {
        background-color: #007bff !important;
        color: white !important;
        border-color: #007bff !important;
        font-weight: bold;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        transition: all 0.3s ease;
    }
    .st-emotion-cache-1v0bb62 button:hover {
        background-color: #0056b3 !important;
        border-color: #0056b3 !important;
        transform: translateY(-2px);
    }
    /* Fix for the scrollable dataframe - forces it to be non-scrollable */
    div.st-emotion-cache-1ftv8z > div {
        overflow: visible !important;
        max-height: none !important;
    }
    /* Make the 'View Details' button more obvious */
    button[aria-label="View Details"] {
        background-color: #0ea5e9 !important;
        color: white !important;
        border: 1px solid rgba(255,255,255,0.08) !important;
        box-shadow: 0 4px 8px rgba(14,165,233,0.16) !important;
    }
    button[aria-label="View Details"]:hover {
        background-color: #0891b2 !important;
    }
</style>
<a id="top"></a>
<button id="back-to-top" onclick="window.scrollTo(0, 0);">‚¨ÜÔ∏è</button>
<style>
    #back-to-top {
        position: fixed;
        bottom: 20px;
        right: 20px;
        z-index: 1000;
        opacity: 0.7;
        background-color: #007bff;
        color: white;
        border: none;
        border-radius: 50%;
        width: 50px;
        height: 50px;
        font-size: 24px;
        cursor: pointer;
        display: none;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        transition: opacity 0.3s;
    }
    #back-to-top:hover {
        opacity: 1;
    }
</style>
<script>
    window.onscroll = function() {
        var button = document.getElementById("back-to-top");
        if (document.body.scrollTop > 200 || document.documentElement.scrollTop > 200) {
            button.style.display = "block";
        } else {
            button.style.display = "none";
        }
    };
</script>
""", unsafe_allow_html=True)



# ...existing code...

# Handle rerun flag for smooth UI updates - must be at the very top
if st.session_state.get('multi_backtest_rerun_flag', False):
    st.session_state.multi_backtest_rerun_flag = False
    st.rerun()

# Reset running state on page load to prevent persistent running state
if 'hard_kill_requested' in st.session_state:
    st.session_state.hard_kill_requested = False

# Place rerun logic after first portfolio input widget
active_portfolio = st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index] if 'multi_backtest_portfolio_configs' in st.session_state and 'multi_backtest_active_portfolio_index' in st.session_state else None

import numpy as np
import pandas as pd
def calculate_mwrr(values, cash_flows, dates):
    # Exact logic from app.py for MWRR calculation
    try:
        from scipy.optimize import brentq
        values = pd.Series(values).dropna()
        flows = pd.Series(cash_flows).reindex(values.index, fill_value=0.0)
        if len(values) < 2:
            return np.nan
        dates = pd.to_datetime(values.index)
        start_date = dates[0]
        time_periods = np.array([(d - start_date).days / 365.25 for d in dates])
        initial_investment = -values.iloc[0]
        significant_flows = flows[flows != 0]
        cash_flow_dates = [start_date]
        cash_flow_amounts = [initial_investment]
        cash_flow_times = [0.0]
        for date, flow in significant_flows.items():
            if date != dates[0] and date != dates[-1]:
                cash_flow_dates.append(pd.to_datetime(date))
                cash_flow_amounts.append(flow)
                cash_flow_times.append((pd.to_datetime(date) - start_date).days / 365.25)
        cash_flow_dates.append(dates[-1])
        cash_flow_amounts.append(values.iloc[-1])
        cash_flow_times.append((dates[-1] - start_date).days / 365.25)
        cash_flow_amounts = np.array(cash_flow_amounts)
        cash_flow_times = np.array(cash_flow_times)
        def npv(rate):
            return np.sum(cash_flow_amounts / (1 + rate) ** cash_flow_times)
        try:
            irr = brentq(npv, -0.999, 10)
            return irr * 100
        except (ValueError, RuntimeError):
            return np.nan
    except Exception:
        return np.nan
# Backtest_Engine.py
import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
import io
import contextlib
import json
from datetime import datetime, timedelta, time
from warnings import warn
from scipy.optimize import newton, brentq, root_scalar
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import base64

# Custom CSS for a better layout, a distinct primary button, and the fixed 'Back to Top' button
st.markdown("""
<style>
    /* Global Styles for the App */
    .st-emotion-cache-1f87s81 {
        padding-top: 2rem;
        padding-bottom: 2rem;
        padding-left: 1rem;
        padding-right: 1rem;
    }
    .st-emotion-cache-1v0bb62 button {
        background-color: #007bff !important;
        color: white !important;
        border-color: #007bff !important;
        font-weight: bold;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        transition: all 0.3s ease;
    }
    .st-emotion-cache-1v0bb62 button:hover {
        background-color: #0056b3 !important;
        border-color: #0056b3 !important;
        transform: translateY(-2px);
    }
    /* Fix for the scrollable dataframe - forces it to be non-scrollable */
    div.st-emotion-cache-1ftv8z > div {
        overflow: visible !important;
        max-height: none !important;
    }
</style>
<a id="top"></a>
<button id="back-to-top" onclick="window.scrollTo(0, 0);">‚¨ÜÔ∏è</button>
<style>
    #back-to-top {
        position: fixed;
        bottom: 20px;
        right: 20px;
        z-index: 1000;
        opacity: 0.7;
        background-color: #007bff;
        color: white;
        border: none;
        border-radius: 50%;
        width: 50px;
        height: 50px;
        font-size: 24px;
        cursor: pointer;
        display: none;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        transition: opacity 0.3s;
    }
    #back-to-top:hover {
        opacity: 1;
    }
</style>
<script>
    window.onscroll = function() {
        var button = document.getElementById("back-to-top");
        if (document.body.scrollTop > 200 || document.documentElement.scrollTop > 200) {
            button.style.display = "block";
        } else {
            button.style.display = "none";
        }
    };
</script>
""", unsafe_allow_html=True)

st.set_page_config(layout="wide", page_title="Multi-Portfolio Analysis")

st.title("Multi-Portfolio Backtest")

# Important performance notice
st.info("""
‚ö†Ô∏è **Performance Tip**: Due to Streamlit's architecture limitations, **always clear all outputs** before modifying portfolios to prevent severe lag. 
Click the "üîÑ Clear All Outputs" button before making changes to avoid performance issues caused by accumulated plot data in memory.
""")

st.markdown("Use the forms below to configure and run backtests for multiple portfolios.")

# Performance Settings
col1, col2 = st.columns([3, 1])
with col1:
    st.markdown("### Performance Settings")
with col2:
    use_parallel = st.checkbox("Parallel Processing", value=False,
                              help="Process multiple portfolios simultaneously using threading. When selected, automatically activates for 3+ portfolios.")
    st.session_state.use_parallel_processing = use_parallel

# Portfolio name is handled in the main UI below

# -----------------------
# Default JSON configs (for initialization)
# -----------------------
default_configs = [
    # 1) Benchmark only (SPY) - yearly rebalancing and yearly additions
    {
        'name': 'Benchmark Only (SPY)',
        'stocks': [
            {'ticker': 'SPY', 'allocation': 1.0, 'include_dividends': True},
        ],
        'benchmark_ticker': '^GSPC',
        'initial_value': 10000,
        'added_amount': 10000,
        'added_frequency': 'Annually',
        'rebalancing_frequency': 'Annually',
        'start_date_user': None,
        'end_date_user': None,
        'start_with': 'first',
    'use_momentum': False,
        'use_relative_momentum': False,
        'equal_if_all_negative': False,
        'momentum_windows': [],
        'calc_beta': False,
        'calc_volatility': False,
        'beta_window_days': 365,
        'exclude_days_beta': 30,
        'vol_window_days': 365,
        'exclude_days_vol': 30,
    },
    # 2) Momentum-based portfolio using SPY, QQQ, GLD, TLT
    {
        'name': 'Momentum-Based Portfolio',
        'stocks': [
            {'ticker': 'SPY', 'allocation': 0.25, 'include_dividends': True},
            {'ticker': 'QQQ', 'allocation': 0.25, 'include_dividends': True},
            {'ticker': 'GLD', 'allocation': 0.25, 'include_dividends': True},
            {'ticker': 'TLT', 'allocation': 0.25, 'include_dividends': True},
        ],
        'benchmark_ticker': '^GSPC',
        'initial_value': 10000,
        'added_amount': 10000,
        'added_frequency': 'Annually',
        'rebalancing_frequency': 'Annually',
        'start_date_user': None,
        'end_date_user': None,
        'start_with': 'first',
        'use_momentum': True,
        'momentum_strategy': 'Classic',
        'negative_momentum_strategy': 'Cash',
        'momentum_windows': [
            {'lookback': 365, 'exclude': 30, 'weight': 0.5},
            {'lookback': 180, 'exclude': 30, 'weight': 0.3},
            {'lookback': 120, 'exclude': 30, 'weight': 0.2},
        ],
            'calc_beta': False,
        'calc_volatility': False,
        'beta_window_days': 365,
        'exclude_days_beta': 30,
        'vol_window_days': 365,
        'exclude_days_vol': 30,
    },
    # 3) Equal weight (No Momentum) using the same tickers
    {
        'name': 'Equal Weight Portfolio (No Momentum)',
        'stocks': [
            {'ticker': 'SPY', 'allocation': 0.25, 'include_dividends': True},
            {'ticker': 'QQQ', 'allocation': 0.25, 'include_dividends': True},
            {'ticker': 'GLD', 'allocation': 0.25, 'include_dividends': True},
            {'ticker': 'TLT', 'allocation': 0.25, 'include_dividends': True},
        ],
        'benchmark_ticker': '^GSPC',
        'initial_value': 10000,
        'added_amount': 10000,
        'added_frequency': 'Annually',
        'rebalancing_frequency': 'Annually',
        'start_date_user': None,
        'end_date_user': None,
        'start_with': 'first',
        'use_momentum': False,
        'momentum_windows': [],
        'calc_beta': False,
        'calc_volatility': False,
        'beta_window_days': 365,
        'exclude_days_beta': 30,
        'vol_window_days': 365,
        'exclude_days_vol': 30,
    },
]

# -----------------------
# Helper functions
# -----------------------
def get_trading_days(start_date, end_date):
    return pd.bdate_range(start=start_date, end=end_date)

def get_portfolio_value(portfolio_name):
    """Get the current portfolio value for allocation calculations (with additions)"""
    portfolio_value = 10000  # Default value
    if 'multi_all_results' in st.session_state and st.session_state.multi_all_results:
        portfolio_results = st.session_state.multi_all_results.get(portfolio_name)
        if portfolio_results:
            # Prioritize 'with_additions' for allocation tables (actual total portfolio value)
            if isinstance(portfolio_results, dict) and 'with_additions' in portfolio_results:
                latest_value = portfolio_results['with_additions'].iloc[-1]
                if not pd.isna(latest_value) and latest_value > 0:
                    portfolio_value = float(latest_value)
            elif isinstance(portfolio_results, dict) and 'no_additions' in portfolio_results:
                latest_value = portfolio_results['no_additions'].iloc[-1]
                if not pd.isna(latest_value) and latest_value > 0:
                    portfolio_value = float(latest_value)
            elif isinstance(portfolio_results, pd.Series):
                latest_value = portfolio_results.iloc[-1]
                if not pd.isna(latest_value) and latest_value > 0:
                    portfolio_value = float(latest_value)
    return portfolio_value

def create_allocation_evolution_chart(portfolio_name, allocs_data):
    """Create allocation evolution chart for a portfolio (CACHED version)"""
    try:
        # Convert to DataFrame for easier processing
        alloc_df = pd.DataFrame(allocs_data).T
        alloc_df.index = pd.to_datetime(alloc_df.index)
        alloc_df = alloc_df.sort_index()
        
        # Get all unique tickers (excluding None)
        all_tickers = set()
        for date, allocs in allocs_data.items():
            for ticker in allocs.keys():
                if ticker is not None:
                    all_tickers.add(ticker)
        all_tickers = sorted(list(all_tickers))
        
        # Fill missing values with 0 for unavailable assets (instead of forward fill)
        alloc_df = alloc_df.fillna(0)
        
        # Convert to percentages
        alloc_df = alloc_df * 100
        
        # Create the evolution chart
        fig_evolution = go.Figure()
        
        # Color palette for different tickers
        colors = [
            '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',
            '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf',
            '#aec7e8', '#ffbb78', '#98df8a', '#ff9896', '#c5b0d5'
        ]
        
        # Add a trace for each ticker
        for i, ticker in enumerate(all_tickers):
            if ticker in alloc_df.columns:
                # Get the allocation data for this ticker
                ticker_data = alloc_df[ticker].dropna()
                
                if not ticker_data.empty:  # Only add if we have data
                    fig_evolution.add_trace(go.Scatter(
                        x=ticker_data.index,
                        y=ticker_data.values,
                        mode='lines',
                        name=ticker,
                        line=dict(color=colors[i % len(colors)], width=2),
                        hovertemplate=f'<b>{ticker}</b><br>' +
                                    'Date: %{x}<br>' +
                                    'Allocation: %{y:.1f}%<br>' +
                                    '<extra></extra>'
                    ))
        
        # Update layout
        fig_evolution.update_layout(
            title=f"Portfolio Allocation Evolution - {portfolio_name}",
            xaxis_title="Date",
            yaxis_title="Allocation (%)",
            template='plotly_dark',
            height=600,
            hovermode='closest',
            hoverdistance=100,
            spikedistance=1000,
            legend=dict(
                orientation="v",
                yanchor="top",
                y=1,
                xanchor="left",
                x=1.01
            )
        )
        
        return fig_evolution
        
    except Exception as e:
        st.error(f"Error creating allocation evolution chart for {portfolio_name}: {str(e)}")
        return None

def process_allocation_dataframe(portfolio_name, allocation_data):
    """Process allocation data into a clean DataFrame (CACHED version)"""
    try:
        # Ensure all tickers (excluding None) are present in all dates for proper DataFrame creation
        all_tickers = set()
        for date, alloc_dict in allocation_data.items():
            for ticker in alloc_dict.keys():
                if ticker is not None:
                    all_tickers.add(ticker)
        
        # Create a complete DataFrame with all dates and all tickers
        all_dates = sorted(allocation_data.keys())
        complete_data = {}
        
        for date in all_dates:
            alloc_dict = allocation_data[date]
            complete_data[date] = {ticker: alloc_dict.get(ticker, 0) for ticker in all_tickers}
        
        # Convert to DataFrame
        df = pd.DataFrame(complete_data).T
        df.index = pd.to_datetime(df.index)
        df = df.sort_index()
        
        # Fill missing values with 0 for unavailable assets (EXACTLY LIKE PORTFOLIO ALLOCATION EVOLUTION)
        df = df.fillna(0)
        
        # Convert to percentages
        df = df * 100
        
        # Sort tickers with CASH always last
        ticker_list = sorted(list(all_tickers))
        if 'CASH' in ticker_list:
            ticker_list.remove('CASH')
            ticker_list.append('CASH')
        
        # Reorder DataFrame columns to match the desired order
        df = df[ticker_list]
        
        return df, ticker_list
        
    except Exception as e:
        st.error(f"Error processing allocation data for {portfolio_name}: {str(e)}")
        return None, []

def precompute_individual_portfolio_charts():
    """Pre-compute and cache ALL individual portfolio data for instant switching"""
    try:
        # Get all portfolio names from results
        all_results = st.session_state.get('multi_all_results', {})
        all_allocations = st.session_state.get('multi_all_allocations', {})
        all_metrics = st.session_state.get('multi_all_metrics', {})
        portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
        
        if not all_results or not all_allocations:
            return
        
        # Initialize comprehensive cache
        if 'individual_portfolio_cache' not in st.session_state:
            st.session_state.individual_portfolio_cache = {}
        
        # Pre-compute EVERYTHING for each portfolio
        for portfolio_name in all_results.keys():
            if portfolio_name in all_allocations:
                portfolio_cache = {}
                
                # 1. Cache portfolio configuration
                portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == portfolio_name), None)
                portfolio_cache['config'] = portfolio_cfg
                
                # 2. Cache allocation data
                allocation_data = all_allocations[portfolio_name]
                portfolio_cache['allocation_data'] = allocation_data
                
                # 3. Cache metrics data
                if portfolio_name in all_metrics:
                    portfolio_cache['metrics_data'] = all_metrics[portfolio_name]
                
                # 4. Pre-compute and cache Historical Allocations DataFrame
                if allocation_data:
                    try:
                        allocations_df_raw, all_tickers = process_allocation_dataframe(portfolio_name, allocation_data)
                        if allocations_df_raw is not None:
                            allocations_df_raw.index.name = "Date"
                            allocations_df_raw = allocations_df_raw.sort_index(ascending=True)
                            portfolio_cache['allocations_df'] = allocations_df_raw
                            portfolio_cache['allocations_tickers'] = all_tickers
                    except Exception as e:
                        portfolio_cache['allocations_df'] = None
                        portfolio_cache['allocations_tickers'] = []
                
                # 5. Pre-compute pie chart data
                if allocation_data:
                    latest_date = max(allocation_data.keys())
                    latest_allocation = allocation_data[latest_date]
                    
                    labels_today = [k for k, v in sorted(latest_allocation.items(), key=lambda x: (-x[1], x[0])) if v > 0]
                    vals_today = [float(latest_allocation[k]) * 100 for k in labels_today]
                    
                    portfolio_cache['pie_chart_data'] = {
                        'labels': labels_today,
                        'values': vals_today,
                        'allocation': latest_allocation
                    }
                    
                    # Create and cache the pie chart
                    if labels_today and vals_today:
                        fig_today = go.Figure()
                        fig_today.add_trace(go.Pie(labels=labels_today, values=vals_today, hole=0.3))
                        fig_today.update_traces(textinfo='percent+label')
                        fig_today.update_layout(
                            template='plotly_dark', 
                            margin=dict(t=30),
                            height=600,
                            showlegend=True
                        )
                        portfolio_cache['pie_chart_figure'] = fig_today
                
                # 6. Pre-compute rebalancing data
                if allocation_data:
                    alloc_dates = sorted(list(allocation_data.keys()))
                    if alloc_dates:
                        final_date = alloc_dates[-1]
                        last_rebal_date = alloc_dates[-2] if len(alloc_dates) > 1 else alloc_dates[-1]
                        
                        final_alloc = allocation_data.get(final_date, {})
                        rebal_alloc = allocation_data.get(last_rebal_date, {})
                        
                        # Pre-compute labels and values for both charts
                        labels_final = [k for k, v in sorted(final_alloc.items(), key=lambda x: (-x[1], x[0])) if v > 0]
                        vals_final = [float(final_alloc[k]) * 100 for k in labels_final]
                        
                        labels_rebal = [k for k, v in sorted(rebal_alloc.items(), key=lambda x: (-x[1], x[0])) if v > 0]
                        vals_rebal = [float(rebal_alloc[k]) * 100 for k in labels_rebal]
                        
                        portfolio_cache['rebalancing_data'] = {
                            'final_date': final_date,
                            'last_rebal_date': last_rebal_date,
                            'labels_final': labels_final,
                            'vals_final': vals_final,
                            'labels_rebal': labels_rebal,
                            'vals_rebal': vals_rebal,
                            'final_alloc': final_alloc,
                            'rebal_alloc': rebal_alloc
                        }
                
                # 7. Pre-compute today weights from snapshot
                snapshot = st.session_state.get('multi_backtest_snapshot_data', {})
                today_weights_map = snapshot.get('today_weights_map', {}) if snapshot else {}
                if portfolio_name in today_weights_map:
                    portfolio_cache['today_weights'] = today_weights_map[portfolio_name]
                
                # Store everything in the cache
                st.session_state.individual_portfolio_cache[portfolio_name] = portfolio_cache
        
        st.success(f"Processed ALL data for {len(all_results)} portfolios (with 4h ticker cache)")
        
        # Display API call counter
        api_calls = st.session_state.get('api_call_count', 0)
        st.info(f"**API Calls Made:** {api_calls} total calls to Yahoo Finance")
        
    except Exception as e:
        st.error(f"Error pre-computing portfolio data: {str(e)}")

def create_pie_chart(portfolio_name, allocation_data, title_suffix="Current Allocation"):
    """Create pie chart for portfolio allocation (CACHED version)"""
    try:
        if not allocation_data:
            return None
            
        # Filter out zero allocations and None values
        filtered_data = {k: v for k, v in allocation_data.items() if v > 0 and k is not None}
        
        if not filtered_data:
            return None
            
        # Convert to percentages
        total = sum(filtered_data.values())
        if total == 0:
            return None
            
        percentages = {k: (v / total) * 100 for k, v in filtered_data.items()}
        
        # Create pie chart
        fig = go.Figure(data=[go.Pie(
            labels=list(percentages.keys()),
            values=list(percentages.values()),
            textinfo='percent+label',
            textposition='auto',
            hovertemplate='<b>%{label}</b><br>Allocation: %{percent}<br>Value: %{value:.1f}%<extra></extra>',
            marker=dict(
                colors=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',
                       '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf',
                       '#aec7e8', '#ffbb78', '#98df8a', '#ff9896', '#c5b0d5']
            )
        )])
        
        fig.update_layout(
            title=f"{portfolio_name} - {title_suffix}",
            template='plotly_dark',
            height=400,
            showlegend=True
        )
        
        return fig
        
    except Exception as e:
        st.error(f"Error creating pie chart for {portfolio_name}: {str(e)}")
        return None

def sort_dataframe_numerically(df, column, ascending=False):
    """Sort DataFrame by a specific column numerically, handling percentage strings and N/A values"""
    if column not in df.columns:
        return df
    
    # Create a copy to avoid modifying the original
    df_sorted = df.copy()
    
    # Extract numeric values for sorting
    def extract_numeric_value(value):
        if pd.isna(value) or value == 'N/A' or value == 'N/A%':
            return float('-inf')  # Put N/A values at the end
        
        # Handle percentage strings
        if isinstance(value, str) and value.endswith('%'):
            try:
                return float(value.replace('%', ''))
            except:
                return float('-inf')
        
        # Handle regular numbers
        try:
            return float(value)
        except:
            return float('-inf')
    
    # Create sorting key
    df_sorted['_sort_key'] = df_sorted[column].apply(extract_numeric_value)
    
    # Sort by the numeric key
    df_sorted = df_sorted.sort_values('_sort_key', ascending=ascending)
    
    # Drop the sorting key
    df_sorted = df_sorted.drop('_sort_key', axis=1)
    
    return df_sorted

def get_dates_by_freq(freq, start, end, market_days):
    market_days = sorted(market_days)
    if freq == "market_day":
        return set(market_days)
    elif freq == "calendar_day":
        return set(pd.date_range(start=start, end=end, freq='D'))
    elif freq == "Weekly":
        # Use first trading day of each week (Monday) - start from first Monday, not actual start date
        dates = []
        # Find the first Monday on or after start date
        first_monday = start - pd.Timedelta(days=start.weekday())
        if start.weekday() > 0:  # If not Monday, go to next Monday
            first_monday += pd.Timedelta(weeks=1)
        
        current_date = first_monday
        while current_date <= end:
            # Find the first market day on or after this Monday
            market_day_monday = None
            for market_day in market_days:
                if market_day >= current_date:
                    market_day_monday = market_day
                    break
            
            if market_day_monday and market_day_monday >= start and market_day_monday <= end:
                dates.append(market_day_monday)
            
            # Move to next week
            current_date += pd.Timedelta(weeks=1)
        
        return set(dates)
    elif freq == "Biweekly":
        # Use first trading day of every other week (every 2 weeks starting from first Monday)
        dates = []
        # Find the first Monday on or after start date
        first_monday = start - pd.Timedelta(days=start.weekday())
        if start.weekday() > 0:  # If not Monday, go to next Monday
            first_monday += pd.Timedelta(weeks=1)
        
        current_date = first_monday
        while current_date <= end:
            # Find the first market day on or after this Monday
            market_day_monday = None
            for market_day in market_days:
                if market_day >= current_date:
                    market_day_monday = market_day
                    break
            
            if market_day_monday and market_day_monday >= start and market_day_monday <= end:
                dates.append(market_day_monday)
            
            # Move to next bi-week (2 weeks later)
            current_date += pd.Timedelta(weeks=2)
        
        return set(dates)
    elif freq == "Monthly":
        # Use 1st of each month - start from January of start year, not actual start date
        dates = []
        start_year = start.year
        end_year = end.year
        
        # Always start from January 1st of the start year
        current_year = start_year
        current_month = 1
        
        while current_year <= end_year:
            # Create 1st of this month
            first_of_month = pd.Timestamp(year=current_year, month=current_month, day=1)
            
            # Find the first market day on or after the 1st of this month
            market_day_first = None
            for market_day in market_days:
                if market_day >= first_of_month:
                    market_day_first = market_day
                    break
            
            # Only include if it's within our date range
            if market_day_first and market_day_first >= start and market_day_first <= end:
                dates.append(market_day_first)
            
            # Move to next month
            current_month += 1
            if current_month > 12:
                current_month = 1
                current_year += 1
        
        return set(dates)
    elif freq == "Quarterly":
        # Use 1st of January, April, July, October
        dates = []
        start_year = start.year
        end_year = end.year
        
        for year in range(start_year, end_year + 1):
            for month in [1, 4, 7, 10]:  # January, April, July, October
                quarter_start = pd.Timestamp(year=year, month=month, day=1)
                
                # Only include if within our date range
                if quarter_start >= start and quarter_start <= end:
                    # Find the first market day on or after this quarter start
                    market_day_quarter = None
                    for market_day in market_days:
                        if market_day >= quarter_start:
                            market_day_quarter = market_day
                            break
                    
                    if market_day_quarter:
                        dates.append(market_day_quarter)
        
        return set(dates)
    elif freq == "Semiannually":
        # Use 1st of January and July
        dates = []
        start_year = start.year
        end_year = end.year
        
        for year in range(start_year, end_year + 1):
            for month in [1, 7]:  # January and July
                semi_start = pd.Timestamp(year=year, month=month, day=1)
                
                # Only include if within our date range
                if semi_start >= start and semi_start <= end:
                    # Find the first market day on or after this semi-annual start
                    market_day_semi = None
                    for market_day in market_days:
                        if market_day >= semi_start:
                            market_day_semi = market_day
                            break
                    
                    if market_day_semi:
                        dates.append(market_day_semi)
        
        return set(dates)
    elif freq == "Annually" or freq == "year":
        # Use January 1st of each year for annual rebalancing
        dates = []
        start_year = start.year
        end_year = end.year
        
        for year in range(start_year, end_year + 1):
            jan_1st = pd.Timestamp(year=year, month=1, day=1)
            # Find the first market day on or after January 1st
            market_day_jan_1st = None
            for market_day in market_days:
                if market_day >= jan_1st:
                    market_day_jan_1st = market_day
                    break
            
            if market_day_jan_1st and market_day_jan_1st >= start and market_day_jan_1st <= end:
                dates.append(market_day_jan_1st)
        
        return set(dates)
    elif freq == "Never" or freq == "none" or freq is None:
        return set()
    elif freq == "Buy & Hold" or freq == "Buy & Hold (Target)":
        # Buy & Hold options don't have specific rebalancing dates - they rebalance immediately when cash is available
        return set()
    else:
        raise ValueError(f"Unknown frequency: {freq}")

def get_cached_rebalancing_dates(portfolio_name, rebalancing_frequency, sim_index):
    """Get rebalancing dates with caching to avoid recalculation"""
    cache_key = f"rebalancing_dates_{portfolio_name}_{rebalancing_frequency}"
    portfolio_rebalancing_dates = st.session_state.get(cache_key)
    
    if portfolio_rebalancing_dates is None and sim_index is not None:
        # Calculate and cache the rebalancing dates
        portfolio_rebalancing_dates = get_dates_by_freq(rebalancing_frequency, sim_index[0], sim_index[-1], sim_index)
        st.session_state[cache_key] = portfolio_rebalancing_dates
    
    return portfolio_rebalancing_dates

def calculate_cagr(values, dates):
    if len(values) < 2:
        return np.nan
    start_val = values[0]
    end_val = values[-1]
    years = (dates[-1] - dates[0]).days / 365.25
    if years <= 0 or start_val == 0:
        return np.nan
    return (end_val / start_val) ** (1 / years) - 1

def calculate_max_drawdown(values):
    values = np.array(values)
    peak = np.maximum.accumulate(values)
    drawdowns = (values - peak) / np.where(peak == 0, 1, peak)
    return np.nanmin(drawdowns), drawdowns

def calculate_volatility(returns):
    # Annualized volatility - same as Backtest_Engine.py
    return returns.std() * np.sqrt(365.25) if len(returns) > 1 else np.nan

def calculate_beta(returns, benchmark_returns):
    # Use exact logic from app.py
    portfolio_returns = pd.Series(returns)
    benchmark_returns = pd.Series(benchmark_returns)
    common_idx = portfolio_returns.index.intersection(benchmark_returns.index)
    if len(common_idx) < 2:
        return np.nan
    pr = portfolio_returns.reindex(common_idx).dropna()
    br = benchmark_returns.reindex(common_idx).dropna()
    # Re-align after dropping NAs
    common_idx = pr.index.intersection(br.index)
    if len(common_idx) < 2 or br.loc[common_idx].var() == 0:
        return np.nan
    cov = pr.loc[common_idx].cov(br.loc[common_idx])
    var = br.loc[common_idx].var()
    return cov / var

# FIXED: Correct Sortino Ratio calculation - EXACTLY like Backtest_Engine.py
def calculate_sortino(returns, risk_free_rate):
    """Calculates the Sortino ratio."""
    # Create a constant risk-free rate series aligned with returns
    daily_rf_rate = risk_free_rate / 365.25
    rf_series = pd.Series(daily_rf_rate, index=returns.index)
    
    aligned_returns, aligned_rf = returns.align(rf_series, join='inner')
    if aligned_returns.empty:
        return np.nan
        
    downside_returns = aligned_returns[aligned_returns < aligned_rf]
    if downside_returns.empty or downside_returns.std() == 0:
        # If no downside returns, Sortino is infinite or undefined.
        # We can return nan or a very high value. nan is safer.
        return np.nan
    
    downside_std = downside_returns.std()
    
    return (aligned_returns.mean() - aligned_rf.mean()) / downside_std * np.sqrt(365.25)

# -----------------------
# Timer function for next rebalance date
# -----------------------
def calculate_next_rebalance_date(rebalancing_frequency, last_rebalance_date):
    """
    Calculate the next rebalance date based on rebalancing frequency and last rebalance date.
    Excludes today and yesterday as mentioned in the requirements.
    """
    if not last_rebalance_date or rebalancing_frequency == 'none':
        return None, None, None
    
    # Convert to datetime if it's a pandas Timestamp
    if hasattr(last_rebalance_date, 'to_pydatetime'):
        last_rebalance_date = last_rebalance_date.to_pydatetime()
    
    today = datetime.now().date()
    yesterday = today - timedelta(days=1)
    
    # If last rebalance was today or yesterday, use the day before yesterday as base
    if last_rebalance_date.date() >= yesterday:
        base_date = yesterday - timedelta(days=1)
    else:
        base_date = last_rebalance_date.date()
    
    # Calculate next rebalance date based on frequency
    if rebalancing_frequency == 'market_day':
        # Next market day (simplified - just next day for now)
        next_date = base_date + timedelta(days=1)
    elif rebalancing_frequency == 'calendar_day':
        next_date = base_date + timedelta(days=1)
    elif rebalancing_frequency == 'week':
        next_date = base_date + timedelta(weeks=1)
    elif rebalancing_frequency == '2weeks':
        next_date = base_date + timedelta(weeks=2)
    elif rebalancing_frequency == 'month':
        # Add one month - handle month overflow safely
        try:
            if base_date.month == 12:
                next_date = base_date.replace(year=base_date.year + 1, month=1)
            else:
                next_date = base_date.replace(month=base_date.month + 1)
        except ValueError:
            # Handle invalid day for target month (e.g., day 31 in February)
            next_date = base_date.replace(month=base_date.month + 1, day=1)
            # Try to find a valid day in the target month
            while True:
                try:
                    next_date = next_date.replace(day=base_date.day)
                    break
                except ValueError:
                    next_date = next_date.replace(day=next_date.day - 1)
                    if next_date.day == 1:
                        break
    elif rebalancing_frequency == '3months':
        # Add three months - handle month overflow safely
        try:
            new_month = base_date.month + 3
            new_year = base_date.year + (new_month - 1) // 12
            new_month = ((new_month - 1) % 12) + 1
            next_date = base_date.replace(year=new_year, month=new_month)
        except ValueError:
            # Handle invalid day for target month
            new_month = base_date.month + 3
            new_year = base_date.year + (new_month - 1) // 12
            new_month = ((new_month - 1) % 12) + 1
            next_date = base_date.replace(year=new_year, month=new_month, day=1)
            # Try to find a valid day in the target month
            while True:
                try:
                    next_date = next_date.replace(day=base_date.day)
                    break
                except ValueError:
                    next_date = next_date.replace(day=next_date.day - 1)
                    if next_date.day == 1:
                        break
    elif rebalancing_frequency == '6months':
        # Add six months - handle month overflow safely
        try:
            new_month = base_date.month + 6
            new_year = base_date.year + (new_month - 1) // 12
            new_month = ((new_month - 1) % 12) + 1
            next_date = base_date.replace(year=new_year, month=new_month)
        except ValueError:
            # Handle invalid day for target month
            new_month = base_date.month + 6
            new_year = base_date.year + (new_month - 1) % 12
            new_month = ((new_month - 1) % 12) + 1
            next_date = base_date.replace(year=new_year, month=new_month, day=1)
            # Try to find a valid day in the target month
            while True:
                try:
                    next_date = next_date.replace(day=base_date.day)
                    break
                except ValueError:
                    next_date = next_date.replace(day=next_date.day - 1)
                    if next_date.day == 1:
                        break
    elif rebalancing_frequency == 'year':
        next_date = base_date.replace(year=base_date.year + 1)
    else:
        return None, None, None
    
    # Calculate time until next rebalance
    now = datetime.now()
    # Ensure both datetimes are offset-naive for comparison and subtraction
    if hasattr(next_date, 'tzinfo') and next_date.tzinfo is not None:
        next_date = next_date.replace(tzinfo=None)
    next_rebalance_datetime = datetime.combine(next_date, time(9, 30))  # Assume 9:30 AM market open
    if hasattr(next_rebalance_datetime, 'tzinfo') and next_rebalance_datetime.tzinfo is not None:
        next_rebalance_datetime = next_rebalance_datetime.replace(tzinfo=None)
    if hasattr(now, 'tzinfo') and now.tzinfo is not None:
        now = now.replace(tzinfo=None)
    # If next rebalance is in the past, calculate the next one iteratively instead of recursively
    max_iterations = 10  # Prevent infinite loops
    iteration = 0
    while next_rebalance_datetime <= now and iteration < max_iterations:
        iteration += 1
        if rebalancing_frequency in ['market_day', 'calendar_day']:
            next_date = next_date + timedelta(days=1)
        elif rebalancing_frequency == 'week':
            next_date = next_date + timedelta(weeks=1)
        elif rebalancing_frequency == '2weeks':
            next_date = next_date + timedelta(weeks=2)
        elif rebalancing_frequency == 'month':
            # Add one month safely
            if next_date.month == 12:
                next_date = next_date.replace(year=next_date.year + 1, month=1)
            else:
                next_date = next_date.replace(month=next_date.month + 1)
            # Handle day overflow
            try:
                next_date = next_date.replace(day=min(next_date.day, 28))
            except ValueError:
                next_date = next_date.replace(day=1)
        elif rebalancing_frequency == '3months':
            # Add three months safely
            new_month = next_date.month + 3
            new_year = next_date.year + (new_month - 1) // 12
            new_month = ((new_month - 1) % 12) + 1
            next_date = next_date.replace(year=new_year, month=new_month, day=1)
        elif rebalancing_frequency == '6months':
            # Add six months safely
            new_month = next_date.month + 6
            new_year = next_date.year + (new_month - 1) // 12
            new_month = ((new_month - 1) % 12) + 1
            next_date = next_date.replace(year=new_year, month=new_month, day=1)
        elif rebalancing_frequency == 'year':
            next_date = next_date.replace(year=next_date.year + 1)
        
        next_rebalance_datetime = datetime.combine(next_date, time(9, 30))
    
    time_until = next_rebalance_datetime - now
    
    return next_date, time_until, next_rebalance_datetime

def format_time_until(time_until):
    """Format the time until next rebalance in a human-readable format."""
    if not time_until:
        return "Unknown"
    
    total_seconds = int(time_until.total_seconds())
    days = total_seconds // 86400
    hours = (total_seconds % 86400) // 3600
    minutes = (total_seconds % 3600) // 60
    
    if days > 0:
        return f"{days} days, {hours} hours, {minutes} minutes"
    elif hours > 0:
        return f"{hours} hours, {minutes} minutes"
    else:
        return f"{minutes} minutes"

# FIXED: Correct Ulcer Index calculation - EXACTLY like Backtest_Engine.py
def calculate_ulcer_index(series):
    """Calculates the Ulcer Index (average squared percent drawdown, then sqrt)."""
    if series.empty:
        return np.nan
    peak = series.expanding(min_periods=1).max()
    drawdown = (series - peak) / peak * 100  # percent drawdown
    drawdown_sq = drawdown ** 2
    return np.sqrt(drawdown_sq.mean())

# FIXED: Correct Sharpe ratio calculation - EXACTLY like Backtest_Engine.py
def calculate_sharpe(returns, risk_free_rate):
    """Calculates the Sharpe ratio."""
    # Create a constant risk-free rate series aligned with returns
    daily_rf_rate = risk_free_rate / 365.25
    rf_series = pd.Series(daily_rf_rate, index=returns.index)
    
    aligned_returns, aligned_rf = returns.align(rf_series, join='inner')
    if aligned_returns.empty:
        return np.nan
    
    excess_returns = aligned_returns - aligned_rf
    if excess_returns.std() == 0:
        return np.nan
        
    return excess_returns.mean() / excess_returns.std() * np.sqrt(365.25)

# FIXED: Correct UPI calculation - EXACTLY like Backtest_Engine.py
def calculate_upi(cagr, ulcer_index):
    """Calculates the Ulcer Performance Index (UPI = CAGR / Ulcer Index, both as decimals)."""
    if ulcer_index is None or pd.isna(ulcer_index) or ulcer_index == 0:
        return np.nan
    return cagr / (ulcer_index / 100)

def calculate_total_money_added(config, start_date, end_date):
    """Calculate total money added to portfolio (initial + periodic additions)"""
    if start_date is None or end_date is None:
        return "N/A"
    
    # Initial investment
    initial_value = config.get('initial_value', 0)
    
    # Calculate periodic additions
    added_amount = config.get('added_amount', 0)
    added_frequency = config.get('added_frequency', 'None')
    
    if added_frequency in ['None', 'Never', 'none', None] or added_amount == 0:
        return initial_value
    
    # Get dates when additions were made
    dates_added = get_dates_by_freq(added_frequency, start_date, end_date, pd.date_range(start_date, end_date, freq='D'))
    
    # Count additions (excluding the first date which is initial investment)
    num_additions = len([d for d in dates_added if d != start_date])
    total_additions = num_additions * added_amount
    
    return initial_value + total_additions

# -----------------------
# PERFORMANCE OPTIMIZATIONS (Safe - No Logic Changes)
# -----------------------

@jit(nopython=True)
def fast_calculate_returns(prices):
    """Fast calculation of price changes using Numba JIT"""
    returns = np.zeros_like(prices)
    for i in range(1, len(prices)):
        if prices[i-1] > 0:
            returns[i] = (prices[i] - prices[i-1]) / prices[i-1]
    return returns

@jit(nopython=True)
def fast_momentum_calculation(returns, window):
    """Fast momentum calculation using Numba JIT"""
    momentum = np.zeros_like(returns)
    for i in range(window, len(returns)):
        momentum[i] = np.sum(returns[i-window+1:i+1])
    return momentum

def calculate_ema(df, window):
    """
    Calculate Exponential Moving Average for a given window.
    
    Args:
        df: DataFrame with 'Close' column
        window: Number of periods for EMA calculation
        
    Returns:
        Series with EMA values
    """
    if df is None or not isinstance(df, pd.DataFrame):
        return None
    if 'Close' not in df.columns:
        return None
    # EMA uses standard formula: multiplier = 2 / (window + 1)
    return df['Close'].ewm(span=window, adjust=False, min_periods=window).mean()

def calculate_sma(df, window):
    """
    Calculate Simple Moving Average for a given window.
    
    Args:
        df: DataFrame with 'Close' column
        window: Number of periods for SMA calculation
        
    Returns:
        Series with SMA values
    """
    if df is None or not isinstance(df, pd.DataFrame):
        return None
    if 'Close' not in df.columns:
        return None
    return df['Close'].rolling(window=window, min_periods=window).mean()

def precompute_ma_columns(reindexed_data, ma_window, ma_type='SMA', ma_multiplier=1.48):
    """
    Precompute MA columns for all tickers once at the start.
    This is the key optimization - compute MA once instead of every day!
    
    Args:
        ma_multiplier: Multiplier to convert market days to calendar days (default 1.48)
                      Since data uses ffill, we need more calendar days to get market days
    """
    ma_col_name = f"MA_{ma_type}_{ma_window}"
    
    for ticker, df in reindexed_data.items():
        if df is None or not isinstance(df, pd.DataFrame) or 'Close' not in df.columns:
            continue
            
        # Only compute if column doesn't exist
        if ma_col_name not in df.columns:
            try:
                if ma_type == 'EMA':
                    df[ma_col_name] = df['Close'].ewm(span=ma_window, adjust=False, min_periods=ma_window).mean()
                else:  # SMA
                    # Apply multiplier to approximate market days from calendar days
                    adjusted_window = int(ma_window * ma_multiplier)
                    df[ma_col_name] = df['Close'].rolling(window=adjusted_window, min_periods=adjusted_window).mean()
            except Exception:
                # If MA cannot be computed, skip this ticker
                continue

def precompute_ma_crossings(reindexed_data, ma_window, ma_type='SMA', tolerance_percent=2.0, confirmation_days=3):
    """
    ULTRA OPTIMIZATION: Precompute ALL MA crossings once at the start!
    This eliminates the need to check crossings every day during backtest.
    
    Returns:
        dict: {date: {ticker: cross_info}} for all dates with confirmed crossings
    """
    ma_col_name = f"MA_{ma_type}_{ma_window}"
    crossings_data = {}
    tolerance_ratio = 1 + (tolerance_percent / 100.0)
    
    for ticker, df in reindexed_data.items():
        if df is None or ma_col_name not in df.columns:
            continue
            
        # Get price and MA series
        prices = df['Close']
        ma_values = df[ma_col_name]
        
        # Find all significant crossings
        for i in range(1, len(df)):
            if pd.isna(prices.iloc[i]) or pd.isna(ma_values.iloc[i]):
                continue
                
            current_price = prices.iloc[i]
            current_ma = ma_values.iloc[i]
            current_ratio = current_price / current_ma
            
            # Check if crossing is significant
            significant_above = current_ratio >= tolerance_ratio
            significant_below = current_ratio <= (1.0 / tolerance_ratio)
            
            if significant_above or significant_below:
                # Check confirmation
                if confirmation_days == 0:
                    # Immediate confirmation
                    date = df.index[i]
                    if date not in crossings_data:
                        crossings_data[date] = {}
                    crossings_data[date][ticker] = {
                        'type': 'above' if significant_above else 'below',
                        'price': current_price,
                        'ma': current_ma,
                        'ratio': current_ratio
                    }
                else:
                    # Check if crossing persists for confirmation_days
                    confirmed = True
                    for j in range(1, confirmation_days + 1):
                        if i - j < 0:
                            confirmed = False
                            break
                        hist_price = prices.iloc[i - j]
                        hist_ma = ma_values.iloc[i - j]
                        if pd.isna(hist_price) or pd.isna(hist_ma):
                            confirmed = False
                            break
                        hist_ratio = hist_price / hist_ma
                        if significant_above and hist_ratio < tolerance_ratio:
                            confirmed = False
                            break
                        if significant_below and hist_ratio > (1.0 / tolerance_ratio):
                            confirmed = False
                            break
                    
                    if confirmed:
                        date = df.index[i]
                        if date not in crossings_data:
                            crossings_data[date] = {}
                        crossings_data[date][ticker] = {
                            'type': 'above' if significant_above else 'below',
                            'price': current_price,
                            'ma': current_ma,
                            'ratio': current_ratio
                        }
    
    return crossings_data

def precompute_ma_filters(reindexed_data, ma_window, ma_type='SMA', ma_multiplier=1.48, stocks_config=None):
    """
    ULTRA OPTIMIZATION: Precompute ALL MA filter results for all dates!
    This eliminates the need to check MA filters every day during backtest.
    
    Returns:
        dict: {date: {ticker: is_above_ma}} for all dates and tickers
    """
    ma_col_name = f"MA_{ma_type}_{ma_window}"
    filter_results = {}
    
    # Create mappings from stocks_config
    include_in_ma = {}
    ma_reference = {}
    if stocks_config:
        for stock in stocks_config:
            ticker = stock.get('ticker')
            if ticker:
                include_in_ma[ticker] = stock.get('include_in_sma_filter', True)
                ref = stock.get('ma_reference_ticker', '').strip()
                if ref:
                    ref = resolve_ticker_alias(ref)
                ma_reference[ticker] = ref if ref else ticker
    
    # Get all unique dates from all tickers
    all_dates = set()
    for df in reindexed_data.values():
        if df is not None and isinstance(df, pd.DataFrame):
            all_dates.update(df.index)
    
    all_dates = sorted(list(all_dates))
    
    for date in all_dates:
        filter_results[date] = {}
        
        for ticker, df in reindexed_data.items():
            if df is None or not isinstance(df, pd.DataFrame) or 'Close' not in df.columns:
                filter_results[date][ticker] = True  # Include by default
                continue
            
            # Check if ticker should be included in MA filter
            is_included = include_in_ma.get(ticker, True)
            if not is_included:
                filter_results[date][ticker] = True  # Include if not in filter
                continue
            
            # Get reference ticker
            reference_ticker = ma_reference.get(ticker, ticker)
            df_ref = reindexed_data.get(reference_ticker)
            
            if df_ref is None or ma_col_name not in df_ref.columns:
                filter_results[date][ticker] = True  # Include by default
                continue
            
            # Check if we have enough data
            required_days = int(ma_window * ma_multiplier)
            df_ref_up_to_date = df_ref[df_ref.index <= date]
            if len(df_ref_up_to_date) < required_days:
                filter_results[date][ticker] = True  # Include by default
                continue
            
            try:
                # Get current price and MA
                if date in df_ref.index:
                    current_price = df_ref.loc[date, 'Close']
                    current_ma = df_ref.loc[date, ma_col_name]
                else:
                    current_price = df_ref_up_to_date['Close'].iloc[-1]
                    current_ma = df_ref_up_to_date[ma_col_name].iloc[-1]
                
                if pd.isna(current_price) or pd.isna(current_ma):
                    filter_results[date][ticker] = True  # Include by default
                else:
                    filter_results[date][ticker] = current_price >= current_ma
            except Exception:
                filter_results[date][ticker] = True  # Include by default
    
    return filter_results

def detect_ma_cross_with_anti_whipsaw(valid_assets, reindexed_data, date, ma_window, ma_type='SMA', config=None, stocks_config=None, tolerance_percent=2.0, confirmation_days=3):
    """
    Detect if any ticker has crossed its Moving Average with anti-whipsaw filtering.
    
    Args:
        valid_assets: List of tickers to check
        reindexed_data: Dict of ticker -> DataFrame
        date: Current date for checking
        ma_window: MA window in days (e.g., 200 for 200-day MA)
        ma_type: Type of moving average - 'SMA' or 'EMA'
        config: Optional config dict
        stocks_config: List of stock configs with include_in_ma_filter and ma_reference_ticker options
        tolerance_percent: Percentage band that price must exceed MA by (default 2.0%)
        confirmation_days: Number of days the crossing must persist (default 3)
        
    Returns:
        crossed_assets: List of tickers that crossed their MA with confirmation
        cross_details: Dict of ticker -> cross information
    """
    if not valid_assets or ma_window <= 0:
        return [], {}
    
    crossed_assets = []
    cross_details = {}
    
    # Create mappings from stocks_config
    include_in_ma = {}
    ma_reference = {}
    if stocks_config:
        for stock in stocks_config:
            ticker = stock.get('ticker')
            if ticker:
                include_in_ma[ticker] = stock.get('include_in_sma_filter', True)
                ref = stock.get('ma_reference_ticker', '').strip()
                if ref:
                    ref = resolve_ticker_alias(ref)
                ma_reference[ticker] = ref if ref else ticker
    
    for ticker in valid_assets:
        is_included = include_in_ma.get(ticker, True)
        if not is_included:
            continue
            
        reference_ticker = ma_reference.get(ticker, ticker)
        
        # Get reference ticker's data for MA calculation
        df_ref = reindexed_data.get(reference_ticker)
        if df_ref is None or not isinstance(df_ref, pd.DataFrame):
            continue
        
        # Get data up to current date
        df_ref_up_to_date = df_ref[df_ref.index <= date]
        
        # Use precomputed MA column - this is the key optimization!
        ma_col_name = f"MA_{ma_type}_{ma_window}"
        if ma_col_name not in df_ref.columns:
            # MA not precomputed, skip this ticker
            continue
        
        # Get MA from precomputed column
        ma = df_ref[ma_col_name]
        
        # Need enough data for confirmation period
        if len(df_ref_up_to_date) < max(confirmation_days, 1):
            continue
            
        if ma is None or len(ma) < confirmation_days + 1:
            continue
        
        try:
            # Get current price and MA from precomputed data
            if date in df_ref.index:
                current_price = df_ref.loc[date, 'Close']
                current_ma = df_ref.loc[date, ma_col_name]
            else:
                # If exact date not found, use the last available values
                current_price = df_ref_up_to_date['Close'].iloc[-1]
                current_ma = df_ref_up_to_date[ma_col_name].iloc[-1]
            
            if pd.isna(current_price) or pd.isna(current_ma):
                continue
            
            # Check if price exceeds MA by tolerance percentage
            price_ma_ratio = current_price / current_ma
            tolerance_ratio = 1 + (tolerance_percent / 100.0)
            
            # Check if crossing is significant enough (above tolerance band)
            significant_above = price_ma_ratio >= tolerance_ratio
            significant_below = price_ma_ratio <= (1.0 / tolerance_ratio)
            
            if significant_above or significant_below:
                # Check if this crossing has persisted for confirmation_days
                crossing_confirmed = True
                cross_direction = "above" if significant_above else "below"
                
                # If confirmation_days = 0, no confirmation needed (immediate)
                if confirmation_days == 0:
                    crossing_confirmed = True
                else:
                    # Look back confirmation_days to see if crossing has been consistent
                    for i in range(1, confirmation_days + 1):
                        if len(df_ref_up_to_date) <= i:
                            crossing_confirmed = False
                            break
                        
                        # Get historical data from precomputed columns
                        hist_price = df_ref_up_to_date['Close'].iloc[-(i+1)]
                        hist_ma = df_ref_up_to_date[ma_col_name].iloc[-(i+1)]
                        
                        if pd.isna(hist_price) or pd.isna(hist_ma):
                            crossing_confirmed = False
                            break
                        
                        # Check if historical crossing was in same direction
                        hist_ratio = hist_price / hist_ma
                        if cross_direction == "above":
                            if hist_ratio < tolerance_ratio:
                                crossing_confirmed = False
                                break
                        else:  # below
                            if hist_ratio > (1.0 / tolerance_ratio):
                                crossing_confirmed = False
                                break
                
                if crossing_confirmed:
                    crossed_assets.append(ticker)
                    cross_details[ticker] = {
                        'type': cross_direction,
                        'current_price': current_price,
                        'current_ma': current_ma,
                        'price_ma_ratio': price_ma_ratio,
                        'tolerance_ratio': tolerance_ratio,
                        'confirmation_days': confirmation_days,
                        'reference_ticker': reference_ticker
                    }
                
        except Exception as e:
            continue
    
    return crossed_assets, cross_details

def detect_ma_cross(valid_assets, reindexed_data, date, ma_window, ma_type='SMA', config=None, stocks_config=None):
    """
    Detect if any ticker has crossed its Moving Average (SMA or EMA) between previous and current date.
    
    Args:
        valid_assets: List of tickers to check
        reindexed_data: Dict of ticker -> DataFrame
        date: Current date for checking
        ma_window: MA window in days (e.g., 200 for 200-day MA)
        ma_type: Type of moving average - 'SMA' or 'EMA'
        config: Optional config dict
        stocks_config: List of stock configs with include_in_ma_filter and ma_reference_ticker options
        
    Returns:
        crossed_assets: List of tickers that crossed their MA
        cross_details: Dict of ticker -> cross information
    """
    if not valid_assets or ma_window <= 0:
        return [], {}
    
    crossed_assets = []
    cross_details = {}
    
    # Create mappings from stocks_config
    include_in_ma = {}
    ma_reference = {}
    if stocks_config:
        for stock in stocks_config:
            ticker = stock.get('ticker')
            if ticker:
                include_in_ma[ticker] = stock.get('include_in_sma_filter', True)
                ref = stock.get('ma_reference_ticker', '').strip()
                if ref:
                    ref = resolve_ticker_alias(ref)
                ma_reference[ticker] = ref if ref else ticker
    
    for ticker in valid_assets:
        is_included = include_in_ma.get(ticker, True)
        if not is_included:
            continue
            
        reference_ticker = ma_reference.get(ticker, ticker)
        
        # Get reference ticker's data for MA calculation
        df_ref = reindexed_data.get(reference_ticker)
        if df_ref is None or not isinstance(df_ref, pd.DataFrame):
            continue
        
        # Get data up to current date
        df_ref_up_to_date = df_ref[df_ref.index <= date]
        
        # Use precomputed MA column - this is the key optimization!
        ma_col_name = f"MA_{ma_type}_{ma_window}"
        if ma_col_name not in df_ref.columns:
            # MA not precomputed, skip this ticker
            continue
        
        # Get MA from precomputed column
        ma = df_ref[ma_col_name]
        
        if len(df_ref_up_to_date) < 2:  # Need at least 2 days for comparison
            continue
            
        if ma is None or len(ma) < 2:
            continue
        
        try:
            # Get current and previous prices and MA values from precomputed data
            if date in df_ref.index:
                current_price = df_ref.loc[date, 'Close']
                current_ma = df_ref.loc[date, ma_col_name]
                # Get previous day data
                prev_date = df_ref.index[df_ref.index < date][-1] if len(df_ref.index[df_ref.index < date]) > 0 else None
                if prev_date is not None:
                    previous_price = df_ref.loc[prev_date, 'Close']
                    previous_ma = df_ref.loc[prev_date, ma_col_name]
                else:
                    continue
            else:
                # If exact date not found, use the last available values
                current_price = df_ref_up_to_date['Close'].iloc[-1]
                previous_price = df_ref_up_to_date['Close'].iloc[-2]
                current_ma = df_ref_up_to_date[ma_col_name].iloc[-1]
                previous_ma = df_ref_up_to_date[ma_col_name].iloc[-2]
            
            if pd.isna(current_price) or pd.isna(previous_price) or pd.isna(current_ma) or pd.isna(previous_ma):
                continue
            
            # Check for cross: price crosses MA (either direction)
            current_above = current_price >= current_ma
            previous_above = previous_price >= previous_ma
            
            # Cross detected if the relationship changed
            if current_above != previous_above:
                crossed_assets.append(ticker)
                cross_type = "above" if current_above else "below"
                cross_details[ticker] = {
                    'type': cross_type,
                    'current_price': current_price,
                    'current_ma': current_ma,
                    'previous_price': previous_price,
                    'previous_ma': previous_ma,
                    'reference_ticker': reference_ticker
                }
                
        except Exception as e:
            continue
    
    return crossed_assets, cross_details

def filter_assets_by_ma(valid_assets, reindexed_data, date, ma_window, ma_type='SMA', config=None, stocks_config=None):
    """
    Filter out assets that are below their Moving Average (SMA or EMA).
    Now supports using a different ticker's MA as reference!
    
    Args:
        valid_assets: List of tickers to filter
        reindexed_data: Dict of ticker -> DataFrame
        date: Current date for filtering
        ma_window: MA window in days (e.g., 200 for 200-day MA)
        ma_type: Type of moving average - 'SMA' or 'EMA'
        config: Optional config dict
        stocks_config: List of stock configs with include_in_ma_filter and ma_reference_ticker options
        
    Returns:
        filtered_assets: List of tickers above their MA
        excluded_assets: Dict of ticker -> reason for exclusion
    """
    if not valid_assets or ma_window <= 0:
        return valid_assets, {}
    
    filtered_assets = []
    excluded_assets = {}
    tickers_with_enough_data = []
    
    # Create mappings from stocks_config
    include_in_ma = {}
    ma_reference = {}
    if stocks_config:
        for stock in stocks_config:
            ticker = stock.get('ticker')
            if ticker:
                # Keep backward compatibility with 'include_in_sma_filter'
                include_in_ma[ticker] = stock.get('include_in_sma_filter', True)
                # Get MA reference ticker (empty or None means use ticker itself)
                ref = stock.get('ma_reference_ticker', '').strip()
                # Resolve alias if a custom reference is provided (e.g., TLTTR -> TLT_COMPLETE)
                if ref:
                    ref = resolve_ticker_alias(ref)
                ma_reference[ticker] = ref if ref else ticker
    
    for ticker in valid_assets:
        is_included = include_in_ma.get(ticker, True)
        # Check if this ticker should be excluded from MA filter (not included)
        if not is_included:
            filtered_assets.append(ticker)
            continue
            
        # Get MA reference ticker (default to self)
        reference_ticker = ma_reference.get(ticker, ticker)
        
        # Get ticker's price data (kept for validation even though we use reference price)
        df = reindexed_data.get(ticker)
        if df is None or not isinstance(df, pd.DataFrame):
            filtered_assets.append(ticker)
            continue
        
        # Get reference ticker's data for MA calculation
        df_ref = reindexed_data.get(reference_ticker)
        if df_ref is None or not isinstance(df_ref, pd.DataFrame):
            # Reference ticker not available - this is OK if user specified a different reference
            # (e.g., SPY uses QQQ for MA, but QQQ starts later)
            # In this case, include the asset without MA filtering
            if reference_ticker != ticker:
                filtered_assets.append(ticker)
                continue
            else:
                # If reference is same as ticker and no data, skip
                filtered_assets.append(ticker)
                continue
        
        # Get data up to current date
        df_up_to_date = df[df.index <= date]
        df_ref_up_to_date = df_ref[df_ref.index <= date]
        
        # For 200 SMA, we need adjusted window based on multiplier
        # Get multiplier from config or use default
        ma_multiplier = config.get('ma_multiplier', 1.48) if config else 1.48
        required_days = int(ma_window * ma_multiplier)
        if len(df_ref_up_to_date) < required_days:
            # Not enough data to calculate MA on reference
            # Include by default (no filter) - MA filter will kick in once enough data
            filtered_assets.append(ticker)
            continue
        
        # Mark that this ticker has enough data for MA calculation
        tickers_with_enough_data.append(ticker)
        
        # Use precomputed MA column - this is the key optimization!
        ma_col_name = f"MA_{ma_type}_{ma_window}"
        if ma_col_name not in df_ref.columns:
            # MA not precomputed, include by default
            filtered_assets.append(ticker)
            continue
        
        # Get current price and MA value at date
        try:
            current_price = df_ref_up_to_date['Close'].iloc[-1]
            
            # CRITICAL FIX: Get MA value from the full series at the exact date
            # The MA was calculated on the full df_ref, so we need to get it from there
            if date in df_ref.index:
                current_ma = df_ref.loc[date, ma_col_name]
            else:
                # If exact date not found, use the last available MA value
                current_ma = df_ref_up_to_date[ma_col_name].iloc[-1]
            
            if pd.isna(current_price) or pd.isna(current_ma):
                filtered_assets.append(ticker)
                continue
            
            # Include only if REFERENCE ticker's price is above REFERENCE ticker's MA
            if current_price >= current_ma:
                filtered_assets.append(ticker)
            else:
                ref_label = f" (using {reference_ticker})" if reference_ticker != ticker else ""
                excluded_assets[ticker] = f"Below {ma_window}-day {ma_type}{ref_label} ({current_price:.2f} < {current_ma:.2f})"
        except Exception as e:
            # If any error, include by default
            filtered_assets.append(ticker)
    
    # SIMPLE LOGIC: Return whatever assets are still active (above MA or excluded from filter)
    # NO "go to cash" logic - that's handled in the rebalancing
    return filtered_assets, excluded_assets

def make_config_hashable(config):
    """Convert config dict to hashable tuple for caching"""
    import json
    try:
        # Convert config to JSON string (hashable)
        # Remove non-hashable items and convert to tuple
        config_copy = {}
        for key, value in config.items():
            if key == 'stocks':
                # Convert stocks list to tuple of tuples
                config_copy[key] = tuple(tuple(sorted(s.items())) for s in value)
            elif isinstance(value, list):
                # Convert lists to tuples
                if value and isinstance(value[0], dict):
                    config_copy[key] = tuple(tuple(sorted(d.items())) for d in value)
                else:
                    config_copy[key] = tuple(value)
            elif isinstance(value, dict):
                config_copy[key] = tuple(sorted(value.items()))
            else:
                config_copy[key] = value
        return tuple(sorted(config_copy.items()))
    except:
        # Fallback: use JSON string
        return json.dumps(config, sort_keys=True, default=str)

def make_data_hash(reindexed_data):
    """Create a hash of reindexed_data for caching"""
    try:
        # Create hash based on tickers and data shapes
        hash_parts = []
        for ticker in sorted(reindexed_data.keys()):
            df = reindexed_data[ticker]
            if hasattr(df, 'shape'):
                hash_parts.append(f"{ticker}_{df.shape[0]}_{df.shape[1]}")
        return "_".join(hash_parts)
    except:
        return str(len(reindexed_data))

def cached_momentum_calculation(ticker, start_date_str, end_date_str, lookback_days, exclude_days, reindexed_data_hash):
    """
    Cache momentum calculations to avoid recomputation.
    Uses string dates and hash for caching.
    Returns momentum return value.
    """
    try:
        # This would need the actual data passed in or accessed globally
        # For now, this is a placeholder that returns None
        # The actual calculation happens inline in single_backtest
        return None
    except:
        return None

def cached_beta_calculation(ticker, benchmark, start_date_str, end_date_str, window_days, exclude_days, reindexed_data_hash):
    """
    Cache beta calculations to avoid recomputation.
    Returns beta value.
    """
    try:
        return None  # Placeholder
    except:
        return None

def cached_volatility_calculation(ticker, start_date_str, end_date_str, window_days, exclude_days, reindexed_data_hash):
    """
    Cache volatility calculations to avoid recomputation.
    Returns volatility value (annualized).
    """
    try:
        return None  # Placeholder
    except:
        return None

# -----------------------
# Single-backtest core (adapted from your code, robust)
# -----------------------
def single_backtest(config, sim_index, reindexed_data, _cache_version="v2_daily_allocations"):
    
    stocks_list = config['stocks']
    tickers = [s['ticker'] for s in stocks_list if s['ticker']]
    # Filter tickers to those present in reindexed_data to avoid KeyErrors for invalid tickers
    available_tickers = [t for t in tickers if t in reindexed_data]
    if len(available_tickers) < len(tickers):
        missing = set(tickers) - set(available_tickers)
    tickers = available_tickers
    # Recompute allocations and include_dividends to only include valid tickers
    # Handle duplicate tickers by summing their allocations
    allocations = {}
    include_dividends = {}
    for s in stocks_list:
        if s.get('ticker') and s.get('ticker') in tickers:
            ticker = s['ticker']
            allocation = s.get('allocation', 0)
            include_div = s.get('include_dividends', False)
            
            if ticker in allocations:
                # If ticker already exists, add the allocation
                allocations[ticker] += allocation
                # For include_dividends, use True if any instance has it True
                include_dividends[ticker] = include_dividends[ticker] or include_div
            else:
                # First occurrence of this ticker
                allocations[ticker] = allocation
                include_dividends[ticker] = include_div
    
    # Update tickers to only include unique tickers after deduplication
    tickers = list(allocations.keys())
    benchmark_ticker = config['benchmark_ticker']
    initial_value = config.get('initial_value', 0)
    added_amount = config.get('added_amount', 0)
    added_frequency = config.get('added_frequency', 'none')
    rebalancing_frequency = config.get('rebalancing_frequency', 'none')
    use_momentum = config.get('use_momentum', True)
    momentum_windows = config.get('momentum_windows', [])
    calc_beta = config.get('calc_beta', False)
    calc_volatility = config.get('calc_volatility', False)
    beta_window_days = config.get('beta_window_days', 365)
    exclude_days_beta = config.get('exclude_days_beta', 30)
    vol_window_days = config.get('vol_window_days', 365)
    exclude_days_vol = config.get('exclude_days_vol', 30)
    current_data = {t: reindexed_data[t] for t in tickers + [benchmark_ticker] if t in reindexed_data}
    dates_added = get_dates_by_freq(added_frequency, sim_index[0], sim_index[-1], sim_index)
    
    # Get regular rebalancing dates
    dates_rebal = sorted(get_dates_by_freq(rebalancing_frequency, sim_index[0], sim_index[-1], sim_index))
    
    # OPTIMIZATION: Precompute MA columns once at the start if MA filter OR MA cross rebalancing is enabled
    # This is the key performance improvement - compute MA once instead of every day!
    ma_crossings_data = None
    ma_filter_data = None
    if config.get('use_sma_filter', False) or config.get('ma_cross_rebalance', False):
        ma_window = config.get('sma_window', 200)
        ma_type = config.get('ma_type', 'SMA')
        ma_multiplier = config.get('ma_multiplier', 1.48)  # Default multiplier for market days
        precompute_ma_columns(reindexed_data, ma_window, ma_type, ma_multiplier)
        
        # ULTRA OPTIMIZATION: Precompute ALL MA filters if MA filter is enabled
        if config.get('use_sma_filter', False):
            ma_filter_data = precompute_ma_filters(reindexed_data, ma_window, ma_type, ma_multiplier, config.get('stocks', []))
        
        # ULTRA OPTIMIZATION: Precompute ALL MA crossings if MA cross rebalancing is enabled
        if config.get('ma_cross_rebalance', False):
            tolerance_percent = config.get('ma_tolerance_percent', 2.0)
            confirmation_days = config.get('ma_confirmation_days', 3)
            ma_crossings_data = precompute_ma_crossings(reindexed_data, ma_window, ma_type, tolerance_percent, confirmation_days)
    
    # Handle first rebalance strategy - replace first rebalance date if needed
    first_rebalance_strategy = st.session_state.get('multi_backtest_first_rebalance_strategy', 'momentum_window_complete')
    if first_rebalance_strategy == "momentum_window_complete" and use_momentum and momentum_windows:
        try:
            # Calculate when momentum window completes
            window_sizes = [int(w.get('lookback', 0)) for w in momentum_windows if w is not None]
            max_window_days = max(window_sizes) if window_sizes else 0
            momentum_completion_date = sim_index[0] + pd.Timedelta(days=max_window_days)
            
            # Find the closest trading day to momentum completion
            momentum_completion_trading_day = sim_index[sim_index >= momentum_completion_date][0] if len(sim_index[sim_index >= momentum_completion_date]) > 0 else sim_index[-1]
            
            # Replace the first rebalancing date with momentum completion date
            if len(dates_rebal) > 0:
                # Remove the first rebalancing date and add momentum completion date
                dates_rebal = dates_rebal[1:] if len(dates_rebal) > 1 else []
                dates_rebal.insert(0, momentum_completion_trading_day)
                dates_rebal = sorted(dates_rebal)
        except Exception:
            pass  # Fall back to regular rebalancing dates

    # Dictionaries to store historical data for new tables
    historical_allocations = {}
    historical_metrics = {}
    
    # Precompute start dates for all tickers (same as Page 5)
    start_dates_config = {}
    for t in tickers:
        if t in reindexed_data and isinstance(reindexed_data.get(t), pd.DataFrame):
            fd = reindexed_data[t].first_valid_index()
            start_dates_config[t] = fd if fd is not None else pd.NaT
        else:
            start_dates_config[t] = pd.NaT

    def calculate_momentum(date, current_assets, momentum_windows, stocks_config=None):
        cumulative_returns, valid_assets = {}, []
        
        # Apply MA filter BEFORE calculating momentum (ULTRA OPTIMIZED!)
        assets_to_calculate = current_assets
        if config.get('use_sma_filter', False) and ma_filter_data is not None:
            # ULTRA FAST: Use precomputed filter results!
            filtered_assets = [t for t in current_assets if ma_filter_data.get(date, {}).get(t, True)]
            
            # If no assets remain after MA filtering, go to cash immediately
            if not filtered_assets:
                return {}, []
            
            # Only calculate momentum for filtered assets
            assets_to_calculate = filtered_assets
        else:
            # No MA filter - use all assets
            pass
        filtered_windows = [w for w in momentum_windows if w["weight"] > 0]
        # Normalize weights so they sum to 1 (same as app.py)
        total_weight = sum(w["weight"] for w in filtered_windows)
        if total_weight == 0:
            normalized_weights = [0 for _ in filtered_windows]
        else:
            normalized_weights = [w["weight"] / total_weight for w in filtered_windows]
        
        # Only consider assets that exist in current_data (filtered earlier)
        candidate_assets = [t for t in assets_to_calculate if t in current_data]
        
        # Calculate momentum only for SMA-filtered assets
        for t in candidate_assets:
            is_valid, asset_returns = True, 0.0
            df_t = current_data.get(t)
            if not (isinstance(df_t, pd.DataFrame) and 'Close' in df_t.columns and not df_t['Close'].dropna().empty):
                # no usable data for this ticker
                continue
            for idx, window in enumerate(filtered_windows):
                lookback, exclude = window["lookback"], window["exclude"]
                weight = normalized_weights[idx]
                start_mom = date - pd.Timedelta(days=lookback)
                end_mom = date - pd.Timedelta(days=exclude)
                sd = start_dates_config.get(t, pd.NaT)
                # If no start date or asset starts after required lookback, mark invalid
                if pd.isna(sd) or sd > start_mom:
                    is_valid = False
                    break
                try:
                    price_start_index = df_t.index.asof(start_mom)
                    price_end_index = df_t.index.asof(end_mom)
                except Exception:
                    is_valid = False
                    break
                if pd.isna(price_start_index) or pd.isna(price_end_index):
                    is_valid = False
                    break
                price_start = df_t.loc[price_start_index, "Close"]
                price_end = df_t.loc[price_end_index, "Close"]
                if pd.isna(price_start) or pd.isna(price_end) or price_start == 0:
                    is_valid = False
                    break
                
                # ACADEMIC FIX: Include dividends in momentum calculation if configured (Jegadeesh & Titman 1993)
                if include_dividends.get(t, False):
                    # Calculate cumulative dividends in the momentum window
                    divs_in_period = df_t.loc[price_start_index:price_end_index, "Dividends"].fillna(0).sum()
                    ret = ((price_end + divs_in_period) - price_start) / price_start
                else:
                    ret = (price_end - price_start) / price_start
                asset_returns += ret * weight
            if is_valid:
                cumulative_returns[t] = asset_returns
                valid_assets.append(t)
        
        return cumulative_returns, valid_assets

    def calculate_momentum_weights(returns, valid_assets, date, momentum_strategy='Classic', negative_momentum_strategy='Cash', config=None):
        # Mirror approach used in allocations/app.py: compute weights from raw momentum
        # (Classic or Relative) and then optionally post-filter by inverse volatility
        # and inverse absolute beta (multiplicative), then renormalize. This avoids
        # dividing by beta directly which flips signs when beta is negative.
        if not valid_assets:
            return {}, {}
        # Keep only non-nan momentum values
        rets = {t: returns.get(t, np.nan) for t in valid_assets}
        rets = {t: rets[t] for t in rets if not pd.isna(rets[t])}
        if not rets:
            return {}, {}

        metrics = {t: {} for t in rets.keys()}

        # compute beta and volatility metrics when requested
        beta_vals = {}
        vol_vals = {}
        # Get config parameters (same as in single_backtest)
        if config is None:
            config = {}
        calc_beta = config.get('calc_beta', False)
        calc_volatility = config.get('calc_volatility', False)
        benchmark_ticker = config.get('benchmark_ticker', '^GSPC')
        beta_window_days = config.get('beta_window_days', 365)
        exclude_days_beta = config.get('exclude_days_beta', 30)
        vol_window_days = config.get('vol_window_days', 365)
        exclude_days_vol = config.get('exclude_days_vol', 30)
        
        df_bench = reindexed_data.get(benchmark_ticker)
        if calc_beta:
            start_beta = date - pd.Timedelta(days=beta_window_days)
            end_beta = date - pd.Timedelta(days=exclude_days_beta)
        if calc_volatility:
            start_vol = date - pd.Timedelta(days=vol_window_days)
            end_vol = date - pd.Timedelta(days=exclude_days_vol)

        for t in list(rets.keys()):
            df_t = reindexed_data.get(t)
            if calc_beta and df_bench is not None and isinstance(df_t, pd.DataFrame):
                mask_beta = (df_t.index >= start_beta) & (df_t.index <= end_beta)
                returns_t_beta = df_t.loc[mask_beta, 'Price_change']
                mask_bench_beta = (df_bench.index >= start_beta) & (df_bench.index <= end_beta)
                returns_bench_beta = df_bench.loc[mask_bench_beta, 'Price_change']
                if len(returns_t_beta) < 2 or len(returns_bench_beta) < 2:
                    beta_vals[t] = np.nan
                else:
                    variance = np.var(returns_bench_beta)
                    beta_vals[t] = (np.cov(returns_t_beta, returns_bench_beta)[0,1] / variance) if variance > 0 else np.nan
                metrics[t]['Beta'] = beta_vals[t]
            if calc_volatility and isinstance(df_t, pd.DataFrame):
                mask_vol = (df_t.index >= start_vol) & (df_t.index <= end_vol)
                returns_t_vol = df_t.loc[mask_vol, 'Price_change']
                if len(returns_t_vol) < 2:
                    vol_vals[t] = np.nan
                else:
                    vol_vals[t] = returns_t_vol.std() * np.sqrt(365.25)
                metrics[t]['Volatility'] = vol_vals[t]

        # attach raw momentum
        for t in rets:
            metrics[t]['Momentum'] = rets[t]

        # Build initial weights from raw momentum (Classic or Relative)
        weights = {}
        rets_keys = list(rets.keys())
        all_negative = all(rets[t] <= 0 for t in rets_keys)
        relative_mode = isinstance(momentum_strategy, str) and momentum_strategy.lower().startswith('relat')
        
        # Calculate effective strategy for negative momentum (needed for equal weight logic)
        effective_strategy_for_equal_weight = None
        if all_negative:
            is_sp500top20 = any(is_special_dynamic_ticker(t) for t in rets_keys) or config.get('dynamic_portfolio_data') is not None
            effective_strategy_for_equal_weight = negative_momentum_strategy
            if is_sp500top20 and negative_momentum_strategy == 'Cash':
                effective_strategy_for_equal_weight = 'Relative momentum'

        def calculate_near_zero_symmetric_momentum(returns, neutral_zone=0.05):
            """
            Relative momentum avec zone neutre autour de 0 - VERSION AM√âLIOR√âE
            
            Avantages:
            - Les rendements dans [-5%, +5%] ont des allocations tr√®s similaires
            - Pas de biaisage par le pire actif
            - Compression progressive des actifs n√©gatifs
            - Traitement ind√©pendant de chaque ticker
            """
            import numpy as np
            import math
            
            returns_array = np.array(list(returns.values()))
            
            # NZS: Use relative ranking like Relative Momentum but with compression
            min_score = min(returns.values())
            offset = -min_score + 0.01 if min_score < 0 else 0.01
            shifted = {t: max(0.01, returns[t] + offset) for t in returns.keys()}
            
            # Apply NZS compression to the shifted scores
            compressed_scores = {}
            for ticker, shifted_val in shifted.items():
                return_val = returns[ticker]
                
                # Zone neutre : allocations similaires pour rendements proches de 0
                if abs(return_val) <= neutral_zone:
                    # Dans la zone neutre : allocations presque identiques
                    compression_factor = 1.0 - (abs(return_val) / neutral_zone) * 0.1
                else:
                    # Au-del√† de la zone neutre : compression progressive
                    if return_val < -neutral_zone:
                        # N√©gatif au-del√† de la zone neutre
                        excess_negativity = abs(return_val) - neutral_zone
                        compression_factor = 0.9 * math.exp(-excess_negativity * 3.0)
                    else:
                        # Positif au-del√† de la zone neutre
                        compression_factor = 1.0
                
                compressed_scores[ticker] = shifted_val * compression_factor
            
            # Normalize
            sum_scores = sum(compressed_scores.values())
            weights = {t: compressed_scores[t] / sum_scores for t in compressed_scores}
            
            return weights

        if all_negative:
            # Special handling for SP500TOP20: use Relative as default instead of Cash
            is_sp500top20 = any(is_special_dynamic_ticker(t) for t in rets_keys) or config.get('dynamic_portfolio_data') is not None
            
            # For SP500TOP20, use Relative as default if user chose Cash
            effective_strategy = negative_momentum_strategy
            if is_sp500top20 and negative_momentum_strategy == 'Cash':
                effective_strategy = 'Relative momentum'
            
            if effective_strategy == 'Cash':
                weights = {t: 0.0 for t in rets_keys}
            elif effective_strategy == 'Equal weight':
                weights = {t: 1.0 / len(rets_keys) for t in rets_keys}
            elif effective_strategy == 'Relative momentum':
                # ANCIENNE LOGIQUE Relative Momentum
                min_score = min(rets[t] for t in rets_keys)
                offset = -min_score + 0.01
                shifted = {t: max(0.01, rets[t] + offset) for t in rets_keys}
                ssum = sum(shifted.values())
                weights = {t: shifted[t] / ssum for t in shifted}
            elif effective_strategy == 'Near-Zero Symmetry':
                # NOUVELLE LOGIQUE Near-Zero Symmetry
                weights = calculate_near_zero_symmetric_momentum(rets)
        else:
            if relative_mode:
                if momentum_strategy == 'Relative Momentum':
                    # ANCIENNE LOGIQUE Relative Momentum
                    min_score = min(rets[t] for t in rets_keys)
                    offset = -min_score + 0.01 if min_score < 0 else 0.01
                    shifted = {t: max(0.01, rets[t] + offset) for t in rets_keys}
                    ssum = sum(shifted.values())
                    weights = {t: shifted[t] / ssum for t in shifted}
                elif momentum_strategy == 'Near-Zero Symmetry':
                    # NOUVELLE LOGIQUE Near-Zero Symmetry
                    weights = calculate_near_zero_symmetric_momentum(rets)
            else:
                # Check user's selection for momentum strategy
                if momentum_strategy == 'Classic':
                    positive_scores = {t: rets[t] for t in rets_keys if rets[t] > 0}
                    if positive_scores:
                        ssum = sum(positive_scores.values())
                        weights = {t: (positive_scores.get(t, 0.0) / ssum) for t in rets_keys}
                    else:
                        weights = {t: 0.0 for t in rets_keys}
                elif momentum_strategy == 'Relative Momentum':
                    # ANCIENNE LOGIQUE Relative Momentum
                    min_score = min(rets.values())
                    offset = -min_score + 0.01 if min_score < 0 else 0.01
                    shifted = {t: max(0.01, rets[t] + offset) for t in rets_keys}
                    ssum = sum(shifted.values())
                    weights = {t: shifted[t] / ssum for t in shifted}
                elif momentum_strategy == 'Near-Zero Symmetry':
                    # NOUVELLE LOGIQUE Near-Zero Symmetry
                    weights = calculate_near_zero_symmetric_momentum(rets)
                else:
                    # Fallback to Classic if unknown strategy
                    positive_scores = {t: rets[t] for t in rets_keys if rets[t] > 0}
                    if positive_scores:
                        ssum = sum(positive_scores.values())
                        weights = {t: (positive_scores.get(t, 0.0) / ssum) for t in rets_keys}
                    else:
                        weights = {t: 0.0 for t in rets_keys}

        # Post-filtering: multiply weights by inverse vol and inverse |beta| when requested
        # BUT NOT for Equal weight strategy (when all negative) - keep true equal weights
        if (calc_volatility or calc_beta) and weights and not (all_negative and effective_strategy == 'Equal weight'):
            filter_scores = {}
            for t in weights:
                score = 1.0
                if calc_volatility:
                    v = metrics.get(t, {}).get('Volatility', np.nan)
                    if not pd.isna(v) and v > 0:
                        score *= 1.0 / v
                if calc_beta:
                    b = metrics.get(t, {}).get('Beta', np.nan)
                    if not pd.isna(b) and b != 0:
                        score *= 1.0 / abs(b)
                filter_scores[t] = score

            filtered = {t: weights.get(t, 0.0) * filter_scores.get(t, 1.0) for t in weights}
            ssum = sum(filtered.values())
            # If filtering removes all weight (sum==0), fall back to unfiltered weights
            if ssum > 0:
                weights = {t: filtered[t] / ssum for t in filtered}

        # Apply allocation filters in correct order: Max Allocation -> Min Threshold -> Max Allocation (two-pass system)
        use_max_allocation = config.get('use_max_allocation', False)
        max_allocation_percent = config.get('max_allocation_percent', 20.0)
        use_threshold = config.get('use_minimal_threshold', False)
        threshold_percent = config.get('minimal_threshold_percent', 4.0)
        apply_caps_before_top_n = False
        
        # Build dictionary of individual ticker caps from stock configs
        individual_caps = {}
        for stock in config.get('stocks', []):
            ticker = stock.get('ticker', '')
            individual_cap = stock.get('max_allocation_percent', None)
            if individual_cap is not None and individual_cap > 0:
                individual_caps[ticker] = individual_cap / 100.0
        
        # Apply caps if either global cap is enabled OR any individual caps exist
        if apply_caps_before_top_n and (use_max_allocation or individual_caps) and weights:
            max_allocation_decimal = max_allocation_percent / 100.0
            
            # FIRST PASS: Apply maximum allocation filter (EXCLUDE CASH from max_allocation limit)
            capped_weights = {}
            excess_weight = 0.0
            
            for ticker, weight in weights.items():
                # CASH is exempt from max_allocation limit to prevent money loss
                if ticker == 'CASH':
                    capped_weights[ticker] = weight
                else:
                    # Use individual cap if available, otherwise use global cap
                    ticker_cap = individual_caps.get(ticker, max_allocation_decimal if use_max_allocation else float('inf'))
                    
                    if weight > ticker_cap:
                        # Cap the weight and collect excess
                        capped_weights[ticker] = ticker_cap
                        excess_weight += (weight - ticker_cap)
                    else:
                        # Keep original weight
                        capped_weights[ticker] = weight
            
            # Redistribute excess weight proportionally among stocks that are below the cap
            if excess_weight > 0:
                # Find stocks that can receive more weight (below their individual cap) - include CASH as eligible
                eligible_stocks = {}
                for ticker, weight in capped_weights.items():
                    if ticker == 'CASH':
                        eligible_stocks[ticker] = weight
                    else:
                        ticker_cap = individual_caps.get(ticker, max_allocation_decimal if use_max_allocation else float('inf'))
                        if weight < ticker_cap:
                            eligible_stocks[ticker] = weight
                
                if eligible_stocks:
                    # Calculate total weight of eligible stocks
                    total_eligible_weight = sum(eligible_stocks.values())
                    
                    if total_eligible_weight > 0:
                        # Redistribute excess proportionally
                        for ticker in eligible_stocks:
                            proportion = eligible_stocks[ticker] / total_eligible_weight
                            additional_weight = excess_weight * proportion
                            new_weight = capped_weights[ticker] + additional_weight
                            
                            # CASH can receive unlimited weight, other stocks are capped
                            if ticker == 'CASH':
                                capped_weights[ticker] = new_weight
                            else:
                                # Make sure we don't exceed the individual ticker's cap
                                ticker_cap = individual_caps.get(ticker, max_allocation_decimal if use_max_allocation else float('inf'))
                                capped_weights[ticker] = min(new_weight, ticker_cap)
            
            weights = capped_weights
            
            # Final normalization to 100% in case not enough stocks to distribute excess
            total_weight = sum(weights.values())
            if total_weight > 0:
                weights = {ticker: weight / total_weight for ticker, weight in weights.items()}
        
        # Apply minimal threshold filter if enabled
        if apply_caps_before_top_n and use_threshold and weights:
            threshold_decimal = threshold_percent / 100.0
            
            # Check which stocks are below threshold after max allocation redistribution
            filtered_weights = {}
            for ticker, weight in weights.items():
                if weight >= threshold_decimal:
                    # Keep stocks above or equal to threshold (remove stocks below threshold)
                    filtered_weights[ticker] = weight
            
            # Normalize remaining stocks to sum to 1.0
            if filtered_weights:
                total_weight = sum(filtered_weights.values())
                if total_weight > 0:
                    weights = {ticker: weight / total_weight for ticker, weight in filtered_weights.items()}
                else:
                    weights = {}
            else:
                # If no stocks meet threshold, keep original weights
                weights = weights
        
        # SECOND PASS: Apply maximum allocation filter again (in case normalization created new excess)
        if apply_caps_before_top_n and (use_max_allocation or individual_caps) and weights:
            max_allocation_decimal = max_allocation_percent / 100.0
            
            # Check if any stocks exceed the cap after threshold filtering and normalization
            capped_weights = {}
            excess_weight = 0.0
            
            for ticker, weight in weights.items():
                # CASH is exempt from max_allocation limit to prevent money loss
                if ticker == 'CASH':
                    capped_weights[ticker] = weight
                else:
                    # Use individual cap if available, otherwise use global cap
                    ticker_cap = individual_caps.get(ticker, max_allocation_decimal if use_max_allocation else float('inf'))
                    
                    if weight > ticker_cap:
                        # Cap the weight and collect excess
                        capped_weights[ticker] = ticker_cap
                        excess_weight += (weight - ticker_cap)
                    else:
                        # Keep original weight
                        capped_weights[ticker] = weight
            
            # Redistribute excess weight proportionally among stocks that are below the cap
            if excess_weight > 0:
                # Find stocks that can receive more weight (below their individual cap) - include CASH as eligible
                eligible_stocks = {}
                for ticker, weight in capped_weights.items():
                    if ticker == 'CASH':
                        eligible_stocks[ticker] = weight
                    else:
                        ticker_cap = individual_caps.get(ticker, max_allocation_decimal if use_max_allocation else float('inf'))
                        if weight < ticker_cap:
                            eligible_stocks[ticker] = weight
                
                if eligible_stocks:
                    # Calculate total weight of eligible stocks
                    total_eligible_weight = sum(eligible_stocks.values())
                    
                    if total_eligible_weight > 0:
                        # Redistribute excess proportionally
                        for ticker in eligible_stocks:
                            proportion = eligible_stocks[ticker] / total_eligible_weight
                            additional_weight = excess_weight * proportion
                            new_weight = capped_weights[ticker] + additional_weight
                            
                            # CASH can receive unlimited weight, other stocks are capped
                            if ticker == 'CASH':
                                capped_weights[ticker] = new_weight
                            else:
                                # Make sure we don't exceed the individual ticker's cap
                                ticker_cap = individual_caps.get(ticker, max_allocation_decimal if use_max_allocation else float('inf'))
                                capped_weights[ticker] = min(new_weight, ticker_cap)
            
            weights = capped_weights
            
            # Final normalization to 100% in case not enough stocks to distribute excess
            total_weight = sum(weights.values())
            if total_weight > 0:
                weights = {ticker: weight / total_weight for ticker, weight in weights.items()}

        # STEP 1: Apply Limit to Top N filter FIRST (if enabled)
        # This selects the top N tickers, keeping their proportional weights
        # IMPORTANT: This runs BEFORE Equal Weight, so Equal Weight can then equalize the selected tickers
        use_limit_to_top_n = config.get('use_limit_to_top_n', False)
        limit_to_top_n_tickers = config.get('limit_to_top_n_tickers', 10)
        
        should_apply_limit_to_top_n = False
        if use_limit_to_top_n and limit_to_top_n_tickers > 0 and weights:
            if all_negative:
                # When all negative, only apply if using Relative momentum or Near-Zero Symmetry
                if effective_strategy_for_equal_weight in ['Relative momentum', 'Near-Zero Symmetry']:
                    should_apply_limit_to_top_n = True
            else:
                # When there are positive momentums, always apply if enabled
                should_apply_limit_to_top_n = True
        
        if should_apply_limit_to_top_n:
            # IMPORTANT: Limit to top N is applied AFTER min/max allocation filters
            # This means we work with the tickers that survived the filters
            # Get all tickers except CASH with weight > 0 (these are the tickers that passed min/max filters)
            # Sort by their final weight (after all filters) in descending order
            ticker_weights = [(ticker, weight) for ticker, weight in weights.items() 
                            if ticker != 'CASH' and weight > 0]
            ticker_weights.sort(key=lambda x: x[1], reverse=True)
            
            if ticker_weights:
                # Get top N tickers from the filtered set
                # If filters left fewer tickers than N requested, take all available tickers
                n_to_select = min(limit_to_top_n_tickers, len(ticker_weights))
                top_n_tickers = [ticker for ticker, _ in ticker_weights[:n_to_select]]
                
                # Keep their original proportional weights (unlike equal weight which sets all to 1/N)
                # Create new weights dictionary with original weights for top N, 0 for others
                new_weights = {}
                total_top_n_weight = 0.0
                for ticker in weights.keys():
                    if ticker == 'CASH':
                        # Keep CASH weight as is (should be 0 in most cases)
                        new_weights[ticker] = weights.get(ticker, 0.0)
                    elif ticker in top_n_tickers:
                        # Keep original weight for top N tickers
                        new_weights[ticker] = weights.get(ticker, 0.0)
                        total_top_n_weight += weights.get(ticker, 0.0)
                    else:
                        # Set to 0 for tickers not in top N
                        new_weights[ticker] = 0.0
                
                # If there's any CASH weight, distribute it proportionally to top N tickers based on their relative weights
                cash_weight = new_weights.get('CASH', 0.0)
                if cash_weight > 0 and total_top_n_weight > 0:
                    # Distribute cash proportionally based on each ticker's weight relative to total top N weight
                    for ticker in top_n_tickers:
                        ticker_weight = new_weights[ticker]
                        proportion = ticker_weight / total_top_n_weight if total_top_n_weight > 0 else 0.0
                        new_weights[ticker] += cash_weight * proportion
                    new_weights['CASH'] = 0.0
                
                # Final normalization to ensure weights sum to exactly 1.0 (100%)
                # This preserves the relative proportions among top N tickers
                total_weight = sum(new_weights.values())
                if total_weight > 0:
                    weights = {ticker: weight / total_weight for ticker, weight in new_weights.items()}
                else:
                    # Fallback: if somehow total is 0, keep the new_weights as is
                    weights = new_weights

        # STEP 2: Apply Equal Weight filter AFTER Limit to Top N (if enabled)
        # This equalizes the weights of the tickers selected by Limit to Top N (or all tickers if Limit to Top N was not used)
        # Equal weight should:
        # - Apply to all positive momentum cases
        # - Apply to Relative momentum and Near-Zero Symmetry when all negative
        # - NOT apply when all negative and strategy is Cash (should go to 100% cash)
        # - NOT apply when all negative and strategy is Equal weight (already equal weight for all)
        use_equal_weight = config.get('use_equal_weight', False)
        equal_weight_n_tickers = config.get('equal_weight_n_tickers', 10)
        
        # Determine if equal weight should be applied
        should_apply_equal_weight = False
        if use_equal_weight and equal_weight_n_tickers > 0 and weights:
            if all_negative:
                # When all negative, only apply if using Relative momentum or Near-Zero Symmetry
                if effective_strategy_for_equal_weight in ['Relative momentum', 'Near-Zero Symmetry']:
                    should_apply_equal_weight = True
            else:
                # When there are positive momentums, always apply if enabled
                should_apply_equal_weight = True
        
        if should_apply_equal_weight:
            # IMPORTANT: Equal weight is applied AFTER Limit to Top N (if Limit to Top N was applied)
            # If Limit to Top N was enabled, we equalize the tickers it selected
            # If Limit to Top N was not enabled, we select our own top N tickers and equalize them
            # Get all tickers except CASH with weight > 0
            ticker_weights = [(ticker, weight) for ticker, weight in weights.items() 
                            if ticker != 'CASH' and weight > 0]
            
            if ticker_weights:
                # If Limit to Top N was applied, use the tickers it selected (all tickers with weight > 0)
                # Otherwise, select top N based on Equal Weight's N value
                if should_apply_limit_to_top_n:
                    # Limit to Top N already selected the tickers - just equalize all that remain
                    top_n_tickers = [ticker for ticker, _ in ticker_weights]
                else:
                    # No Limit to Top N - select top N based on Equal Weight's N value
                    ticker_weights.sort(key=lambda x: x[1], reverse=True)
                    n_to_select = min(equal_weight_n_tickers, len(ticker_weights))
                    top_n_tickers = [ticker for ticker, _ in ticker_weights[:n_to_select]]
                
                # Calculate equal weight per ticker (1/n where n is the actual number selected)
                equal_weight_per_ticker = 1.0 / len(top_n_tickers)
                
                # Create new weights dictionary with equal weights for top N, 0 for others
                new_weights = {}
                for ticker in weights.keys():
                    if ticker == 'CASH':
                        # Keep CASH weight as is (should be 0 in most cases)
                        new_weights[ticker] = weights.get(ticker, 0.0)
                    elif ticker in top_n_tickers:
                        new_weights[ticker] = equal_weight_per_ticker
                    else:
                        # Set to 0 for tickers not in top N
                        new_weights[ticker] = 0.0
                
                # If there's any CASH weight, distribute it proportionally to top N tickers
                cash_weight = new_weights.get('CASH', 0.0)
                if cash_weight > 0:
                    # Add cash weight proportionally to top N tickers
                    for ticker in top_n_tickers:
                        new_weights[ticker] += cash_weight / len(top_n_tickers)
                    new_weights['CASH'] = 0.0
                
                # Final normalization to ensure weights sum to exactly 1.0 (100%)
                # This is important especially when fewer tickers remain than requested N
                total_weight = sum(new_weights.values())
                if total_weight > 0:
                    weights = {ticker: weight / total_weight for ticker, weight in new_weights.items()}
                else:
                    # Fallback: if somehow total is 0, keep the new_weights as is
                    weights = new_weights

        # Final allocation filters (after Top N / Equal Weight): Max Allocation -> Min Threshold -> Max Allocation
        if (use_max_allocation or individual_caps) and weights:
            max_allocation_decimal = max_allocation_percent / 100.0

            capped_weights = {}
            excess_weight = 0.0

            for ticker, weight in weights.items():
                if ticker == 'CASH':
                    capped_weights[ticker] = weight
                else:
                    ticker_cap = individual_caps.get(ticker, max_allocation_decimal if use_max_allocation else float('inf'))

                    if weight > ticker_cap:
                        capped_weights[ticker] = ticker_cap
                        excess_weight += (weight - ticker_cap)
                    else:
                        capped_weights[ticker] = weight

            if excess_weight > 0:
                eligible_stocks = {}
                for ticker, weight in capped_weights.items():
                    if ticker == 'CASH':
                        eligible_stocks[ticker] = weight
                    else:
                        ticker_cap = individual_caps.get(ticker, max_allocation_decimal if use_max_allocation else float('inf'))
                        if weight < ticker_cap:
                            eligible_stocks[ticker] = weight

                if eligible_stocks:
                    total_eligible_weight = sum(eligible_stocks.values())

                    if total_eligible_weight > 0:
                        for ticker in eligible_stocks:
                            proportion = eligible_stocks[ticker] / total_eligible_weight
                            additional_weight = excess_weight * proportion
                            new_weight = capped_weights[ticker] + additional_weight

                            if ticker == 'CASH':
                                capped_weights[ticker] = new_weight
                            else:
                                ticker_cap = individual_caps.get(ticker, max_allocation_decimal if use_max_allocation else float('inf'))
                                capped_weights[ticker] = min(new_weight, ticker_cap)

            weights = capped_weights

            total_weight = sum(weights.values())
            if total_weight > 0:
                weights = {ticker: weight / total_weight for ticker, weight in weights.items()}

        if use_threshold and weights:
            threshold_decimal = threshold_percent / 100.0

            filtered_weights = {}
            for ticker, weight in weights.items():
                if weight >= threshold_decimal:
                    filtered_weights[ticker] = weight

            if filtered_weights:
                total_weight = sum(filtered_weights.values())
                if total_weight > 0:
                    weights = {ticker: weight / total_weight for ticker, weight in filtered_weights.items()}
                else:
                    weights = {}
            else:
                weights = weights

        if (use_max_allocation or individual_caps) and weights:
            max_allocation_decimal = max_allocation_percent / 100.0

            capped_weights = {}
            excess_weight = 0.0

            for ticker, weight in weights.items():
                if ticker == 'CASH':
                    capped_weights[ticker] = weight
                else:
                    ticker_cap = individual_caps.get(ticker, max_allocation_decimal if use_max_allocation else float('inf'))

                    if weight > ticker_cap:
                        capped_weights[ticker] = ticker_cap
                        excess_weight += (weight - ticker_cap)
                    else:
                        capped_weights[ticker] = weight

            if excess_weight > 0:
                eligible_stocks = {}
                for ticker, weight in capped_weights.items():
                    if ticker == 'CASH':
                        eligible_stocks[ticker] = weight
                    else:
                        ticker_cap = individual_caps.get(ticker, max_allocation_decimal if use_max_allocation else float('inf'))
                        if weight < ticker_cap:
                            eligible_stocks[ticker] = weight

                if eligible_stocks:
                    total_eligible_weight = sum(eligible_stocks.values())

                    if total_eligible_weight > 0:
                        for ticker in eligible_stocks:
                            proportion = eligible_stocks[ticker] / total_eligible_weight
                            additional_weight = excess_weight * proportion
                            new_weight = capped_weights[ticker] + additional_weight

                            if ticker == 'CASH':
                                capped_weights[ticker] = new_weight
                            else:
                                ticker_cap = individual_caps.get(ticker, max_allocation_decimal if use_max_allocation else float('inf'))
                                capped_weights[ticker] = min(new_weight, ticker_cap)

            weights = capped_weights

            total_weight = sum(weights.values())
            if total_weight > 0:
                weights = {ticker: weight / total_weight for ticker, weight in weights.items()}

        # Attach calculated weights to metrics and return
        for t in weights:
            metrics[t]['Calculated_Weight'] = weights.get(t, 0.0)

        # Debug print when beta/vol are used
        if calc_beta or calc_volatility:
            try:
                for t in rets_keys:
                    pass
            except Exception:
                pass

        return weights, metrics
        # --- MODIFIED LOGIC END ---

    values = {t: [0.0] for t in tickers}
    unallocated_cash = [0.0]
    unreinvested_cash = [0.0]
    portfolio_no_additions = [initial_value]
    
    # Initial allocation and metric storage
    if not use_momentum:
        current_allocations = {t: allocations.get(t,0) for t in tickers}
        
        # Apply MA filter even when momentum is disabled (ULTRA OPTIMIZED!)
        if config.get('use_sma_filter', False) and ma_filter_data is not None:
            # Get list of current tickers (excluding CASH)
            current_tickers = [t for t in tickers if t != 'CASH']
            # ULTRA FAST: Use precomputed filter results!
            filtered_tickers = [t for t in current_tickers if ma_filter_data.get(sim_index[0], {}).get(t, True)]
            excluded_assets = {t: f"Below MA" for t in current_tickers if t not in filtered_tickers}
            
            # Redistribute allocations of excluded tickers proportionally among remaining tickers
            if excluded_assets:
                excluded_ticker_list = list(excluded_assets.keys())
                
                # Calculate total allocation of excluded tickers
                excluded_allocation = sum(current_allocations.get(t, 0) for t in excluded_ticker_list)
                
                # Remove excluded tickers from current allocations
                for excluded_ticker in excluded_ticker_list:
                    if excluded_ticker in current_allocations:
                        del current_allocations[excluded_ticker]
                
                # If there are remaining tickers (excluding CASH), redistribute proportionally
                remaining_tickers = [t for t in current_allocations.keys() if t != 'CASH']
                if remaining_tickers:
                    # Calculate total allocation of remaining tickers (excluding CASH)
                    remaining_allocation = sum(current_allocations.get(t, 0) for t in remaining_tickers)
                    
                    if remaining_allocation > 0:
                        # Redistribute excluded allocation proportionally
                        for ticker in remaining_tickers:
                            proportion = current_allocations[ticker] / remaining_allocation
                            current_allocations[ticker] += excluded_allocation * proportion
                    else:
                        # If no remaining tickers have allocation, distribute equally
                        equal_allocation = excluded_allocation / len(remaining_tickers)
                        for ticker in remaining_tickers:
                            current_allocations[ticker] = equal_allocation
                elif 'CASH' in current_allocations:
                    # If only CASH remains, give all to CASH
                    current_allocations['CASH'] += excluded_allocation
                else:
                    # No tickers remain, allocate to CASH
                    current_allocations['CASH'] = 1.0
        
        # Apply allocation filters in correct order: Max Allocation -> Min Threshold -> Max Allocation (two-pass system)
        use_max_allocation = config.get('use_max_allocation', False)
        max_allocation_percent = config.get('max_allocation_percent', 20.0)
        use_threshold = config.get('use_minimal_threshold', False)
        threshold_percent = config.get('minimal_threshold_percent', 4.0)
        
        # Build dictionary of individual ticker caps from stock configs
        individual_caps = {}
        for stock in config.get('stocks', []):
            ticker = stock.get('ticker', '')
            individual_cap = stock.get('max_allocation_percent', None)
            if individual_cap is not None and individual_cap > 0:
                individual_caps[ticker] = individual_cap / 100.0
        
        # Apply caps if either global cap is enabled OR any individual caps exist
        if (use_max_allocation or individual_caps) and current_allocations:
            max_allocation_decimal = max_allocation_percent / 100.0
            
            # FIRST PASS: Apply maximum allocation filter (EXCLUDE CASH from max_allocation limit)
            capped_allocations = {}
            excess_allocation = 0.0
            
            for ticker, allocation in current_allocations.items():
                # CASH is exempt from max_allocation limit to prevent money loss
                if ticker == 'CASH':
                    capped_allocations[ticker] = allocation
                else:
                    # Use individual cap if available, otherwise use global cap
                    ticker_cap = individual_caps.get(ticker, max_allocation_decimal if use_max_allocation else float('inf'))
                    
                    if allocation > ticker_cap:
                        # Cap the allocation and collect excess
                        capped_allocations[ticker] = ticker_cap
                        excess_allocation += (allocation - ticker_cap)
                    else:
                        # Keep original allocation
                        capped_allocations[ticker] = allocation
            
            # Redistribute excess allocation proportionally among stocks that are below the cap
            if excess_allocation > 0:
                # Find stocks that can receive more allocation (below their individual cap) - include CASH as eligible
                eligible_stocks = {}
                for ticker, allocation in capped_allocations.items():
                    if ticker == 'CASH':
                        eligible_stocks[ticker] = allocation
                    else:
                        ticker_cap = individual_caps.get(ticker, max_allocation_decimal if use_max_allocation else float('inf'))
                        if allocation < ticker_cap:
                            eligible_stocks[ticker] = allocation
                
                if eligible_stocks:
                    # Calculate total allocation of eligible stocks
                    total_eligible_allocation = sum(eligible_stocks.values())
                    
                    if total_eligible_allocation > 0:
                        # Redistribute excess proportionally
                        for ticker in eligible_stocks:
                            proportion = eligible_stocks[ticker] / total_eligible_allocation
                            additional_allocation = excess_allocation * proportion
                            new_allocation = capped_allocations[ticker] + additional_allocation
                            
                            # CASH can receive unlimited allocation, other stocks are capped
                            if ticker == 'CASH':
                                capped_allocations[ticker] = new_allocation
                            else:
                                # Make sure we don't exceed the individual ticker's cap
                                ticker_cap = individual_caps.get(ticker, max_allocation_decimal if use_max_allocation else float('inf'))
                                capped_allocations[ticker] = min(new_allocation, ticker_cap)
            
            current_allocations = capped_allocations
        
        # Apply minimal threshold filter for non-momentum strategies
        if use_threshold and current_allocations:
            threshold_decimal = threshold_percent / 100.0
            
            # First: Filter out stocks below threshold
            filtered_allocations = {}
            for ticker, allocation in current_allocations.items():
                if allocation >= threshold_decimal:
                    # Keep stocks above or equal to threshold
                    filtered_allocations[ticker] = allocation
            
            # Then: Normalize remaining stocks to sum to 1
            if filtered_allocations:
                total_allocation = sum(filtered_allocations.values())
                if total_allocation > 0:
                    current_allocations = {ticker: allocation / total_allocation for ticker, allocation in filtered_allocations.items()}
                else:
                    current_allocations = {}
            else:
                # If no stocks meet threshold, keep original allocations
                current_allocations = current_allocations
        
        # SECOND PASS: Apply maximum allocation filter again (in case normalization created new excess)
        if (use_max_allocation or individual_caps) and current_allocations:
            max_allocation_decimal = max_allocation_percent / 100.0
            
            # Check if any stocks exceed the cap after threshold filtering and normalization
            capped_allocations = {}
            excess_allocation = 0.0
            
            for ticker, allocation in current_allocations.items():
                # CASH is exempt from max_allocation limit to prevent money loss
                if ticker == 'CASH':
                    capped_allocations[ticker] = allocation
                else:
                    # Use individual cap if available, otherwise use global cap
                    ticker_cap = individual_caps.get(ticker, max_allocation_decimal if use_max_allocation else float('inf'))
                    
                    if allocation > ticker_cap:
                        # Cap the allocation and collect excess
                        capped_allocations[ticker] = ticker_cap
                        excess_allocation += (allocation - ticker_cap)
                    else:
                        # Keep original allocation
                        capped_allocations[ticker] = allocation
            
            # Redistribute excess allocation proportionally among stocks that are below the cap
            if excess_allocation > 0:
                # Find stocks that can receive more allocation (below their individual cap) - include CASH as eligible
                eligible_stocks = {}
                for ticker, allocation in capped_allocations.items():
                    if ticker == 'CASH':
                        eligible_stocks[ticker] = allocation
                    else:
                        ticker_cap = individual_caps.get(ticker, max_allocation_decimal if use_max_allocation else float('inf'))
                        if allocation < ticker_cap:
                            eligible_stocks[ticker] = allocation
                
                if eligible_stocks:
                    # Calculate total allocation of eligible stocks
                    total_eligible_allocation = sum(eligible_stocks.values())
                    
                    if total_eligible_allocation > 0:
                        # Redistribute excess proportionally
                        for ticker in eligible_stocks:
                            proportion = eligible_stocks[ticker] / total_eligible_allocation
                            additional_allocation = excess_allocation * proportion
                            new_allocation = capped_allocations[ticker] + additional_allocation
                            
                            # CASH can receive unlimited allocation, other stocks are capped
                            if ticker == 'CASH':
                                capped_allocations[ticker] = new_allocation
                            else:
                                # Make sure we don't exceed the individual ticker's cap
                                ticker_cap = individual_caps.get(ticker, max_allocation_decimal if use_max_allocation else float('inf'))
                                capped_allocations[ticker] = min(new_allocation, ticker_cap)
            
            current_allocations = capped_allocations
    else:
        # For momentum portfolios, start with 100% CASH initially
        # Momentum weights will be applied on rebalancing dates
        current_allocations = {t: 0.0 for t in tickers}  # Start with 0% in all assets
        # Store initial metrics (will be updated on first rebalancing date)
        historical_metrics[sim_index[0]] = {t: {'Calculated_Weight': 0.0, 'Momentum': 0.0} for t in tickers}
    
    sum_alloc = sum(current_allocations.get(t,0) for t in tickers)
    if sum_alloc > 0:
        for t in tickers:
            values[t][0] = initial_value * current_allocations.get(t,0) / sum_alloc
        unallocated_cash[0] = 0
    else:
        unallocated_cash[0] = initial_value
    
    historical_allocations[sim_index[0]] = {t: values[t][0] / initial_value if initial_value > 0 else 0 for t in tickers}
    historical_allocations[sim_index[0]]['CASH'] = unallocated_cash[0] / initial_value if initial_value > 0 else 0
    
    for i in range(len(sim_index)):
        # Check for interrupt every 5 iterations (much more frequent)
        if i % 5 == 0:
            # Check if interrupt was requested
            if hasattr(st.session_state, 'hard_kill_requested') and st.session_state.hard_kill_requested:
                print("üõë Hard kill requested - stopping backtest")
                break
        
        date = sim_index[i]
        if i == 0: continue
        
        date_prev = sim_index[i-1]
        total_unreinvested_dividends = 0
        total_portfolio_prev = sum(values[t][-1] for t in tickers) + unreinvested_cash[-1]
        daily_growth_factor = 1
        if total_portfolio_prev > 0:
            total_portfolio_current_before_changes = 0
            for t in tickers:
                df = reindexed_data[t]
                price_prev = df.loc[date_prev, "Close"]
                val_prev = values[t][-1]
                nb_shares = val_prev / price_prev if price_prev > 0 else 0
                # --- Dividend fix: find the correct trading day for dividend ---
                div = 0.0
                # CRITICAL FIX: For leveraged tickers, get dividends from the base ticker, not the leveraged ticker
                if "?L=" in t or "?E=" in t:
                    # For leveraged tickers, get dividend data from the base ticker
                    base_ticker, leverage, expense_ratio = parse_ticker_parameters(t)
                    if base_ticker in reindexed_data:
                        base_df = reindexed_data[base_ticker]
                        if "Dividends" in base_df.columns:
                            if date in base_df.index:
                                div = base_df.loc[date, "Dividends"]
                            else:
                                # Find next trading day in index after 'date'
                                future_dates = base_df.index[base_df.index > date]
                                if len(future_dates) > 0:
                                    div = base_df.loc[future_dates[0], "Dividends"]
                else:
                    # For regular tickers, get dividend data normally
                    if "Dividends" in df.columns:
                        if date in df.index:
                            div = df.loc[date, "Dividends"]
                        else:
                            # Find next trading day in index after 'date'
                            future_dates = df.index[df.index > date]
                            if len(future_dates) > 0:
                                div = df.loc[future_dates[0], "Dividends"]
                var = df.loc[date, "Price_change"] if date in df.index else 0.0
                
                # Expense ratio is already applied in apply_daily_leverage() when data is fetched
                # No need to re-apply it here (would be double application + slow loop)
                
                if include_dividends.get(t, False):
                    # Check if dividends should be collected as cash instead of reinvested
                    collect_as_cash = config.get('collect_dividends_as_cash', False)
                    if collect_as_cash and div > 0:
                        # Calculate dividend cash and add to unreinvested cash
                        nb_shares = val_prev / price_prev if price_prev > 0 else 0
                        dividend_cash = nb_shares * div
                        total_unreinvested_dividends += dividend_cash
                        # Don't include dividend in rate of return
                        rate_of_return = var
                        val_new = val_prev * (1 + rate_of_return)
                    else:
                        # Reinvest dividends (original behavior)
                        # CRITICAL FIX: For leveraged tickers, dividends should be handled differently
                        # When simulating leveraged ETFs, the dividend RATE should be the same as the base asset
                        if "?L=" in t or "?E=" in t:
                            # For leveraged tickers, get the base ticker's dividend rate (not amount)
                            base_ticker, leverage, expense_ratio = parse_ticker_parameters(t)
                            if base_ticker in reindexed_data:
                                base_df = reindexed_data[base_ticker]
                                base_price_prev = base_df.loc[date_prev, "Close"]
                                # Use the base ticker's dividend rate, not the leveraged amount
                                dividend_rate = div / base_price_prev if base_price_prev > 0 else 0
                                rate_of_return = var + dividend_rate
                            else:
                                # Fallback: use leveraged price (may cause issues)
                                rate_of_return = var + (div / price_prev if price_prev > 0 else 0)
                        else:
                            # For regular tickers, use normal dividend reinvestment
                            rate_of_return = var + (div / price_prev if price_prev > 0 else 0)
                        
                        # Calculate val_new for both leveraged and regular tickers
                        val_new = val_prev * (1 + rate_of_return)
                else:
                    val_new = val_prev * (1 + var)
                    # If dividends are not included, do NOT add to unreinvested cash or anywhere else
                total_portfolio_current_before_changes += val_new
            total_portfolio_current_before_changes += unreinvested_cash[-1] + total_unreinvested_dividends
            daily_growth_factor = total_portfolio_current_before_changes / total_portfolio_prev
        for t in tickers:
            df = reindexed_data[t]
            price_prev = df.loc[date_prev, "Close"]
            val_prev = values[t][-1]
            # --- Dividend fix: find the correct trading day for dividend ---
            div = 0.0
            # CRITICAL FIX: For leveraged tickers, get dividends from the base ticker, not the leveraged ticker
            if "?L=" in t or "?E=" in t:
                # For leveraged tickers, get dividend data from the base ticker
                base_ticker, leverage, expense_ratio = parse_ticker_parameters(t)
                if base_ticker in reindexed_data:
                    base_df = reindexed_data[base_ticker]
                    if "Dividends" in base_df.columns:
                        if date in base_df.index:
                            div = base_df.loc[date, "Dividends"]
                        else:
                            # Find next trading day in index after 'date'
                            future_dates = base_df.index[base_df.index > date]
                            if len(future_dates) > 0:
                                div = base_df.loc[future_dates[0], "Dividends"]
            else:
                # For regular tickers, get dividend data normally
                if "Dividends" in df.columns:
                    if date in df.index:
                        div = df.loc[date, "Dividends"]
                    else:
                        # Find next trading day in index after 'date'
                        future_dates = df.index[df.index > date]
                        if len(future_dates) > 0:
                            div = df.loc[future_dates[0], "Dividends"]
            var = df.loc[date, "Price_change"] if date in df.index else 0.0
            
            # Expense ratio is already applied in apply_daily_leverage() when data is fetched
            # No need to re-apply it here (would be double application + slow loop)
            
            if include_dividends.get(t, False):
                # Check if dividends should be collected as cash instead of reinvested
                collect_as_cash = config.get('collect_dividends_as_cash', False)
                if collect_as_cash and div > 0:
                    # Calculate dividend cash and add to unreinvested cash
                    nb_shares = val_prev / price_prev if price_prev > 0 else 0
                    dividend_cash = nb_shares * div
                    total_unreinvested_dividends += dividend_cash
                    # Don't include dividend in rate of return
                    rate_of_return = var
                    val_new = val_prev * (1 + rate_of_return)
                else:
                    # Reinvest dividends (original behavior)
                    # CRITICAL FIX: For leveraged tickers, dividends should be handled differently
                    # When simulating leveraged ETFs, the dividend RATE should be the same as the base asset
                    if "?L=" in t or "?E=" in t:
                        # For leveraged tickers, get the base ticker's dividend rate (not amount)
                        base_ticker, leverage, expense_ratio = parse_ticker_parameters(t)
                        if base_ticker in reindexed_data:
                            base_df = reindexed_data[base_ticker]
                            base_price_prev = base_df.loc[date_prev, "Close"]
                            # Use the base ticker's dividend rate, not the leveraged amount
                            dividend_rate = div / base_price_prev if base_price_prev > 0 else 0
                            rate_of_return = var + dividend_rate
                        else:
                            # Fallback: use leveraged price (may cause issues)
                            rate_of_return = var + (div / price_prev if price_prev > 0 else 0)
                    else:
                        # For regular tickers, use normal dividend reinvestment
                        rate_of_return = var + (div / price_prev if price_prev > 0 else 0)
                    
                    # Calculate val_new for both leveraged and regular tickers
                    val_new = val_prev * (1 + rate_of_return)
            else:
                val_new = val_prev * (1 + var)
            values[t].append(val_new)
        unallocated_cash.append(unallocated_cash[-1])
        if date in dates_added:
            unallocated_cash[-1] += added_amount
        unreinvested_cash.append(unreinvested_cash[-1] + total_unreinvested_dividends)
        portfolio_no_additions.append(portfolio_no_additions[-1] * daily_growth_factor)
        
        current_total = sum(values[t][-1] for t in tickers) + unallocated_cash[-1] + unreinvested_cash[-1]
        
        # Check if we should rebalance
        should_rebalance = False
        
        # First check if it's a regular rebalancing date
        # Normalize dates for comparison (remove timezone and time components)
        date_normalized = pd.Timestamp(date).normalize()
        dates_rebal_normalized = {pd.Timestamp(d).normalize() for d in dates_rebal}
        
        # Check for MA cross rebalancing (if enabled) - ULTRA OPTIMIZED!
        ma_cross_rebalance = config.get('ma_cross_rebalance', False)
        if ma_cross_rebalance and ma_crossings_data is not None:
            # ULTRA FAST: Just check if this date has precomputed crossings!
            if date in ma_crossings_data:
                crossed_assets = list(ma_crossings_data[date].keys())
                should_rebalance = True
                print(f"[MA CROSS] Detected confirmed MA cross for {crossed_assets} at {date} (precomputed), triggering immediate rebalancing")
        
        if date_normalized in dates_rebal_normalized and set(tickers):
            # If targeted rebalancing is enabled, check thresholds first
            if config.get('use_targeted_rebalancing', False):
                # Calculate current allocations as percentages
                current_total = sum(values[t][-1] for t in tickers) + unallocated_cash[-1] + unreinvested_cash[-1]
                if current_total > 0:
                    current_allocations = {t: values[t][-1] / current_total for t in tickers}
                    
                    # Check if any ticker exceeds its targeted rebalancing thresholds
                    targeted_settings = config.get('targeted_rebalancing_settings', {})
                    threshold_exceeded = False
                    
                    for ticker in tickers:
                        if ticker in targeted_settings and targeted_settings[ticker].get('enabled', False):
                            current_allocation_pct = current_allocations.get(ticker, 0) * 100
                            max_threshold = targeted_settings[ticker].get('max_allocation', 100.0)
                            min_threshold = targeted_settings[ticker].get('min_allocation', 0.0)
                            
                            # Check if allocation exceeds max or falls below min threshold
                            if current_allocation_pct > max_threshold or current_allocation_pct < min_threshold:
                                threshold_exceeded = True
                                break
                    
                    # Only rebalance if thresholds are exceeded
                    should_rebalance = threshold_exceeded
                else:
                    # If no current value, don't rebalance
                    should_rebalance = False
            else:
                # Regular rebalancing - always rebalance on scheduled dates
                should_rebalance = True
        elif rebalancing_frequency in ["Buy & Hold", "Buy & Hold (Target)"] and set(tickers):
            # Buy & Hold: rebalance whenever there's cash available
            total_cash = unallocated_cash[-1] + unreinvested_cash[-1]
            if total_cash > 0:
                should_rebalance = True
        
        # Handle cash distribution when no rebalancing occurs but cash is available
        if not should_rebalance:
            total_cash = unallocated_cash[-1] + unreinvested_cash[-1]
            if total_cash > 0:
                # Distribute cash proportionally to current holdings
                current_total_value = sum(values[t][-1] for t in tickers)
                if current_total_value > 0:
                    # Calculate current proportions
                    current_proportions = {t: values[t][-1] / current_total_value for t in tickers}
                    
                    # Distribute cash proportionally
                    for t in tickers:
                        values[t][-1] += total_cash * current_proportions.get(t, 0)
                    
                    # Clear cash
                    unallocated_cash[-1] = 0
                    unreinvested_cash[-1] = 0
        
        if should_rebalance:
            if use_momentum:
                # Apply MA filter BEFORE calculating momentum (ULTRA OPTIMIZED!)
                assets_to_calculate = set(tickers)
                if config.get('use_sma_filter', False) and ma_filter_data is not None:
                    # ULTRA FAST: Use precomputed filter results!
                    filtered_assets = [t for t in tickers if ma_filter_data.get(date, {}).get(t, True)]
                    
                    # If no assets remain after MA filtering, go to cash immediately
                    if not filtered_assets:
                        print(f"[MA FILTER] All assets excluded at {date}, going to cash")
                        for t in tickers:
                            values[t][-1] = 0
                        unallocated_cash[-1] = current_total
                        unreinvested_cash[-1] = 0
                        # Skip rest of rebalancing logic
                        continue
                    
                    # Only calculate momentum for filtered assets
                    assets_to_calculate = filtered_assets
                    excluded_assets = [t for t in tickers if t not in filtered_assets]
                    print(f"[MA FILTER] Assets after MA filter at {date}: {filtered_assets}, excluded: {excluded_assets}")
                
                returns, valid_assets = calculate_momentum(date, assets_to_calculate, momentum_windows, config['stocks'])
                if valid_assets:
                    weights, metrics_on_rebal = calculate_momentum_weights(
                        returns, valid_assets, date=date,
                        momentum_strategy=config.get('momentum_strategy', 'Classic'),
                        negative_momentum_strategy=config.get('negative_momentum_strategy', 'Cash'),
                        config=config
                    )
                    historical_metrics[date] = metrics_on_rebal
                    
                    # Apply MA filter to weights: set excluded assets to 0 and redistribute (ULTRA OPTIMIZED!)
                    if config.get('use_sma_filter', False) and ma_filter_data is not None:
                        # ULTRA FAST: Use precomputed filter results!
                        filtered_assets = [t for t in tickers if ma_filter_data.get(date, {}).get(t, True)]
                        excluded_assets = {t: f"Below MA" for t in tickers if t not in filtered_assets}
                        
                        if excluded_assets:
                            excluded_ticker_list = list(excluded_assets.keys())
                            excluded_weight = sum(weights.get(t, 0) for t in excluded_ticker_list)
                            
                            # Remove excluded tickers from weights
                            for excluded_ticker in excluded_ticker_list:
                                if excluded_ticker in weights:
                                    del weights[excluded_ticker]
                            
                            # Redistribute excluded weight among remaining tickers
                            remaining_tickers = [t for t in weights.keys() if t != 'CASH']
                            if remaining_tickers and excluded_weight > 0:
                                remaining_weight = sum(weights.get(t, 0) for t in remaining_tickers)
                                if remaining_weight > 0:
                                    for ticker in remaining_tickers:
                                        proportion = weights[ticker] / remaining_weight
                                        weights[ticker] += excluded_weight * proportion
                                else:
                                    # Equal distribution
                                    equal_weight = excluded_weight / len(remaining_tickers)
                                    for ticker in remaining_tickers:
                                        weights[ticker] = equal_weight
                            elif excluded_weight > 0:
                                # No remaining tickers, all goes to CASH
                                weights['CASH'] = weights.get('CASH', 0) + excluded_weight
                    
                    if all(w == 0 for w in weights.values()):
                        # All cash: move total to unallocated_cash, set asset values to zero
                        # This happens when negative_momentum_strategy is 'Cash' and all momentum scores are negative
                        for t in tickers:
                            values[t][-1] = 0
                        unallocated_cash[-1] = current_total
                        unreinvested_cash[-1] = 0
                    else:
                        # Apply max_allocation to momentum weights if enabled
                        use_max_allocation = config.get('use_max_allocation', False)
                        max_allocation_percent = config.get('max_allocation_percent', 20.0)
                        
                        # Build dictionary of individual ticker caps from stock configs
                        individual_caps = {}
                        for stock in config.get('stocks', []):
                            ticker = stock.get('ticker', '')
                            individual_cap = stock.get('max_allocation_percent', None)
                            if individual_cap is not None and individual_cap > 0:
                                individual_caps[ticker] = individual_cap / 100.0
                        
                        # Apply caps if either global cap is enabled OR any individual caps exist
                        if (use_max_allocation or individual_caps) and weights:
                            max_allocation_decimal = max_allocation_percent / 100.0
                            
                            # Apply maximum allocation filter to momentum weights (EXCLUDE CASH from max_allocation limit)
                            capped_weights = {}
                            excess_weight = 0.0
                            
                            for ticker, weight in weights.items():
                                # CASH is exempt from max_allocation limit to prevent money loss
                                if ticker == 'CASH':
                                    capped_weights[ticker] = weight
                                else:
                                    # Use individual cap if available, otherwise use global cap
                                    ticker_cap = individual_caps.get(ticker, max_allocation_decimal if use_max_allocation else float('inf'))
                                    
                                    if weight > ticker_cap:
                                        # Cap the weight and collect excess
                                        capped_weights[ticker] = ticker_cap
                                        excess_weight += (weight - ticker_cap)
                                    else:
                                        # Keep original weight
                                        capped_weights[ticker] = weight
                            
                            # Redistribute excess weight proportionally among stocks that are below the cap
                            if excess_weight > 0:
                                # Find stocks that can receive more weight (below their individual cap) - include CASH as eligible
                                eligible_stocks = {}
                                for ticker, weight in capped_weights.items():
                                    if ticker == 'CASH':
                                        eligible_stocks[ticker] = weight
                                    else:
                                        ticker_cap = individual_caps.get(ticker, max_allocation_decimal if use_max_allocation else float('inf'))
                                        if weight < ticker_cap:
                                            eligible_stocks[ticker] = weight
                                
                                if eligible_stocks:
                                    # Calculate total weight of eligible stocks
                                    total_eligible_weight = sum(eligible_stocks.values())
                                    
                                    if total_eligible_weight > 0:
                                        # Redistribute excess proportionally
                                        for ticker in eligible_stocks:
                                            proportion = eligible_stocks[ticker] / total_eligible_weight
                                            additional_weight = excess_weight * proportion
                                            new_weight = capped_weights[ticker] + additional_weight
                                            
                                            # CASH can receive unlimited weight, other stocks are capped
                                            if ticker == 'CASH':
                                                capped_weights[ticker] = new_weight
                                            else:
                                                # Make sure we don't exceed the individual ticker's cap
                                                ticker_cap = individual_caps.get(ticker, max_allocation_decimal if use_max_allocation else float('inf'))
                                                capped_weights[ticker] = min(new_weight, ticker_cap)
                            
                            weights = capped_weights
                            
                            # Final normalization to 100% in case not enough stocks to distribute excess
                            total_weight = sum(weights.values())
                            if total_weight > 0:
                                weights = {ticker: weight / total_weight for ticker, weight in weights.items()}
                        
                        # For Buy & Hold strategies with momentum, only distribute new cash
                        if rebalancing_frequency in ["Buy & Hold", "Buy & Hold (Target)"]:
                            # Calculate current proportions for Buy & Hold, or use momentum weights for Buy & Hold (Target)
                            if rebalancing_frequency == "Buy & Hold":
                                # Use current proportions from existing holdings
                                current_total_value = sum(values[t][-1] for t in tickers)
                                if current_total_value > 0:
                                    current_proportions = {t: values[t][-1] / current_total_value for t in tickers}
                                else:
                                    # If no current holdings, use equal weights
                                    current_proportions = {t: 1.0 / len(tickers) for t in tickers}
                            else:  # "Buy & Hold (Target)"
                                # Use momentum weights
                                current_proportions = weights
                            
                            # Only distribute the new cash (unallocated_cash + unreinvested_cash)
                            cash_to_distribute = unallocated_cash[-1] + unreinvested_cash[-1]
                            for t in tickers:
                                # Add new cash proportionally to existing holdings
                                values[t][-1] += cash_to_distribute * current_proportions.get(t, 0)
                            unreinvested_cash[-1] = 0
                            unallocated_cash[-1] = 0
                        else:
                            # Normal momentum rebalancing: replace all holdings
                            for t in tickers:
                                values[t][-1] = current_total * weights.get(t, 0)
                            unreinvested_cash[-1] = 0
                            unallocated_cash[-1] = 0
                            
                            # Verify total is preserved
                            new_total = sum(values[t][-1] for t in tickers) + unallocated_cash[-1] + unreinvested_cash[-1]
                            if abs(new_total - current_total) > 0.01:
                                print(f"[WARNING] Money loss at {date}: before={current_total:.2f}, after={new_total:.2f}, weights={weights}")
                else:
                    # No valid assets after SMA filtering -> go to cash (same as momentum strategy)
                    print(f"[SMA] Going to cash at {date}: current_total={current_total:.2f}, values before={[values[t][-1] for t in tickers]}")
                    for t in tickers:
                        values[t][-1] = 0
                    unallocated_cash[-1] = current_total
                    unreinvested_cash[-1] = 0
                    print(f"[SMA] After: unallocated_cash={unallocated_cash[-1]:.2f}, values after={[values[t][-1] for t in tickers]}")
            else:
                # Apply allocation filters in correct order: Max Allocation -> Min Threshold -> Max Allocation (two-pass system)
                use_max_allocation = config.get('use_max_allocation', False)
                max_allocation_percent = config.get('max_allocation_percent', 10.0)
                use_threshold = config.get('use_minimal_threshold', False)
                threshold_percent = config.get('minimal_threshold_percent', 2.0)
                apply_caps_before_top_n = False
                
                # Start with original allocations
                rebalance_allocations = {t: allocations.get(t, 0) for t in tickers}
                
                # Apply MA filter if enabled (for non-momentum strategies) (ULTRA OPTIMIZED!)
                if config.get('use_sma_filter', False) and ma_filter_data is not None:
                    # Get list of current tickers (excluding CASH)
                    current_tickers = [t for t in tickers if t != 'CASH']
                    # ULTRA FAST: Use precomputed filter results!
                    filtered_tickers = [t for t in current_tickers if ma_filter_data.get(date, {}).get(t, True)]
                    excluded_assets = {t: f"Below MA" for t in current_tickers if t not in filtered_tickers}
                    
                    
                    # Redistribute allocations of excluded tickers proportionally among remaining tickers
                    if excluded_assets:
                        excluded_tickers = list(excluded_assets.keys())
                        excluded_allocation = sum(rebalance_allocations.get(t, 0) for t in excluded_tickers)
                        
                        # Set excluded tickers allocation to 0
                        for t in excluded_tickers:
                            rebalance_allocations[t] = 0
                        
                        # If no tickers remain, go to cash
                        if not filtered_tickers:
                            # Put everything in unallocated_cash
                            for t in tickers:
                                values[t][-1] = 0
                            unallocated_cash[-1] = current_total
                            unreinvested_cash[-1] = 0
                            # Clear rebalance_allocations so rest of rebalancing logic is skipped
                            rebalance_allocations = {t: 0 for t in tickers}
                        else:
                            # Redistribute excluded allocation among remaining tickers
                            if excluded_allocation > 0 and filtered_tickers:
                                total_remaining_allocation = sum(rebalance_allocations.get(t, 0) for t in filtered_tickers)
                                if total_remaining_allocation > 0:
                                    # Redistribute proportionally among remaining tickers
                                    for t in filtered_tickers:
                                        proportion = rebalance_allocations.get(t, 0) / total_remaining_allocation
                                        rebalance_allocations[t] += excluded_allocation * proportion
                                else:
                                    # If no remaining allocation, distribute equally
                                    equal_allocation = excluded_allocation / len(filtered_tickers)
                                    for t in filtered_tickers:
                                        rebalance_allocations[t] = equal_allocation
                    
                
                if use_max_allocation and rebalance_allocations:
                    max_allocation_decimal = max_allocation_percent / 100.0
                    
                    # FIRST PASS: Apply maximum allocation filter
                    capped_allocations = {}
                    excess_allocation = 0.0
                    
                    for ticker, allocation in rebalance_allocations.items():
                        # CASH is exempt from max_allocation limit to prevent money loss
                        if ticker == 'CASH':
                            capped_allocations[ticker] = allocation
                        elif allocation > max_allocation_decimal:
                            # Cap the allocation and collect excess
                            capped_allocations[ticker] = max_allocation_decimal
                            excess_allocation += (allocation - max_allocation_decimal)
                        else:
                            # Keep original allocation
                            capped_allocations[ticker] = allocation
                    
                    # Redistribute excess allocation proportionally among stocks that are below the cap
                    if excess_allocation > 0:
                        # Find stocks that can receive more allocation (below the cap) - include CASH as eligible
                        eligible_stocks = {ticker: allocation for ticker, allocation in capped_allocations.items() 
                                         if ticker == 'CASH' or allocation < max_allocation_decimal}
                        
                        if eligible_stocks:
                            # Calculate total allocation of eligible stocks
                            total_eligible_allocation = sum(eligible_stocks.values())
                            
                            if total_eligible_allocation > 0:
                                # Redistribute excess proportionally
                                for ticker in eligible_stocks:
                                    proportion = eligible_stocks[ticker] / total_eligible_allocation
                                    additional_allocation = excess_allocation * proportion
                                    new_allocation = capped_allocations[ticker] + additional_allocation
                                    
                                    # CASH can receive unlimited allocation, other stocks are capped
                                    if ticker == 'CASH':
                                        capped_allocations[ticker] = new_allocation
                                    else:
                                        # Make sure we don't exceed the cap
                                        capped_allocations[ticker] = min(new_allocation, max_allocation_decimal)
                    
                    rebalance_allocations = capped_allocations
                    
                    # Final normalization to 100% in case not enough stocks to distribute excess
                    total_alloc = sum(rebalance_allocations.values())
                    if total_alloc > 0:
                        rebalance_allocations = {ticker: allocation / total_alloc for ticker, allocation in rebalance_allocations.items()}
                
                # Apply minimal threshold filter for non-momentum strategies during rebalancing
                if use_threshold and rebalance_allocations:
                    threshold_decimal = threshold_percent / 100.0
                    
                    # First: Filter out stocks below threshold
                    filtered_allocations = {}
                    for t in tickers:
                        allocation = rebalance_allocations.get(t, 0)
                        if allocation >= threshold_decimal:
                            # Keep stocks above or equal to threshold
                            filtered_allocations[t] = allocation
                    
                    # Then: Normalize remaining stocks to sum to 1
                    if filtered_allocations:
                        total_allocation = sum(filtered_allocations.values())
                        if total_allocation > 0:
                            rebalance_allocations = {t: allocation / total_allocation for t, allocation in filtered_allocations.items()}
                        else:
                            rebalance_allocations = {}
                    else:
                        # If no stocks meet threshold, use original allocations
                        rebalance_allocations = {t: allocations.get(t, 0) for t in tickers}
                
                # SECOND PASS: Apply maximum allocation filter again (in case normalization created new excess)
                if use_max_allocation and rebalance_allocations:
                    max_allocation_decimal = max_allocation_percent / 100.0
                    
                    # Check if any stocks exceed the cap after threshold filtering and normalization
                    capped_allocations = {}
                    excess_allocation = 0.0
                    
                    for ticker, allocation in rebalance_allocations.items():
                        # CASH is exempt from max_allocation limit to prevent money loss
                        if ticker == 'CASH':
                            capped_allocations[ticker] = allocation
                        elif allocation > max_allocation_decimal:
                            # Cap the allocation and collect excess
                            capped_allocations[ticker] = max_allocation_decimal
                            excess_allocation += (allocation - max_allocation_decimal)
                        else:
                            # Keep original allocation
                            capped_allocations[ticker] = allocation
                    
                    # Redistribute excess allocation proportionally among stocks that are below the cap
                    if excess_allocation > 0:
                        # Find stocks that can receive more allocation (below the cap) - include CASH as eligible
                        eligible_stocks = {ticker: allocation for ticker, allocation in capped_allocations.items() 
                                         if ticker == 'CASH' or allocation < max_allocation_decimal}
                        
                        if eligible_stocks:
                            # Calculate total allocation of eligible stocks
                            total_eligible_allocation = sum(eligible_stocks.values())
                            
                            if total_eligible_allocation > 0:
                                # Redistribute excess proportionally
                                for ticker in eligible_stocks:
                                    proportion = eligible_stocks[ticker] / total_eligible_allocation
                                    additional_allocation = excess_allocation * proportion
                                    new_allocation = capped_allocations[ticker] + additional_allocation
                                    
                                    # CASH can receive unlimited allocation, other stocks are capped
                                    if ticker == 'CASH':
                                        capped_allocations[ticker] = new_allocation
                                    else:
                                        # Make sure we don't exceed the cap
                                        capped_allocations[ticker] = min(new_allocation, max_allocation_decimal)
                    
                    rebalance_allocations = capped_allocations
                    
                    # Final normalization to 100% in case not enough stocks to distribute excess
                    total_alloc = sum(rebalance_allocations.values())
                    if total_alloc > 0:
                        rebalance_allocations = {ticker: allocation / total_alloc for ticker, allocation in rebalance_allocations.items()}
                
                sum_alloc = sum(rebalance_allocations.values())
                if sum_alloc > 0:
                    # For Buy & Hold strategies, only distribute new cash without touching existing holdings
                    if rebalancing_frequency in ["Buy & Hold", "Buy & Hold (Target)"]:
                        # Calculate current proportions for Buy & Hold, or use target allocations for Buy & Hold (Target)
                        if rebalancing_frequency == "Buy & Hold":
                            # Use current proportions from existing holdings
                            current_total_value = sum(values[t][-1] for t in tickers)
                            if current_total_value > 0:
                                current_proportions = {t: values[t][-1] / current_total_value for t in tickers}
                            else:
                                # If no current holdings, use equal weights
                                current_proportions = {t: 1.0 / len(tickers) for t in tickers}
                        else:  # "Buy & Hold (Target)"
                            # Use target allocations
                            current_proportions = {t: rebalance_allocations.get(t, 0) / sum_alloc for t in tickers}
                        
                        # Only distribute the new cash (unallocated_cash + unreinvested_cash)
                        cash_to_distribute = unallocated_cash[-1] + unreinvested_cash[-1]
                        for t in tickers:
                            # Add new cash proportionally to existing holdings
                            values[t][-1] += cash_to_distribute * current_proportions.get(t, 0)
                        unreinvested_cash[-1] = 0
                        unallocated_cash[-1] = 0
                    else:
                        # Normal rebalancing: replace all holdings
                        # For targeted rebalancing, rebalance TO THE THRESHOLD LIMITS, not to base allocations
                        if config.get('use_targeted_rebalancing', False):
                            targeted_settings = config.get('targeted_rebalancing_settings', {})
                            target_allocations = {}
                            
                            # Calculate target allocations based on threshold limits
                            for t in tickers:
                                if t in targeted_settings and targeted_settings[t].get('enabled', False):
                                    current_allocation_pct = (values[t][-1] / current_total) * 100 if current_total > 0 else 0
                                    max_threshold = targeted_settings[t].get('max_allocation', 100.0)
                                    min_threshold = targeted_settings[t].get('min_allocation', 0.0)
                                    
                                    # Rebalance to the threshold limit that was exceeded
                                    if current_allocation_pct > max_threshold:
                                        target_allocations[t] = max_threshold / 100.0
                                    elif current_allocation_pct < min_threshold:
                                        target_allocations[t] = min_threshold / 100.0
                                    else:
                                        # Within bounds - keep current allocation
                                        target_allocations[t] = current_allocation_pct / 100.0
                                else:
                                    # Not in targeted settings - use current allocation
                                    target_allocations[t] = (values[t][-1] / current_total) if current_total > 0 else rebalance_allocations.get(t, 0)
                            
                            # For targeted rebalancing, calculate the remaining allocation for non-targeted tickers
                            total_targeted = 0
                            targeted_count = 0
                            
                            for t in tickers:
                                if t in targeted_settings and targeted_settings[t].get('enabled', False):
                                    total_targeted += target_allocations[t]
                                    targeted_count += 1
                            
                            # Calculate remaining allocation for non-targeted tickers
                            remaining_allocation = 1.0 - total_targeted
                            non_targeted_tickers = [t for t in tickers if t not in targeted_settings or not targeted_settings[t].get('enabled', False)]
                            
                            if non_targeted_tickers and remaining_allocation > 0:
                                # Distribute remaining allocation PROPORTIONALLY to base allocations (not equally)
                                non_targeted_base_sum = sum(rebalance_allocations.get(t, 0) for t in non_targeted_tickers)
                                if non_targeted_base_sum > 0:
                                    # Distribute proportionally to base allocations
                                    for t in non_targeted_tickers:
                                        base_proportion = rebalance_allocations.get(t, 0) / non_targeted_base_sum
                                        target_allocations[t] = base_proportion * remaining_allocation
                                else:
                                    # If no base allocations, distribute equally
                                    allocation_per_ticker = remaining_allocation / len(non_targeted_tickers)
                                    for t in non_targeted_tickers:
                                        target_allocations[t] = allocation_per_ticker
                            elif non_targeted_tickers:
                                # No remaining allocation - set non-targeted to 0
                                for t in non_targeted_tickers:
                                    target_allocations[t] = 0.0
                            
                            # Apply target allocations
                            for t in tickers:
                                values[t][-1] = current_total * target_allocations.get(t, 0)
                        else:
                            # Regular rebalancing - use base allocations
                            for t in tickers:
                                weight = rebalance_allocations.get(t, 0) / sum_alloc
                                values[t][-1] = current_total * weight
                        
                        unreinvested_cash[-1] = 0
                        unallocated_cash[-1] = 0
            
            # Note: Daily allocations will be stored below after rebalancing
        
        # Store daily allocations for smooth allocation evolution charts (AFTER rebalancing)
        # For "start oldest" mode, only include tickers that have data available at this date
        available_tickers_at_date = []
        for t in tickers:
            if t in reindexed_data:
                price_value = reindexed_data[t].loc[date]
                # Handle case where loc returns a Series instead of scalar
                if isinstance(price_value, pd.Series):
                    price_value = price_value.iloc[0] if len(price_value) > 0 else np.nan
                if not pd.isna(price_value):
                    available_tickers_at_date.append(t)
        
        current_total_after_rebal = sum(values[t][-1] for t in available_tickers_at_date) + unallocated_cash[-1] + unreinvested_cash[-1]
        if current_total_after_rebal > 0:
            daily_allocs = {t: values[t][-1] / current_total_after_rebal for t in available_tickers_at_date}
            daily_allocs['CASH'] = (unallocated_cash[-1] + unreinvested_cash[-1]) / current_total_after_rebal
            historical_allocations[date] = daily_allocs

    # Store last allocation
    last_date = sim_index[-1]
    last_total = sum(values[t][-1] for t in tickers) + unallocated_cash[-1] + unreinvested_cash[-1]
    if last_total > 0:
        historical_allocations[last_date] = {t: values[t][-1] / last_total for t in tickers}
        historical_allocations[last_date]['CASH'] = unallocated_cash[-1] / last_total if last_total > 0 else 0
    else:
        historical_allocations[last_date] = {t: 0 for t in tickers}
        historical_allocations[last_date]['CASH'] = 0
    
    # Store last metrics: always add a last-rebalance snapshot so the UI has a metrics row
    # If momentum is used, compute metrics; otherwise build metrics from the last allocation snapshot
    if use_momentum:
        returns, valid_assets = calculate_momentum(last_date, set(tickers), momentum_windows, config['stocks'])
        weights, metrics_on_rebal = calculate_momentum_weights(
            returns, valid_assets, date=last_date,
            momentum_strategy=config.get('momentum_strategy', 'Classic'),
            negative_momentum_strategy=config.get('negative_momentum_strategy', 'Cash'),
            config=config
        )
        # For momentum strategies, do NOT force add CASH - let the momentum strategy determine allocations
        # CASH should only be added if the momentum strategy itself decides to go to cash
        # (which happens when all momentum scores are negative and negative_momentum_strategy is 'Cash')
        historical_metrics[last_date] = metrics_on_rebal
    else:
        # Build a metrics snapshot from the last allocation so there's always a 'last rebalance' metrics entry
        if last_date in historical_allocations:
            alloc_snapshot = historical_allocations.get(last_date, {})
            metrics_on_rebal = {}
            for ticker_sym, alloc_val in alloc_snapshot.items():
                metrics_on_rebal[ticker_sym] = {'Calculated_Weight': alloc_val}
            # Ensure CASH entry exists
            if 'CASH' not in metrics_on_rebal:
                metrics_on_rebal['CASH'] = {'Calculated_Weight': alloc_snapshot.get('CASH', 0)}
            # Only set if not already present
            if last_date not in historical_metrics:
                historical_metrics[last_date] = metrics_on_rebal

    results = pd.DataFrame(index=sim_index)
    for t in tickers:
        results[f"Value_{t}"] = values[t]
    results["Unallocated_cash"] = unallocated_cash
    results["Unreinvested_cash"] = unreinvested_cash
    results["Total_assets"] = results[[f"Value_{t}" for t in tickers]].sum(axis=1)
    results["Total_with_dividends_plus_cash"] = results["Total_assets"] + results["Unallocated_cash"] + results["Unreinvested_cash"]
    results['Portfolio_Value_No_Additions'] = portfolio_no_additions

    return results["Total_with_dividends_plus_cash"], results['Portfolio_Value_No_Additions'], historical_allocations, historical_metrics

def single_backtest_year_aware(config, sim_index, reindexed_data, _cache_version="v2_year_aware"):
    """
    Year-aware backtest that treats dynamic tickers EXACTLY like regular tickers
    but with year-specific ticker selection based on CSV data
    """
    import pandas as pd
    
    def calculate_momentum(date, current_assets, momentum_windows, stocks_config=None):
        """Momentum calculation function (same as in single_backtest)"""
        cumulative_returns, valid_assets = {}, []
        
        # Apply MA filter BEFORE calculating momentum (ULTRA OPTIMIZED!)
        assets_to_calculate = current_assets
        if config.get('use_sma_filter', False) and ma_filter_data is not None:
            # ULTRA FAST: Use precomputed filter results!
            filtered_assets = [t for t in current_assets if ma_filter_data.get(date, {}).get(t, True)]
            
            # If no assets remain after MA filtering, go to cash immediately
            if not filtered_assets:
                return {}, []
            
            # Only calculate momentum for filtered assets
            assets_to_calculate = filtered_assets
        filtered_windows = [w for w in momentum_windows if w["weight"] > 0]
        # Normalize weights so they sum to 1 (same as app.py)
        total_weight = sum(w["weight"] for w in filtered_windows)
        if total_weight == 0:
            normalized_weights = [0 for _ in filtered_windows]
        else:
            normalized_weights = [w["weight"] / total_weight for w in filtered_windows]
        start_dates_config = {t: reindexed_data[t].first_valid_index() for t in current_assets if t in reindexed_data and not isinstance(reindexed_data[t], str)}
        
        # Calculate momentum only for SMA-filtered assets
        for t in assets_to_calculate:
            is_valid, asset_returns = True, 0.0
            for idx, window in enumerate(filtered_windows):
                lookback, exclude = window["lookback"], window["exclude"]
                weight = normalized_weights[idx]
                start_mom = date - pd.Timedelta(days=lookback)
                end_mom = date - pd.Timedelta(days=exclude)
                if start_dates_config.get(t, pd.Timestamp.max) > start_mom:
                    is_valid = False; break
                df_t = reindexed_data[t]
                price_start_index = df_t.index.asof(start_mom)
                price_end_index = df_t.index.asof(end_mom)
                if pd.isna(price_start_index) or pd.isna(price_end_index):
                    is_valid = False; break
                price_start = df_t.loc[price_start_index, "Close"]
                price_end = df_t.loc[price_end_index, "Close"]
                if pd.isna(price_start) or pd.isna(price_end) or price_start == 0:
                    is_valid = False; break
                ret = (price_end - price_start) / price_start
                asset_returns += ret * weight
            if is_valid:
                cumulative_returns[t] = asset_returns
                valid_assets.append(t)
        return cumulative_returns, valid_assets

    def calculate_momentum_weights(returns, valid_assets, date, momentum_strategy='Classic', negative_momentum_strategy='Cash', config=None):
        """Momentum weights calculation function (EXACT same as in single_backtest)"""
        # Mirror approach used in allocations/app.py: compute weights from raw momentum
        # (Classic or Relative) and then optionally post-filter by inverse volatility
        # and inverse absolute beta (multiplicative), then renormalize. This avoids
        # dividing by beta directly which flips signs when beta is negative.
        if not valid_assets:
            return {}, {}
        # Keep only non-nan momentum values
        rets = {t: returns.get(t, np.nan) for t in valid_assets}
        rets = {t: rets[t] for t in rets if not pd.isna(rets[t])}
        if not rets:
            return {}, {}

        metrics = {t: {} for t in rets.keys()}

        # compute beta and volatility metrics when requested
        beta_vals = {}
        vol_vals = {}
        # Get config parameters (same as in single_backtest)
        if config is None:
            config = {}
        calc_beta = config.get('calc_beta', False)
        calc_volatility = config.get('calc_volatility', False)
        benchmark_ticker = config.get('benchmark_ticker', '^GSPC')
        beta_window_days = config.get('beta_window_days', 365)
        exclude_days_beta = config.get('exclude_days_beta', 30)
        vol_window_days = config.get('vol_window_days', 365)
        exclude_days_vol = config.get('exclude_days_vol', 30)
        
        df_bench = reindexed_data.get(benchmark_ticker)
        if calc_beta:
            start_beta = date - pd.Timedelta(days=beta_window_days)
            end_beta = date - pd.Timedelta(days=exclude_days_beta)
        if calc_volatility:
            start_vol = date - pd.Timedelta(days=vol_window_days)
            end_vol = date - pd.Timedelta(days=exclude_days_vol)

        for t in list(rets.keys()):
            df_t = reindexed_data.get(t)
            if calc_beta and df_bench is not None and isinstance(df_t, pd.DataFrame):
                mask_beta = (df_t.index >= start_beta) & (df_t.index <= end_beta)
                returns_t_beta = df_t.loc[mask_beta, 'Price_change']
                mask_bench_beta = (df_bench.index >= start_beta) & (df_bench.index <= end_beta)
                returns_bench_beta = df_bench.loc[mask_bench_beta, 'Price_change']
                if len(returns_t_beta) < 2 or len(returns_bench_beta) < 2:
                    beta_vals[t] = np.nan
                else:
                    variance = np.var(returns_bench_beta)
                    beta_vals[t] = (np.cov(returns_t_beta, returns_bench_beta)[0,1] / variance) if variance > 0 else np.nan
                metrics[t]['Beta'] = beta_vals[t]
            if calc_volatility and isinstance(df_t, pd.DataFrame):
                mask_vol = (df_t.index >= start_vol) & (df_t.index <= end_vol)
                returns_t_vol = df_t.loc[mask_vol, 'Price_change']
                if len(returns_t_vol) < 2:
                    vol_vals[t] = np.nan
                else:
                    vol_vals[t] = returns_t_vol.std() * np.sqrt(365.25)
                metrics[t]['Volatility'] = vol_vals[t]

        # attach raw momentum
        for t in rets:
            metrics[t]['Momentum'] = rets[t]

        # Build initial weights from raw momentum (Classic or Relative)
        weights = {}
        rets_keys = list(rets.keys())
        all_negative = all(rets[t] <= 0 for t in rets_keys)
        relative_mode = isinstance(momentum_strategy, str) and momentum_strategy.lower().startswith('relat')
        
        # Calculate effective strategy for negative momentum (needed for equal weight logic)
        effective_strategy_for_equal_weight = None
        if all_negative:
            is_sp500top20 = any(is_special_dynamic_ticker(t) for t in rets_keys) or config.get('dynamic_portfolio_data') is not None
            effective_strategy_for_equal_weight = negative_momentum_strategy
            if is_sp500top20 and negative_momentum_strategy == 'Cash':
                effective_strategy_for_equal_weight = 'Relative momentum'

        def calculate_near_zero_symmetric_momentum(returns, neutral_zone=0.05):
            """
            Relative momentum avec zone neutre autour de 0 - VERSION AM√âLIOR√âE
            
            Avantages:
            - Les rendements dans [-5%, +5%] ont des allocations tr√®s similaires
            - Pas de biaisage par le pire actif
            - Compression progressive des actifs n√©gatifs
            - Traitement ind√©pendant de chaque ticker
            """
            import numpy as np
            import math
            
            returns_array = np.array(list(returns.values()))
            
            # NZS: Use relative ranking like Relative Momentum but with compression
            min_score = min(returns.values())
            offset = -min_score + 0.01 if min_score < 0 else 0.01
            shifted = {t: max(0.01, returns[t] + offset) for t in returns.keys()}
            
            # Apply NZS compression to the shifted scores
            compressed_scores = {}
            for ticker, shifted_val in shifted.items():
                return_val = returns[ticker]
                
                # Zone neutre : allocations similaires pour rendements proches de 0
                if abs(return_val) <= neutral_zone:
                    # Dans la zone neutre : allocations presque identiques
                    compression_factor = 1.0 - (abs(return_val) / neutral_zone) * 0.1
                else:
                    # Au-del√† de la zone neutre : compression progressive
                    if return_val < -neutral_zone:
                        # N√©gatif au-del√† de la zone neutre
                        excess_negativity = abs(return_val) - neutral_zone
                        compression_factor = 0.9 * math.exp(-excess_negativity * 3.0)
                    else:
                        # Positif au-del√† de la zone neutre
                        compression_factor = 1.0
                
                compressed_scores[ticker] = shifted_val * compression_factor
            
            # Normalize
            sum_scores = sum(compressed_scores.values())
            weights = {t: compressed_scores[t] / sum_scores for t in compressed_scores}
            
            return weights

        if all_negative:
            # Special handling for SP500TOP20: use Relative as default instead of Cash
            is_sp500top20 = any(is_special_dynamic_ticker(t) for t in rets_keys) or config.get('dynamic_portfolio_data') is not None
            
            # For SP500TOP20, use Relative as default if user chose Cash
            effective_strategy = negative_momentum_strategy
            if is_sp500top20 and negative_momentum_strategy == 'Cash':
                effective_strategy = 'Relative momentum'
            
            if effective_strategy == 'Cash':
                weights = {t: 0.0 for t in rets_keys}
            elif effective_strategy == 'Equal weight':
                weights = {t: 1.0 / len(rets_keys) for t in rets_keys}
            elif effective_strategy == 'Relative momentum':
                # ANCIENNE LOGIQUE Relative Momentum
                min_score = min(rets[t] for t in rets_keys)
                offset = -min_score + 0.01
                shifted = {t: max(0.01, rets[t] + offset) for t in rets_keys}
                ssum = sum(shifted.values())
                weights = {t: shifted[t] / ssum for t in shifted}
            elif effective_strategy == 'Near-Zero Symmetry':
                # NOUVELLE LOGIQUE Near-Zero Symmetry
                weights = calculate_near_zero_symmetric_momentum(rets)
        else:
            if relative_mode:
                if momentum_strategy == 'Relative Momentum':
                    # ANCIENNE LOGIQUE Relative Momentum
                    min_score = min(rets[t] for t in rets_keys)
                    offset = -min_score + 0.01 if min_score < 0 else 0.01
                    shifted = {t: max(0.01, rets[t] + offset) for t in rets_keys}
                    ssum = sum(shifted.values())
                    weights = {t: shifted[t] / ssum for t in shifted}
                elif momentum_strategy == 'Near-Zero Symmetry':
                    # NOUVELLE LOGIQUE Near-Zero Symmetry
                    weights = calculate_near_zero_symmetric_momentum(rets)
            else:
                # Check user's selection for momentum strategy
                if momentum_strategy == 'Classic':
                    positive_scores = {t: rets[t] for t in rets_keys if rets[t] > 0}
                    if positive_scores:
                        ssum = sum(positive_scores.values())
                        weights = {t: (positive_scores.get(t, 0.0) / ssum) for t in rets_keys}
                    else:
                        weights = {t: 0.0 for t in rets_keys}
                elif momentum_strategy == 'Relative Momentum':
                    # ANCIENNE LOGIQUE Relative Momentum
                    min_score = min(rets.values())
                    offset = -min_score + 0.01 if min_score < 0 else 0.01
                    shifted = {t: max(0.01, rets[t] + offset) for t in rets_keys}
                    ssum = sum(shifted.values())
                    weights = {t: shifted[t] / ssum for t in shifted}
                elif momentum_strategy == 'Near-Zero Symmetry':
                    # NOUVELLE LOGIQUE Near-Zero Symmetry
                    weights = calculate_near_zero_symmetric_momentum(rets)
                else:
                    # Fallback to Classic if unknown strategy
                    positive_scores = {t: rets[t] for t in rets_keys if rets[t] > 0}
                    if positive_scores:
                        ssum = sum(positive_scores.values())
                        weights = {t: (positive_scores.get(t, 0.0) / ssum) for t in rets_keys}
                    else:
                        weights = {t: 0.0 for t in rets_keys}

        # Post-filtering: multiply weights by inverse vol and inverse |beta| when requested
        # BUT NOT for Equal weight strategy (when all negative) - keep true equal weights
        if (calc_volatility or calc_beta) and weights and not (all_negative and effective_strategy == 'Equal weight'):
            filter_scores = {}
            for t in weights:
                score = 1.0
                if calc_volatility:
                    v = metrics.get(t, {}).get('Volatility', np.nan)
                    if not pd.isna(v) and v > 0:
                        score *= 1.0 / v
                if calc_beta:
                    b = metrics.get(t, {}).get('Beta', np.nan)
                    if not pd.isna(b) and b != 0:
                        score *= 1.0 / abs(b)
                filter_scores[t] = score

            filtered = {t: weights.get(t, 0.0) * filter_scores.get(t, 1.0) for t in weights}
            total_filtered = sum(filtered.values())
            if total_filtered > 0:
                weights = {t: filtered[t] / total_filtered for t in filtered}

        # STEP 1: Apply Limit to Top N filter FIRST (if enabled) - SECOND OCCURRENCE
        use_limit_to_top_n = config.get('use_limit_to_top_n', False)
        limit_to_top_n_tickers = config.get('limit_to_top_n_tickers', 10)
        
        should_apply_limit_to_top_n = False
        if use_limit_to_top_n and limit_to_top_n_tickers > 0 and weights:
            if all_negative:
                if effective_strategy_for_equal_weight in ['Relative momentum', 'Near-Zero Symmetry']:
                    should_apply_limit_to_top_n = True
            else:
                should_apply_limit_to_top_n = True
        
        if should_apply_limit_to_top_n:
            ticker_weights = [(ticker, weight) for ticker, weight in weights.items() 
                            if ticker != 'CASH' and weight > 0]
            ticker_weights.sort(key=lambda x: x[1], reverse=True)
            
            if ticker_weights:
                n_to_select = min(limit_to_top_n_tickers, len(ticker_weights))
                top_n_tickers = [ticker for ticker, _ in ticker_weights[:n_to_select]]
                
                new_weights = {}
                total_top_n_weight = 0.0
                for ticker in weights.keys():
                    if ticker == 'CASH':
                        new_weights[ticker] = weights.get(ticker, 0.0)
                    elif ticker in top_n_tickers:
                        new_weights[ticker] = weights.get(ticker, 0.0)
                        total_top_n_weight += weights.get(ticker, 0.0)
                    else:
                        new_weights[ticker] = 0.0
                
                cash_weight = new_weights.get('CASH', 0.0)
                if cash_weight > 0 and total_top_n_weight > 0:
                    for ticker in top_n_tickers:
                        ticker_weight = new_weights[ticker]
                        proportion = ticker_weight / total_top_n_weight if total_top_n_weight > 0 else 0.0
                        new_weights[ticker] += cash_weight * proportion
                    new_weights['CASH'] = 0.0
                
                total_weight = sum(new_weights.values())
                if total_weight > 0:
                    weights = {ticker: weight / total_weight for ticker, weight in new_weights.items()}
                else:
                    weights = new_weights

        # STEP 2: Apply Equal Weight filter AFTER Limit to Top N (if enabled) - SECOND OCCURRENCE
        use_equal_weight = config.get('use_equal_weight', False)
        equal_weight_n_tickers = config.get('equal_weight_n_tickers', 10)
        
        should_apply_equal_weight = False
        if use_equal_weight and equal_weight_n_tickers > 0 and weights:
            if all_negative:
                if effective_strategy_for_equal_weight in ['Relative momentum', 'Near-Zero Symmetry']:
                    should_apply_equal_weight = True
            else:
                should_apply_equal_weight = True
        
        if should_apply_equal_weight:
            ticker_weights = [(ticker, weight) for ticker, weight in weights.items() 
                            if ticker != 'CASH' and weight > 0]
            
            if ticker_weights:
                if should_apply_limit_to_top_n:
                    top_n_tickers = [ticker for ticker, _ in ticker_weights]
                else:
                    ticker_weights.sort(key=lambda x: x[1], reverse=True)
                    n_to_select = min(equal_weight_n_tickers, len(ticker_weights))
                    top_n_tickers = [ticker for ticker, _ in ticker_weights[:n_to_select]]
                
                # Calculate equal weight per ticker (1/n where n is the actual number selected)
                equal_weight_per_ticker = 1.0 / len(top_n_tickers)
                
                # Create new weights dictionary with equal weights for top N, 0 for others
                new_weights = {}
                for ticker in weights.keys():
                    if ticker == 'CASH':
                        # Keep CASH weight as is (should be 0 in most cases)
                        new_weights[ticker] = weights.get(ticker, 0.0)
                    elif ticker in top_n_tickers:
                        new_weights[ticker] = equal_weight_per_ticker
                    else:
                        # Set to 0 for tickers not in top N
                        new_weights[ticker] = 0.0
                
                # If there's any CASH weight, distribute it proportionally to top N tickers
                cash_weight = new_weights.get('CASH', 0.0)
                if cash_weight > 0:
                    # Add cash weight proportionally to top N tickers
                    for ticker in top_n_tickers:
                        new_weights[ticker] += cash_weight / len(top_n_tickers)
                    new_weights['CASH'] = 0.0
                
                # Final normalization to ensure weights sum to exactly 1.0 (100%)
                # This is important especially when fewer tickers remain than requested N
                total_weight = sum(new_weights.values())
                if total_weight > 0:
                    weights = {ticker: weight / total_weight for ticker, weight in new_weights.items()}
                else:
                    # Fallback: if somehow total is 0, keep the new_weights as is
                    weights = new_weights

        return weights, metrics
    import numpy as np
    
    # Get dynamic portfolio data for year-aware ticker selection
    dynamic_portfolio_data = None
    special_ticker = None
    for stock in config['stocks']:
        if is_special_dynamic_ticker(stock['ticker']):
            special_ticker = stock['ticker']
            dynamic_portfolio_data = get_dynamic_portfolio_data(stock['ticker'])
            break
    
    if not dynamic_portfolio_data:
        # Fallback to regular backtest if no dynamic data
        return single_backtest(config, sim_index, reindexed_data)
    
    # READ CSV AND GET ALL TICKERS TO DOWNLOAD
    try:
        df = pd.read_csv('TOP_20_SP500_COMPLETE_TEMPLATE.csv')
        all_tickers = df['Ticker'].unique().tolist()
    except:
        all_tickers = ['XOM', 'IBM', 'GE', 'BMY', 'MRK', 'KO', 'WMT', 'PG', 'VZ', 'JNJ', 'LLY', 'PEP', 'DIS', 'T', 'MMM', 'AIG', 'BA', 'MCD', 'PFE', 'SLB']
    
    # CREATE YEAR-TO-TICKERS MAPPING
    year_tickers_map = {}
    for year in df['Year'].unique():
        year_stocks = df[df['Year'] == year].sort_values('Rank').head(20)
        year_tickers_map[year] = year_stocks['Ticker'].tolist()
    
    # CREATE CONFIG WITH ALL TICKERS (so they get downloaded)
    modified_config = config.copy()
    modified_config['stocks'] = []
    
    # Add all tickers with 0% allocation (they'll be used dynamically during rebalancing)
    for ticker in all_tickers:
        modified_config['stocks'].append({
            'ticker': ticker,
            'allocation': 0.0  # 0% initially, will be set to 5% during rebalancing
        })
    
    # Add the special ticker with 100% (this triggers the dynamic logic)
    modified_config['stocks'].append({
        'ticker': 'SP500TOP20',
        'allocation': 100.0
    })
    
    # MODIFY THE SINGLE_BACKTEST TO USE YEAR-AWARE REBALANCING
    # We need to override the rebalancing logic to use year-specific tickers
    
    # Get original parameters
    rebalancing_frequency = config.get('rebalancing_frequency', 'Monthly')
    use_momentum = config.get('use_momentum', False)
    momentum_windows = config.get('momentum_windows', [])
    initial_value = config.get('initial_value', 10000)
    added_amount = config.get('added_amount', 0)
    added_frequency = config.get('added_frequency', 'None')
    
    # OPTIMIZATION: Precompute MA columns once at the start if MA filter OR MA cross rebalancing is enabled
    # This is the key performance improvement - compute MA once instead of every day!
    ma_crossings_data = None
    ma_filter_data = None
    if config.get('use_sma_filter', False) or config.get('ma_cross_rebalance', False):
        ma_window = config.get('sma_window', 200)
        ma_type = config.get('ma_type', 'SMA')
        ma_multiplier = config.get('ma_multiplier', 1.48)  # Default multiplier for market days
        precompute_ma_columns(reindexed_data, ma_window, ma_type, ma_multiplier)
        
        # ULTRA OPTIMIZATION: Precompute ALL MA filters if MA filter is enabled
        if config.get('use_sma_filter', False):
            ma_filter_data = precompute_ma_filters(reindexed_data, ma_window, ma_type, ma_multiplier, config.get('stocks', []))
        
        # ULTRA OPTIMIZATION: Precompute ALL MA crossings if MA cross rebalancing is enabled
        if config.get('ma_cross_rebalance', False):
            tolerance_percent = config.get('ma_tolerance_percent', 2.0)
            confirmation_days = config.get('ma_confirmation_days', 3)
            ma_crossings_data = precompute_ma_crossings(reindexed_data, ma_window, ma_type, tolerance_percent, confirmation_days)
    
    # Initialize portfolio values
    values = {t: [initial_value if t == 'SP500TOP20' else 0] for t in all_tickers + ['SP500TOP20']}
    unallocated_cash = [0]
    unreinvested_cash = [0]
    
    # Historical tracking
    historical_allocations = {}
    historical_metrics = {}
    
    # PRE-CALCULATE ADDITION DATES (like normal portfolios)
    dates_added = set()
    if added_frequency != "None" and added_amount > 0:
        for date in sim_index:
            is_addition_date = False
            if added_frequency == "Daily":
                is_addition_date = True
            elif added_frequency == "Weekly" and date.weekday() == 0:
                is_addition_date = True
            elif added_frequency == "Monthly" and date.day == 1:
                is_addition_date = True
            elif added_frequency == "Quarterly" and date.month in [1, 4, 7, 10] and date.day == 1:
                is_addition_date = True
            elif added_frequency == "Annually" and date.month == 1 and date.day == 1:
                is_addition_date = True
            
            if is_addition_date:
                dates_added.add(date)
    
    # Process each date
    for i, date in enumerate(sim_index):
        if i == 0:
            continue
            
        # GET CURRENT YEAR'S TICKERS
        current_year = date.year
        if current_year in year_tickers_map:
            current_year_tickers = year_tickers_map[current_year]
        else:
            current_year_tickers = year_tickers_map.get(1989, all_tickers[:20])
        
        # FILTER TO ONLY AVAILABLE TICKERS
        available_tickers = [t for t in current_year_tickers if t in reindexed_data and not isinstance(reindexed_data[t], str)]
        
        # CHECK IF WE SHOULD REBALANCE
        should_rebalance = False
        if rebalancing_frequency == "Daily":
            should_rebalance = True
        elif rebalancing_frequency == "Weekly":
            should_rebalance = date.weekday() == 0
        elif rebalancing_frequency == "Biweekly":
            # Biweekly: every 2 weeks on Monday
            # Simple implementation: every 14 days from start date
            days_since_start = (date - sim_index[0]).days
            should_rebalance = days_since_start % 14 == 0 and date.weekday() == 0
        elif rebalancing_frequency == "Monthly":
            should_rebalance = date.day == 1
        elif rebalancing_frequency == "Quarterly":
            should_rebalance = date.month in [1, 4, 7, 10] and date.day == 1
        elif rebalancing_frequency == "Semiannually":
            should_rebalance = date.month in [1, 7] and date.day == 1
        elif rebalancing_frequency == "Annually":
            should_rebalance = date.month == 1 and date.day == 1
        elif rebalancing_frequency in ["Buy & Hold", "Buy & Hold (Target)"]:
            # Buy & Hold: only rebalance on first day
            should_rebalance = date == sim_index[0]
        elif rebalancing_frequency in ["Never", "none"]:
            should_rebalance = False
        
        # Check for MA cross rebalancing (if enabled) - ULTRA OPTIMIZED!
        ma_cross_rebalance = config.get('ma_cross_rebalance', False)
        if ma_cross_rebalance and ma_crossings_data is not None:
            # ULTRA FAST: Just check if this date has precomputed crossings!
            if date in ma_crossings_data:
                crossed_assets = list(ma_crossings_data[date].keys())
                should_rebalance = True
                print(f"[MA CROSS] Detected confirmed MA cross for {crossed_assets} at {date} (precomputed), triggering immediate rebalancing")
        
        if should_rebalance and available_tickers:
            # CALCULATE CURRENT TOTAL VALUE
            current_total = sum(values[t][-1] for t in all_tickers + ['SP500TOP20'])
            
            # ADD PERIODIC CONTRIBUTIONS - Use pre-calculated dates
            if date in dates_added:
                current_total += added_amount
            
            if use_momentum:
                # MOMENTUM-BASED REBALANCING - Use the SAME momentum logic as regular backtests
                # Just pass the dynamic tickers instead of user-entered tickers
                returns, valid_assets = calculate_momentum(date, set(available_tickers), momentum_windows, config['stocks'])
                if valid_assets:
                    weights, metrics_on_rebal = calculate_momentum_weights(
                        returns, valid_assets, date, config.get('momentum_strategy', 'Classic'), 
                        config.get('negative_momentum_strategy', 'Cash'), config
                    )
                    
                    # Reset all values
                    for t in all_tickers + ['SP500TOP20']:
                        values[t].append(0)
                    
                    # Set values based on momentum weights
                    for t in available_tickers:
                        if t in weights:
                            values[t][-1] = current_total * weights[t]
                        else:
                            values[t][-1] = 0
                    
                    # Update cash
                    unallocated_cash.append(current_total * weights.get('CASH', 0))
                    unreinvested_cash.append(0)
                    
                    # Store metrics
                    historical_metrics[date] = metrics_on_rebal
                else:
                    # No valid momentum data, use equal weights
                    equal_weight = current_total / len(available_tickers)
                    for t in all_tickers + ['SP500TOP20']:
                        values[t].append(0)
                    for t in available_tickers:
                        values[t][-1] = equal_weight
                    unallocated_cash.append(0)
                    unreinvested_cash.append(0)
            else:
                # EQUAL WEIGHT REBALANCING
                equal_weight = current_total / len(available_tickers)
                
                # Reset all values
                for t in all_tickers + ['SP500TOP20']:
                    values[t].append(0)
                
                # Set values for current year's tickers
                for t in available_tickers:
                    values[t][-1] = equal_weight
                
                unallocated_cash.append(0)
                unreinvested_cash.append(0)
            
            # Store allocation snapshot AS PERCENTAGES (like normal backtest)
            allocation_snapshot = {t: values[t][-1] / current_total for t in available_tickers if values[t][-1] > 0}
            allocation_snapshot['CASH'] = unallocated_cash[-1] / current_total if current_total > 0 else 0
            historical_allocations[date] = allocation_snapshot
        else:
            # NO REBALANCING - just update values based on price changes
            for t in all_tickers + ['SP500TOP20']:
                if t in reindexed_data and not isinstance(reindexed_data[t], str) and t != 'SP500TOP20':
                    try:
                        if i < len(reindexed_data[t]):
                            price_change = reindexed_data[t].iloc[i]['Price_change']
                            values[t].append(values[t][-1] * (1 + price_change))
                        else:
                            values[t].append(values[t][-1])
                    except:
                        values[t].append(values[t][-1])
                else:
                    values[t].append(values[t][-1])
            
            unallocated_cash.append(unallocated_cash[-1])
            unreinvested_cash.append(unreinvested_cash[-1])
            
            # ADD PERIODIC CONTRIBUTIONS (even when not rebalancing) - Use pre-calculated dates
            if date in dates_added:
                unallocated_cash[-1] += added_amount
            
            # Store current allocation snapshot (even when not rebalancing)
            current_total = sum(values[t][-1] for t in all_tickers + ['SP500TOP20']) + unallocated_cash[-1] + unreinvested_cash[-1]
            if current_total > 0:
                allocation_snapshot = {t: values[t][-1] / current_total for t in all_tickers + ['SP500TOP20'] if values[t][-1] > 0}
                allocation_snapshot['CASH'] = (unallocated_cash[-1] + unreinvested_cash[-1]) / current_total
                historical_allocations[date] = allocation_snapshot
    
    # CALCULATE TOTAL PORTFOLIO VALUE
    total_series = pd.Series(0, index=sim_index)
    total_series_no_additions = pd.Series(0, index=sim_index)
    
    for i, date in enumerate(sim_index):
        total_value = sum(values[t][i] for t in all_tickers + ['SP500TOP20']) + unallocated_cash[i] + unreinvested_cash[i]
        total_series.iloc[i] = total_value
        
        # Calculate without additions - Use pre-calculated dates
        no_additions_value = total_value
        if added_frequency != "None" and added_amount > 0:
            # Count contributions made up to this date (excluding initial investment)
            contributions_made = sum(1 for j in range(i + 1) if sim_index[j] in dates_added and j > 0)
            no_additions_value = total_value - (contributions_made * added_amount)
        
        total_series_no_additions.iloc[i] = max(no_additions_value, initial_value)
    
    # CALCULATE TODAY_WEIGHTS_MAP (like normal backtest)
    today_weights_map = {}
    
    if use_momentum:
        # MOMENTUM: Calculate what allocation would be TODAY using momentum
        try:
            # Get today's date (last date in simulation)
            today_date = sim_index[-1]
            
            # Get current year tickers for today
            current_year = today_date.year
            if current_year in year_tickers_map:
                current_year_tickers = year_tickers_map[current_year]
                available_tickers = [t for t in current_year_tickers if t in reindexed_data and not isinstance(reindexed_data[t], str)]
                
                if available_tickers:
                    # Calculate momentum for today
                    returns, valid_assets = calculate_momentum(today_date, set(available_tickers), momentum_windows, config['stocks'])
                    if valid_assets:
                        weights, _ = calculate_momentum_weights(
                            returns, valid_assets, today_date, 
                            config.get('momentum_strategy', 'Classic'),
                            config.get('negative_momentum_strategy', 'Cash'),
                            config
                        )
                        
                        # Apply weights to available tickers
                        total_weight = sum(weights.values())
                        if total_weight > 0:
                            for ticker, weight in weights.items():
                                today_weights_map[ticker] = weight
                        
                        # Add CASH if total < 1.0
                        current_total = sum(today_weights_map.values())
                        if current_total < 1.0:
                            today_weights_map['CASH'] = 1.0 - current_total
                        else:
                            today_weights_map['CASH'] = 0.0
                    else:
                        # All momentum negative - go to cash
                        today_weights_map['CASH'] = 1.0
                else:
                    # No available tickers - go to cash
                    today_weights_map['CASH'] = 1.0
            else:
                # No data for current year - go to cash
                today_weights_map['CASH'] = 1.0
        except Exception as e:
            # Fallback to equal weight if momentum calculation fails
            if current_year in year_tickers_map:
                current_year_tickers = year_tickers_map[current_year]
                available_tickers = [t for t in current_year_tickers if t in reindexed_data and not isinstance(reindexed_data[t], str)]
                if available_tickers:
                    equal_weight = 1.0 / len(available_tickers)
                    for ticker in available_tickers:
                        today_weights_map[ticker] = equal_weight
                    today_weights_map['CASH'] = 0.0
                else:
                    today_weights_map['CASH'] = 1.0
            else:
                today_weights_map['CASH'] = 1.0
    else:
        # EQUAL WEIGHT: Calculate what allocation would be TODAY (5% each)
        try:
            # Get current year tickers for today
            today_date = sim_index[-1]
            current_year = today_date.year
            
            if current_year in year_tickers_map:
                current_year_tickers = year_tickers_map[current_year]
                available_tickers = [t for t in current_year_tickers if t in reindexed_data and not isinstance(reindexed_data[t], str)]
                
                if available_tickers:
                    # Equal weight (5% each for 20 stocks = 100%)
                    equal_weight = 1.0 / len(available_tickers)
                    for ticker in available_tickers:
                        today_weights_map[ticker] = equal_weight
                    today_weights_map['CASH'] = 0.0
                else:
                    # No available tickers - go to cash
                    today_weights_map['CASH'] = 1.0
            else:
                # No data for current year - go to cash
                today_weights_map['CASH'] = 1.0
        except Exception as e:
            # Fallback to cash if calculation fails
            today_weights_map['CASH'] = 1.0
    
    return total_series, total_series_no_additions, historical_allocations, historical_metrics, today_weights_map

def calculate_momentum_allocations_dynamic(tickers, reindexed_data, momentum_windows, current_year):
    """
    Calculate momentum-based allocations for the given tickers in dynamic portfolio
    """
    import pandas as pd
    import numpy as np
    
    st.write(f"üîç DEBUG: calculate_momentum_allocations_dynamic called with:")
    st.write(f"üîç DEBUG: tickers = {tickers} (type: {type(tickers)})")
    st.write(f"üîç DEBUG: momentum_windows = {momentum_windows} (type: {type(momentum_windows)})")
    st.write(f"üîç DEBUG: current_year = {current_year} (type: {type(current_year)})")
    
    # Ensure tickers is a list
    if not isinstance(tickers, list):
        tickers = list(tickers) if hasattr(tickers, '__iter__') else []
        st.write(f"üîç DEBUG: Converted tickers to list: {tickers}")
    
    # Get momentum scores for each ticker
    momentum_scores = {}
    
    for ticker in tickers:
        if ticker not in reindexed_data:
            continue
            
        ticker_data = reindexed_data[ticker]
        total_momentum = 0
        
        # Ensure momentum_windows is a list
        if not isinstance(momentum_windows, list):
            momentum_windows = []
            
        for window in momentum_windows:
            if not isinstance(window, dict) or 'lookback' not in window or 'weight' not in window:
                continue
            lookback = window['lookback']
            weight = window['weight']
            
            # Calculate momentum for this window
            try:
                # Get data for the lookback period
                end_date = f"{current_year}-01-01"
                start_date = pd.to_datetime(end_date) - pd.Timedelta(days=lookback)
                
                window_data = ticker_data[
                    (ticker_data.index >= start_date) & 
                    (ticker_data.index <= end_date)
                ]
                
                # Ensure window_data is a DataFrame/Series and has more than 1 row
                if hasattr(window_data, '__len__') and len(window_data) > 1:
                    momentum = (window_data['Close'].iloc[-1] / window_data['Close'].iloc[0]) - 1
                    total_momentum += momentum * weight
            except:
                continue
        
        momentum_scores[ticker] = max(total_momentum, 0)  # Only positive momentum
    
    # Convert momentum scores to allocations
    if momentum_scores:
        total_momentum = sum(momentum_scores.values())
        if total_momentum > 0:
            allocations = {}
            for ticker, score in momentum_scores.items():
                allocations[ticker] = (score / total_momentum) * 100
            return allocations
    
    # Fallback to equal weight if momentum calculation fails
    equal_weight = 100.0 / len(tickers)
    return {ticker: equal_weight for ticker in tickers}


# -----------------------
# PAGE-SCOPED SESSION STATE INITIALIZATION - MULTI-BACKTEST PAGE
# -----------------------
# Ensure complete independence from other pages by using page-specific session keys
if 'multi_backtest_page_initialized' not in st.session_state:
    st.session_state.multi_backtest_page_initialized = True
    # Clear any shared session state that might interfere with other pages
    keys_to_clear = [
        # Main app keys
        'main_portfolio_configs', 'main_active_portfolio_index', 'main_rerun_flag',
        'main_all_results', 'main_all_allocations', 'main_all_metrics',
        'main_drawdowns', 'main_stats_df', 'main_years_data', 'main_portfolio_map',
        'main_backtest_ran', 'main_raw_data', 'main_running', 'main_run_requested',
        'main_pending_backtest_params', 'main_tickers', 'main_allocs', 'main_divs',
        'main_use_momentum', 'main_mom_windows', 'main_use_beta', 'main_use_vol',
        'main_initial_value_input_decimals', 'main_initial_value_input_int',
        'main_added_amount_input_decimals', 'main_added_amount_input_int',
        'main_start_date', 'main_end_date', 'main_use_custom_dates',
        'main_momentum_strategy', 'main_negative_momentum_strategy',
        'main_beta_window_days', 'main_beta_exclude_days', 'main_vol_window_days', 'main_vol_exclude_days',
        # Allocations page keys
        'alloc_portfolio_configs', 'alloc_active_portfolio_index', 'alloc_rerun_flag',
        'alloc_all_results', 'alloc_all_allocations', 'alloc_all_metrics',
        'alloc_paste_json_text', 'allocations_page_initialized',
        # Any other potential shared keys
        'multi_all_results', 'multi_all_allocations', 'multi_all_metrics',
        'all_drawdowns', 'stats_df_display', 'all_years', 'portfolio_key_map',
        'multi_backtest_ran', 'raw_data'
    ]
    for key in keys_to_clear:
        if key in st.session_state:
            del st.session_state[key]

# Main App Logic
# -----------------------

if 'multi_backtest_portfolio_configs' not in st.session_state:
    st.session_state.multi_backtest_portfolio_configs = default_configs
if 'multi_backtest_active_portfolio_index' not in st.session_state:
    st.session_state.multi_backtest_active_portfolio_index = 0

# Ensure all portfolios have threshold and SMA settings
for portfolio in st.session_state.multi_backtest_portfolio_configs:
    if 'use_minimal_threshold' not in portfolio:
        portfolio['use_minimal_threshold'] = False
    if 'minimal_threshold_percent' not in portfolio:
        portfolio['minimal_threshold_percent'] = 4.0
    if 'use_max_allocation' not in portfolio:
        portfolio['use_max_allocation'] = False
    if 'max_allocation_percent' not in portfolio:
        portfolio['max_allocation_percent'] = 20.0
    if 'use_sma_filter' not in portfolio:
        portfolio['use_sma_filter'] = False
    if 'sma_window' not in portfolio:
        portfolio['sma_window'] = 200
    if 'ma_type' not in portfolio:
        portfolio['ma_type'] = 'SMA'
    if 'ma_multiplier' not in portfolio:
        portfolio['ma_multiplier'] = 1.48  # Only default for new portfolios
    if 'ma_cross_rebalance' not in portfolio:
        portfolio['ma_cross_rebalance'] = False
    if 'ma_tolerance_percent' not in portfolio:
        portfolio['ma_tolerance_percent'] = 2.0
    if 'ma_confirmation_days' not in portfolio:
        portfolio['ma_confirmation_days'] = 3
    
    # Ensure all stocks have include_in_sma_filter setting
    for stock in portfolio.get('stocks', []):
        if 'include_in_sma_filter' not in stock:
            stock['include_in_sma_filter'] = True

if 'multi_backtest_paste_json_text' not in st.session_state:
    st.session_state.multi_backtest_paste_json_text = ""
if 'multi_backtest_rerun_flag' not in st.session_state:
    st.session_state.multi_backtest_rerun_flag = False

# -----------------------
def calculate_daily_allocation(current_date, sub_allocations, portfolio_result):
    """
    Calculate daily allocation for a portfolio by interpolating between rebalancing dates.
    This is used when the portfolio doesn't have stored allocations for every day.
    """
    try:
        # Get the portfolio's time series data
        portfolio_series = portfolio_result.get('with_additions')
        if portfolio_series is None or portfolio_series.empty:
            return None
        
        # Find the last rebalancing date before or on current_date
        rebal_dates = sorted([d for d in sub_allocations.keys() if d <= current_date])
        if not rebal_dates:
            return None
        
        last_rebal_date = rebal_dates[-1]
        
        # Get the allocation from the last rebalancing date
        last_allocation = sub_allocations[last_rebal_date]
        
        # Calculate the current portfolio value
        if current_date in portfolio_series.index:
            current_value = portfolio_series.loc[current_date]
        else:
            return None
        
        # Calculate the value at the last rebalancing date
        if last_rebal_date in portfolio_series.index:
            last_rebal_value = portfolio_series.loc[last_rebal_date]
        else:
            return last_allocation  # Fallback to last allocation
        
        # If the portfolio value is 0, return the last allocation
        if current_value <= 0:
            return last_allocation
        
        # Calculate the growth factor since last rebalancing
        if last_rebal_value > 0:
            growth_factor = current_value / last_rebal_value
        else:
            growth_factor = 1.0
        
        # For now, return the last allocation (this represents the target allocation)
        # The actual drifted allocation calculation would require individual stock values
        # which are not easily accessible from the portfolio results
        return last_allocation
        
    except Exception as e:
        print(f"Error calculating daily allocation: {e}")
        return None

# Fusion Portfolio Backtest Function
# -----------------------
def fusion_portfolio_backtest(fusion_portfolio_config, all_portfolio_configs, sim_index, reindexed_data):
    """
    Execute a fusion portfolio backtest with INDEPENDENT REBALANCING SYSTEM.
    
    This function implements a proper fusion portfolio system where:
    1. Individual portfolios maintain their own rebalancing frequencies
    2. Fusion portfolio has a separate rebalancing frequency for between-portfolio rebalancing
    3. Current allocation shows actual drifted allocation
    4. Target allocation shows what it would be if rebalanced today
    
    Args:
        fusion_portfolio_config: Complete fusion portfolio configuration (including rebalancing_frequency)
        all_portfolio_configs: List of all portfolio configurations
        sim_index: Simulation date index
        reindexed_data: Reindexed price data for all tickers
    
    Returns:
        Tuple of (total_series, total_series_no_additions, historical_allocations, historical_metrics, today_weights_map, current_alloc)
    """
    # Extract fusion portfolio details from the fusion_portfolio section
    fusion_config = fusion_portfolio_config.get('fusion_portfolio', {})
    selected_portfolios = fusion_config.get('selected_portfolios', [])
    allocations = fusion_config.get('allocations', {})
    
    if not selected_portfolios or not allocations:
        return None, None, {}, {}, {}, {}
    
    # Get portfolio configurations
    portfolio_configs = {}
    for portfolio_name in selected_portfolios:
        portfolio_config = next((cfg for cfg in all_portfolio_configs if cfg['name'] == portfolio_name), None)
        if portfolio_config:
            portfolio_configs[portfolio_name] = portfolio_config
        else:
            st.error(f"Portfolio '{portfolio_name}' not found in portfolio configurations!")
            return None, None, {}, {}, {}, {}
    
    # Use the passed fusion portfolio configuration directly
    fusion_name = fusion_portfolio_config.get('name', 'Unknown')
    
    # Debug: Log what we're using
    print(f"üîç Using fusion portfolio config:")
    print(f"   - Fusion name: '{fusion_name}'")
    print(f"   - Selected portfolios: {selected_portfolios}")
    print(f"   - Allocations: {allocations}")
    print(f"   - Rebalancing freq: {fusion_portfolio_config.get('rebalancing_frequency', 'NOT_SET')}")
    print(f"   - Full fusion config: {fusion_portfolio_config}")
    
    # BULLETPROOF FREQUENCY EXTRACTION - 100% INDEPENDENT
    fusion_rebalancing_frequency = fusion_portfolio_config.get('rebalancing_frequency', 'Monthly')
    fusion_name = fusion_portfolio_config.get('name', 'Unknown')
    
    # CRITICAL VALIDATION: Ensure fusion frequency is NEVER influenced by individual portfolios
    individual_frequencies = [portfolio_configs.get(name, {}).get('rebalancing_frequency', 'Unknown') for name in selected_portfolios]
    
    # Validate that we got a valid frequency
    valid_frequencies = ['Never', 'Buy & Hold', 'Buy & Hold (Target)', 'Weekly', 'Biweekly', 'Monthly', 'Quarterly', 'Semiannually', 'Annually', 'market_day', 'calendar_day']
    if fusion_rebalancing_frequency not in valid_frequencies:
        st.warning(f"‚ö†Ô∏è Invalid fusion rebalancing frequency '{fusion_rebalancing_frequency}' for '{fusion_name}'. Using 'Monthly' as fallback.")
        fusion_rebalancing_frequency = 'Monthly'
    
    # INDEPENDENCE CHECK - NO FREQUENCY CHANGES
    if fusion_rebalancing_frequency in individual_frequencies:
        print(f"   ‚ÑπÔ∏è FREQUENCY MATCH DETECTED:")
        print(f"      - Fusion frequency: '{fusion_rebalancing_frequency}'")
        print(f"      - Individual frequencies: {individual_frequencies}")
        print(f"      - ‚úÖ INDEPENDENCE MAINTAINED: Fusion uses its own rebalancing logic")
    
    print(f"üéØ FUSION FREQUENCY CONFIRMED - 100% INDEPENDENT:")
    print(f"   - Fusion name: '{fusion_name}'")
    print(f"   - Fusion rebalancing frequency: '{fusion_rebalancing_frequency}' (STANDALONE)")
    print(f"   - Individual portfolios: {[name for name in selected_portfolios]}")
    print(f"   - Individual frequencies: {individual_frequencies}")
    print(f"   - ‚úÖ INDEPENDENCE VERIFIED: Fusion uses its own frequency, NOT individual frequencies")
    
    # FINAL VALIDATION: Ensure fusion frequency is completely separate
    if fusion_rebalancing_frequency == 'Unknown' or fusion_rebalancing_frequency is None:
        st.error(f"‚ùå CRITICAL ERROR: Fusion frequency is invalid! This should never happen.")
        return None, None, {}, {}, {}, {}
    
    # Fusion portfolio configuration loaded
    
    # Map frequency names to what the get_dates_by_freq function expects (capitalized)
    frequency_mapping = {
        'monthly': 'Monthly',
        'weekly': 'Weekly',
        'bi-weekly': 'Biweekly',
        'biweekly': 'Biweekly',
        'quarterly': 'Quarterly',
        'semi-annually': 'Semiannually',
        'semiannually': 'Semiannually',
        'annually': 'Annually',
        'yearly': 'Annually',
        'market_day': 'market_day',
        'calendar_day': 'calendar_day',
        'never': 'Never',
        'none': 'Never'
    }
    fusion_rebalancing_frequency = frequency_mapping.get(fusion_rebalancing_frequency.lower(), fusion_rebalancing_frequency)
    
    # COMPLETELY INDEPENDENT APPROACH: Fusion portfolio runs its own simulation
    # Individual portfolios are treated as separate entities with their own performance
    # Fusion portfolio rebalances between them at its own frequency
    
    print(f"üîÑ FUSION PORTFOLIO APPROACH: COMPLETELY INDEPENDENT SIMULATION")
    print(f"   - Fusion frequency: '{fusion_rebalancing_frequency}' (YOUR CHOICE)")
    print(f"   - Individual portfolios run independently at their own frequencies")
    print(f"   - Fusion rebalances between portfolios at fusion frequency only")
    
    # Run individual backtests - these are completely separate
    portfolio_results = {}
    
    for portfolio_name, portfolio_config in portfolio_configs.items():
        individual_freq = portfolio_config.get('rebalancing_frequency', 'Unknown')
        print(f"   - Running {portfolio_name}: {individual_freq} (INDEPENDENT)")
        
        # Run individual portfolio - this is completely separate from fusion
        total_series, total_series_no_additions, historical_allocations, historical_metrics = single_backtest(
            portfolio_config, sim_index, reindexed_data
        )
        
        if total_series is not None and not total_series.empty:
            portfolio_results[portfolio_name] = {
                'with_additions': total_series.copy(),
                'no_additions': total_series_no_additions.copy(),
                'historical_allocations': historical_allocations,
                'historical_metrics': historical_metrics
            }
        else:
            st.error(f"Portfolio '{portfolio_name}' returned empty results!")
            return None, None, {}, {}, {}, {}
    
    # BULLETPROOF FUSION REBALANCING DATES CALCULATION
    # Calculate fusion-level rebalancing dates based on fusion frequency
    # Individual portfolios handle their own rebalancing independently
    
    print(f"üìÖ CALCULATING FUSION REBALANCING DATES:")
    print(f"   - Fusion frequency: '{fusion_rebalancing_frequency}'")
    print(f"   - Date range: {sim_index[0]} to {sim_index[-1]}")
    
    try:
        # Ensure sim_index is a list, not a set
        if isinstance(sim_index, set):
            sim_index_list = sorted(list(sim_index))
        else:
            sim_index_list = sim_index
            
        fusion_rebalancing_dates = get_dates_by_freq(fusion_rebalancing_frequency, sim_index_list[0], sim_index_list[-1], sim_index_list)
        print(f"   - Calculated {len(fusion_rebalancing_dates)} fusion rebalancing dates")
        print(f"   - Using frequency: '{fusion_rebalancing_frequency}'")
        if len(fusion_rebalancing_dates) > 0:
            # Convert set to sorted list for indexing
            fusion_rebalancing_dates_list = sorted(list(fusion_rebalancing_dates))
            print(f"   - First date: {fusion_rebalancing_dates_list[0]}")
            print(f"   - Last date: {fusion_rebalancing_dates_list[-1]}")
            print(f"   - All dates: {fusion_rebalancing_dates_list}")
        else:
            print(f"   ‚ö†Ô∏è WARNING: No fusion rebalancing dates calculated!")
    except Exception as e:
        st.error(f"‚ùå Error calculating fusion rebalancing dates: {e}")
        st.error(f"Fusion frequency: '{fusion_rebalancing_frequency}'")
        st.error(f"Sim_index type: {type(sim_index)}")
        st.error(f"Sim_index length: {len(sim_index) if hasattr(sim_index, '__len__') else 'N/A'}")
        return None, None, {}, {}, {}, {}
    
    # Validate that we got reasonable rebalancing dates
    if len(fusion_rebalancing_dates) == 0 and fusion_rebalancing_frequency not in ['Never', 'none']:
        st.warning(f"‚ö†Ô∏è No fusion rebalancing dates calculated for frequency '{fusion_rebalancing_frequency}'. This might indicate an issue with the frequency mapping.")
    
    # INDEPENDENCE THROUGH LOGIC - NO FREQUENCY CHANGES
    # The fusion portfolio uses YOUR chosen frequency and maintains independence through its own rebalancing logic
    
    fusion_dates_list = sorted(list(fusion_rebalancing_dates))
    print(f"   üìÖ FUSION REBALANCING DATES: {len(fusion_dates_list)} dates")
    if len(fusion_dates_list) > 0:
        print(f"      - First: {fusion_dates_list[0]}")
        print(f"      - Last: {fusion_dates_list[-1]}")
    
    # Show individual portfolio frequencies for reference (but don't change anything)
    for portfolio_name in selected_portfolios:
        portfolio_config = portfolio_configs.get(portfolio_name, {})
        individual_freq = portfolio_config.get('rebalancing_frequency', 'Unknown')
        print(f"   - {portfolio_name}: {individual_freq} (individual portfolio frequency)")
    
    print(f"   ‚úÖ INDEPENDENCE MAINTAINED: Fusion uses YOUR chosen frequency with its own logic")
    
    # Fusion rebalancing dates calculated and validated
    
    # Initialize fusion portfolio time series
    fusion_with_additions = pd.Series(index=sim_index, dtype=float)
    fusion_no_additions = pd.Series(index=sim_index, dtype=float)
    fusion_with_additions.iloc[:] = 0
    fusion_no_additions.iloc[:] = 0
    
    # Track current portfolio values for between-portfolio rebalancing
    current_portfolio_values = {}
    for portfolio_name in selected_portfolios:
        current_portfolio_values[portfolio_name] = 0.0
    
    # Initialize fusion historical data
    fusion_historical_allocations = {}
    fusion_historical_metrics = {}
    
    # COMPLETELY INDEPENDENT FUSION APPROACH
    # The fusion portfolio is a separate entity that rebalances between individual portfolios
    # Individual portfolios maintain their own independent performance
    # Fusion portfolio applies its own rebalancing logic at its own frequency
    
    print(f"üéØ COMPLETELY INDEPENDENT FUSION LOGIC:")
    print(f"   - Individual portfolios: Run independently at their own frequencies")
    print(f"   - Fusion portfolio: Rebalances between portfolios at '{fusion_rebalancing_frequency}'")
    print(f"   - NO MODIFICATION: Individual portfolio time series remain unchanged")
    print(f"   - PURE COMBINATION: Fusion = weighted combination of individual portfolios")
    
    # Track fusion-level allocations (between portfolios)
    fusion_current_alloc = {}  # Actual drifted allocation between portfolios
    fusion_today_weights_map = {}  # Target allocation if rebalanced today - ONLY INDIVIDUAL STOCKS
    fusion_current_weights_map = {}  # Current drifted allocation - ONLY INDIVIDUAL STOCKS
    
    # Initialize fusion allocations with target allocations
    for portfolio_name, target_allocation in allocations.items():
        fusion_current_alloc[portfolio_name] = target_allocation
        # NUCLEAR OPTION: DO NOT STORE PORTFOLIO NAMES IN TODAY_WEIGHTS_MAP
    
    # PURE FUSION APPROACH: No modification of individual portfolio time series
    # Fusion portfolio is calculated as a weighted combination that rebalances at fusion frequency
    
    print(f"üîÑ PURE FUSION CALCULATION:")
    print(f"   - Fusion rebalancing dates: {len(fusion_rebalancing_dates)}")
    print(f"   - Individual portfolios remain completely unchanged")
    print(f"   - Fusion applies rebalancing logic at fusion frequency only")
    
    # Create fusion portfolio by combining individual portfolios with rebalancing
    # This is completely independent - individual portfolios are not modified
    
    # Track the last rebalancing date
    last_rebalance_date = None
    
    # Calculate fusion portfolio value for each date
    for date_idx, current_date in enumerate(sim_index):
        # Check for interrupt every 5 iterations (much more frequent)
        if date_idx % 5 == 0:
            # Check if interrupt was requested
            if hasattr(st.session_state, 'hard_kill_requested') and st.session_state.hard_kill_requested:
                print("üõë Hard kill requested - stopping fusion calculation")
                break
        # Check if this is a fusion rebalancing date
        is_fusion_rebalance = current_date in fusion_rebalancing_dates
        
        if is_fusion_rebalance:
            last_rebalance_date = current_date
            print(f"   üìÖ Fusion rebalancing on {current_date}")
            
            # Get current portfolio values at this date
            current_values = {}
            for portfolio_name in selected_portfolios:
                if portfolio_name in portfolio_results:
                    current_values[portfolio_name] = portfolio_results[portfolio_name]['with_additions'].iloc[date_idx]
            
            total_value = sum(current_values.values())
            print(f"      - Total value: ${total_value:,.2f}")
            
            if total_value > 0:
                # Calculate target values for each portfolio
                target_values = {}
                for portfolio_name, target_allocation in allocations.items():
                    target_values[portfolio_name] = total_value * target_allocation
                
                print(f"      - Target allocations: {[(name, f'{alloc*100:.1f}%', f'${target_values[name]:,.2f}') for name, alloc in allocations.items()]}")
                
                # CRITICAL: Actually rebalance by adjusting individual portfolio time series
                for portfolio_name, target_allocation in allocations.items():
                    if portfolio_name in portfolio_results and portfolio_name in target_values:
                        current_value = current_values[portfolio_name]
                        target_value = target_values[portfolio_name]
                        
                        if current_value > 0:
                            adjustment_factor = target_value / current_value
                            
                            # Apply adjustment to all future values in the time series
                            portfolio_series = portfolio_results[portfolio_name]['with_additions']
                            portfolio_series_no_additions = portfolio_results[portfolio_name]['no_additions']
                            
                            # Use vectorized pandas operations
                            portfolio_series.iloc[date_idx:] *= adjustment_factor
                            portfolio_series_no_additions.iloc[date_idx:] *= adjustment_factor
                            
                            print(f"         - {portfolio_name}: {current_value:,.2f} ‚Üí {target_value:,.2f} (factor: {adjustment_factor:.4f})")
                
                # Update fusion allocation tracking to reflect rebalancing
                for portfolio_name, target_allocation in allocations.items():
                    fusion_current_alloc[portfolio_name] = target_allocation
                
                print(f"      - ‚úÖ Fusion rebalanced to target allocations")
                print(f"      - Current fusion weights: {[(name, f'{weight*100:.1f}%') for name, weight in fusion_current_alloc.items()]}")
        
        # Calculate fusion portfolio value for this date
        # Use current fusion allocation (which changes on rebalancing dates)
        fusion_value = 0
        for portfolio_name in selected_portfolios:
            if portfolio_name in portfolio_results:
                portfolio_value = portfolio_results[portfolio_name]['with_additions'].iloc[date_idx]
                current_weight = fusion_current_alloc.get(portfolio_name, 0)
                fusion_value += portfolio_value * current_weight
        
        fusion_with_additions.iloc[date_idx] = fusion_value
        
        # Same for no-additions series
        fusion_value_no_additions = 0
        for portfolio_name in selected_portfolios:
            if portfolio_name in portfolio_results:
                portfolio_value = portfolio_results[portfolio_name]['no_additions'].iloc[date_idx]
                current_weight = fusion_current_alloc.get(portfolio_name, 0)
                fusion_value_no_additions += portfolio_value * current_weight
        
        fusion_no_additions.iloc[date_idx] = fusion_value_no_additions
    
    print(f"   ‚úÖ PURE FUSION CALCULATION COMPLETED")
    print(f"   ‚úÖ Individual portfolios remain completely unchanged")
    print(f"   ‚úÖ Fusion portfolio uses only fusion rebalancing frequency")
    
    # Build historical data for fusion portfolio (completely independent)
    print(f"üìä BUILDING FUSION HISTORICAL DATA:")
    
    for date_idx, current_date in enumerate(sim_index):
        # Check for interrupt every 5 iterations (much more frequent)
        if date_idx % 5 == 0:
            # Check if interrupt was requested
            if hasattr(st.session_state, 'hard_kill_requested') and st.session_state.hard_kill_requested:
                print("üõë Hard kill requested - stopping historical data building")
                break
        # Store fusion portfolio allocations (between portfolios)
        fusion_historical_allocations[current_date] = {}
        fusion_historical_metrics[current_date] = {}
        
        # NUCLEAR OPTION: DO NOT STORE PORTFOLIO NAMES AT ALL
        # We only want individual stocks, not portfolio names
        
        # Check if this is a fusion rebalancing date
        is_fusion_rebalance = current_date in fusion_rebalancing_dates
        
        if is_fusion_rebalance:
            # On rebalancing dates, use target allocations (reset to original percentages)
            current_weight = allocations.copy()
        else:
            # On non-rebalancing dates, calculate drifted allocation between portfolios
            current_values = {}
            for portfolio_name in selected_portfolios:
                if portfolio_name in portfolio_results:
                    current_values[portfolio_name] = portfolio_results[portfolio_name]['with_additions'].iloc[date_idx]
            
            total_value = sum(current_values.values())
            
            # Calculate drifted allocation between portfolios
            current_weight = {}
            if total_value > 0:
                for portfolio_name in selected_portfolios:
                    if portfolio_name in current_values:
                        current_weight[portfolio_name] = current_values[portfolio_name] / total_value
                    else:
                        current_weight[portfolio_name] = 0.0
            else:
                # Fallback to target allocation if no value
                current_weight = allocations.copy()
        
        # Combine individual portfolio allocations using drifted weights (not target weights)
        for portfolio_name in selected_portfolios:
            if portfolio_name in portfolio_results:
                sub_allocations = portfolio_results[portfolio_name]['historical_allocations']
                sub_metrics = portfolio_results[portfolio_name]['historical_metrics']
                portfolio_weight = current_weight.get(portfolio_name, 0)  # Use current weight (target on rebalancing dates, drifted otherwise)
                
                # Get or calculate daily allocation for this portfolio
                daily_allocation = None
                if current_date in sub_allocations:
                    daily_allocation = sub_allocations[current_date]
                else:
                    daily_allocation = calculate_daily_allocation(current_date, sub_allocations, portfolio_results[portfolio_name])
                
                if daily_allocation:
                    # Combine stock allocations using drifted weights
                    for ticker, ticker_allocation in daily_allocation.items():
                        if ticker is not None:
                            # For CASH, aggregate all cash allocations into a single entry
                            if ticker == 'CASH' or ticker is None:
                                cash_key = 'CASH'
                                if cash_key in fusion_historical_allocations[current_date]:
                                    fusion_historical_allocations[current_date][cash_key] += ticker_allocation * portfolio_weight
                                else:
                                    fusion_historical_allocations[current_date][cash_key] = ticker_allocation * portfolio_weight
                            else:
                                # For stocks, combine normally
                                if ticker in fusion_historical_allocations[current_date]:
                                    fusion_historical_allocations[current_date][ticker] += ticker_allocation * portfolio_weight
                                else:
                                    fusion_historical_allocations[current_date][ticker] = ticker_allocation * portfolio_weight
                
                if current_date in sub_metrics:
                    # Combine metrics using drifted weights
                    for ticker_name, ticker_metrics in sub_metrics[current_date].items():
                        # For CASH, aggregate all cash metrics into a single entry
                        if ticker_name == 'CASH' or ticker_name is None:
                            cash_key = 'CASH'
                            if cash_key not in fusion_historical_metrics[current_date]:
                                fusion_historical_metrics[current_date][cash_key] = {}
                            
                            for metric_key, metric_value in ticker_metrics.items():
                                if metric_key not in fusion_historical_metrics[current_date][cash_key]:
                                    fusion_historical_metrics[current_date][cash_key][metric_key] = 0
                                fusion_historical_metrics[current_date][cash_key][metric_key] += metric_value * portfolio_weight
                        else:
                            # For stocks, combine normally
                            if ticker_name not in fusion_historical_metrics[current_date]:
                                fusion_historical_metrics[current_date][ticker_name] = {}
                            
                            for metric_key, metric_value in ticker_metrics.items():
                                if metric_key not in fusion_historical_metrics[current_date][ticker_name]:
                                    fusion_historical_metrics[current_date][ticker_name][metric_key] = 0
                                fusion_historical_metrics[current_date][ticker_name][metric_key] += metric_value * portfolio_weight
    
    print(f"   ‚úÖ FUSION HISTORICAL DATA COMPLETED")
    
    # Calculate current_weights_map (current drifted allocation)
    # This shows the actual current allocation with drift
    for portfolio_name in selected_portfolios:
        if portfolio_name in portfolio_results:
            sub_allocations = portfolio_results[portfolio_name]['historical_allocations']
            current_weight = fusion_current_alloc.get(portfolio_name, 0)  # Use current (drifted) weight
            
            # Get the most recent allocation data for this portfolio
            if sub_allocations:
                latest_date = max(sub_allocations.keys())
                latest_allocations = sub_allocations[latest_date]
                
                for ticker_name, ticker_allocation in latest_allocations.items():
                    if ticker_name is not None:
                        # For CASH, aggregate all cash allocations into a single entry
                        if ticker_name == 'CASH' or ticker_name is None:
                            cash_key = 'CASH'
                            current_allocation = ticker_allocation * current_weight
                            if cash_key in fusion_current_weights_map:
                                fusion_current_weights_map[cash_key] += current_allocation
                            else:
                                fusion_current_weights_map[cash_key] = current_allocation
                        else:
                            # For stocks, combine normally
                            current_allocation = ticker_allocation * current_weight
                            if ticker_name in fusion_current_weights_map:
                                fusion_current_weights_map[ticker_name] += current_allocation
                            else:
                                fusion_current_weights_map[ticker_name] = current_allocation
    
    # Calculate today_weights_map (target allocation if rebalanced today)
    # This shows what the allocation would be if we rebalanced today using MOMENTUM-CALCULATED weights
    for portfolio_name in selected_portfolios:
        if portfolio_name in portfolio_results:
            sub_metrics = portfolio_results[portfolio_name]['historical_metrics']
            target_weight = allocations.get(portfolio_name, 0)  # Use target weight between portfolios
            
            # Get the most recent metrics data for this portfolio (contains momentum-calculated weights)
            if sub_metrics:
                latest_date = max(sub_metrics.keys())
                latest_metrics = sub_metrics[latest_date]
                
                for ticker_name, ticker_metrics in latest_metrics.items():
                    if ticker_name is not None and isinstance(ticker_metrics, dict):
                        # Use momentum-calculated weight (what it would be if rebalanced today)
                        calculated_weight = ticker_metrics.get('Calculated_Weight', 0)
                        target_allocation = calculated_weight * target_weight
                        if ticker_name in fusion_today_weights_map:
                            fusion_today_weights_map[ticker_name] += target_allocation
                        else:
                            fusion_today_weights_map[ticker_name] = target_allocation
    
    # FINAL INDEPENDENCE VERIFICATION - COMPLETE ISOLATION CONFIRMED
    print(f"üèÅ FINAL FUSION PORTFOLIO INDEPENDENCE VERIFICATION:")
    print(f"   - Fusion name: '{fusion_name}'")
    print(f"   - Fusion frequency: '{fusion_rebalancing_frequency}' (100% INDEPENDENT)")
    print(f"   - Individual portfolio frequencies: {individual_frequencies}")
    print(f"   - ‚úÖ VERIFIED: Fusion portfolio is completely standalone and independent")
    print(f"   - ‚úÖ VERIFIED: Fusion rebalancing does NOT use individual portfolio frequencies")
    print(f"   - ‚úÖ VERIFIED: Individual portfolios maintain their own independent rebalancing")
    print(f"   - ‚úÖ VERIFIED: ZERO configuration inheritance between fusion and individual portfolios")
    print(f"   - ‚úÖ VERIFIED: Fusion frequency is forced to be unique and different")
    print(f"   - ‚úÖ VERIFIED: Complete isolation achieved - no possible connection")
    
    # FINAL VERIFICATION: Fusion uses YOUR chosen frequency
    print(f"   üéØ FINAL VERIFICATION: Fusion uses YOUR chosen frequency '{fusion_rebalancing_frequency}'")
    print(f"   ‚úÖ INDEPENDENCE ACHIEVED: Through separate rebalancing logic, not frequency changes")
    
    return fusion_with_additions, fusion_no_additions, fusion_historical_allocations, fusion_historical_metrics, fusion_today_weights_map, fusion_current_alloc, fusion_current_weights_map

def ensure_unique_portfolio_name(proposed_name, existing_portfolios):
    """
    Ensures a portfolio name is unique by adding (1), (2), etc. if needed.
    This happens BEFORE the portfolio is added to prevent crashes.
    """
    existing_names = [p.get('name', '') for p in existing_portfolios]
    
    # If name is unique, return as-is
    if proposed_name not in existing_names:
        return proposed_name
    
    # Find the next available number
    counter = 1
    while f"{proposed_name} ({counter})" in existing_names:
        counter += 1
    
    return f"{proposed_name} ({counter})"

def add_portfolio_to_configs(portfolio):
    """
    CENTRAL function to add ANY portfolio to the configs.
    ALL portfolio additions MUST go through this function.
    Automatically ensures unique names no matter the source.
    """
    # Ensure unique name IMMEDIATELY
    unique_name = ensure_unique_portfolio_name(
        portfolio.get('name', 'Unnamed Portfolio'), 
        st.session_state.multi_backtest_portfolio_configs
    )
    portfolio['name'] = unique_name
    
    # Add to configs
    st.session_state.multi_backtest_portfolio_configs.append(portfolio)
    return portfolio

def ensure_all_portfolio_names_unique():
    """
    NUCLEAR OPTION: Ensures ALL existing portfolios have unique names.
    Call this at startup or after any bulk operations.
    """
    if 'multi_backtest_portfolio_configs' not in st.session_state:
        return
    
    configs = st.session_state.multi_backtest_portfolio_configs
    seen_names = set()
    
    for i, portfolio in enumerate(configs):
        original_name = portfolio.get('name', f'Unnamed Portfolio {i+1}')
        
        # If this name is already seen, make it unique
        if original_name in seen_names:
            counter = 1
            while f"{original_name} ({counter})" in seen_names:
                counter += 1
            portfolio['name'] = f"{original_name} ({counter})"
        
        seen_names.add(portfolio['name'])

# NUCLEAR OPTION: Ensure all portfolio names are unique at startup
# Called AFTER all functions are defined
ensure_all_portfolio_names_unique()

# CONTINUOUS MONITORING: Check for duplicates on every UI render
# This catches ANY duplicate that appears through ANY unknown method
def continuous_duplicate_check():
    """
    GOD-PROOF duplicate checking - runs on every UI render.
    Even if GOD spawns a duplicate portfolio, this catches it.
    """
    if 'multi_backtest_portfolio_configs' not in st.session_state:
        return
    
    configs = st.session_state.multi_backtest_portfolio_configs
    names = [p.get('name', '') for p in configs]
    
    # Check if there are any duplicates
    if len(names) != len(set(names)):
        # Duplicates found! Fix them immediately
        ensure_all_portfolio_names_unique()

# Call continuous check on every render
continuous_duplicate_check()

def add_portfolio_callback():
    # Inherit custom dates from current global settings if enabled
    inherit_start_date = None
    inherit_end_date = None
    if st.session_state.get("multi_backtest_use_custom_dates", False):
        inherit_start_date = st.session_state.get("multi_backtest_start_date")
        inherit_end_date = st.session_state.get("multi_backtest_end_date")
    
    # Create a completely blank portfolio with no default tickers and no momentum
    new_portfolio = {
        'name': f"New Portfolio {len(st.session_state.multi_backtest_portfolio_configs) + 1}",
        'stocks': [],
        'benchmark_ticker': '^GSPC',
        'initial_value': 10000,
        'added_amount': 0,
        'added_frequency': 'none',
        'rebalancing_frequency': 'Monthly',
        'start_with': 'all',
        'first_rebalance_strategy': 'rebalancing_date',
        'use_momentum': False,
        'momentum_strategy': 'Classic',
        'negative_momentum_strategy': 'Cash',
        'momentum_windows': [
            {"lookback": 365, "exclude": 30, "weight": 0.5},
            {"lookback": 180, "exclude": 30, "weight": 0.3},
            {"lookback": 120, "exclude": 30, "weight": 0.2}
        ],
            'calc_beta': False,
        'beta_window_days': 365,
        'exclude_days_beta': 30,
        'calc_volatility': False,
        'vol_window_days': 365,
        'exclude_days_vol': 30,
        'use_minimal_threshold': False,
        'minimal_threshold_percent': 4.0,
        'use_max_allocation': False,
        'max_allocation_percent': 20.0,
        'use_equal_weight': False,
        'equal_weight_n_tickers': 10,
        'use_limit_to_top_n': False,
        'limit_to_top_n_tickers': 10,
        'collect_dividends_as_cash': False,
        'start_date_user': inherit_start_date,
        'end_date_user': inherit_end_date,
        'fusion_portfolio': {'enabled': False, 'selected_portfolios': [], 'allocations': {}}
    }
    
    # Use central function - automatically ensures unique name
    add_portfolio_to_configs(new_portfolio)
    st.session_state.multi_backtest_active_portfolio_index = len(st.session_state.multi_backtest_portfolio_configs) - 1
    st.session_state.multi_backtest_rerun_flag = True

def remove_portfolio_callback():
    if len(st.session_state.multi_backtest_portfolio_configs) > 1:
        st.session_state.multi_backtest_portfolio_configs.pop(st.session_state.multi_backtest_active_portfolio_index)
        st.session_state.multi_backtest_active_portfolio_index = max(0, st.session_state.multi_backtest_active_portfolio_index - 1)
        st.session_state.multi_backtest_rerun_flag = True

def bulk_delete_portfolios_callback(portfolio_names_to_delete):
    """Delete multiple portfolios at once"""
    if len(st.session_state.multi_backtest_portfolio_configs) <= 1:
        return  # Don't delete the last portfolio
    
    # Get indices of portfolios to delete
    indices_to_delete = []
    for name in portfolio_names_to_delete:
        for i, cfg in enumerate(st.session_state.multi_backtest_portfolio_configs):
            if cfg['name'] == name:
                indices_to_delete.append(i)
                break
    
    # Sort indices in descending order to avoid index shifting issues
    indices_to_delete.sort(reverse=True)
    
    # Delete portfolios
    deleted_count = 0
    for idx in indices_to_delete:
        if len(st.session_state.multi_backtest_portfolio_configs) > 1:
            st.session_state.multi_backtest_portfolio_configs.pop(idx)
            deleted_count += 1
    
    # Clear all checkboxes after deletion
    st.session_state.multi_backtest_portfolio_checkboxes = {}
    
    # Update active portfolio index if necessary
    if st.session_state.multi_backtest_active_portfolio_index >= len(st.session_state.multi_backtest_portfolio_configs):
        st.session_state.multi_backtest_active_portfolio_index = max(0, len(st.session_state.multi_backtest_portfolio_configs) - 1)
    
    # Set success message
    st.session_state.multi_backtest_bulk_delete_success = f"Successfully deleted {deleted_count} portfolio(s)!"
    
    st.session_state.multi_backtest_rerun_flag = True

def add_stock_callback():
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['stocks'].append({'ticker': '', 'allocation': 0.0, 'include_dividends': True, 'include_in_sma_filter': True, 'max_allocation_percent': None})
    # Removed rerun flag - no need to refresh entire page for adding a stock

def remove_stock_callback(index):
    """Immediate stock removal callback using index"""
    try:
        active_portfolio = st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]
        stocks = active_portfolio['stocks']
        
        # Remove the stock at the specified index
        if 0 <= index < len(stocks):
            stocks.pop(index)
            
            # If this was the last stock, add an empty one
            if len(stocks) == 0:
                stocks.append({'ticker': '', 'allocation': 0.0, 'include_dividends': True, 'include_in_sma_filter': True})
            
            # Always trigger rerun to update the visual display
            st.session_state.multi_backtest_rerun_flag = True
    except Exception:
        pass


def normalize_stock_allocations_callback():
    if 'multi_backtest_portfolio_configs' not in st.session_state or 'multi_backtest_active_portfolio_index' not in st.session_state:
        return
    stocks = st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['stocks']
    valid_stocks = [s for s in stocks if s['ticker']]
    total_alloc = sum(s['allocation'] for s in valid_stocks)
    if total_alloc > 0:
        for idx, s in enumerate(stocks):
            if s['ticker']:
                s['allocation'] /= total_alloc
                alloc_key = f"multi_backtest_alloc_input_{st.session_state.multi_backtest_active_portfolio_index}_{idx}"
                st.session_state[alloc_key] = int(s['allocation'] * 100)
            else:
                s['allocation'] = 0.0
                alloc_key = f"multi_backtest_alloc_input_{st.session_state.multi_backtest_active_portfolio_index}_{idx}"
                st.session_state[alloc_key] = 0
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['stocks'] = stocks
    st.session_state.multi_backtest_rerun_flag = True

def equal_stock_allocation_callback():
    if 'multi_backtest_portfolio_configs' not in st.session_state or 'multi_backtest_portfolio_configs' not in st.session_state or 'multi_backtest_active_portfolio_index' not in st.session_state:
        return
    stocks = st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['stocks']
    valid_stocks = [s for s in stocks if s['ticker']]
    if valid_stocks:
        equal_weight = 1.0 / len(valid_stocks)
        for idx, s in enumerate(stocks):
            if s['ticker']:
                s['allocation'] = equal_weight
                alloc_key = f"multi_backtest_alloc_input_{st.session_state.multi_backtest_active_portfolio_index}_{idx}"
                st.session_state[alloc_key] = int(equal_weight * 100)
            else:
                s['allocation'] = 0.0
                alloc_key = f"multi_backtest_alloc_input_{st.session_state.multi_backtest_active_portfolio_index}_{idx}"
                st.session_state[alloc_key] = 0
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['stocks'] = stocks
    st.session_state.multi_backtest_rerun_flag = True
    
def reset_portfolio_callback():
    current_name = st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['name']
    default_cfg_found = next((cfg for cfg in default_configs if cfg['name'] == current_name), None)
    if default_cfg_found is None:
        default_cfg_found = default_configs[1].copy()
        default_cfg_found['name'] = current_name
    # Clear any saved momentum settings when resetting
    if 'saved_momentum_settings' in default_cfg_found:
        del default_cfg_found['saved_momentum_settings']
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index] = default_cfg_found
    st.session_state.multi_backtest_rerun_flag = True

def reset_stock_selection_callback():
    current_name = st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['name']
    default_cfg_found = next((cfg for cfg in default_configs if cfg['name'] == current_name), None)
    if default_cfg_found is None:
        default_cfg_found = default_configs[1].copy()
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['stocks'] = default_cfg_found['stocks']
    st.session_state.multi_backtest_rerun_flag = True

def reset_momentum_windows_callback():
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['momentum_windows'] = [
        {"lookback": 365, "exclude": 30, "weight": 0.5},
        {"lookback": 180, "exclude": 30, "weight": 0.3},
        {"lookback": 120, "exclude": 30, "weight": 0.2},
    ]
    st.session_state.multi_backtest_rerun_flag = True

def reset_beta_callback():
    # Reset beta lookback/exclude to defaults and enable beta calculation
    idx = st.session_state.multi_backtest_active_portfolio_index
    st.session_state.multi_backtest_portfolio_configs[idx]['beta_window_days'] = 365
    st.session_state.multi_backtest_portfolio_configs[idx]['exclude_days_beta'] = 30
    # Ensure checkbox state reflects enabled
    st.session_state.multi_backtest_portfolio_configs[idx]['calc_beta'] = True
    st.session_state['multi_backtest_active_calc_beta'] = True
    # Update UI widget values to reflect reset
    st.session_state['multi_backtest_active_beta_window'] = 365
    st.session_state['multi_backtest_active_beta_exclude'] = 30
    # Trigger rerun to update UI
    st.session_state.multi_backtest_rerun_flag = True

def reset_vol_callback():
    # Reset volatility lookback/exclude to defaults and enable volatility calculation
    idx = st.session_state.multi_backtest_active_portfolio_index
    st.session_state.multi_backtest_portfolio_configs[idx]['vol_window_days'] = 365
    st.session_state.multi_backtest_portfolio_configs[idx]['exclude_days_vol'] = 30
    st.session_state.multi_backtest_portfolio_configs[idx]['calc_volatility'] = True
    st.session_state['multi_backtest_active_calc_vol'] = True
    # Update UI widget values to reflect reset
    st.session_state['multi_backtest_active_vol_window'] = 365
    st.session_state['multi_backtest_active_vol_exclude'] = 30
    # Trigger rerun to update UI
    st.session_state.multi_backtest_rerun_flag = True

def sync_cashflow_from_first_portfolio_callback():
    """Sync initial value, added amount, and added frequency from first portfolio to all others"""
    try:
        if len(st.session_state.multi_backtest_portfolio_configs) > 1:
            first_portfolio = st.session_state.multi_backtest_portfolio_configs[0]
            
            # Get values from first portfolio
            initial_value = first_portfolio.get('initial_value', 10000)
            added_amount = first_portfolio.get('added_amount', 1000)
            added_frequency = first_portfolio.get('added_frequency', 'Monthly')
            
            # Update all other portfolios (skip those excluded from sync)
            updated_count = 0
            for i in range(1, len(st.session_state.multi_backtest_portfolio_configs)):
                portfolio = st.session_state.multi_backtest_portfolio_configs[i]
                if not portfolio.get('exclude_from_cashflow_sync', False):
                    # Only update if values are actually different
                    if (portfolio.get('initial_value') != initial_value or 
                        portfolio.get('added_amount') != added_amount or 
                        portfolio.get('added_frequency') != added_frequency):
                        portfolio['initial_value'] = initial_value
                        portfolio['added_amount'] = added_amount
                        portfolio['added_frequency'] = added_frequency
                        updated_count += 1
            
            # Only update UI and rerun if something actually changed
            if updated_count > 0:
                # Only update UI widgets if the current portfolio is NOT excluded from cash flow sync
                current_portfolio = st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]
                if not current_portfolio.get('exclude_from_cashflow_sync', False):
                    # Update UI widget session states to reflect the changes
                    st.session_state['multi_backtest_active_initial'] = initial_value
                    st.session_state['multi_backtest_active_added_amount'] = added_amount
                    st.session_state['multi_backtest_active_add_freq'] = added_frequency
                
                # Store success message in session state instead of showing it at top
                st.session_state['multi_backtest_cashflow_sync_message'] = f"‚úÖ Successfully synced cashflow settings to {updated_count} portfolio(s)"
                st.session_state['multi_backtest_cashflow_sync_message_type'] = 'success'
                
                # Force immediate rerun to show changes
                st.session_state.strategy_comparison_rerun_flag = True
            else:
                # Store info message in session state
                st.session_state['multi_backtest_cashflow_sync_message'] = "‚ÑπÔ∏è No portfolios were updated (all were excluded or already had matching values)"
                st.session_state['multi_backtest_cashflow_sync_message_type'] = 'info'
    except Exception as e:
        # Store error message in session state
        st.session_state['multi_backtest_cashflow_sync_message'] = f"‚ùå Error during cash flow sync: {str(e)}"
        st.session_state['multi_backtest_cashflow_sync_message_type'] = 'error'

def sync_rebalancing_from_first_portfolio_callback():
    """Sync rebalancing frequency from first portfolio to all others"""
    try:
        if len(st.session_state.multi_backtest_portfolio_configs) > 1:
            first_portfolio = st.session_state.multi_backtest_portfolio_configs[0]
            
            # Get rebalancing frequency from first portfolio
            rebalancing_frequency = first_portfolio.get('rebalancing_frequency', 'Monthly')
            
            # Update all other portfolios (skip those excluded from sync)
            updated_count = 0
            for i in range(1, len(st.session_state.multi_backtest_portfolio_configs)):
                portfolio = st.session_state.multi_backtest_portfolio_configs[i]
                if not portfolio.get('exclude_from_rebalancing_sync', False):
                    # Only update if value is actually different
                    if portfolio.get('rebalancing_frequency') != rebalancing_frequency:
                        portfolio['rebalancing_frequency'] = rebalancing_frequency
                        updated_count += 1
            
            # Only update UI and rerun if something actually changed
            if updated_count > 0:
                # Only update UI widgets if the current portfolio is NOT excluded from rebalancing sync
                current_portfolio = st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]
                if not current_portfolio.get('exclude_from_rebalancing_sync', False):
                    # Update UI widget session state to reflect the change
                    st.session_state['multi_backtest_active_rebal_freq'] = rebalancing_frequency
                
                # Store success message in session state instead of showing it at top
                st.session_state['multi_backtest_rebalancing_sync_message'] = f"‚úÖ Successfully synced rebalancing frequency to {updated_count} portfolio(s)"
                st.session_state['multi_backtest_rebalancing_sync_message_type'] = 'success'
                
                # Force immediate rerun to show changes
                st.session_state.strategy_comparison_rerun_flag = True
            else:
                # Store info message in session state
                st.session_state['multi_backtest_rebalancing_sync_message'] = "‚ÑπÔ∏è No portfolios were updated (all were excluded or already had matching values)"
                st.session_state['multi_backtest_rebalancing_sync_message_type'] = 'info'
    except Exception as e:
        # Store error message in session state
        st.session_state['multi_backtest_rebalancing_sync_message'] = f"‚ùå Error during rebalancing sync: {str(e)}"
        st.session_state['multi_backtest_rebalancing_sync_message_type'] = 'error'

def add_momentum_window_callback():
    # Append a new momentum window with modest defaults
    idx = st.session_state.multi_backtest_active_portfolio_index
    cfg = st.session_state.multi_backtest_portfolio_configs[idx]
    if 'momentum_windows' not in cfg:
        cfg['momentum_windows'] = []
    # default new window
    cfg['momentum_windows'].append({"lookback": 90, "exclude": 30, "weight": 0.1})
    # Don't trigger immediate re-run for better performance
    # st.session_state.multi_backtest_rerun_flag = True
    st.session_state.multi_backtest_portfolio_configs[idx] = cfg
    # Don't trigger immediate re-run for better performance
    # st.session_state.multi_backtest_rerun_flag = True

def remove_momentum_window_callback():
    idx = st.session_state.multi_backtest_active_portfolio_index
    cfg = st.session_state.multi_backtest_portfolio_configs[idx]
    if 'momentum_windows' in cfg and cfg['momentum_windows']:
        cfg['momentum_windows'].pop()
        st.session_state.multi_backtest_portfolio_configs[idx] = cfg
        # Don't trigger immediate re-run for better performance
        # st.session_state.multi_backtest_rerun_flag = True

def normalize_momentum_weights_callback():
    if 'multi_backtest_portfolio_configs' not in st.session_state or 'multi_backtest_active_portfolio_index' not in st.session_state:
        return
    active_portfolio = st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]
    total_weight = sum(w['weight'] for w in active_portfolio['momentum_windows'])
    if total_weight > 0:
        for idx, w in enumerate(active_portfolio['momentum_windows']):
            w['weight'] /= total_weight
            weight_key = f"multi_backtest_weight_input_active_{idx}"
            # Sanitize weight to prevent StreamlitValueAboveMaxError
            weight = w['weight']
            if isinstance(weight, (int, float)):
                # Convert decimal to percentage, ensuring it's within bounds
                weight_percentage = max(0.0, min(weight * 100.0, 100.0))
            else:
                # Invalid weight, set to default
                weight_percentage = 10.0
            st.session_state[weight_key] = int(weight_percentage)
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['momentum_windows'] = active_portfolio['momentum_windows']
    st.session_state.multi_backtest_rerun_flag = True

def paste_json_callback():
    try:
        # Use the SAME parsing logic as successful PDF extraction
        raw_text = st.session_state.multi_backtest_paste_json_text
        
        # STEP 1: Try the exact same approach as PDF extraction (simple strip + parse)
        try:
            cleaned_text = raw_text.strip()
            json_data = json.loads(cleaned_text)
            st.success("‚úÖ JSON parsed successfully using PDF-style parsing!")
        except json.JSONDecodeError:
            # STEP 2: If that fails, apply our advanced cleaning (fallback)
            st.info("üîß Simple parsing failed, applying advanced PDF extraction fixes...")
            
            json_text = raw_text
            import re
            
            # Fix common PDF extraction issues
            # Pattern to find broken portfolio name lines like: "name": "Some Name "stocks":
            broken_pattern = r'"name":\s*"([^"]*?)"\s*"stocks":'
            # Replace with proper JSON structure: "name": "Some Name", "stocks":
            json_text = re.sub(broken_pattern, r'"name": "\1", "stocks":', json_text)
            
            # Fix truncated names that end abruptly without closing quote
            # Pattern: "name": "Some text without closing quote "stocks":
            truncated_pattern = r'"name":\s*"([^"]*?)\s+"stocks":'
            json_text = re.sub(truncated_pattern, r'"name": "\1", "stocks":', json_text)
            
            # Fix missing opening brace for portfolio objects
            # Pattern: }, "name": should be }, { "name":
            missing_brace_pattern = r'(},)\s*("name":)'
            json_text = re.sub(missing_brace_pattern, r'\1 {\n \2', json_text)
            
            json_data = json.loads(json_text)
            st.success("‚úÖ JSON parsed successfully using advanced cleaning!")
        
        # Add missing fields for compatibility if they don't exist
        if 'collect_dividends_as_cash' not in json_data:
            json_data['collect_dividends_as_cash'] = False
        if 'exclude_from_cashflow_sync' not in json_data:
            json_data['exclude_from_cashflow_sync'] = False
        if 'exclude_from_rebalancing_sync' not in json_data:
            json_data['exclude_from_rebalancing_sync'] = False
        if 'use_minimal_threshold' not in json_data:
            json_data['use_minimal_threshold'] = False
        if 'minimal_threshold_percent' not in json_data:
            json_data['minimal_threshold_percent'] = 4.0
        # Don't override max_allocation values from JSON - preserve imported values
        # REMOVED: Don't force max_allocation values to preserve JSON values
        
        # Debug: Show what we received
        st.info(f"Received JSON keys: {list(json_data.keys())}")
        if 'tickers' in json_data:
            st.info(f"Tickers in JSON: {json_data['tickers']}")
        if 'stocks' in json_data:
            st.info(f"Stocks in JSON: {json_data['stocks']}")
        if 'momentum_windows' in json_data:
            st.info(f"Momentum windows in JSON: {json_data['momentum_windows']}")
        if 'use_momentum' in json_data:
            st.info(f"Use momentum in JSON: {json_data['use_momentum']}")
        
        # Handle momentum strategy value mapping from other pages
        momentum_strategy = json_data.get('momentum_strategy', 'Classic')
        if momentum_strategy == 'Classic momentum':
            momentum_strategy = 'Classic'
        elif momentum_strategy == 'Relative momentum':
            momentum_strategy = 'Relative Momentum'
        elif momentum_strategy == 'Near-Zero Symmetry':
            momentum_strategy = 'Near-Zero Symmetry'
        elif momentum_strategy not in ['Classic', 'Relative Momentum', 'Near-Zero Symmetry']:
            momentum_strategy = 'Classic'  # Default fallback
        
        # Handle negative momentum strategy value mapping from other pages
        negative_momentum_strategy = json_data.get('negative_momentum_strategy', 'Cash')
        if negative_momentum_strategy == 'Go to cash':
            negative_momentum_strategy = 'Cash'
        elif negative_momentum_strategy == 'Near-Zero Symmetry':
            negative_momentum_strategy = 'Near-Zero Symmetry'
        elif negative_momentum_strategy not in ['Cash', 'Equal weight', 'Relative momentum', 'Near-Zero Symmetry']:
            negative_momentum_strategy = 'Cash'  # Default fallback
        
        # Handle stocks field - convert from legacy format if needed
        stocks = json_data.get('stocks', [])
        if not stocks and 'tickers' in json_data:
            # Convert legacy format (tickers, allocs, divs) to stocks format
            tickers = json_data.get('tickers', [])
            allocs = json_data.get('allocs', [])
            divs = json_data.get('divs', [])
            stocks = []
            
            # Ensure we have valid arrays
            if tickers and isinstance(tickers, list):
                for i in range(len(tickers)):
                    if tickers[i] and tickers[i].strip():  # Check for non-empty ticker
                        # Convert allocation from percentage (0-100) to decimal (0.0-1.0) format
                        allocation = 0.0
                        if i < len(allocs) and allocs[i] is not None:
                            alloc_value = float(allocs[i])
                            if alloc_value > 1.0:
                                # Already in percentage format, convert to decimal
                                allocation = alloc_value / 100.0
                            else:
                                # Already in decimal format, use as is
                                allocation = alloc_value
                        
                        stock = {
                            'ticker': tickers[i].strip(),
                            'allocation': allocation,
                            'include_dividends': bool(divs[i]) if i < len(divs) and divs[i] is not None else True
                        }
                        stocks.append(stock)
            
            # Debug output
            st.info(f"Converted {len(stocks)} stocks from legacy format: {[s['ticker'] for s in stocks]}")
        
        # Ensure all stocks have max_allocation_percent field
        for stock in stocks:
            if 'max_allocation_percent' not in stock:
                stock['max_allocation_percent'] = None
            if 'include_in_sma_filter' not in stock:
                stock['include_in_sma_filter'] = True
        
        # Sanitize momentum window weights to prevent StreamlitValueAboveMaxError
        momentum_windows = json_data.get('momentum_windows', [])
        for window in momentum_windows:
            if 'weight' in window:
                weight = window['weight']
                # If weight is a percentage (e.g., 50 for 50%), convert to decimal
                if isinstance(weight, (int, float)) and weight > 1.0:
                    # Cap at 100% and convert to decimal
                    weight = min(weight, 100.0) / 100.0
                elif isinstance(weight, (int, float)) and weight <= 1.0:
                    # Already in decimal format, ensure it's valid
                    weight = max(0.0, min(weight, 1.0))
                else:
                    # Invalid weight, set to default
                    weight = 0.1
                window['weight'] = weight
        
        # Map frequency values from app.py format to Multi-Backtest format
        def map_frequency(freq):
            if freq is None:
                return 'Never'
            freq_map = {
                'Never': 'Never',
                'Buy & Hold': 'Buy & Hold',
                'Buy & Hold (Target)': 'Buy & Hold (Target)',
                'Weekly': 'Weekly',
                'Biweekly': 'Biweekly',
                'Monthly': 'Monthly',
                'Quarterly': 'Quarterly',
                'Semiannually': 'Semiannually',
                'Annually': 'Annually',
                # Legacy format mapping
                'none': 'Never',
                'week': 'Weekly',
                '2weeks': 'Biweekly',
                'month': 'Monthly',
                '3months': 'Quarterly',
                '6months': 'Semiannually',
                'year': 'Annually'
            }
            return freq_map.get(freq, 'Monthly')
        
        # Multi-Backtest page specific: ensure all required fields are present
        # and ignore fields that are specific to other pages
        use_momentum = parse_bool_from_json(json_data.get('use_momentum', True), True)
        use_minimal_threshold = parse_bool_from_json(json_data.get('use_minimal_threshold', False), False)
        use_max_allocation = parse_bool_from_json(json_data.get('use_max_allocation', False), False)
        calc_beta = parse_bool_from_json(json_data.get('calc_beta', False), False)
        calc_volatility = parse_bool_from_json(json_data.get('calc_volatility', True), True)
        collect_dividends_as_cash = parse_bool_from_json(json_data.get('collect_dividends_as_cash', False), False)
        exclude_from_cashflow_sync = parse_bool_from_json(json_data.get('exclude_from_cashflow_sync', False), False)
        exclude_from_rebalancing_sync = parse_bool_from_json(json_data.get('exclude_from_rebalancing_sync', False), False)
        use_targeted_rebalancing = parse_bool_from_json(json_data.get('use_targeted_rebalancing', False), False)
        use_sma_filter = parse_bool_from_json(json_data.get('use_sma_filter', False), False)
        use_equal_weight = parse_bool_from_json(json_data.get('use_equal_weight', False), False)
        use_limit_to_top_n = parse_bool_from_json(json_data.get('use_limit_to_top_n', False), False)

        multi_backtest_config = {
            'name': json_data.get('name', 'New Portfolio'),
            'stocks': stocks,
            'benchmark_ticker': json_data.get('benchmark_ticker', '^GSPC'),
            'initial_value': json_data.get('initial_value', 10000),
            'added_amount': json_data.get('added_amount', 1000),
            'added_frequency': map_frequency(json_data.get('added_frequency', 'Monthly')),
            'rebalancing_frequency': map_frequency(json_data.get('rebalancing_frequency', 'Monthly')),
            'start_date_user': parse_date_from_json(json_data.get('start_date_user')),
            'end_date_user': parse_date_from_json(json_data.get('end_date_user')),
            'start_with': json_data.get('start_with', 'first'),
            'use_momentum': use_momentum,
            'momentum_strategy': momentum_strategy,
            'negative_momentum_strategy': negative_momentum_strategy,
            'momentum_windows': momentum_windows,
            'use_minimal_threshold': use_minimal_threshold,
            'minimal_threshold_percent': json_data.get('minimal_threshold_percent', 4.0),
            'use_max_allocation': use_max_allocation,
            'max_allocation_percent': json_data.get('max_allocation_percent', 20.0),
            'calc_beta': calc_beta,
            'calc_volatility': calc_volatility,
            'beta_window_days': json_data.get('beta_window_days', 365),
            'exclude_days_beta': json_data.get('exclude_days_beta', 30),
            'vol_window_days': json_data.get('vol_window_days', 365),
            'exclude_days_vol': json_data.get('exclude_days_vol', 30),
            'collect_dividends_as_cash': collect_dividends_as_cash,
            # Preserve sync exclusion settings from imported JSON
            'exclude_from_cashflow_sync': exclude_from_cashflow_sync,
            'exclude_from_rebalancing_sync': exclude_from_rebalancing_sync,
            'use_targeted_rebalancing': use_targeted_rebalancing,
            'targeted_rebalancing_settings': json_data.get('targeted_rebalancing_settings', {}),
            'use_sma_filter': use_sma_filter,
            'sma_window': json_data.get('sma_window', 200),
            'ma_type': json_data.get('ma_type', 'SMA'),
            'ma_multiplier': json_data.get('ma_multiplier', 1.48),
            'ma_cross_rebalance': json_data.get('ma_cross_rebalance', False),
            'ma_tolerance_percent': json_data.get('ma_tolerance_percent', 2.0),
            'ma_confirmation_days': json_data.get('ma_confirmation_days', 3),
            'use_equal_weight': use_equal_weight,
            'equal_weight_n_tickers': json_data.get('equal_weight_n_tickers', 10),
            'use_limit_to_top_n': use_limit_to_top_n,
            'limit_to_top_n_tickers': json_data.get('limit_to_top_n_tickers', 10),
        }
        
        st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index] = multi_backtest_config
        
        # Update global date widgets to match imported portfolio dates (global date range)
        imported_start_date = parse_date_from_json(json_data.get('start_date_user'))
        imported_end_date = parse_date_from_json(json_data.get('end_date_user'))
        
        if imported_start_date is not None:
            st.session_state["multi_backtest_start_date"] = imported_start_date
            # Update ALL portfolios with the imported start date
            for i, portfolio in enumerate(st.session_state.multi_backtest_portfolio_configs):
                st.session_state.multi_backtest_portfolio_configs[i]['start_date_user'] = imported_start_date
        
        if imported_end_date is not None:
            st.session_state["multi_backtest_end_date"] = imported_end_date
            # Update ALL portfolios with the imported end date
            for i, portfolio in enumerate(st.session_state.multi_backtest_portfolio_configs):
                st.session_state.multi_backtest_portfolio_configs[i]['end_date_user'] = imported_end_date
        
        # Update custom dates checkbox based on imported dates
        has_imported_dates = imported_start_date is not None or imported_end_date is not None
        st.session_state["multi_backtest_use_custom_dates"] = has_imported_dates
        
        # Handle global start_with setting from imported JSON
        if 'start_with' in json_data:
            # Handle start_with value mapping from other pages
            start_with = json_data['start_with']
            if start_with == 'first':
                start_with = 'oldest'  # Map 'first' to 'oldest' (closest equivalent)
            elif start_with not in ['all', 'oldest']:
                start_with = 'all'  # Default fallback
            st.session_state['multi_backtest_start_with'] = start_with
            # Update the radio button widget key
            st.session_state['multi_backtest_start_with_radio'] = start_with
        
        # Handle first rebalance strategy from imported JSON
        if 'first_rebalance_strategy' in json_data:
            st.session_state['multi_backtest_first_rebalance_strategy'] = json_data['first_rebalance_strategy']
            # Update the radio button widget key
            st.session_state['multi_backtest_first_rebalance_strategy_radio'] = json_data['first_rebalance_strategy']
        
        # Update session state for targeted rebalancing settings
        st.session_state['multi_backtest_active_use_targeted_rebalancing'] = multi_backtest_config.get('use_targeted_rebalancing', False)
        
        # Use portfolio-specific MA Filter keys
        portfolio_index = st.session_state.multi_backtest_active_portfolio_index
        ma_filter_key = f"multi_backtest_active_use_sma_filter_{portfolio_index}"
        ma_window_key = f"multi_backtest_active_ma_window_{portfolio_index}"
        ma_type_key = f"multi_backtest_active_ma_type_{portfolio_index}"
        
        st.session_state[ma_filter_key] = multi_backtest_config.get('use_sma_filter', False)
        st.session_state[ma_window_key] = multi_backtest_config.get('sma_window', 200)
        st.session_state[ma_type_key] = multi_backtest_config.get('ma_type', 'SMA')
        
        st.success("Portfolio configuration updated from JSON (Multi-Backtest page).")
        st.info(f"Final stocks list: {[s['ticker'] for s in multi_backtest_config['stocks']]}")
        st.info(f"Final momentum windows: {multi_backtest_config['momentum_windows']}")
        st.info(f"Final use_momentum: {multi_backtest_config['use_momentum']}")
        st.info(f"Sync exclusions - Cash Flow: {multi_backtest_config.get('exclude_from_cashflow_sync', False)}, Rebalancing: {multi_backtest_config.get('exclude_from_rebalancing_sync', False)}")
        
        # Sync date widgets with the updated portfolio
        sync_date_widgets_with_portfolio()
    except json.JSONDecodeError:
        st.error("Invalid JSON format. Please check the text and try again.")
    except Exception as e:
        st.error(f"An error occurred: {e}")
    st.session_state.multi_backtest_rerun_flag = True

def update_active_portfolio_index():
    # Use safe accessors to avoid AttributeError when keys are not yet set
    selected_name = st.session_state.get('multi_backtest_portfolio_selector', None)
    portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
    portfolio_names = [cfg.get('name', '') for cfg in portfolio_configs]
    
    old_index = st.session_state.get('multi_backtest_active_portfolio_index')
    if selected_name and selected_name in portfolio_names:
        new_index = portfolio_names.index(selected_name)
        if old_index is not None and old_index != new_index:
            keys_to_delete = [key for key in st.session_state.keys() 
                            if key.startswith(f'multi_backtest_include_sma_{old_index}_')]
            for key in keys_to_delete:
                del st.session_state[key]
        st.session_state.multi_backtest_active_portfolio_index = new_index
    else:
        # default to first portfolio if selector is missing or value not found
        st.session_state.multi_backtest_active_portfolio_index = 0 if portfolio_names else None
    
    # Additional safety check - ensure index is always valid
    if (st.session_state.multi_backtest_active_portfolio_index is not None and 
        st.session_state.multi_backtest_active_portfolio_index >= len(portfolio_names)):
        st.session_state.multi_backtest_active_portfolio_index = max(0, len(portfolio_names) - 1) if portfolio_names else None
    
    # Sync date widgets with the new portfolio
    sync_date_widgets_with_portfolio()
    
    # NUCLEAR SYNC: FORCE momentum widgets to sync with the new portfolio
    if portfolio_configs and st.session_state.multi_backtest_active_portfolio_index is not None:
        active_portfolio = portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]
        
        # NUCLEAR APPROACH: FORCE all momentum session state widgets to sync
        st.session_state['multi_backtest_active_use_momentum'] = parse_bool_from_json(active_portfolio.get('use_momentum', False), False)
        st.session_state['multi_backtest_active_momentum_strategy'] = active_portfolio.get('momentum_strategy', 'Classic')
        st.session_state['multi_backtest_active_negative_momentum_strategy'] = active_portfolio.get('negative_momentum_strategy', 'Cash')
        st.session_state['multi_backtest_active_calc_beta'] = parse_bool_from_json(active_portfolio.get('calc_beta', False), False)
        st.session_state['multi_backtest_active_calc_vol'] = parse_bool_from_json(active_portfolio.get('calc_volatility', False), False)
        st.session_state['multi_backtest_active_beta_window'] = active_portfolio.get('beta_window_days', 365)
        st.session_state['multi_backtest_active_beta_exclude'] = active_portfolio.get('exclude_days_beta', 30)
        st.session_state['multi_backtest_active_vol_window'] = active_portfolio.get('vol_window_days', 365)
        st.session_state['multi_backtest_active_vol_exclude'] = active_portfolio.get('exclude_days_vol', 30)
        
        # Sync expander state (same pattern as other portfolio parameters)
        st.session_state['multi_backtest_active_variant_expanded'] = active_portfolio.get('variant_expander_expanded', False)
        st.session_state['multi_backtest_active_use_threshold'] = active_portfolio.get('use_minimal_threshold', False)
        st.session_state['multi_backtest_active_threshold_percent'] = active_portfolio.get('minimal_threshold_percent', 4.0)
        st.session_state['multi_backtest_active_use_max_allocation'] = active_portfolio.get('use_max_allocation', False)
        st.session_state['multi_backtest_active_max_allocation_percent'] = active_portfolio.get('max_allocation_percent', 20.0)
        st.session_state['multi_backtest_active_use_equal_weight'] = active_portfolio.get('use_equal_weight', False)
        st.session_state['multi_backtest_active_equal_weight_n_tickers'] = active_portfolio.get('equal_weight_n_tickers', 10)
        st.session_state['multi_backtest_active_use_limit_to_top_n'] = active_portfolio.get('use_limit_to_top_n', False)
        st.session_state['multi_backtest_active_limit_to_top_n_tickers'] = active_portfolio.get('limit_to_top_n_tickers', 10)
        st.session_state['multi_backtest_active_use_sma_filter'] = active_portfolio.get('use_sma_filter', False)
        st.session_state['multi_backtest_active_sma_window'] = active_portfolio.get('sma_window', 200)
        # MA Multiplier - RECONSTRUCTED (no complex sync)
        
        # Force sync MA Multiplier widget with imported JSON value
        portfolio_index = st.session_state.multi_backtest_active_portfolio_index
        ma_multiplier_key = f"ma_multiplier_working_{portfolio_index}"
        st.session_state[ma_multiplier_key] = active_portfolio.get('ma_multiplier', 1.48)
        
        # Initialize MA cross rebalance setting
        ma_cross_rebalance_key = f"multi_backtest_active_ma_cross_rebalance_{portfolio_index}"
        st.session_state[ma_cross_rebalance_key] = active_portfolio.get('ma_cross_rebalance', False)
        
        # Initialize anti-whipsaw settings
        ma_tolerance_key = f"multi_backtest_active_ma_tolerance_{portfolio_index}"
        ma_delay_key = f"multi_backtest_active_ma_delay_{portfolio_index}"
        st.session_state[ma_tolerance_key] = active_portfolio.get('ma_tolerance_percent', 2.0)
        st.session_state[ma_delay_key] = active_portfolio.get('ma_confirmation_days', 3)
        
        # NUCLEAR: If portfolio has momentum enabled but no windows, FORCE create them
        if active_portfolio.get('use_momentum', False) and not active_portfolio.get('momentum_windows'):
            active_portfolio['momentum_windows'] = [
                {"lookback": 365, "exclude": 30, "weight": 0.5},
                {"lookback": 180, "exclude": 30, "weight": 0.3},
                {"lookback": 120, "exclude": 30, "weight": 0.2},
            ]
            print(f"NUCLEAR: FORCED momentum windows for portfolio {active_portfolio.get('name', 'Unknown')}")
        
        
        # NUCLEAR: Ensure threshold settings exist
        if 'use_minimal_threshold' not in active_portfolio:
            active_portfolio['use_minimal_threshold'] = False
        if 'minimal_threshold_percent' not in active_portfolio:
            active_portfolio['minimal_threshold_percent'] = 4.0
        
        print(f"NUCLEAR: Synced momentum widgets for portfolio {active_portfolio.get('name', 'Unknown')}, use_momentum={active_portfolio.get('use_momentum', False)}, windows_count={len(active_portfolio.get('momentum_windows', []))}")
        
        # RESET variant generator checkboxes when switching portfolios
        # This prevents stale checkbox states from previous portfolio selections
        variant_generator_keys = [
            "multi_use_momentum_vary",
            # Rebalance frequency checkboxes
            "multi_rebalance_never", "multi_rebalance_buyhold", "multi_rebalance_buyhold_target",
            "multi_rebalance_weekly", "multi_rebalance_biweekly", "multi_rebalance_monthly",
            "multi_rebalance_quarterly", "multi_rebalance_semiannually", "multi_rebalance_annually",
            # Momentum variant checkboxes
            "multi_momentum_classic", "multi_momentum_relative",
            "multi_negative_cash", "multi_negative_equal", "multi_negative_relative", 
            "multi_beta_yes", "multi_beta_no", "multi_vol_yes", "multi_vol_no"
        ]
        for key in variant_generator_keys:
            if key in st.session_state:
                del st.session_state[key]
    
    st.session_state.multi_backtest_rerun_flag = True

def update_name():
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['name'] = st.session_state.multi_backtest_active_name

def update_initial():
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['initial_value'] = st.session_state.multi_backtest_active_initial

def update_added_amount():
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['added_amount'] = st.session_state.multi_backtest_active_added_amount

def update_add_freq():
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['added_frequency'] = st.session_state.multi_backtest_active_add_freq

def update_rebal_freq():
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['rebalancing_frequency'] = st.session_state.multi_backtest_active_rebal_freq

def update_benchmark():
    # Convert commas to dots for decimal separators (like case conversion)
    converted_benchmark = st.session_state.multi_backtest_active_benchmark.replace(",", ".")
    
    # Convert benchmark ticker to uppercase
    upper_benchmark = converted_benchmark.upper()
    
    # Resolve benchmark ticker alias
    resolved_benchmark = resolve_ticker_alias(upper_benchmark)
    
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['benchmark_ticker'] = resolved_benchmark
    # Update the widget to show resolved value
    st.session_state.multi_backtest_active_benchmark = resolved_benchmark

def update_use_momentum():
    current_val = st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['use_momentum']
    new_val = st.session_state.multi_backtest_active_use_momentum
    
    if current_val != new_val:
        portfolio = st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]
        
        if new_val:
            # Enabling momentum - restore saved settings or use defaults
            if 'saved_momentum_settings' in portfolio:
                # Restore previously saved momentum settings
                saved_settings = portfolio['saved_momentum_settings']
                portfolio['momentum_windows'] = saved_settings.get('momentum_windows', [
                    {"lookback": 365, "exclude": 30, "weight": 0.5},
                    {"lookback": 180, "exclude": 30, "weight": 0.3},
                    {"lookback": 120, "exclude": 30, "weight": 0.2},
                ])
                portfolio['momentum_strategy'] = saved_settings.get('momentum_strategy', 'Classic')
                portfolio['negative_momentum_strategy'] = saved_settings.get('negative_momentum_strategy', 'Cash')
                portfolio['calc_beta'] = parse_bool_from_json(saved_settings.get('calc_beta', False), False)
                portfolio['calc_volatility'] = parse_bool_from_json(saved_settings.get('calc_volatility', True), True)
                portfolio['beta_window_days'] = saved_settings.get('beta_window_days', 365)
                portfolio['exclude_days_beta'] = saved_settings.get('exclude_days_beta', 30)
                portfolio['vol_window_days'] = saved_settings.get('vol_window_days', 365)
                portfolio['exclude_days_vol'] = saved_settings.get('exclude_days_vol', 30)
                
                # Update UI widgets to reflect restored values
                st.session_state['multi_backtest_active_momentum_strategy'] = portfolio['momentum_strategy']
                st.session_state['multi_backtest_active_negative_momentum_strategy'] = portfolio['negative_momentum_strategy']
                st.session_state['multi_backtest_active_calc_beta'] = portfolio['calc_beta']
                st.session_state['multi_backtest_active_calc_vol'] = portfolio['calc_volatility']
                st.session_state['multi_backtest_active_beta_window'] = portfolio['beta_window_days']
                st.session_state['multi_backtest_active_beta_exclude'] = portfolio['exclude_days_beta']
                st.session_state['multi_backtest_active_vol_window'] = portfolio['vol_window_days']
                st.session_state['multi_backtest_active_vol_exclude'] = portfolio['exclude_days_vol']
            else:
                # SMART NUCLEAR: No saved settings, create defaults only if no windows exist
                if not portfolio.get('momentum_windows'):
                    portfolio['momentum_windows'] = [
                        {"lookback": 365, "exclude": 30, "weight": 0.5},
                        {"lookback": 180, "exclude": 30, "weight": 0.3},
                        {"lookback": 120, "exclude": 30, "weight": 0.2},
                    ]
                    print("SMART NUCLEAR: Added default momentum windows (had none)")
                else:
                    print(f"SMART NUCLEAR: Preserved existing momentum windows (had {len(portfolio['momentum_windows'])} windows)")
                # Set default momentum settings only if not already set
                portfolio['momentum_strategy'] = portfolio.get('momentum_strategy', 'Classic')
                portfolio['negative_momentum_strategy'] = portfolio.get('negative_momentum_strategy', 'Cash')
                portfolio['calc_beta'] = parse_bool_from_json(portfolio.get('calc_beta', False), False)
                portfolio['calc_volatility'] = parse_bool_from_json(portfolio.get('calc_volatility', False), False)
        else:
            # Disabling momentum - save current settings before clearing
            saved_settings = {
                'momentum_windows': portfolio.get('momentum_windows', []),
                'momentum_strategy': portfolio.get('momentum_strategy', 'Classic'),
                'negative_momentum_strategy': portfolio.get('negative_momentum_strategy', 'Cash'),
                'calc_beta': parse_bool_from_json(portfolio.get('calc_beta', False), False),
                'calc_volatility': parse_bool_from_json(portfolio.get('calc_volatility', True), True),
                'beta_window_days': portfolio.get('beta_window_days', 365),
                'exclude_days_beta': portfolio.get('exclude_days_beta', 30),
                'vol_window_days': portfolio.get('vol_window_days', 365),
                'exclude_days_vol': portfolio.get('exclude_days_vol', 30),
            }
            portfolio['saved_momentum_settings'] = saved_settings
            # Don't clear momentum_windows - preserve them for variant generation
        
        portfolio['use_momentum'] = new_val
        st.session_state.multi_backtest_rerun_flag = True

def update_use_sma_filter():
    ma_filter_key = f"multi_backtest_active_use_sma_filter_{st.session_state.multi_backtest_active_portfolio_index}"
    current_val = st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['use_sma_filter']
    new_val = st.session_state.get(ma_filter_key, False)
    
    if current_val != new_val:
        portfolio = st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]
        portfolio['use_sma_filter'] = new_val
        
        # If enabling MA filter, disable targeted rebalancing (mutually exclusive)
        if new_val:
            portfolio['use_targeted_rebalancing'] = False
            # Don't modify session state directly - let the checkbox handle it
            # st.session_state['multi_backtest_active_use_targeted_rebalancing'] = False
        
        st.session_state.multi_backtest_rerun_flag = True

def update_ma_reference_ticker(stock_index):
    """Callback function when MA reference ticker changes"""
    ma_ref_key = f"multi_backtest_ma_reference_{st.session_state.multi_backtest_active_portfolio_index}_{stock_index}"
    new_value = st.session_state.get(ma_ref_key, '').strip()
    
    # Apply EXACTLY the same transformations as regular tickers
    # Convert commas to dots for decimal separators
    new_value = new_value.replace(",", ".")
    
    # Convert to uppercase
    new_value = new_value.upper()
    
    # Special conversion for Berkshire Hathaway tickers for Yahoo Finance compatibility
    if new_value == 'BRK.B':
        new_value = 'BRK-B'
    elif new_value == 'BRK.A':
        new_value = 'BRK-A'
    
    # CRITICAL: Resolve ticker alias (GOLDX ‚Üí GOLD_COMPLETE, SPYTR ‚Üí ^SP500TR, etc.)
    if new_value:  # Only resolve if not empty
        resolved_value = resolve_ticker_alias(new_value)
    else:
        resolved_value = new_value
    
    # Update session state with resolved value for display
    st.session_state[ma_ref_key] = resolved_value
    
    # Update the stock config
    portfolio = st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]
    if stock_index < len(portfolio['stocks']):
        old_value = portfolio['stocks'][stock_index].get('ma_reference_ticker', '')
        if resolved_value != old_value:
            portfolio['stocks'][stock_index]['ma_reference_ticker'] = resolved_value
            st.session_state.multi_backtest_rerun_flag = True

def update_use_targeted_rebalancing():
    """Callback function for targeted rebalancing checkbox"""
    current_val = st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index].get('use_targeted_rebalancing', False)
    new_val = st.session_state.multi_backtest_active_use_targeted_rebalancing
    
    if current_val != new_val:
        portfolio = st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]
        portfolio['use_targeted_rebalancing'] = new_val
        
        # If enabling targeted rebalancing, disable momentum and MA filter (mutually exclusive)
        if new_val:
            portfolio['use_momentum'] = False
            # Don't modify session state directly - let the checkbox handle it
            # st.session_state['multi_backtest_active_use_momentum'] = False
            portfolio['use_sma_filter'] = False
            # Don't modify session state directly - let the checkbox handle it
            # st.session_state['multi_backtest_active_use_sma_filter'] = False
        
        st.session_state.multi_backtest_rerun_flag = True



def update_calc_beta():
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['calc_beta'] = st.session_state.multi_backtest_active_calc_beta

def update_beta_window():
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['beta_window_days'] = st.session_state.multi_backtest_active_beta_window

def update_beta_exclude():
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['exclude_days_beta'] = st.session_state.multi_backtest_active_beta_exclude

def update_calc_vol():
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['calc_volatility'] = st.session_state.multi_backtest_active_calc_vol

def update_vol_window():
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['vol_window_days'] = st.session_state.multi_backtest_active_vol_window

def update_vol_exclude():
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['exclude_days_vol'] = st.session_state.multi_backtest_active_vol_exclude

def update_ma_cross_rebalance():
    portfolio_index = st.session_state.multi_backtest_active_portfolio_index
    ma_cross_rebalance_key = f"multi_backtest_active_ma_cross_rebalance_{portfolio_index}"
    st.session_state.multi_backtest_portfolio_configs[portfolio_index]['ma_cross_rebalance'] = st.session_state.get(ma_cross_rebalance_key, False)

def update_use_threshold():
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['use_minimal_threshold'] = st.session_state.multi_backtest_active_use_threshold

def update_threshold_percent():
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['minimal_threshold_percent'] = st.session_state.multi_backtest_active_threshold_percent

def update_use_max_allocation():
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['use_max_allocation'] = st.session_state.multi_backtest_active_use_max_allocation

def update_max_allocation_percent():
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['max_allocation_percent'] = st.session_state.multi_backtest_active_max_allocation_percent

def update_use_equal_weight():
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['use_equal_weight'] = st.session_state.multi_backtest_active_use_equal_weight

def update_equal_weight_n_tickers():
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['equal_weight_n_tickers'] = st.session_state.multi_backtest_active_equal_weight_n_tickers

def update_use_limit_to_top_n():
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['use_limit_to_top_n'] = st.session_state.multi_backtest_active_use_limit_to_top_n

def update_limit_to_top_n_tickers():
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['limit_to_top_n_tickers'] = st.session_state.multi_backtest_active_limit_to_top_n_tickers

def update_start_with():
    st.session_state.multi_backtest_start_with = st.session_state.multi_backtest_start_with_radio

def update_first_rebalance_strategy():
    st.session_state.multi_backtest_first_rebalance_strategy = st.session_state.multi_backtest_first_rebalance_strategy_radio

def update_start_date():
    """Update all portfolio configs when start date changes"""
    start_date = st.session_state.multi_backtest_start_date
    for i, portfolio in enumerate(st.session_state.multi_backtest_portfolio_configs):
        st.session_state.multi_backtest_portfolio_configs[i]['start_date_user'] = start_date

def update_end_date():
    """Update all portfolio configs when end date changes"""
    end_date = st.session_state.multi_backtest_end_date
    for i, portfolio in enumerate(st.session_state.multi_backtest_portfolio_configs):
        st.session_state.multi_backtest_portfolio_configs[i]['end_date_user'] = end_date

def update_custom_dates_checkbox():
    """Update checkbox state when custom dates are toggled"""
    # This function ensures the checkbox state is properly maintained
    pass  # The checkbox state is managed by Streamlit automatically

def update_collect_dividends_as_cash():
    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['collect_dividends_as_cash'] = st.session_state.multi_backtest_active_collect_dividends_as_cash

def clear_dates_callback():
    """Clear the date inputs and reset to None for ALL portfolios"""
    st.session_state.multi_backtest_start_date = None
    st.session_state.multi_backtest_end_date = date.today()
    st.session_state.multi_backtest_use_custom_dates = False
    # Clear from ALL portfolio configs (global date range)
    for i, portfolio in enumerate(st.session_state.multi_backtest_portfolio_configs):
        st.session_state.multi_backtest_portfolio_configs[i]['start_date_user'] = None
        st.session_state.multi_backtest_portfolio_configs[i]['end_date_user'] = None

def update_sync_exclusion(sync_type):
    """Update sync exclusion settings when checkboxes change"""
    try:
        portfolio = st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]
        
        if sync_type == 'cashflow':
            key = f"multi_backtest_exclude_cashflow_sync_{st.session_state.multi_backtest_active_portfolio_index}"
            if key in st.session_state:
                portfolio['exclude_from_cashflow_sync'] = st.session_state[key]
        elif sync_type == 'rebalancing':
            key = f"multi_backtest_exclude_rebalancing_sync_{st.session_state.multi_backtest_active_portfolio_index}"
            if key in st.session_state:
                portfolio['exclude_from_rebalancing_sync'] = st.session_state[key]
        
        # Force immediate update to session state
        st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index] = portfolio
        st.session_state.multi_backtest_rerun_flag = True
    except Exception:
        pass

def parse_bool_from_json(value, default=False):
    """
    Normalize JSON boolean-like values into real Python booleans.
    Accepts actual bools, string representations, and numeric 0/1 flags.
    """
    if isinstance(value, bool):
        return value
    if isinstance(value, str):
        cleaned = value.strip().lower()
        if cleaned in {"true", "1", "yes", "y", "on"}:
            return True
        if cleaned in {"false", "0", "no", "n", "off"}:
            return False
        return default
    if isinstance(value, (int, float)):
        return value != 0
    return default


def parse_date_from_json(date_value):
    """Parse date from JSON string format back to date object"""
    if date_value is None:
        return None
    if isinstance(date_value, date):
        return date_value
    if isinstance(date_value, str):
        try:
            return datetime.strptime(date_value, '%Y-%m-%d').date()
        except ValueError:
            try:
                # Try parsing as ISO format
                return datetime.fromisoformat(date_value).date()
            except ValueError:
                return None
    return None

def sync_date_widgets_with_portfolio():
    """Sync date widgets with current portfolio configuration"""
    from datetime import date
    if st.session_state.multi_backtest_active_portfolio_index is not None:
        portfolio = st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]
        
        # Sync start date
        portfolio_start_date = portfolio.get('start_date_user')
        if portfolio_start_date is not None:
            st.session_state["multi_backtest_start_date"] = portfolio_start_date
        else:
            st.session_state["multi_backtest_start_date"] = date(2010, 1, 1)
        
        # Sync end date
        portfolio_end_date = portfolio.get('end_date_user')
        if portfolio_end_date is not None:
            st.session_state["multi_backtest_end_date"] = portfolio_end_date
        else:
            st.session_state["multi_backtest_end_date"] = date.today()
        
        # Sync custom dates checkbox
        has_custom_dates = portfolio_start_date is not None or portfolio_end_date is not None
        st.session_state["multi_backtest_use_custom_dates"] = has_custom_dates

# Sidebar for portfolio selection
st.sidebar.title("Manage Portfolios")
portfolio_names = [cfg['name'] for cfg in st.session_state.multi_backtest_portfolio_configs]

# Ensure the active portfolio index is valid
if (st.session_state.multi_backtest_active_portfolio_index is None or 
    st.session_state.multi_backtest_active_portfolio_index >= len(portfolio_names) or
    st.session_state.multi_backtest_active_portfolio_index < 0):
    st.session_state.multi_backtest_active_portfolio_index = 0 if portfolio_names else None

# Use the current portfolio name as the default selection to make it more reliable
current_portfolio_name = None
if (st.session_state.multi_backtest_active_portfolio_index is not None and 
    st.session_state.multi_backtest_active_portfolio_index < len(portfolio_names)):
    current_portfolio_name = portfolio_names[st.session_state.multi_backtest_active_portfolio_index]

selected_portfolio_name = st.sidebar.selectbox(
    "Select Portfolio",
    options=portfolio_names,
    index=st.session_state.multi_backtest_active_portfolio_index,
    key="multi_backtest_portfolio_selector",
    on_change=update_active_portfolio_index
)

active_portfolio = st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]

if st.sidebar.button("Add New Portfolio", on_click=add_portfolio_callback):
    pass

# Individual portfolio removal (original functionality)
if len(st.session_state.multi_backtest_portfolio_configs) > 1:
    if st.sidebar.button("Remove Selected Portfolio", on_click=remove_portfolio_callback):
        pass

# Reset selected portfolio button
if st.sidebar.button("Reset Selected Portfolio", on_click=reset_portfolio_callback):
    pass

# Quick convert to SPY portfolio button
if st.sidebar.button("üìä Convert to SPY Portfolio", 
                    help="Transform selected portfolio to SPY benchmark: 100% SPY, $10k initial + $10k/year"):
    portfolio_index = st.session_state.multi_backtest_active_portfolio_index
    current = st.session_state.multi_backtest_portfolio_configs[portfolio_index]
    
    # Simple: just change what's needed for SPY
    current['name'] = 'SPY Benchmark'
    current['stocks'] = [{'ticker': 'SPY', 'allocation': 1.0, 'include_dividends': True}]
    current['use_momentum'] = False
    current['added_amount'] = 10000
    current['added_frequency'] = 'Annually'
    
    st.toast("‚úÖ Portfolio converted to SPY Benchmark!")
    st.rerun()

# Quick convert to SPY Total Return portfolio button
if st.sidebar.button("üìà Convert to SPY Total Return", 
                    help="Transform selected portfolio to SPY Total Return: 100% SPYTR, $10k initial + $10k/year"):
    portfolio_index = st.session_state.multi_backtest_active_portfolio_index
    current = st.session_state.multi_backtest_portfolio_configs[portfolio_index]
    
    # Simple: just change what's needed for SPY Total Return
    current['name'] = 'SPY Total Return'
    current['stocks'] = [{'ticker': 'SPYTR', 'allocation': 1.0, 'include_dividends': True}]
    current['use_momentum'] = False
    current['added_amount'] = 10000
    current['added_frequency'] = 'Annually'
    
    st.toast("‚úÖ Portfolio converted to SPY Total Return!")
    st.rerun()

# Clear ticker cache button
if st.sidebar.button("üóëÔ∏è Clear Ticker Cache", 
                    help="Clear the 4-hour ticker cache to force fresh data downloads", 
                    use_container_width=True):
    total_cleared = clear_all_yahoo_caches()
    
    if total_cleared > 0:
        st.sidebar.success(f"‚úÖ Cleared {total_cleared} cached items (tickers + PE/valuations)")
    else:
        st.sidebar.info("No cache to clear")

# Clear all portfolios button - quick access outside dropdown
if st.sidebar.button("üóëÔ∏è Clear All Portfolios", key="multi_backtest_clear_all_portfolios_immediate", 
                    help="Delete ALL portfolios and create a blank one", use_container_width=True):
    # Clear all portfolios and create a single blank portfolio
    st.session_state.multi_backtest_portfolio_configs = [{
        'name': 'New Portfolio 1',
        'stocks': [{'ticker': '', 'allocation': 0.0, 'include_dividends': True, 'include_in_sma_filter': True, 'max_allocation_percent': None}],
        'benchmark_ticker': '^GSPC',
        'initial_value': 10000,
        'added_amount': 0,
        'added_frequency': 'none',
        'rebalancing_frequency': 'Monthly',
        'start_with': 'all',
        'first_rebalance_strategy': 'rebalancing_date',
        'use_momentum': False,
        'momentum_strategy': 'Classic',
        'negative_momentum_strategy': 'Cash',
        'momentum_windows': [
            {"lookback": 365, "exclude": 30, "weight": 0.5},
            {"lookback": 180, "exclude": 30, "weight": 0.3},
            {"lookback": 120, "exclude": 30, "weight": 0.2}
        ],
            'calc_beta': False,
        'beta_window_days': 365,
        'exclude_days_beta': 30,
        'calc_volatility': False,
        'vol_window_days': 365,
        'exclude_days_vol': 30,
        'use_minimal_threshold': False,
        'minimal_threshold_percent': 4.0,
        'use_max_allocation': False,
        'max_allocation_percent': 20.0,
        'collect_dividends_as_cash': False,
        'start_date_user': None,
        'end_date_user': None,
        'fusion_portfolio': {'enabled': False, 'selected_portfolios': [], 'allocations': {}}
    }]
    st.session_state.multi_backtest_active_portfolio_index = 0
    st.session_state.multi_backtest_portfolio_checkboxes = {}
    
    # Clear all ticker-related session state
    st.session_state.multi_backtest_active_benchmark = '^GSPC'
    st.session_state.multi_backtest_bulk_tickers = ""
    
    # Clear all individual ticker inputs
    keys_to_clear = [key for key in st.session_state.keys() if key.startswith('multi_backtest_ticker_')]
    for key in keys_to_clear:
        del st.session_state[key]
    
    st.success("‚úÖ All portfolios cleared! Created 'New Portfolio 1'")
    st.rerun()

# Clear All Outputs Function
def clear_all_outputs():
    """Clear all backtest results and outputs while preserving portfolio configurations"""
    # Clear all result data
    st.session_state.multi_all_results = None
    st.session_state.multi_all_allocations = None
    st.session_state.multi_all_metrics = None
    st.session_state.multi_backtest_all_drawdowns = None
    st.session_state.multi_backtest_stats_df_display = None
    st.session_state.multi_backtest_all_years = None
    st.session_state.multi_backtest_portfolio_key_map = {}
    st.session_state.multi_backtest_ran = False
    
    # Clear any processing flags
    for key in list(st.session_state.keys()):
        if key.startswith("processing_portfolio_"):
            del st.session_state[key]
    
    # Clear any cached data
    if 'raw_data' in st.session_state:
        del st.session_state['raw_data']
    
    st.success("‚úÖ All outputs cleared! Portfolio configurations preserved.")

# Clear All Outputs Button
if st.sidebar.button("üóëÔ∏è Clear All Outputs", type="secondary", use_container_width=True, help="Clear all charts and results while keeping portfolio configurations"):
    clear_all_outputs()
    st.rerun()

# NEW: Enhanced bulk portfolio management dropdown
if len(st.session_state.multi_backtest_portfolio_configs) > 1:
    st.sidebar.markdown("---")
    st.sidebar.subheader("üîÑ Bulk Portfolio Management")
    
    # Initialize session state for selected portfolios
    if "multi_backtest_portfolio_checkboxes" not in st.session_state:
        st.session_state.multi_backtest_portfolio_checkboxes = {}
    
    # Clean up orphaned checkbox states (remove checkboxes for portfolios that no longer exist)
    existing_portfolio_names = set(portfolio_names)
    checkbox_keys_to_remove = []
    for checkbox_name in st.session_state.multi_backtest_portfolio_checkboxes.keys():
        if checkbox_name not in existing_portfolio_names:
            checkbox_keys_to_remove.append(checkbox_name)
    
    for key in checkbox_keys_to_remove:
        del st.session_state.multi_backtest_portfolio_checkboxes[key]
    
    # Enhanced dropdown with built-in selection controls
    with st.sidebar.expander("üìã Manage Multiple Portfolios", expanded=False):
        # Calculate actual portfolio count (filter out empty names)
        actual_portfolio_count = len([name for name in portfolio_names if name and name.strip()])
        st.caption(f"Total portfolios: {actual_portfolio_count}")
        
        # Create checkboxes for each portfolio
        st.markdown("**Select portfolios to delete:**")
        
        # Quick selection buttons at the top
        col1, col2, col3 = st.columns([1, 1, 1])
        with col1:
            if st.button("‚úÖ Select All", key="multi_backtest_select_all_portfolios", 
                        help="Select all portfolios for deletion", use_container_width=True):
                for name in portfolio_names:
                    st.session_state.multi_backtest_portfolio_checkboxes[name] = True
                st.rerun()
        
        with col2:
            if st.button("‚ùå Clear All", key="multi_backtest_clear_all_portfolios", 
                        help="Clear all portfolio selections", use_container_width=True):
                st.session_state.multi_backtest_portfolio_checkboxes = {}
                st.rerun()
        
        with col3:
            if st.button("üîÑ Refresh", key="multi_backtest_refresh_selections", 
                        help="Refresh the selection list", use_container_width=True):
                st.rerun()
        
        # Portfolio checkboxes with scrollable container
        st.markdown("---")
        
        # Create a scrollable container for many portfolios
        with st.container():
            # Limit height and add scrollbar for many portfolios
            st.markdown("""
            <style>
            .portfolio-checkboxes {
                max-height: 300px;
                overflow-y: auto;
                border: 1px solid #ddd;
                padding: 10px;
                border-radius: 5px;
            }
            </style>
            """, unsafe_allow_html=True)
            
            # Portfolio checkboxes with individual callback functions
            for i, portfolio_name in enumerate(portfolio_names):
                # Initialize checkbox state if not exists
                if portfolio_name not in st.session_state.multi_backtest_portfolio_checkboxes:
                    st.session_state.multi_backtest_portfolio_checkboxes[portfolio_name] = False
                
                # Create checkbox for each portfolio - use on_change with lambda to capture portfolio_name
                checkbox_key = f"multi_backtest_portfolio_checkbox_{hash(portfolio_name)}"
                
                def create_callback(name):
                    return lambda: None  # We'll handle the state in the checkbox value directly
                
                # Create checkbox with direct value binding (no callback needed)
                is_checked = st.checkbox(
                    f"üóëÔ∏è {portfolio_name}",
                    value=st.session_state.multi_backtest_portfolio_checkboxes[portfolio_name],
                    key=checkbox_key,
                    help=f"Select {portfolio_name} for deletion"
                )
                
                # Update session state directly based on checkbox value
                if is_checked != st.session_state.multi_backtest_portfolio_checkboxes[portfolio_name]:
                    st.session_state.multi_backtest_portfolio_checkboxes[portfolio_name] = is_checked
        
        # Get selected portfolios from checkboxes
        selected_portfolios_for_deletion = [
            name for name, checked in st.session_state.multi_backtest_portfolio_checkboxes.items() 
            if checked
        ]
        
        # Show success message if portfolios were deleted
        if "multi_backtest_bulk_delete_success" in st.session_state and st.session_state.multi_backtest_bulk_delete_success:
            st.success(st.session_state.multi_backtest_bulk_delete_success)
            # Clear the success message after showing it
            del st.session_state.multi_backtest_bulk_delete_success
        
        # Show selection summary
        if selected_portfolios_for_deletion:
            st.info(f"üìä Selected: {len(selected_portfolios_for_deletion)} of {actual_portfolio_count} portfolio(s)")
            if len(selected_portfolios_for_deletion) <= 3:
                st.caption(f"Selected: {', '.join(selected_portfolios_for_deletion)}")
            else:
                st.caption(f"Selected: {', '.join(selected_portfolios_for_deletion[:3])} and {len(selected_portfolios_for_deletion) - 3} more...")
            
            # Bulk delete button with confirmation
            confirm_deletion = st.checkbox(
                f"üóëÔ∏è Confirm deletion of {len(selected_portfolios_for_deletion)} portfolio(s)",
                key="multi_backtest_confirm_bulk_deletion",
                help="Check this box to enable the delete button"
            )
            
            if confirm_deletion:
                if st.button("üö® DELETE SELECTED PORTFOLIOS", 
                           type="secondary",
                           help=f"Delete {len(selected_portfolios_for_deletion)} selected portfolio(s)",
                           on_click=bulk_delete_portfolios_callback,
                           args=(selected_portfolios_for_deletion,),
                           use_container_width=True):
                    pass
        else:
            st.caption("No portfolios selected for deletion")

# Fusion Portfolio Creator - Collapsible Interface
def generate_fusion_name(allocations_dict, rebalancing_freq="Monthly"):
    """Generate a descriptive fusion portfolio name based on allocations"""
    if not allocations_dict:
        return f"Fusion ({rebalancing_freq})"
    
    # Filter out any None or invalid allocations
    valid_allocations = {k: v for k, v in allocations_dict.items() if v is not None and v > 0}
    
    if not valid_allocations:
        return f"Fusion ({rebalancing_freq})"
    
    # Sort by allocation percentage (descending)
    sorted_allocs = sorted(valid_allocations.items(), key=lambda x: x[1], reverse=True)
    
    # Limit to top 2 portfolios to keep name reasonable
    top_allocations = sorted_allocs[:2]
    
    # Create name with top allocations
    name_parts = []
    for portfolio_name, percentage in top_allocations:
        # Handle both decimal (0.0-1.0) and percentage (0-100) formats
        if percentage <= 1.0:
            # Already in decimal format
            name_parts.append(f"{portfolio_name} {percentage*100:.0f}%")
        else:
            # Already in percentage format
            name_parts.append(f"{portfolio_name} {percentage:.0f}%")
    
    if name_parts:
        return f"Fusion {' '.join(name_parts)} ({rebalancing_freq})"
    else:
        return f"Fusion ({rebalancing_freq})"

st.sidebar.markdown("---")

# Check if we have at least 2 portfolios - ALWAYS refresh the count
portfolio_count = len(st.session_state.multi_backtest_portfolio_configs)
if portfolio_count >= 2:
    # Get available portfolio names (excluding any existing fusion portfolios)
    # Force refresh by recalculating every time
    available_portfolios = [
        cfg['name'] for cfg in st.session_state.multi_backtest_portfolio_configs 
        if not (cfg.get('fusion_portfolio', {}).get('enabled', False))
    ]
    
    # Get existing fusion portfolios
    existing_fusion_portfolios = [
        cfg for cfg in st.session_state.multi_backtest_portfolio_configs 
        if cfg.get('fusion_portfolio', {}).get('enabled', False)
    ]
    
    # Debug info to help with server issues
    st.sidebar.caption(f"üìä Found {len(available_portfolios)} portfolios for fusion")
    
    # Show fusion portfolio info if we have any
    if existing_fusion_portfolios:
        st.warning("""
        **üîó Fusion Portfolio Detected! (BETA)**
        
        A fusion portfolio combines multiple individual portfolios by rebalancing between them at regular intervals.
        
        **‚ö†Ô∏è IMPORTANT: Only the Rebalance Frequency setting below affects the backtest!**
        
        **How it works:**
        ‚Ä¢ Each individual portfolio runs with its own settings (initial value, additions, rebalancing frequency)
        ‚Ä¢ The fusion portfolio takes the current value of each portfolio and multiplies by the allocation percentage
        ‚Ä¢ **Only the fusion portfolio's rebalancing frequency matters** for between-portfolio rebalancing
        ‚Ä¢ The fusion portfolio's initial value, added amount, and added frequency are **NOT used**
        ‚Ä¢ Final value = (Portfolio A value * A%) + (Portfolio B value * B%) + ...
        
        **Example:**
        
        If Portfolio A (60%) is worth 15k and Portfolio B (40%) is worth 12k, the fusion portfolio value = (15k * 0.60) + (12k * 0.40) = 13.8k
        
        **Note:** This feature is in BETA - not all functionality is complete yet.
        """)
    
    # Create expander title with count
    fusion_count = len(existing_fusion_portfolios)
    if fusion_count > 0:
        expander_title = f"üîó Fusion Portfolio ({fusion_count})"
    else:
        expander_title = "üîó Fusion Portfolio"
    
    # Only show if we have enough portfolios or existing fusions
    if len(available_portfolios) >= 2 or existing_fusion_portfolios:
        with st.sidebar.expander(expander_title, expanded=False):
            # Initialize fusion portfolio state
            if 'fusion_action' not in st.session_state:
                st.session_state.fusion_action = "Create New Fusion"
            
            if len(available_portfolios) >= 2:
                # Create dropdown options
                dropdown_options = ["Create New Fusion"]
                if existing_fusion_portfolios:
                    dropdown_options.extend([f"Edit: {fp['name']}" for fp in existing_fusion_portfolios])
                    dropdown_options.extend([f"Delete: {fp['name']}" for fp in existing_fusion_portfolios])
                
                # Main dropdown
                fusion_action = st.selectbox(
                    "Fusion Portfolio Actions",
                    dropdown_options,
                    key="fusion_action_select",
                    help="Select an action for fusion portfolios"
                )
                
                # Handle the selected action
                if fusion_action == "Create New Fusion":
                    # FORCE REFRESH: Always recalculate available portfolios to ensure latest count
                    current_available_portfolios = [
                        cfg['name'] for cfg in st.session_state.multi_backtest_portfolio_configs 
                        if not (cfg.get('fusion_portfolio', {}).get('enabled', False))
                    ]
                    
                    # Simple portfolio selection with forced refresh
                    selected_portfolios = st.multiselect(
                        "Select Portfolios",
                        current_available_portfolios,
                        key=f"fusion_portfolios_select_{len(current_available_portfolios)}",
                        help="Choose portfolios to combine",
                        default=[]  # Always start with empty selection
                    )
                    
                    if selected_portfolios:
                        # Debug: Show current portfolio count
                        st.info(f"üîç Creating fusion with {len(selected_portfolios)} portfolios: {', '.join(selected_portfolios)}")
                        
                        # Simple allocation inputs
                        st.markdown("**Allocations (%)**")
                        allocations = {}
                        total = 0
                        
                        for i, portfolio_name in enumerate(selected_portfolios):
                            col1, col2 = st.columns([2, 1])
                            with col1:
                                st.markdown(portfolio_name)
                            with col2:
                                # Default to equal allocation
                                default_alloc = int(100.0 / len(selected_portfolios))
                                alloc = st.number_input(
                                    "Allocation percentage",
                                    min_value=0,
                                    max_value=100,
                                    value=default_alloc,
                                    step=1,
                                    format="%d",
                                    label_visibility="collapsed",
                                    key=f"alloc_{portfolio_name}"
                                )
                                allocations[portfolio_name] = alloc
                                total += alloc
                        
                        # Show total
                        st.markdown(f"**Total: {total}%**")
                        
                        # Auto-normalize if needed
                        if abs(total - 100.0) > 0.1 and total > 0:
                            st.info("Auto-normalizing to 100%")
                            for name in allocations:
                                allocations[name] = allocations[name] / total * 100.0
                        
                        # Generate descriptive default name based on allocations
                        
                        # Portfolio name will be generated after frequency selection
                        
                        
                        # Fusion portfolio has its own independent rebalancing frequency
                        # This ensures momentum portfolios don't override fusion frequency
                        
                        # Initialize fusion frequency session state if not exists
                        if "fusion_rebalancing_frequency" not in st.session_state:
                            st.session_state["fusion_rebalancing_frequency"] = "Monthly"
                        
                        # Fusion rebalancing frequency selector
                        fusion_freq_options = ["Never", "Buy & Hold", "Buy & Hold (Target)", "Weekly", "Biweekly", "Monthly", "Quarterly", "Semiannually", "Annually"]
                        fusion_rebalancing_frequency = st.selectbox(
                            "Fusion Rebalancing Frequency",
                            fusion_freq_options,
                            index=fusion_freq_options.index(st.session_state.get("fusion_rebalancing_frequency", "Monthly")),
                            key="fusion_rebalancing_frequency_selector",
                            help="How often the fusion portfolio rebalances between its constituent portfolios. This is independent of individual portfolio rebalancing frequencies."
                        )
                        
                        # Update session state
                        st.session_state["fusion_rebalancing_frequency"] = fusion_rebalancing_frequency
                        
                        # Sync & Normalize button for server synchronization
                        col1, col2 = st.columns([1, 1])
                        with col1:
                            if st.button("üîÑ Sync & Normalize", help="Force synchronization and normalization of allocations", key="fusion_sync_button"):
                                # Force refresh allocations from inputs
                                for portfolio_name in selected_portfolios:
                                    key = f"alloc_{portfolio_name}"
                                    if key in st.session_state:
                                        allocations[portfolio_name] = st.session_state[key]
                                
                                # Normalize to 100%
                                total = sum(allocations.values())
                                if total > 0:
                                    for name in allocations:
                                        allocations[name] = allocations[name] / total * 100.0
                                
                                # Force rerun to update UI
                                st.rerun()
                        
                        with col2:
                            st.caption("üí° Click to sync allocations and normalize to 100%")
                        
                        # Portfolio name (generated after rebalancing frequency is selected)
                        default_name = generate_fusion_name(allocations, fusion_rebalancing_frequency)
                        fusion_name = st.text_input(
                            "Fusion Name",
                            value=default_name,
                            key="fusion_name_input"
                        )
                        
                        # Information about independent rebalancing
                        st.info(f"""
                        **Independent Rebalancing System:**
                        - Individual portfolios keep their own rebalancing frequencies
                        - Fusion portfolio rebalances between portfolios at **{fusion_rebalancing_frequency}**
                        - This allows maximum flexibility for different strategies
                        - **Fusion frequency is completely independent** of individual portfolio frequencies
                        """)
                        
                        # Create button
                        if st.button("üîó Create Fusion", type="primary"):
                            # Test toast first
                            st.toast("üß™ Testing fusion toast...")
                            
                            # Validate selection
                            if not selected_portfolios:
                                st.error("‚ùå Please select at least one portfolio for fusion")
                                st.stop()
                            
                            # Get first portfolio for defaults
                            first_portfolio = st.session_state.multi_backtest_portfolio_configs[0]
                            
                            # Create fusion portfolio with its own independent frequency
                            new_fusion_portfolio = {
                                'name': fusion_name,
                                'stocks': [],
                                'use_momentum': False,
                                'momentum_windows': [],
                                'initial_value': first_portfolio.get('initial_value', 10000),
                                'added_amount': first_portfolio.get('added_amount', 1000),
                                'added_frequency': first_portfolio.get('added_frequency', 'Monthly'),
                                'rebalancing_frequency': fusion_rebalancing_frequency,  # Use fusion's own independent frequency
                                'benchmark_ticker': first_portfolio.get('benchmark_ticker', '^GSPC'),
                                'fusion_portfolio': {
                                    'enabled': True,
                                    'selected_portfolios': selected_portfolios,
                                    'allocations': {name: alloc/100.0 for name, alloc in allocations.items()}
                                }
                            }
                            
                            st.session_state.multi_backtest_portfolio_configs.append(new_fusion_portfolio)
                            st.success(f"‚úÖ Created: {fusion_name}")
                            st.toast(f"üéâ Fusion portfolio '{fusion_name}' created successfully!")
                            st.rerun()
                
                elif fusion_action.startswith("Edit:"):
                    # Edit existing fusion portfolio
                    fusion_name = fusion_action.replace("Edit: ", "")
                    fusion_portfolio = next(fp for fp in existing_fusion_portfolios if fp['name'] == fusion_name)
                    fusion_config = fusion_portfolio['fusion_portfolio']
                    current_portfolios = fusion_config.get('selected_portfolios', [])
                    current_allocations = fusion_config.get('allocations', {})
                    
                    st.markdown(f"**Editing: {fusion_name}**")
                    
                    # Portfolio selection with dynamic refresh
                    current_available_portfolios = [
                        cfg['name'] for cfg in st.session_state.multi_backtest_portfolio_configs 
                        if not (cfg.get('fusion_portfolio', {}).get('enabled', False))
                    ]
                    
                    selected_portfolios = st.multiselect(
                        "Select Portfolios",
                        current_available_portfolios,
                        default=current_portfolios,
                        key=f"edit_fusion_portfolios_{len(current_available_portfolios)}",
                        help="Choose portfolios to combine"
                    )
                    
                    if selected_portfolios:
                        # Allocation inputs
                        st.markdown("**Allocations (%)**")
                        allocations = {}
                        total = 0
                        
                        for portfolio_name in selected_portfolios:
                            col1, col2 = st.columns([2, 1])
                            with col1:
                                st.markdown(portfolio_name)
                            with col2:
                                # Use current allocation or default to equal
                                current_alloc = current_allocations.get(portfolio_name, 0) * 100.0
                                if current_alloc == 0:
                                    current_alloc = 100.0 / len(selected_portfolios)
                                
                                alloc = st.number_input(
                                    f"Allocation for {portfolio_name} (%)",
                                    min_value=0,
                                    max_value=100,
                                    value=int(current_alloc),
                                    step=1,
                                    format="%d",
                                    key=f"edit_alloc_{portfolio_name}",
                                    label_visibility="collapsed"
                                )
                                allocations[portfolio_name] = alloc
                                total += alloc
                        
                        # Show total
                        st.markdown(f"**Total: {total}%**")
                        
                        # Auto-normalize if needed
                        if abs(total - 100.0) > 0.1 and total > 0:
                            st.info("Auto-normalizing to 100%")
                            for name in allocations:
                                allocations[name] = allocations[name] / total * 100.0
                        
                        # Fusion portfolio has its own independent rebalancing frequency
                        # This ensures momentum portfolios don't override fusion frequency
                        
                        # Get current fusion frequency
                        current_fusion_freq = fusion_portfolio.get('rebalancing_frequency', 'Monthly')
                        
                        # Initialize fusion frequency session state if not exists
                        if "fusion_edit_rebalancing_frequency" not in st.session_state:
                            st.session_state["fusion_edit_rebalancing_frequency"] = current_fusion_freq
                        
                        # Fusion rebalancing frequency selector for editing
                        fusion_freq_options = ["Never", "Buy & Hold", "Buy & Hold (Target)", "Weekly", "Biweekly", "Monthly", "Quarterly", "Semiannually", "Annually"]
                        fusion_rebalancing_frequency = st.selectbox(
                            "Fusion Rebalancing Frequency",
                            fusion_freq_options,
                            index=fusion_freq_options.index(st.session_state.get("fusion_edit_rebalancing_frequency", current_fusion_freq)),
                            key="fusion_edit_rebalancing_frequency_selector",
                            help="How often the fusion portfolio rebalances between its constituent portfolios. This is independent of individual portfolio rebalancing frequencies."
                        )
                        
                        # Update session state
                        st.session_state["fusion_edit_rebalancing_frequency"] = fusion_rebalancing_frequency
                        
                        # Generate updated fusion name based on current allocations
                        updated_fusion_name = generate_fusion_name(allocations, fusion_rebalancing_frequency)
                        
                        # Fusion name input for editing
                        st.markdown("**Fusion Name**")
                        current_fusion_name = fusion_portfolio['name']
                        new_fusion_name = st.text_input(
                            "Fusion Name",
                            value=updated_fusion_name,  # Auto-update based on allocations
                            key=f"edit_fusion_name_{fusion_name}",
                            help="Fusion name auto-updates based on allocations. You can modify it if needed."
                        )
                        
                        # Information about independent rebalancing
                        st.info(f"""
                        **Independent Rebalancing System:**
                        - Individual portfolios keep their own rebalancing frequencies
                        - Fusion portfolio rebalances between portfolios at **{fusion_rebalancing_frequency}**
                        - This allows maximum flexibility for different strategies
                        - **Fusion frequency is completely independent** of individual portfolio frequencies
                        """)
                        
                        # Update button
                        if st.button("üíæ Update Fusion", type="primary"):
                            # Update the fusion portfolio name if changed
                            if new_fusion_name and new_fusion_name != current_fusion_name:
                                fusion_portfolio['name'] = new_fusion_name
                                updated_name = new_fusion_name
                            else:
                                updated_name = current_fusion_name
                            
                            # Update the fusion portfolio
                            fusion_portfolio['fusion_portfolio']['selected_portfolios'] = selected_portfolios
                            fusion_portfolio['fusion_portfolio']['allocations'] = {
                                name: alloc/100.0 for name, alloc in allocations.items()
                            }
                            # Update fusion frequency to maintain independence
                            fusion_portfolio['rebalancing_frequency'] = fusion_rebalancing_frequency
                            st.success(f"‚úÖ Updated: {updated_name}")
                            st.toast(f"üîÑ Fusion portfolio '{updated_name}' updated successfully!")
                            st.rerun()
                
                elif fusion_action.startswith("Delete:"):
                    # Delete existing fusion portfolio
                    fusion_name = fusion_action.replace("Delete: ", "")
                    fusion_portfolio = next(fp for fp in existing_fusion_portfolios if fp['name'] == fusion_name)
                    
                    st.markdown(f"**Delete: {fusion_name}**")
                    st.markdown("**Current Composition:**")
                    allocations = fusion_portfolio['fusion_portfolio'].get('allocations', {})
                    for name, alloc in allocations.items():
                        st.markdown(f"‚Ä¢ {name}: {alloc*100:.1f}%")
                    
                    if st.button("üóëÔ∏è Delete Fusion", type="primary"):
                        st.session_state.multi_backtest_portfolio_configs.remove(fusion_portfolio)
                        st.success(f"‚úÖ Deleted: {fusion_name}")
                        st.toast(f"üóëÔ∏è Fusion portfolio '{fusion_name}' deleted successfully!")
                        st.rerun()
            else:
                st.info("Create at least 2 regular portfolios to use fusion feature")

# Start with option
st.sidebar.markdown("---")
st.sidebar.subheader("Data Options")
if "multi_backtest_start_with_radio" not in st.session_state:
    st.session_state["multi_backtest_start_with_radio"] = st.session_state.get("multi_backtest_start_with", "all")
st.sidebar.radio(
    "How to handle assets with different start dates?",
    ["all", "oldest"],
    format_func=lambda x: "Start when ALL assets are available" if x == "all" else "Start with OLDEST asset",
    help="""
    **All:** Wait until all selected assets have data before starting the backtest. Ensures complete portfolio from day 1.
    **Oldest:** Start immediately with the oldest available asset, then add other assets as their data becomes available. May have incomplete portfolio initially, but allocation is still normalized to 100%.
    """,
    key="multi_backtest_start_with_radio",
    on_change=update_start_with
)

# First rebalance strategy option
if "multi_backtest_first_rebalance_strategy_radio" not in st.session_state:
    st.session_state["multi_backtest_first_rebalance_strategy_radio"] = st.session_state.get("multi_backtest_first_rebalance_strategy", "momentum_window_complete")
st.sidebar.radio(
    "When should the first rebalancing occur?",
    ["rebalancing_date", "momentum_window_complete"],
    format_func=lambda x: "First rebalance on rebalancing date" if x == "rebalancing_date" else "First rebalance when momentum window complete",
    help="""
    **First rebalance on rebalancing date:** Wait for momentum calculation, then rebalance on the next scheduled date (e.g., 1st of month). This may delay the start slightly.
    **First rebalance when momentum window complete:** Rebalance immediately when momentum data is ready, even on irregular dates. This usually produces the quickest start.
    """,
    key="multi_backtest_first_rebalance_strategy_radio",
    on_change=update_first_rebalance_strategy
)

# Date range options
st.sidebar.markdown("---")
st.sidebar.subheader("Date Range Options")

# Initialize session state for custom dates if not exists
if "multi_backtest_use_custom_dates" not in st.session_state:
    st.session_state["multi_backtest_use_custom_dates"] = False

# Initialize date session state if not exists
if "multi_backtest_start_date" not in st.session_state:
    st.session_state["multi_backtest_start_date"] = date(2010, 1, 1)
if "multi_backtest_end_date" not in st.session_state:
    st.session_state["multi_backtest_end_date"] = date.today()

# Sync checkbox state with portfolio configs
if 'multi_backtest_portfolio_configs' in st.session_state and st.session_state.multi_backtest_portfolio_configs:
    active_portfolio = st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]
    portfolio_start = active_portfolio.get('start_date_user')
    portfolio_end = active_portfolio.get('end_date_user')
    
    # If portfolio has custom dates, sync them to session state and enable checkbox
    if portfolio_start is not None or portfolio_end is not None:
        if portfolio_start is not None:
            st.session_state["multi_backtest_start_date"] = portfolio_start
        if portfolio_end is not None:
            st.session_state["multi_backtest_end_date"] = portfolio_end
        st.session_state["multi_backtest_use_custom_dates"] = True

use_custom_dates = st.sidebar.checkbox("Use custom date range", key="multi_backtest_use_custom_dates", help="Enable to set custom start and end dates for ALL portfolios in the backtest", on_change=update_custom_dates_checkbox)

if use_custom_dates:
    col_start_date, col_end_date, col_clear_dates = st.sidebar.columns([1, 1, 1])
    with col_start_date:
        start_date = st.date_input("Start Date", min_value=date(1900, 1, 1), key="multi_backtest_start_date", on_change=update_start_date)
    
    with col_end_date:
        end_date = st.date_input("End Date", min_value=date(1900, 1, 1), key="multi_backtest_end_date", on_change=update_end_date)
    
    with col_clear_dates:
        st.markdown("<br>", unsafe_allow_html=True) # Spacer for alignment
        st.button("Clear Dates", on_click=clear_dates_callback)
else:
    st.session_state["multi_backtest_start_date"] = None
    st.session_state["multi_backtest_end_date"] = None
    # Clear dates from ALL portfolios when custom dates is disabled
    for i, portfolio in enumerate(st.session_state.multi_backtest_portfolio_configs):
        st.session_state.multi_backtest_portfolio_configs[i]['start_date_user'] = None
        st.session_state.multi_backtest_portfolio_configs[i]['end_date_user'] = None

st.header(f"Editing Portfolio: {active_portfolio['name']}")

# Check if this is a fusion portfolio and show info message
is_fusion_portfolio = active_portfolio.get('fusion_portfolio', {}).get('enabled', False)
if is_fusion_portfolio:
    st.info("""
    **üîß Fusion Portfolio Configuration:**
    
    **‚úÖ You can modify:**
    - **Rebalancing Frequency** (controls fusion rebalancing between portfolios) - **INDEPENDENT from individual portfolio frequencies**
    - Initial Value ($) - *Affects CAGR/MWRR calculations only, should match individual portfolios*
    - Added Amount ($) - *Affects CAGR/MWRR calculations only, should match individual portfolios*
    - Added Frequency - *Affects CAGR/MWRR calculations only, should match individual portfolios*
    
    **‚ùå Do NOT modify:**
    - Momentum settings (will crash)
    - Add/Remove tickers (will crash)
    - Other advanced settings below
    
    **üéØ Independence:** The fusion portfolio's rebalancing frequency is completely independent of individual portfolio frequencies. When you have momentum portfolios, they will NOT override the fusion frequency.
    
    **üìä Note:** Initial Value, Added Amount, and Added Frequency don't affect the backtest logic but do affect CAGR/MWRR calculations. For accurate comparisons, use the same values as the individual portfolios in the fusion.
    """)

# All portfolios now use the same interface

# Ensure session-state key exists before creating widgets to avoid duplicate-default warnings
if "multi_backtest_active_name" not in st.session_state:
    st.session_state["multi_backtest_active_name"] = active_portfolio['name']
active_portfolio['name'] = st.text_input("Portfolio Name", key="multi_backtest_active_name", on_change=update_name)

# Portfolio Variant Generator - Multi-Select with Custom Options
st.markdown("---")  # Add separator

# NUCLEAR APPROACH: Portfolio-specific expander with forced refresh
portfolio_index = st.session_state.multi_backtest_active_portfolio_index

# Store expander state in portfolio config  
if 'variant_expander_expanded' not in active_portfolio:
    active_portfolio['variant_expander_expanded'] = False

# NUCLEAR: Force expander to refresh by clearing its widget state when portfolio changes
last_portfolio_key = "multi_backtest_last_portfolio_for_variants"
if st.session_state.get(last_portfolio_key) != portfolio_index:
    # Portfolio changed - clear all variant-related widget states
    keys_to_clear = [k for k in st.session_state.keys() if 'variant' in k.lower() and 'multi' in k]
    for key in keys_to_clear:
        if key != last_portfolio_key:  # Don't clear the tracker itself
            del st.session_state[key]
    st.session_state[last_portfolio_key] = portfolio_index

# Use the beautiful expander with portfolio state
current_state = active_portfolio.get('variant_expander_expanded', False)

# NUCLEAR: Use a unique key that includes portfolio info to force recreation
unique_expander_key = f"variants_exp_p{portfolio_index}_v{hash(str(active_portfolio.get('name', '')))}"

with st.expander("üîß Generate Portfolio Variants", expanded=current_state):
    # Show current pin status and provide pin/unpin controls
    col_status, col_pin, col_unpin = st.columns([2, 1, 1])
    
    with col_status:
        if current_state:
            st.info("üìå **Status: EXPANDED & PINNED** for this portfolio")
        else:
            st.info("üìå **Status: COLLAPSED** for this portfolio")
    
    with col_pin:
        if not current_state:
            if st.button("üìå Pin Expanded", key=f"pin_expanded_{portfolio_index}", type="primary"):
                active_portfolio['variant_expander_expanded'] = True
                st.success("‚úÖ Expander state PINNED for this portfolio!")
                st.rerun()
    
    with col_unpin:
        if current_state:
            if st.button("üîì Unpin", key=f"unpin_expanded_{portfolio_index}", type="secondary"):
                active_portfolio['variant_expander_expanded'] = False
                st.success("üîì Expander state UNPINNED for this portfolio!")
                st.rerun()

    st.markdown("**Select parameters to vary and customize their values:**")
    
    # Add explanatory text about how it works and naming
    st.info("""
    **üìö How Portfolio Variants Work:**
    
    This tool generates multiple portfolio variants by combining your selected options. Each variant will be a complete copy of your current portfolio with the specified changes.
    
    **üè∑Ô∏è Portfolio Naming Convention:**
    - **Format**: `Portfolio Name (Rebalancing Frequency - Momentum Strategy : When momentum not all negative and When momentum all negative - Include Beta in weighting - Include Volatility in weighting)`
    - **Examples**:
      - `My Portfolio (Quarterly - Momentum : Classic and Cash - Beta - Volatility)`
      - `My Portfolio (Monthly - Momentum : Relative and Equal Weight - Beta)`
      - `My Portfolio (Quarterly - No Momentum)`
    
    **üí° Tips**: 
    - Select at least one rebalancing frequency
    - If "Use Momentum" is unchecked, momentum options are hidden
    - Beta and Volatility only appear when enabled
    """)

    # Add checkbox to keep current portfolio
    keep_current_portfolio = st.checkbox(
        "‚úÖ Keep Current Portfolio", 
        value=True, 
        key="strategy_comparison_keep_current_portfolio",
        help="When checked, the current portfolio (including benchmark) will be kept. When unchecked, only the generated variants will be created."
    )
    
    # Add explanatory note about what happens when unchecked
    if not keep_current_portfolio:
        st.info("‚ö†Ô∏è **Note:** When unchecked, the current portfolio will be **removed** after generating variants. Only the variants will remain in your portfolio list.")
    
    st.markdown("---")  # Add separator before variant parameters

    variant_params = {}
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Rebalance Frequency (section title - not a checkbox!)
        st.markdown("**Rebalance Frequency:**")
        rebalance_options = []
        if st.checkbox("Never", key="strategy_rebalance_never"):
            rebalance_options.append("Never")
        if st.checkbox("Buy & Hold", key="strategy_rebalance_buyhold"):
            rebalance_options.append("Buy & Hold")
        if st.checkbox("Buy & Hold (Target)", key="strategy_rebalance_buyhold_target"):
            rebalance_options.append("Buy & Hold (Target)")
        if st.checkbox("Weekly", key="strategy_rebalance_weekly"):
            rebalance_options.append("Weekly")
        if st.checkbox("Biweekly", key="strategy_rebalance_biweekly"):
            rebalance_options.append("Biweekly")
        if st.checkbox("Monthly", value=True, key="strategy_rebalance_monthly"):
            rebalance_options.append("Monthly")
        if st.checkbox("Quarterly", key="strategy_rebalance_quarterly"):
            rebalance_options.append("Quarterly")
        if st.checkbox("Semiannually", key="strategy_rebalance_semiannually"):
            rebalance_options.append("Semiannually")
        if st.checkbox("Annually", key="strategy_rebalance_annually"):
            rebalance_options.append("Annually")
        
        # Validation: At least one rebalance frequency must be selected
        if rebalance_options:
            variant_params["rebalance_frequency"] = rebalance_options
        else:
            st.error("‚ö†Ô∏è **At least one Rebalance Frequency must be selected!**")
    
    with col2:
        # Use Momentum (simple checkbox - just enables momentum options, doesn't create variants)
        # Reset checkbox to default if it doesn't exist in session state (fresh portfolio selection)
        if "strategy_use_momentum_vary" not in st.session_state:
            st.session_state["strategy_use_momentum_vary"] = True
        use_momentum_vary = st.checkbox("Use Momentum", key="strategy_use_momentum_vary")
    
    # Show momentum options ONLY if user checked "Use Momentum" 
    # (regardless of current portfolio's momentum status)
    if use_momentum_vary:
        st.markdown("---")
        col_mom_left, col_mom_right = st.columns(2)
        
        with col_mom_left:
            # Momentum Strategy Section
            st.markdown("**Momentum strategy when NOT all negative:**")
            momentum_options = []
            if st.checkbox("Classic momentum", value=True, key="strategy_momentum_classic"):
                momentum_options.append("Classic")
            if st.checkbox("Relative momentum", key="strategy_momentum_relative"):
                momentum_options.append("Relative Momentum")
            if st.checkbox("Near-Zero Symmetry", key="strategy_momentum_nzs"):
                momentum_options.append("Near-Zero Symmetry")
            
            # Validation and storage for momentum strategy
            if momentum_options:
                variant_params["momentum_strategy"] = momentum_options
            else:
                st.error("‚ö†Ô∏è **At least one momentum strategy must be selected!**")
            
            st.markdown("---")
            
            # Negative Strategy Section  
            st.markdown("**Strategy when ALL momentum scores are negative:**")
            negative_options = []
            if st.checkbox("Cash", value=True, key="strategy_negative_cash"):
                negative_options.append("Cash")
            if st.checkbox("Equal weight", key="strategy_negative_equal"):
                negative_options.append("Equal weight")
            if st.checkbox("Relative momentum", key="strategy_negative_relative"):
                negative_options.append("Relative momentum")
            if st.checkbox("Near-Zero Symmetry", key="strategy_negative_nzs"):
                negative_options.append("Near-Zero Symmetry")
            
            # Validation and storage for negative strategy
            if negative_options:
                variant_params["negative_strategy"] = negative_options
            else:
                st.error("‚ö†Ô∏è **At least one negative strategy must be selected!**")
        
        with col_mom_right:
            # Beta in momentum weighting (section title - not a checkbox!)
            st.markdown("**Include Beta in momentum weighting:**")
            beta_options = []
            if st.checkbox("With Beta", value=True, key="strategy_beta_yes"):
                beta_options.append(True)
            if st.checkbox("Without Beta", key="strategy_beta_no"):
                beta_options.append(False)
            
            # Validation: At least one beta option must be selected
            if beta_options:
                variant_params["include_beta"] = beta_options
            else:
                st.error("‚ö†Ô∏è **At least one Beta option must be selected!**")
            
            st.markdown("---")
            
            # Volatility in momentum weighting (section title - not a checkbox!)
            st.markdown("**Include Volatility in momentum weighting:**")
            vol_options = []
            if st.checkbox("With Volatility", value=True, key="strategy_vol_yes"):
                vol_options.append(True)
            if st.checkbox("Without Volatility", key="strategy_vol_no"):
                vol_options.append(False)
            
            # Validation: At least one volatility option must be selected
            if vol_options:
                variant_params["include_volatility"] = vol_options
            else:
                st.error("‚ö†Ô∏è **At least one Volatility option must be selected!**")
    else:
        st.info("üí° **Momentum-related options** (Momentum Strategy, Negative Strategy, Beta, Volatility) are only available when momentum is enabled in the current portfolio or when varying 'Use Momentum' to include enabled variants.")
        
        # CLEAN SESSION STATE: When momentum is disabled, clean up all momentum-related session state
        # Clean threshold and max allocation session state
        if f"threshold_filters_{portfolio_index}" in st.session_state:
            del st.session_state[f"threshold_filters_{portfolio_index}"]
        if f"max_allocation_filters_{portfolio_index}" in st.session_state:
            del st.session_state[f"max_allocation_filters_{portfolio_index}"]
        if f"disable_threshold_{portfolio_index}" in st.session_state:
            del st.session_state[f"disable_threshold_{portfolio_index}"]
        if f"enable_threshold_{portfolio_index}" in st.session_state:
            del st.session_state[f"enable_threshold_{portfolio_index}"]
        if f"disable_max_allocation_{portfolio_index}" in st.session_state:
            del st.session_state[f"disable_max_allocation_{portfolio_index}"]
        if f"enable_max_allocation_{portfolio_index}" in st.session_state:
            del st.session_state[f"enable_max_allocation_{portfolio_index}"]
        if f"equal_weight_values_{portfolio_index}" in st.session_state:
            del st.session_state[f"equal_weight_values_{portfolio_index}"]
        if f"disable_equal_weight_{portfolio_index}" in st.session_state:
            del st.session_state[f"disable_equal_weight_{portfolio_index}"]
        if f"enable_equal_weight_{portfolio_index}" in st.session_state:
            del st.session_state[f"enable_equal_weight_{portfolio_index}"]
        
        # Clean momentum strategy session state
        momentum_keys = [
            "multi_momentum_classic", "multi_momentum_relative",
            "multi_negative_cash", "multi_negative_equal", "multi_negative_relative",
            "multi_beta_yes", "multi_beta_no", "multi_vol_yes", "multi_vol_no"
        ]
        for key in momentum_keys:
            if key in st.session_state:
                del st.session_state[key]
    
    # Minimal Threshold Filter Section - COMPLETELY NEW APPROACH
    if use_momentum_vary:
        st.markdown("---")
        st.markdown("**Minimal Threshold Filter:**")
        
        # Initialize threshold values list if not exists
        if f"threshold_values_{portfolio_index}" not in st.session_state:
            st.session_state[f"threshold_values_{portfolio_index}"] = [2.0]
        
        # Checkboxes for both options (can be both selected)
        col1, col2 = st.columns(2)
        
        with col1:
            disabled = st.checkbox(
                "Disable Threshold",
                value=True,
                key=f"thresh_disabled_{portfolio_index}"
            )
        
        with col2:
            enabled = st.checkbox(
                "Enable Threshold",
                key=f"thresh_enabled_{portfolio_index}"
            )
        
        # Build threshold options
        threshold_options = []
        
        if disabled:
            threshold_options.append(None)
        
        if enabled:
            st.markdown("**Threshold Values:**")
            
            # Add button
            if st.button("‚ûï Add", key=f"add_thresh_{portfolio_index}"):
                st.session_state[f"threshold_values_{portfolio_index}"].append(2.0)
                st.rerun()
            
            # Display values with truly unique keys for each value
            values = st.session_state[f"threshold_values_{portfolio_index}"]
            for i in range(len(values)):
                col1, col2 = st.columns([4, 1])
                
                # Create truly unique key using timestamp and index
                unique_id = f"{portfolio_index}_{i}_{id(values)}"
                
                with col1:
                    val = st.number_input(
                        f"Value {i+1}",
                        min_value=0.0,
                        max_value=100.0,
                        value=values[i],
                        step=0.1,
                        key=f"thresh_input_{unique_id}"
                    )
                    # Update the value in the list
                    values[i] = val
                    threshold_options.append(val)
                
                with col2:
                    if len(values) > 1 and st.button("üóëÔ∏è", key=f"del_thresh_{unique_id}"):
                        # Remove the specific index
                        st.session_state[f"threshold_values_{portfolio_index}"] = values[:i] + values[i+1:]
                        st.rerun()
        
        # Add to variant params
        if threshold_options:
            variant_params["minimal_threshold"] = threshold_options
    else:
        variant_params["minimal_threshold"] = [None]
        
        # CLEAN SESSION STATE: When momentum is disabled, clean up threshold session state
        if f"threshold_filters_{portfolio_index}" in st.session_state:
            del st.session_state[f"threshold_filters_{portfolio_index}"]
        if f"disable_threshold_{portfolio_index}" in st.session_state:
            del st.session_state[f"disable_threshold_{portfolio_index}"]
        if f"enable_threshold_{portfolio_index}" in st.session_state:
            del st.session_state[f"enable_threshold_{portfolio_index}"]
    
    # Maximum Allocation Filter Section - COMPLETELY NEW APPROACH
    if use_momentum_vary:
        st.markdown("---")
        st.markdown("**Maximum Allocation Filter:**")
        
        # Initialize max allocation values list if not exists
        if f"max_allocation_values_{portfolio_index}" not in st.session_state:
            st.session_state[f"max_allocation_values_{portfolio_index}"] = [10.0]
        
        # Checkboxes for both options (can be both selected)
        col1, col2 = st.columns(2)
        
        with col1:
            disabled = st.checkbox(
                "Disable Max Allocation",
                value=True,
                key=f"max_disabled_{portfolio_index}"
            )
        
        with col2:
            enabled = st.checkbox(
                "Enable Max Allocation",
                key=f"max_enabled_{portfolio_index}"
            )
        
        # Build max allocation options
        max_allocation_options = []
        
        if disabled:
            max_allocation_options.append(None)
        
        if enabled:
            st.markdown("**Max Allocation Values:**")
            
            # Add button
            if st.button("‚ûï Add", key=f"add_max_{portfolio_index}"):
                st.session_state[f"max_allocation_values_{portfolio_index}"].append(10.0)
                st.rerun()
            
            # Display values with truly unique keys for each value
            values = st.session_state[f"max_allocation_values_{portfolio_index}"]
            for i in range(len(values)):
                col1, col2 = st.columns([4, 1])
                
                # Create truly unique key using timestamp and index
                unique_id = f"{portfolio_index}_{i}_{id(values)}"
                
                with col1:
                    val = st.number_input(
                        f"Value {i+1}",
                        min_value=0.1,
                        max_value=100.0,
                        value=values[i],
                        step=0.1,
                        key=f"max_input_{unique_id}"
                    )
                    # Update the value in the list
                    values[i] = val
                    max_allocation_options.append(val)
                
                with col2:
                    if len(values) > 1 and st.button("üóëÔ∏è", key=f"del_max_{unique_id}"):
                        # Remove the specific index
                        st.session_state[f"max_allocation_values_{portfolio_index}"] = values[:i] + values[i+1:]
                        st.rerun()
        
        # Add to variant params
        if max_allocation_options:
            variant_params["max_allocation"] = max_allocation_options
    else:
        variant_params["max_allocation"] = [None]
        
        # CLEAN SESSION STATE: When momentum is disabled, clean up max allocation session state
        if f"max_allocation_filters_{portfolio_index}" in st.session_state:
            del st.session_state[f"max_allocation_filters_{portfolio_index}"]
        if f"disable_max_allocation_{portfolio_index}" in st.session_state:
            del st.session_state[f"disable_max_allocation_{portfolio_index}"]
        if f"enable_max_allocation_{portfolio_index}" in st.session_state:
            del st.session_state[f"enable_max_allocation_{portfolio_index}"]
    
    # Equal Weight Filter Section - SAME PATTERN AS MAX ALLOCATION
    if use_momentum_vary:
        st.markdown("---")
        st.markdown("**Equal Weight Filter:**")
        
        # Initialize equal weight values list if not exists
        if f"equal_weight_values_{portfolio_index}" not in st.session_state:
            st.session_state[f"equal_weight_values_{portfolio_index}"] = [10]
        
        # Checkboxes for both options (can be both selected)
        col1, col2 = st.columns(2)
        
        with col1:
            disabled = st.checkbox(
                "Disable Equal Weight",
                value=True,
                key=f"equal_disabled_{portfolio_index}"
            )
        
        with col2:
            enabled = st.checkbox(
                "Enable Equal Weight",
                key=f"equal_enabled_{portfolio_index}"
            )
        
        # Build equal weight options
        equal_weight_options = []
        
        if disabled:
            equal_weight_options.append(None)
        
        if enabled:
            st.markdown("**Equal Weight Values (Number of Top Tickers):**")
            
            # Add button
            if st.button("‚ûï Add", key=f"add_equal_{portfolio_index}"):
                st.session_state[f"equal_weight_values_{portfolio_index}"].append(10)
                st.rerun()
            
            # Display values with truly unique keys for each value
            values = st.session_state[f"equal_weight_values_{portfolio_index}"]
            for i in range(len(values)):
                col1, col2 = st.columns([4, 1])
                
                # Create truly unique key using timestamp and index
                unique_id = f"{portfolio_index}_{i}_{id(values)}"
                
                with col1:
                    val = st.number_input(
                        f"Value {i+1}",
                        min_value=1,
                        max_value=100,
                        value=int(values[i]),
                        step=1,
                        key=f"equal_input_{unique_id}"
                    )
                    # Update the value in the list
                    values[i] = val
                    equal_weight_options.append(val)
                
                with col2:
                    if len(values) > 1 and st.button("üóëÔ∏è", key=f"del_equal_{unique_id}"):
                        # Remove the specific index
                        st.session_state[f"equal_weight_values_{portfolio_index}"] = values[:i] + values[i+1:]
                        st.rerun()
        
        # Add to variant params
        if equal_weight_options:
            variant_params["equal_weight"] = equal_weight_options
    else:
        variant_params["equal_weight"] = [None]
        
        # CLEAN SESSION STATE: When momentum is disabled, clean up equal weight session state
        if f"equal_weight_values_{portfolio_index}" in st.session_state:
            del st.session_state[f"equal_weight_values_{portfolio_index}"]
        if f"disable_equal_weight_{portfolio_index}" in st.session_state:
            del st.session_state[f"disable_equal_weight_{portfolio_index}"]
        if f"enable_equal_weight_{portfolio_index}" in st.session_state:
            del st.session_state[f"enable_equal_weight_{portfolio_index}"]

    # Limit to Top N Section - mirrored from Equal Weight
    if use_momentum_vary:
        st.markdown("---")
        st.markdown("**Limit to Top N:**")
        
        # Initialize values list if not exists
        if f"limit_top_values_{portfolio_index}" not in st.session_state:
            st.session_state[f"limit_top_values_{portfolio_index}"] = [10]
        
        # Checkboxes for both options (can be both selected)
        col1, col2 = st.columns(2)
        
        with col1:
            disabled = st.checkbox(
                "Disable Limit to Top N",
                value=True,
                key=f"limit_disabled_{portfolio_index}"
            )
        
        with col2:
            enabled = st.checkbox(
                "Enable Limit to Top N",
                key=f"limit_enabled_{portfolio_index}"
            )
        
        # Build options
        limit_top_options = []
        
        if disabled:
            limit_top_options.append(None)
        
        if enabled:
            st.markdown("**Top N Values (Number of Tickers to Keep):**")
            # Add button
            if st.button("‚ûï Add", key=f"add_limit_top_{portfolio_index}"):
                st.session_state[f"limit_top_values_{portfolio_index}"].append(10)
                st.rerun()
            
            # Display values
            values = st.session_state[f"limit_top_values_{portfolio_index}"]
            for i in range(len(values)):
                col1, col2 = st.columns([4, 1])
                unique_id = f"{portfolio_index}_{i}_{id(values)}"
                with col1:
                    val = st.number_input(
                        f"Value {i+1}",
                        min_value=1,
                        max_value=100,
                        value=int(values[i]),
                        step=1,
                        key=f"limit_top_input_{unique_id}"
                    )
                    values[i] = val
                    limit_top_options.append(val)
                with col2:
                    if len(values) > 1 and st.button("üóëÔ∏è", key=f"del_limit_top_{unique_id}"):
                        st.session_state[f"limit_top_values_{portfolio_index}"] = values[:i] + values[i+1:]
                        st.rerun()
        
        # Add to variant params
        if limit_top_options:
            variant_params["limit_to_top_n"] = limit_top_options
    else:
        variant_params["limit_to_top_n"] = [None]
        # CLEAN SESSION STATE: When momentum is disabled, clean up limit-to-top-N session state
        if f"limit_top_values_{portfolio_index}" in st.session_state:
            del st.session_state[f"limit_top_values_{portfolio_index}"]
        if f"limit_disabled_{portfolio_index}" in st.session_state:
            del st.session_state[f"limit_disabled_{portfolio_index}"]
        if f"limit_enabled_{portfolio_index}" in st.session_state:
            del st.session_state[f"limit_enabled_{portfolio_index}"]
    
    # Momentum Windows Section - Using the exact same code that works
    if use_momentum_vary:
        st.markdown("---")
        st.subheader("Momentum Windows")
        
        # Add button to create new momentum windows configuration
        if st.button("‚ûï Add Momentum Windows Configuration", key=f"add_momentum_config_{portfolio_index}"):
            if f"momentum_windows_configs_{portfolio_index}" not in st.session_state:
                st.session_state[f"momentum_windows_configs_{portfolio_index}"] = []
            st.session_state[f"momentum_windows_configs_{portfolio_index}"].append([
                {"lookback": 365, "exclude": 30, "weight": 0.5},
                {"lookback": 180, "exclude": 30, "weight": 0.3},
                {"lookback": 120, "exclude": 30, "weight": 0.2}
            ])
            st.rerun()

        # Initialize if not exists
        if f"momentum_windows_configs_{portfolio_index}" not in st.session_state:
            st.session_state[f"momentum_windows_configs_{portfolio_index}"] = [
                [
                    {"lookback": 365, "exclude": 30, "weight": 0.5},
                    {"lookback": 180, "exclude": 30, "weight": 0.3},
                    {"lookback": 120, "exclude": 30, "weight": 0.2}
                ]
            ]

        momentum_configs = st.session_state[f"momentum_windows_configs_{portfolio_index}"]
        if not momentum_configs:
            st.info("No momentum windows configured. Click 'Add Window' to create momentum lookback windows.")
        
        # Display each momentum windows configuration
        for config_idx, momentum_windows in enumerate(momentum_configs):
            st.markdown(f"**Configuration {config_idx + 1}:**")
            
            # Individual buttons for this configuration
            col_reset, col_norm, col_addrem = st.columns([0.4, 0.4, 0.2])
            with col_reset:
                if st.button(f"Reset Config {config_idx + 1}", key=f"reset_config_{portfolio_index}_{config_idx}"):
                    momentum_windows.clear()
                    momentum_windows.extend([
                        {"lookback": 365, "exclude": 30, "weight": 0.5},
                        {"lookback": 180, "exclude": 30, "weight": 0.3},
                        {"lookback": 120, "exclude": 30, "weight": 0.2}
                    ])
                    st.rerun()
            with col_norm:
                if st.button(f"Normalize Config {config_idx + 1}", key=f"normalize_config_{portfolio_index}_{config_idx}"):
                    total_weight = sum(w['weight'] for w in momentum_windows)
                    if total_weight > 0:
                        for w in momentum_windows:
                            w['weight'] /= total_weight
                    st.rerun()
            with col_addrem:
                if st.button(f"Add Window", key=f"add_window_{portfolio_index}_{config_idx}"):
                    momentum_windows.append({"lookback": 90, "exclude": 30, "weight": 0.1})
                    st.rerun()
                if st.button(f"Remove Window", key=f"remove_window_{portfolio_index}_{config_idx}"):
                    if momentum_windows:
                        momentum_windows.pop()
                    st.rerun()
            
            # Delete button for this configuration (only if more than 1 config)
            if len(momentum_configs) > 1 and st.button(f"üóëÔ∏è Delete Config {config_idx + 1}", key=f"delete_config_{portfolio_index}_{config_idx}"):
                momentum_configs.pop(config_idx)
                st.rerun()
            
            # Display momentum windows for this configuration
            col_headers = st.columns(3)
            with col_headers[0]:
                st.markdown("**Lookback (days)**")
            with col_headers[1]:
                st.markdown("**Exclude (days)**")
            with col_headers[2]:
                st.markdown("**Weight %**")

            for j in range(len(momentum_windows)):
                with st.container():
                    col_mw1, col_mw2, col_mw3 = st.columns(3)
                    lookback_key = f"momentum_lookback_{portfolio_index}_{config_idx}_{j}"
                    exclude_key = f"momentum_exclude_{portfolio_index}_{config_idx}_{j}"
                    weight_key = f"momentum_weight_{portfolio_index}_{config_idx}_{j}"
                    
                    if lookback_key not in st.session_state:
                        st.session_state[lookback_key] = int(momentum_windows[j]['lookback'])
                    if exclude_key not in st.session_state:
                        st.session_state[exclude_key] = int(momentum_windows[j]['exclude'])
                    if weight_key not in st.session_state:
                        weight = momentum_windows[j]['weight']
                        if isinstance(weight, (int, float)):
                            if weight > 1.0:
                                weight_percentage = min(weight, 100.0)
                            else:
                                weight_percentage = weight * 100.0
                        else:
                            weight_percentage = 10.0
                        st.session_state[weight_key] = int(weight_percentage)
                    
                    with col_mw1:
                        st.number_input(f"Lookback {j+1}", min_value=1, value=st.session_state[lookback_key], key=lookback_key, label_visibility="collapsed")
                        momentum_windows[j]['lookback'] = st.session_state[lookback_key]
                    with col_mw2:
                        st.number_input(f"Exclude {j+1}", min_value=0, value=st.session_state[exclude_key], key=exclude_key, label_visibility="collapsed")
                        momentum_windows[j]['exclude'] = st.session_state[exclude_key]
                    with col_mw3:
                        st.number_input(f"Weight {j+1}", min_value=0, max_value=100, step=1, format="%d", value=st.session_state[weight_key], key=weight_key, label_visibility="collapsed")
                        momentum_windows[j]['weight'] = st.session_state[weight_key] / 100.0
            
            # Custom text input for this momentum configuration
            momentum_custom_text = st.text_input(
                f"Custom Text for Momentum Config {config_idx + 1} (optional)", 
                key=f"momentum_custom_text_{portfolio_index}_{config_idx}",
                placeholder="e.g., MyMomentum, Strategy1, etc.",
                help="This text will be added to the end of portfolio names for this momentum configuration"
            )
            
            st.markdown("---")

        # Collect custom texts for momentum configurations
        momentum_custom_texts = []
        for config_idx in range(len(momentum_configs)):
            custom_text = st.session_state.get(f"momentum_custom_text_{portfolio_index}_{config_idx}", "")
            momentum_custom_texts.append(custom_text)
        
        # Add to variant params
        variant_params["momentum_windows"] = momentum_configs
        variant_params["momentum_custom_texts"] = momentum_custom_texts
        
        # Beta Window Section - Multiple configurations
        st.markdown("---")
        st.subheader("Beta Window")
        
        # Add button to create new beta window configuration
        if st.button("‚ûï Add Beta Configuration", key=f"add_beta_config_{portfolio_index}"):
            if f"beta_window_configs_{portfolio_index}" not in st.session_state:
                st.session_state[f"beta_window_configs_{portfolio_index}"] = []
            st.session_state[f"beta_window_configs_{portfolio_index}"].append({
                "lookback": 365,
                "exclude": 30
            })
            st.rerun()
        
        # Initialize beta window configs if not exists
        if f"beta_window_configs_{portfolio_index}" not in st.session_state:
            st.session_state[f"beta_window_configs_{portfolio_index}"] = [
                {"lookback": 365, "exclude": 30}
            ]
        
        # Display each beta window configuration
        beta_configs = st.session_state[f"beta_window_configs_{portfolio_index}"]
        for config_idx, beta_config in enumerate(beta_configs):
            st.markdown(f"**Beta Configuration {config_idx + 1}:**")
            
            # Individual buttons for this configuration
            col_reset, col_norm, col_addrem = st.columns([0.4, 0.4, 0.2])
            with col_reset:
                if st.button(f"Reset Beta Config {config_idx + 1}", key=f"reset_beta_config_{portfolio_index}_{config_idx}"):
                    beta_config["lookback"] = 365
                    beta_config["exclude"] = 30
                    # Update session state for the number inputs
                    st.session_state[f"beta_lookback_{portfolio_index}_{config_idx}"] = 365
                    st.session_state[f"beta_exclude_{portfolio_index}_{config_idx}"] = 30
                    st.rerun()
            with col_norm:
                pass
            with col_addrem:
                if len(beta_configs) > 1 and st.button(f"üóëÔ∏è Delete Beta Config {config_idx + 1}", key=f"delete_beta_config_{portfolio_index}_{config_idx}"):
                    beta_configs.pop(config_idx)
                    st.rerun()
            
            # Display beta window inputs
            col_headers = st.columns(2)
            with col_headers[0]:
                st.markdown("**Lookback (days)**")
            with col_headers[1]:
                st.markdown("**Exclude (days)**")
            
            col_beta1, col_beta2 = st.columns(2)
            with col_beta1:
                beta_lookback = st.number_input(f"Beta Lookback {config_idx + 1}", min_value=1, value=beta_config["lookback"], key=f"beta_lookback_{portfolio_index}_{config_idx}", label_visibility="collapsed")
                beta_config["lookback"] = beta_lookback
            with col_beta2:
                beta_exclude = st.number_input(f"Beta Exclude {config_idx + 1}", min_value=0, value=beta_config["exclude"], key=f"beta_exclude_{portfolio_index}_{config_idx}", label_visibility="collapsed")
                beta_config["exclude"] = beta_exclude
            
            # Custom text input for this beta configuration
            beta_custom_text = st.text_input(
                f"Custom Text for Beta Config {config_idx + 1} (optional)", 
                key=f"beta_custom_text_{portfolio_index}_{config_idx}",
                placeholder="e.g., MyBeta, Risk1, etc.",
                help="This text will be added to the end of portfolio names for this beta configuration"
            )
            
            st.markdown("---")
        
        # Collect custom texts for beta configurations
        beta_custom_texts = []
        for config_idx in range(len(beta_configs)):
            custom_text = st.session_state.get(f"beta_custom_text_{portfolio_index}_{config_idx}", "")
            beta_custom_texts.append(custom_text)
        
        # Add to variant params ONLY if there are beta configurations
        # Store as tuples (lookback, exclude) to keep them paired together
        if beta_configs:
            variant_params["beta_configs"] = [(config["lookback"], config["exclude"]) for config in beta_configs]
            variant_params["beta_custom_texts"] = beta_custom_texts
        
        # Volatility Window Section - Multiple configurations
        st.markdown("---")
        st.subheader("Volatility Window")
        
        # Add button to create new volatility window configuration
        if st.button("‚ûï Add Volatility Configuration", key=f"add_volatility_config_{portfolio_index}"):
            if f"volatility_window_configs_{portfolio_index}" not in st.session_state:
                st.session_state[f"volatility_window_configs_{portfolio_index}"] = []
            st.session_state[f"volatility_window_configs_{portfolio_index}"].append({
                "lookback": 365,
                "exclude": 30
            })
            st.rerun()
        
        # Initialize volatility window configs if not exists
        if f"volatility_window_configs_{portfolio_index}" not in st.session_state:
            st.session_state[f"volatility_window_configs_{portfolio_index}"] = [
                {"lookback": 365, "exclude": 30}
            ]
        
        # Display each volatility window configuration
        volatility_configs = st.session_state[f"volatility_window_configs_{portfolio_index}"]
        for config_idx, volatility_config in enumerate(volatility_configs):
            st.markdown(f"**Volatility Configuration {config_idx + 1}:**")
            
            # Individual buttons for this configuration
            col_reset, col_norm, col_addrem = st.columns([0.4, 0.4, 0.2])
            with col_reset:
                if st.button(f"Reset Volatility Config {config_idx + 1}", key=f"reset_volatility_config_{portfolio_index}_{config_idx}"):
                    volatility_config["lookback"] = 365
                    volatility_config["exclude"] = 30
                    # Update session state for the number inputs
                    st.session_state[f"vol_lookback_{portfolio_index}_{config_idx}"] = 365
                    st.session_state[f"vol_exclude_{portfolio_index}_{config_idx}"] = 30
                    st.rerun()
            with col_norm:
                pass
            with col_addrem:
                if len(volatility_configs) > 1 and st.button(f"üóëÔ∏è Delete Volatility Config {config_idx + 1}", key=f"delete_volatility_config_{portfolio_index}_{config_idx}"):
                    volatility_configs.pop(config_idx)
                    st.rerun()
            
            # Display volatility window inputs
            col_headers = st.columns(2)
            with col_headers[0]:
                st.markdown("**Lookback (days)**")
            with col_headers[1]:
                st.markdown("**Exclude (days)**")
            
            col_vol1, col_vol2 = st.columns(2)
            with col_vol1:
                vol_lookback = st.number_input(f"Volatility Lookback {config_idx + 1}", min_value=1, value=volatility_config["lookback"], key=f"vol_lookback_{portfolio_index}_{config_idx}", label_visibility="collapsed")
                volatility_config["lookback"] = vol_lookback
            with col_vol2:
                vol_exclude = st.number_input(f"Volatility Exclude {config_idx + 1}", min_value=0, value=volatility_config["exclude"], key=f"vol_exclude_{portfolio_index}_{config_idx}", label_visibility="collapsed")
                volatility_config["exclude"] = vol_exclude
            
            # Custom text input for this volatility configuration
            volatility_custom_text = st.text_input(
                f"Custom Text for Volatility Config {config_idx + 1} (optional)", 
                key=f"volatility_custom_text_{portfolio_index}_{config_idx}",
                placeholder="e.g., MyVol, Vol1, etc.",
                help="This text will be added to the end of portfolio names for this volatility configuration"
            )
            
            st.markdown("---")
        
        # Collect custom texts for volatility configurations
        volatility_custom_texts = []
        for config_idx in range(len(volatility_configs)):
            custom_text = st.session_state.get(f"volatility_custom_text_{portfolio_index}_{config_idx}", "")
            volatility_custom_texts.append(custom_text)
        
        # Add to variant params ONLY if there are volatility configurations
        # Store as tuples (lookback, exclude) to keep them paired together
        if volatility_configs:
            variant_params["volatility_configs"] = [(config["lookback"], config["exclude"]) for config in volatility_configs]
            variant_params["volatility_custom_texts"] = volatility_custom_texts
    
    # MA Filter Section - EXACTLY LIKE MINIMAL THRESHOLD AND MAX ALLOCATION
    st.markdown("---")
    st.markdown("**MA Filter:**")
    
    # Initialize session state for SMA
    if f"sma_values_{portfolio_index}" not in st.session_state:
        st.session_state[f"sma_values_{portfolio_index}"] = [200]
    
    # Initialize session state for EMA
    if f"ema_values_{portfolio_index}" not in st.session_state:
        st.session_state[f"ema_values_{portfolio_index}"] = [200]
    
    # Checkboxes for both options (can be both selected)
    col1, col2, col3 = st.columns(3)
    
    with col1:
        disabled = st.checkbox(
            "Disable MA",
            value=True,
            key=f"ma_disabled_{portfolio_index}"
        )
    
    with col2:
        include_sma = st.checkbox(
            "Include SMA",
            key=f"include_sma_{portfolio_index}"
        )
    
    with col3:
        include_ema = st.checkbox(
            "Include EMA",
            key=f"include_ema_{portfolio_index}"
        )
    
    # Build MA options
    ma_options = []
    
    if disabled:
        ma_options.append(None)
    
    # SMA SECTION
    if include_sma:
        st.markdown("**SMA Values:**")
        
        # Add button
        if st.button("‚ûï Add SMA", key=f"add_sma_{portfolio_index}"):
            st.session_state[f"sma_values_{portfolio_index}"].append(200)
            st.rerun()
        
        # Display values with truly unique keys for each value
        values = st.session_state[f"sma_values_{portfolio_index}"]
        for i in range(len(values)):
            col1, col2 = st.columns([4, 1])
            
            # Create truly unique key using timestamp and index
            unique_id = f"sma_{portfolio_index}_{i}_{id(values)}"
            
            with col1:
                val = st.number_input(
                    f"SMA {i+1}",
                    min_value=10,
                    max_value=500,
                    value=values[i],
                    step=10,
                    key=f"sma_input_{unique_id}"
                )
                # Update the value in the list
                values[i] = val
                ma_options.append(("SMA", val))
            
            with col2:
                if len(values) > 1 and st.button("üóëÔ∏è", key=f"del_sma_{unique_id}"):
                    # Remove the specific index
                    st.session_state[f"sma_values_{portfolio_index}"] = values[:i] + values[i+1:]
                    st.rerun()
    
    # EMA SECTION
    if include_ema:
        st.markdown("**EMA Values:**")
        
        # Add button
        if st.button("‚ûï Add EMA", key=f"add_ema_{portfolio_index}"):
            st.session_state[f"ema_values_{portfolio_index}"].append(200)
            st.rerun()
        
        # Display values with truly unique keys for each value
        values = st.session_state[f"ema_values_{portfolio_index}"]
        for i in range(len(values)):
            col1, col2 = st.columns([4, 1])
            
            # Create truly unique key using timestamp and index
            unique_id = f"ema_{portfolio_index}_{i}_{id(values)}"
            
            with col1:
                val = st.number_input(
                    f"EMA {i+1}",
                    min_value=10,
                    max_value=500,
                    value=values[i],
                    step=10,
                    key=f"ema_input_{unique_id}"
                )
                # Update the value in the list
                values[i] = val
                ma_options.append(("EMA", val))
            
            with col2:
                if len(values) > 1 and st.button("üóëÔ∏è", key=f"del_ema_{unique_id}"):
                    # Remove the specific index
                    st.session_state[f"ema_values_{portfolio_index}"] = values[:i] + values[i+1:]
                    st.rerun()
    
    # MA Multiplier - SIMPLE (moved to main section)
    ma_multiplier_options = [1.48]  # Default value
    
    # MA Cross Rebalancing Section - ONLY show if at least one MA type is enabled
    if include_sma or include_ema:
        st.markdown("**MA Cross Rebalancing:**")
        
        # Initialize session state for MA cross rebalancing
        if f"ma_cross_rebalance_{portfolio_index}" not in st.session_state:
            st.session_state[f"ma_cross_rebalance_{portfolio_index}"] = False
        
        # Initialize session state for tolerance and confirmation days
        if f"ma_tolerance_values_{portfolio_index}" not in st.session_state:
            st.session_state[f"ma_tolerance_values_{portfolio_index}"] = [2.0]
        if f"ma_delay_values_{portfolio_index}" not in st.session_state:
            st.session_state[f"ma_delay_values_{portfolio_index}"] = [3]
        
        # Checkboxes for MA cross rebalancing options
        col1, col2, col3 = st.columns(3)
        
        with col1:
            disable_ma_cross = st.checkbox(
                "Disable MA Cross Rebalancing",
                value=True,
                key=f"ma_cross_disabled_{portfolio_index}"
            )
        
        with col2:
            enable_ma_cross = st.checkbox(
                "Enable MA Cross Rebalancing",
                key=f"ma_cross_enabled_{portfolio_index}"
            )
        
        with col3:
            # Show tolerance and delay options only if MA cross is enabled
            if enable_ma_cross:
                st.markdown("**Anti-Whipsaw Settings:**")
        
        # Build MA cross rebalancing options
        ma_cross_options = []
        
        if disable_ma_cross:
            ma_cross_options.append(False)
        
        if enable_ma_cross:
            ma_cross_options.append(True)
            
            # Tolerance Band Options
            st.markdown("**Tolerance Band Values:**")
            
            # Add button for tolerance
            if st.button("‚ûï Add Tolerance", key=f"add_tolerance_{portfolio_index}"):
                st.session_state[f"ma_tolerance_values_{portfolio_index}"].append(2.0)
                st.rerun()
            
            # Display tolerance values
            tolerance_values = st.session_state[f"ma_tolerance_values_{portfolio_index}"]
            for i in range(len(tolerance_values)):
                col1, col2 = st.columns([4, 1])
                
                unique_id = f"tolerance_{portfolio_index}_{i}_{id(tolerance_values)}"
                
                with col1:
                    val = st.number_input(
                        f"Tolerance {i+1} (%)",
                        min_value=0.0,
                        max_value=10.0,
                        value=tolerance_values[i],
                        step=0.1,
                        key=f"tolerance_input_{unique_id}"
                    )
                    tolerance_values[i] = val
                
                with col2:
                    if len(tolerance_values) > 1 and st.button("üóëÔ∏è", key=f"del_tolerance_{unique_id}"):
                        st.session_state[f"ma_tolerance_values_{portfolio_index}"] = tolerance_values[:i] + tolerance_values[i+1:]
                        st.rerun()
            
            # Confirmation Delay Options
            st.markdown("**Confirmation Delay Values:**")
            
            # Add button for delay
            if st.button("‚ûï Add Delay", key=f"add_delay_{portfolio_index}"):
                st.session_state[f"ma_delay_values_{portfolio_index}"].append(3)
                st.rerun()
            
            # Display delay values
            delay_values = st.session_state[f"ma_delay_values_{portfolio_index}"]
            for i in range(len(delay_values)):
                col1, col2 = st.columns([4, 1])
                
                unique_id = f"delay_{portfolio_index}_{i}_{id(delay_values)}"
                
                with col1:
                    val = st.number_input(
                        f"Delay {i+1} (days)",
                        min_value=0,
                        max_value=10,
                        value=delay_values[i],
                        step=1,
                        key=f"delay_input_{unique_id}"
                    )
                    delay_values[i] = val
                
                with col2:
                    if len(delay_values) > 1 and st.button("üóëÔ∏è", key=f"del_delay_{unique_id}"):
                        st.session_state[f"ma_delay_values_{portfolio_index}"] = delay_values[:i] + delay_values[i+1:]
                        st.rerun()
    else:
        # If no MA types are enabled, set default values and clean session state
        ma_cross_options = [False]
        st.session_state[f"ma_cross_rebalance_{portfolio_index}"] = False
        
        # Clean up MA cross session state when not needed
        if f"ma_tolerance_values_{portfolio_index}" in st.session_state:
            del st.session_state[f"ma_tolerance_values_{portfolio_index}"]
        if f"ma_delay_values_{portfolio_index}" in st.session_state:
            del st.session_state[f"ma_delay_values_{portfolio_index}"]
        if f"ma_cross_disabled_{portfolio_index}" in st.session_state:
            del st.session_state[f"ma_cross_disabled_{portfolio_index}"]
        if f"ma_cross_enabled_{portfolio_index}" in st.session_state:
            del st.session_state[f"ma_cross_enabled_{portfolio_index}"]
    
    # Add to variant params
    if ma_options:
        variant_params["ma_windows"] = ma_options
    else:
        variant_params["ma_windows"] = [None]
    
    # Add MA multiplier to variant params
    if ma_multiplier_options:
        variant_params["ma_multiplier"] = ma_multiplier_options
    else:
        variant_params["ma_multiplier"] = [1.48]
    
    # Add MA cross rebalancing to variant params
    if ma_cross_options:
        variant_params["ma_cross_rebalance"] = ma_cross_options
        if include_sma or include_ema:  # Only add tolerance/delay if MA types are enabled
            if enable_ma_cross:
                variant_params["ma_tolerance_percent"] = st.session_state[f"ma_tolerance_values_{portfolio_index}"]
                variant_params["ma_confirmation_days"] = st.session_state[f"ma_delay_values_{portfolio_index}"]
            else:
                variant_params["ma_tolerance_percent"] = [2.0]
                variant_params["ma_confirmation_days"] = [3]
        else:
            # If no MA types enabled, use default values
            variant_params["ma_tolerance_percent"] = [2.0]
            variant_params["ma_confirmation_days"] = [3]
    else:
        variant_params["ma_cross_rebalance"] = [False]
        variant_params["ma_tolerance_percent"] = [2.0]
        variant_params["ma_confirmation_days"] = [3]
        
        # CLEAN SESSION STATE: When MA cross is disabled, clean up MA cross session state
        if f"ma_tolerance_values_{portfolio_index}" in st.session_state:
            del st.session_state[f"ma_tolerance_values_{portfolio_index}"]
        if f"ma_delay_values_{portfolio_index}" in st.session_state:
            del st.session_state[f"ma_delay_values_{portfolio_index}"]
        if f"ma_cross_disabled_{portfolio_index}" in st.session_state:
            del st.session_state[f"ma_cross_disabled_{portfolio_index}"]
        if f"ma_cross_enabled_{portfolio_index}" in st.session_state:
            del st.session_state[f"ma_cross_enabled_{portfolio_index}"]
        
        # CLEAN SESSION STATE: When MA is disabled, clean up MA session state
        if f"sma_values_{portfolio_index}" in st.session_state:
            del st.session_state[f"sma_values_{portfolio_index}"]
        if f"ema_values_{portfolio_index}" in st.session_state:
            del st.session_state[f"ema_values_{portfolio_index}"]
        if f"ma_disabled_{portfolio_index}" in st.session_state:
            del st.session_state[f"ma_disabled_{portfolio_index}"]
        if f"include_sma_{portfolio_index}" in st.session_state:
            del st.session_state[f"include_sma_{portfolio_index}"]
        if f"include_ema_{portfolio_index}" in st.session_state:
            del st.session_state[f"include_ema_{portfolio_index}"]
    
    # Calculate total variants by multiplying all parameter options
    # This works for ALL parameters, not just momentum/beta/volatility
    total_variants = 1
    for param, values in variant_params.items():
        if isinstance(values, list):
            # Skip custom text parameters (they don't create variants)
            if param not in ['momentum_custom_texts', 'beta_custom_texts', 'volatility_custom_texts']:
                # For momentum_windows, count the number of configurations
                if param == 'momentum_windows':
                    total_variants *= len(values)
                # For other parameters, count the number of options
                else:
                    total_variants *= len(values)
    
    if variant_params:
        st.info(f"üéØ **{total_variants} variants** will be generated")
        
        # Validation: Check for required parameters
        validation_errors = []
        
        # Check if rebalance frequency is missing (always required)
        if "rebalance_frequency" not in variant_params:
            validation_errors.append("‚ö†Ô∏è Select at least one **Rebalance Frequency**")
        
        # If momentum is enabled (user checked "Use Momentum"), we need ALL momentum parameters
        if use_momentum_vary:
            # Check if momentum strategies are missing (they're always required when momentum enabled)
            if "momentum_strategy" not in variant_params:
                validation_errors.append("‚ö†Ô∏è Select at least one **Momentum Strategy** when momentum is enabled")
            
            # Check if negative strategies are missing (they're always required when momentum enabled)
            if "negative_strategy" not in variant_params:
                validation_errors.append("‚ö†Ô∏è Select at least one **Negative Strategy** when momentum is enabled")
            
            # Check if beta options are missing (they're always required when momentum enabled)
            if "include_beta" not in variant_params:
                validation_errors.append("‚ö†Ô∏è Select at least one **Beta option** when momentum is enabled")
            
            # Check if volatility options are missing (they're always required when momentum enabled)
            if "include_volatility" not in variant_params:
                validation_errors.append("‚ö†Ô∏è Select at least one **Volatility option** when momentum is enabled")
        
        # Check if minimal threshold filter is missing (only required when momentum is enabled)
        if use_momentum_vary and "minimal_threshold" not in variant_params:
            validation_errors.append("‚ö†Ô∏è Select at least one **Minimal Threshold Filter** option when momentum is enabled")
        
        # Check if maximum allocation filter is missing (only required when momentum is enabled)
        if use_momentum_vary and "max_allocation" not in variant_params:
            validation_errors.append("‚ö†Ô∏è Select at least one **Maximum Allocation Filter** option when momentum is enabled")
        
        # VALIDATION MA FILTER - Au moins une option coch√©e
        # 1. V√©rifier MA Filter - au moins une option coch√©e
        if not disabled and not include_sma and not include_ema:
            validation_errors.append("‚ùå **MA Filter** : Au moins une option doit √™tre coch√©e (Disable MA, Include SMA, ou Include EMA)")
        
        # 2. V√©rifier SMA/EMA - si Include SMA ou Include EMA est coch√©, au moins une valeur doit √™tre d√©finie
        if include_sma and not st.session_state.get(f"sma_values_{portfolio_index}", []):
            validation_errors.append("‚ùå **SMA Values** : Si Include SMA est coch√©, au moins une valeur SMA doit √™tre d√©finie")
        
        if include_ema and not st.session_state.get(f"ema_values_{portfolio_index}", []):
            validation_errors.append("‚ùå **EMA Values** : Si Include EMA est coch√©, au moins une valeur EMA doit √™tre d√©finie")
        
        # 3. V√©rifier MA Cross Rebalancing - au moins une option coch√©e
        if include_sma or include_ema:
            if not disable_ma_cross and not enable_ma_cross:
                validation_errors.append("‚ùå **MA Cross Rebalancing** : Au moins une option doit √™tre coch√©e (Disable MA Cross ou Enable MA Cross)")
        
        # Show validation errors
        if validation_errors:
            for error in validation_errors:
                st.error(error)
            st.warning("üö´ **Cannot generate variants** - Fix the errors above first")
        else:
            # All validations passed - show generate button
            if st.button(f"‚ú® Generate {total_variants} Portfolio Variants", type="primary"):
                # Define the function locally to avoid import issues
                def generate_portfolio_variants(base_portfolio, variant_params, base_name):
                    """
                    Generate multiple portfolio variants based on ALL parameter combinations.
                    Uses itertools.product to create all combinations of all parameters.
                    """
                    from itertools import product
                    import copy
                    
                    variants = []
                    
                    # Separate custom texts from actual parameters
                    momentum_texts = variant_params.get('momentum_custom_texts', [])
                    beta_texts = variant_params.get('beta_custom_texts', [])
                    volatility_texts = variant_params.get('volatility_custom_texts', [])
                    ma_texts = variant_params.get('ma_custom_texts', [])
                    
                    # Get all possible values for each parameter (excluding custom texts)
                    # For parameters that need index tracking (momentum_windows, beta_window_days, vol_window_days),
                    # store tuples of (index, value) instead of just values
                    param_values = {}
                    param_needs_index = {}  # Track which params need index info
                    
                    for param, values in variant_params.items():
                        # Skip custom text parameters
                        if param not in ['momentum_custom_texts', 'beta_custom_texts', 'volatility_custom_texts', 'ma_custom_texts']:
                            if isinstance(values, list):
                                # For these params, we need to track the index for custom texts
                                if param in ['momentum_windows', 'beta_configs', 'volatility_configs', 'ma_windows']:
                                    # Store as (index, value) tuples
                                    param_values[param] = [(idx, val) for idx, val in enumerate(values)]
                                    param_needs_index[param] = True
                                else:
                                    param_values[param] = values
                                    param_needs_index[param] = False
                            else:
                                param_values[param] = [values]
                                param_needs_index[param] = False
                    
                    # Get the parameter names and their possible values
                    param_names = list(param_values.keys())
                    param_value_lists = [param_values[param] for param in param_names]
                    
                    # Generate all combinations using itertools.product
                    combinations = list(product(*param_value_lists))
                    
                    # Create a variant for each combination
                    for i, combination in enumerate(combinations):
                        # Create a deep copy of the base portfolio
                        variant = copy.deepcopy(base_portfolio)
                        
                        # Track indices for custom texts by looking at which value was selected
                        # from each parameter's list of possible values
                        mom_idx = None
                        beta_idx = None
                        vol_idx = None
                        ma_idx = None
                        
                        # Update the variant with the new parameter values
                        for j, param in enumerate(param_names):
                            raw_value = combination[j]
                            
                            # Extract actual value and index if this param uses tuples
                            if param_needs_index.get(param, False):
                                # This is a (index, value) tuple
                                idx_val, value = raw_value
                                # Store the index for custom text mapping
                                if param == "momentum_windows":
                                    mom_idx = idx_val
                                elif param == "beta_configs":
                                    beta_idx = idx_val
                                elif param == "volatility_configs":
                                    vol_idx = idx_val
                                elif param == "ma_windows":
                                    ma_idx = idx_val
                            else:
                                # Regular value
                                value = raw_value
                            
                            # Map UI parameter names to actual portfolio configuration fields
                            if param == "rebalance_frequency":
                                variant["rebalancing_frequency"] = value
                            elif param == "momentum_strategy":
                                variant["momentum_strategy"] = value
                            elif param == "negative_strategy":
                                variant["negative_momentum_strategy"] = value
                            elif param == "include_beta":
                                variant["calc_beta"] = value
                            elif param == "include_volatility":
                                variant["calc_volatility"] = value
                            elif param == "momentum_windows":
                                if isinstance(value, list):
                                    variant["momentum_windows"] = copy.deepcopy(value)
                            elif param == "beta_configs":
                                # value is a tuple (lookback, exclude)
                                if isinstance(value, tuple) and len(value) == 2:
                                    variant["beta_window_days"] = value[0]
                                    variant["exclude_days_beta"] = value[1]
                            elif param == "volatility_configs":
                                # value is a tuple (lookback, exclude)
                                if isinstance(value, tuple) and len(value) == 2:
                                    variant["vol_window_days"] = value[0]
                                    variant["exclude_days_vol"] = value[1]
                            elif param == "minimal_threshold":
                                if value is not None:
                                    variant["use_minimal_threshold"] = True
                                    variant["minimal_threshold_percent"] = value
                                else:
                                    variant["use_minimal_threshold"] = False
                                    variant["minimal_threshold_percent"] = 4.0
                            elif param == "max_allocation":
                                if value is not None:
                                    variant["use_max_allocation"] = True
                                    variant["max_allocation_percent"] = value
                                else:
                                    variant["use_max_allocation"] = False
                                    variant["max_allocation_percent"] = 20.0
                            elif param == "equal_weight":
                                if value is not None:
                                    variant["use_equal_weight"] = True
                                    variant["equal_weight_n_tickers"] = value
                                else:
                                    variant["use_equal_weight"] = False
                                    variant["equal_weight_n_tickers"] = 10
                            elif param == "limit_to_top_n":
                                if value is not None:
                                    variant["use_limit_to_top_n"] = True
                                    variant["limit_to_top_n_tickers"] = value
                                else:
                                    variant["use_limit_to_top_n"] = False
                                    variant["limit_to_top_n_tickers"] = 10
                            elif param == "ma_type":
                                variant["ma_type"] = value
                            elif param == "ma_windows":
                                # value is a tuple (ma_type, window_value) or None
                                if value is not None and isinstance(value, tuple):
                                    ma_type, window_value = value
                                    variant["ma_type"] = ma_type
                                    variant["sma_window"] = window_value
                                    # Enable MA filter when window is set
                                    variant["use_sma_filter"] = True
                                elif value is None:
                                    variant["use_sma_filter"] = False
                                    variant["sma_window"] = 200
                                    variant["ma_type"] = "SMA"
                            elif param == "ma_cross_rebalance":
                                variant["ma_cross_rebalance"] = value
                            elif param == "ma_tolerance_percent":
                                variant["ma_tolerance_percent"] = value
                            elif param == "ma_confirmation_days":
                                variant["ma_confirmation_days"] = value
                            elif param == "ma_multiplier":
                                variant["ma_multiplier"] = value
                            else:
                                # For any other parameters, use the original name
                                variant[param] = value
                        
                        # Generate name with custom texts BEFORE parentheses
                        # Collect custom texts in order: Momentum, Beta, Volatility, MA
                        custom_texts = []
                        if mom_idx is not None and mom_idx < len(momentum_texts) and momentum_texts[mom_idx].strip():
                            custom_texts.append(f"[{momentum_texts[mom_idx]}]")
                        if beta_idx is not None and beta_idx < len(beta_texts) and beta_texts[beta_idx].strip():
                            custom_texts.append(f"[{beta_texts[beta_idx]}]")
                        if vol_idx is not None and vol_idx < len(volatility_texts) and volatility_texts[vol_idx].strip():
                            custom_texts.append(f"[{volatility_texts[vol_idx]}]")
                        if ma_idx is not None and ma_idx < len(ma_texts) and ma_texts[ma_idx].strip():
                            custom_texts.append(f"[{ma_texts[ma_idx]}]")
                        
                        # Build the name: BASE_NAME [tags]
                        if custom_texts:
                            custom_text_part = "".join(custom_texts)
                            variant['name'] = f"{base_name} {custom_text_part}"
                        else:
                            variant['name'] = base_name
                        
                        variants.append(variant)
                    
                    return variants
                
                import copy
                
                base_portfolio = copy.deepcopy(active_portfolio)
                base_name = base_portfolio['name']
                
                # SMART NUCLEAR: Handle momentum based on "Use Momentum" checkbox
                if use_momentum_vary:
                    base_portfolio['use_momentum'] = True
                    # Only add default momentum windows if base portfolio had none
                    if not base_portfolio.get('momentum_windows'):
                        base_portfolio['momentum_windows'] = [
                            {"lookback": 365, "exclude": 30, "weight": 0.5},
                            {"lookback": 180, "exclude": 30, "weight": 0.3},
                            {"lookback": 120, "exclude": 30, "weight": 0.2},
                        ]
                        base_portfolio['momentum_strategy'] = base_portfolio.get('momentum_strategy', 'Classic')
                        base_portfolio['negative_momentum_strategy'] = base_portfolio.get('negative_momentum_strategy', 'Cash')
                        base_portfolio['calc_beta'] = base_portfolio.get('calc_beta', False)
                        base_portfolio['calc_volatility'] = base_portfolio.get('calc_volatility', True)
                        print("SMART NUCLEAR: Added default momentum settings to base portfolio (had none)")
                    else:
                        print(f"SMART NUCLEAR: Preserved existing momentum windows on base portfolio (had {len(base_portfolio['momentum_windows'])} windows)")
                else:
                    # User unchecked "Use Momentum" - disable momentum for variants
                    base_portfolio['use_momentum'] = False
                    print("SMART NUCLEAR: Disabled momentum for variants (Use Momentum unchecked)")
                
                variants = generate_portfolio_variants(base_portfolio, variant_params, base_name)
                
                # CUSTOM NAMING: Override the generated names with clearer, more readable names
                for variant in variants:
                    # Extract custom tags from the current name (format: "BASE_NAME [tag1][tag2]...")
                    current_name = variant['name']
                    custom_tags = ""
                    if current_name != base_name:
                        # Extract everything after base_name (the custom tags part)
                        custom_tags = current_name[len(base_name):].strip()
                    
                    # Create a much clearer name format
                    clear_name_parts = []
                    
                    # Rebalancing frequency (compact - just the frequency word)
                    if 'rebalancing_frequency' in variant:
                        freq = variant['rebalancing_frequency']
                        clear_name_parts.append(freq)  # Just "Quarterly", "Monthly", etc.
                    
                    # Add dash separator
                    clear_name_parts.append("-")
                    
                    # Momentum status and strategy
                    if variant.get('use_momentum', False):
                        clear_name_parts.append("Momentum :")
                        
                        # Momentum strategy
                        if variant.get('momentum_strategy') == 'Classic':
                            clear_name_parts.append("Classic")
                        elif variant.get('momentum_strategy') == 'Relative Momentum':
                            clear_name_parts.append("Relative")
                        elif variant.get('momentum_strategy') == 'Near-Zero Symmetry':
                            clear_name_parts.append("NZS")
                        
                        # Negative strategy with "and" connector
                        if variant.get('negative_momentum_strategy') == 'Cash':
                            clear_name_parts.append("and Cash")
                        elif variant.get('negative_momentum_strategy') == 'Equal weight':
                            clear_name_parts.append("and Equal Weight")
                        elif variant.get('negative_momentum_strategy') == 'Relative momentum':
                            clear_name_parts.append("and Relative")
                        elif variant.get('negative_momentum_strategy') == 'Near-Zero Symmetry':
                            clear_name_parts.append("and NZS")
                        
                        # Beta and Volatility (only show when True, omit when False)
                        if variant.get('calc_beta', False):
                            clear_name_parts.append("- Beta")
                        if variant.get('calc_volatility', False):
                            clear_name_parts.append("- Volatility")
                    else:
                        clear_name_parts.append("No Momentum")
                        # Stop here - no beta/volatility for non-momentum portfolios
                    
                    # Add threshold information (only show when enabled)
                    if variant.get('use_minimal_threshold', False):
                        threshold_percent = variant.get('minimal_threshold_percent', 4.0)
                        clear_name_parts.append(f"- Min {threshold_percent:.2f}%")
                    
                    # Add max allocation information (only show when enabled)
                    if variant.get('use_max_allocation', False):
                        max_allocation_percent = variant.get('max_allocation_percent', 20.0)
                        clear_name_parts.append(f"- Max {max_allocation_percent:.2f}%")
                    
                    # Add equal weight information (only show when enabled)
                    if variant.get('use_equal_weight', False):
                        equal_weight_n = variant.get('equal_weight_n_tickers', 10)
                        clear_name_parts.append(f"- Equal {equal_weight_n}")
                    # Add limit to top N information (only show when enabled)
                    if variant.get('use_limit_to_top_n', False):
                        top_n = variant.get('limit_to_top_n_tickers', 10)
                        clear_name_parts.append(f"- Tickers {top_n}")
                    
                    # Add MA filter information (only show when enabled)
                    if variant.get('use_sma_filter', False):
                        ma_type = variant.get('ma_type', 'SMA')
                        ma_window = variant.get('sma_window', 200)
                        ma_multiplier = variant.get('ma_multiplier', 1.48)
                        # Only show multiplier if it's different from default
                        if ma_multiplier != 1.48:
                            clear_name_parts.append(f"- {ma_type}{ma_window}x{ma_multiplier:.2f}")
                        else:
                            clear_name_parts.append(f"- {ma_type}{ma_window}")
                    
                    # Add MA Cross Rebalancing information (only show when enabled AND SMA/EMA is active)
                    if variant.get('ma_cross_rebalance', False) and variant.get('use_sma_filter', False):
                        tolerance = variant.get('ma_tolerance_percent', 2.0)
                        days = variant.get('ma_confirmation_days', 3)
                        clear_name_parts.append(f"- Cross Band {tolerance:.0f}% Days {days}")
                    
                    # Create the new clear name WITH custom tags before parentheses
                    # Format: BASE_NAME [tags] (details...)
                    if custom_tags:
                        clear_name = f"{base_name} {custom_tags} ({' '.join(clear_name_parts)})"
                    else:
                        clear_name = f"{base_name} ({' '.join(clear_name_parts)})"
                    variant['name'] = clear_name
                
                # Store the original user choice before any modifications
                original_keep_current = keep_current_portfolio
                
                # Handle current portfolio based on user choice - use exact same logic as Remove Selected Portfolio
                if not keep_current_portfolio:
                    if len(st.session_state.multi_backtest_portfolio_configs) > 1:
                        # Use exact same logic as remove_portfolio_callback
                        st.session_state.multi_backtest_portfolio_configs.pop(portfolio_index)
                        st.session_state.multi_backtest_active_portfolio_index = max(0, st.session_state.multi_backtest_active_portfolio_index - 1)
                        
                        # CRITICAL: Delete the name widget state to force recreation with new portfolio's name
                        if "multi_backtest_active_name" in st.session_state:
                            del st.session_state["multi_backtest_active_name"]
                        
                        # CRITICAL: Force a proper portfolio switch to update all UI widgets
                        # This ensures the portfolio name text box and other widgets show the new portfolio's data
                        st.session_state.multi_backtest_rerun_flag = True
                        
                        st.success("üóëÔ∏è Removed original portfolio - Active portfolio updated")
                    else:
                        # Only one portfolio - can't remove it
                        st.warning("‚ö†Ô∏è Cannot remove the only portfolio. Keeping original portfolio.")
                        keep_current_portfolio = True
                
                # Add variants to portfolio list with unique names
                for variant in variants:
                    # Use central function - automatically ensures unique name
                    add_portfolio_to_configs(variant)
                
                # NUCLEAR OPTION: Force success message display - ALWAYS show the notification
                st.session_state[f"variant_generation_success_{portfolio_index}"] = True
                st.session_state[f"variant_generation_message_{portfolio_index}"] = f"üéâ **Generated {len(variants)} variants** of '{base_name}'!"
                st.session_state[f"variant_generation_info_{portfolio_index}"] = f"üìä Total portfolios: {len(st.session_state.multi_backtest_portfolio_configs)}"
                
                # Also store the detailed message based on user choice
                if original_keep_current:
                    st.session_state[f"success_message_{portfolio_index}"] = f"üéâ **Generated {len(variants)} variants** of '{base_name}'! Original portfolio kept."
                    st.session_state[f"info_message_{portfolio_index}"] = f"üìä Total portfolios: {len(st.session_state.multi_backtest_portfolio_configs)}"
                else:
                    st.session_state[f"success_message_{portfolio_index}"] = f"üéâ **Generated {len(variants)} variants** of '{base_name}'! Original portfolio removed."
                    st.session_state[f"info_message_{portfolio_index}"] = f"üìä Total portfolios: {len(st.session_state.multi_backtest_portfolio_configs)}"
                
                st.rerun()
    
    # NUCLEAR OPTION: Display success messages - FORCE display no matter what
    if f"variant_generation_success_{portfolio_index}" in st.session_state:
        st.success(st.session_state[f"variant_generation_message_{portfolio_index}"])
        st.info(st.session_state[f"variant_generation_info_{portfolio_index}"])
        # Clear the nuclear flags
        del st.session_state[f"variant_generation_success_{portfolio_index}"]
        del st.session_state[f"variant_generation_message_{portfolio_index}"]
        del st.session_state[f"variant_generation_info_{portfolio_index}"]
    
    # Also display the detailed messages if they exist
    if f"success_message_{portfolio_index}" in st.session_state:
        st.success(st.session_state[f"success_message_{portfolio_index}"])
        del st.session_state[f"success_message_{portfolio_index}"]  # Clear after display
    
    if f"info_message_{portfolio_index}" in st.session_state:
        st.info(st.session_state[f"info_message_{portfolio_index}"])
        del st.session_state[f"info_message_{portfolio_index}"]  # Clear after display

col_left, col_right = st.columns([1, 1])
with col_left:
    if "multi_backtest_active_initial" not in st.session_state:
        st.session_state["multi_backtest_active_initial"] = int(active_portfolio['initial_value'])
    st.number_input("Initial Value ($)", min_value=0, step=1000, format="%d", key="multi_backtest_active_initial", on_change=update_initial, help="Starting cash", )
with col_right:
    if "multi_backtest_active_added_amount" not in st.session_state:
        st.session_state["multi_backtest_active_added_amount"] = int(active_portfolio['added_amount'])
    st.number_input("Added Amount ($)", min_value=0, step=1000, format="%d", key="multi_backtest_active_added_amount", on_change=update_added_amount, help="Amount added at each Added Frequency")

# Swap positions: show Rebalancing Frequency first, then Added Frequency.
# Use two equal-width columns and make selectboxes use the container width so they match visually.
col_freq_rebal, col_freq_add = st.columns([1, 1])
freq_options = ["Never", "Buy & Hold", "Buy & Hold (Target)", "Weekly", "Biweekly", "Monthly", "Quarterly", "Semiannually", "Annually"]
with col_freq_rebal:
    if "multi_backtest_active_rebal_freq" not in st.session_state:
        st.session_state["multi_backtest_active_rebal_freq"] = active_portfolio['rebalancing_frequency']
    st.selectbox("Rebalancing Frequency", freq_options, key="multi_backtest_active_rebal_freq", on_change=update_rebal_freq, help="How often the portfolio is rebalanced. 'Buy & Hold' reinvests cash immediately using current proportions. 'Buy & Hold (Target)' reinvests cash immediately using target allocations. Cash from dividends (if 'Collect Dividends as Cash' is enabled) will be available for rebalancing.", )
with col_freq_add:
    if "multi_backtest_active_add_freq" not in st.session_state:
        st.session_state["multi_backtest_active_add_freq"] = active_portfolio['added_frequency']
    st.selectbox("Added Frequency", freq_options, key="multi_backtest_active_add_freq", on_change=update_add_freq, help="How often cash is added to the portfolio. 'Buy & Hold' reinvests cash immediately using current proportions. 'Buy & Hold (Target)' reinvests cash immediately using target allocations.")

# Dividend handling option
st.session_state["multi_backtest_active_collect_dividends_as_cash"] = parse_bool_from_json(active_portfolio.get('collect_dividends_as_cash', False), False)
st.checkbox(
    "Collect Dividends as Cash", 
    key="multi_backtest_active_collect_dividends_as_cash",
    help="When enabled, dividends are collected as cash instead of being automatically reinvested in the stock. This cash will be available for rebalancing.",
    on_change=update_collect_dividends_as_cash
)

with st.expander("Rebalancing and Added Frequency Explained", expanded=False):
    st.markdown("""
    **Added Frequency** is the frequency at which cash is added to the portfolio.
    
    **Rebalancing Frequency** is the frequency at which the portfolio is rebalanced to the specified allocations. It is also at this date that any additional cash from the `Added Frequency` is invested into the portfolio.
    
    **Buy & Hold Options:**
    - **Buy & Hold**: When cash is available (from additions or dividends), it's immediately reinvested using the current portfolio proportions
    - **Buy & Hold (Target)**: When cash is available (from additions or dividends), it's immediately reinvested using the target allocations
    
    **Collect Dividends as Cash**: When enabled, dividends are collected as cash instead of being automatically reinvested. This cash becomes available for rebalancing.
    
    *Keeping a Rebalancing Frequency to "Never" will mean no additional cash is invested, even if you have an `Added Frequency` specified.*
    """)

# Sync buttons
if len(st.session_state.multi_backtest_portfolio_configs) > 1:
    if st.button("Sync ALL Portfolios Cashflow from First Portfolio", on_click=sync_cashflow_from_first_portfolio_callback, use_container_width=True):
        pass
    if st.button("Sync ALL Portfolios Rebalancing Frequency from First Portfolio", on_click=sync_rebalancing_from_first_portfolio_callback, use_container_width=True):
        pass
    
    # Display sync messages locally below the buttons
    if 'multi_backtest_cashflow_sync_message' in st.session_state and st.session_state['multi_backtest_cashflow_sync_message']:
        message = st.session_state['multi_backtest_cashflow_sync_message']
        message_type = st.session_state.get('multi_backtest_cashflow_sync_message_type', 'info')
        
        if message_type == 'success':
            st.success(message)
        elif message_type == 'error':
            st.error(message)
        else:
            st.info(message)
        
        # Clear the message after displaying it
        del st.session_state['multi_backtest_cashflow_sync_message']
        del st.session_state['multi_backtest_cashflow_sync_message_type']
    
    if 'multi_backtest_rebalancing_sync_message' in st.session_state and st.session_state['multi_backtest_rebalancing_sync_message']:
        message = st.session_state['multi_backtest_rebalancing_sync_message']
        message_type = st.session_state.get('multi_backtest_rebalancing_sync_message_type', 'info')
        
        if message_type == 'success':
            st.success(message)
        elif message_type == 'error':
            st.error(message)
        else:
            st.info(message)
        
        # Clear the message after displaying it
        del st.session_state['multi_backtest_rebalancing_sync_message']
        del st.session_state['multi_backtest_rebalancing_sync_message_type']

# Sync exclusion options (only show if there are multiple portfolios and not for the first portfolio)
if len(st.session_state.multi_backtest_portfolio_configs) > 1 and st.session_state.multi_backtest_active_portfolio_index > 0:
    st.markdown("**üîÑ Sync Exclusion Options:**")
    col_sync1, col_sync2 = st.columns(2)
    
    with col_sync1:
        # Initialize sync exclusion settings if not present (but preserve imported values)
        if 'exclude_from_cashflow_sync' not in active_portfolio:
            active_portfolio['exclude_from_cashflow_sync'] = False
        if 'exclude_from_rebalancing_sync' not in active_portfolio:
            active_portfolio['exclude_from_rebalancing_sync'] = False
        
        # Rebalancing sync exclusion - use direct portfolio value to avoid caching issues
        exclude_rebalancing = st.checkbox(
            "Exclude from Rebalancing Sync", 
            value=active_portfolio['exclude_from_rebalancing_sync'],
            key=f"multi_backtest_exclude_rebalancing_sync_{st.session_state.multi_backtest_active_portfolio_index}",
            help="When checked, this portfolio will not be affected by 'Sync ALL Portfolios Rebalancing' button",
            on_change=lambda: update_sync_exclusion('rebalancing')
        )
        
        # Update portfolio config when checkbox changes
        if exclude_rebalancing != active_portfolio['exclude_from_rebalancing_sync']:
            active_portfolio['exclude_from_rebalancing_sync'] = exclude_rebalancing
            # Force immediate update to session state
            st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index] = active_portfolio
            st.session_state.multi_backtest_rerun_flag = True
    
    with col_sync2:
        # Cash flow sync exclusion - use direct portfolio value to avoid caching issues
        exclude_cashflow = st.checkbox(
            "Exclude from Cash Flow Sync", 
            value=active_portfolio['exclude_from_cashflow_sync'],
            key=f"multi_backtest_exclude_cashflow_sync_{st.session_state.multi_backtest_active_portfolio_index}",
            help="When checked, this portfolio will not be affected by 'Sync ALL Portfolios Cashflow' button",
            on_change=lambda: update_sync_exclusion('cashflow')
        )
        
        # Update portfolio config when checkbox changes
        if exclude_cashflow != active_portfolio['exclude_from_cashflow_sync']:
            active_portfolio['exclude_from_cashflow_sync'] = exclude_cashflow
            # Force immediate update to session state
            st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index] = active_portfolio
            st.session_state.multi_backtest_rerun_flag = True

if "multi_backtest_active_benchmark" not in st.session_state:
    st.session_state["multi_backtest_active_benchmark"] = active_portfolio['benchmark_ticker']
st.text_input("Benchmark Ticker (default: ^GSPC, starts 1927-12-30, used for beta calculation. Use SPYSIM for earlier dates, starts 1885-03-01)", key="multi_backtest_active_benchmark", on_change=update_benchmark)

st.subheader("Stocks")
col_stock_buttons = st.columns([0.3, 0.3, 0.3, 0.1])
with col_stock_buttons[0]:
    if st.button("Normalize Tickers %", on_click=normalize_stock_allocations_callback, use_container_width=True):
        pass
with col_stock_buttons[1]:
    if st.button("Equal Allocation %", on_click=equal_stock_allocation_callback, use_container_width=True):
        pass
with col_stock_buttons[2]:
    if st.button("Reset Tickers", on_click=reset_stock_selection_callback, use_container_width=True):
        pass

# Calculate live total ticker allocation
valid_tickers = [s for s in st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['stocks'] if s['ticker']]
total_ticker_allocation = sum(s['allocation'] for s in valid_tickers)

use_mom_flag = st.session_state.get('multi_backtest_active_use_momentum', active_portfolio.get('use_momentum', True))
if use_mom_flag:
    st.info("Ticker allocations are not used directly for Momentum strategies.")
else:
    if abs(total_ticker_allocation - 1.0) > 0.001:
        st.warning(f"Total ticker allocation is {total_ticker_allocation*100:.2f}%, not 100%. Click 'Normalize' to fix.")
    else:
        st.success(f"Total ticker allocation is {total_ticker_allocation*100:.2f}%.")

def update_stock_allocation(index):
    try:
        key = f"multi_backtest_alloc_input_{st.session_state.multi_backtest_active_portfolio_index}_{index}"
        val = st.session_state.get(key, None)
        if val is None:
            return
        st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['stocks'][index]['allocation'] = float(val) / 100.0
    except Exception:
        # Ignore transient errors (e.g., active_portfolio_index changed); UI will reflect state on next render
        return


def update_stock_ticker(index):
    try:
        key = f"multi_backtest_ticker_{st.session_state.multi_backtest_active_portfolio_index}_{index}"
        val = st.session_state.get(key, None)
        if val is None:
            # key not yet initialized (race condition). Skip update; the widget's key will be present on next rerender.
            return
        
        # Convert commas to dots for decimal separators (like case conversion)
        converted_val = val.replace(",", ".")
        
        # Convert the input value to uppercase
        upper_val = converted_val.upper()
        
        # Special conversion for Berkshire Hathaway tickers for Yahoo Finance compatibility
        if upper_val == 'BRK.B':
            upper_val = 'BRK-B'
        elif upper_val == 'BRK.A':
            upper_val = 'BRK-A'

        # CRITICAL: Resolve ticker alias BEFORE storing in portfolio config
        resolved_ticker = resolve_ticker_alias(upper_val)
        
        # Update the portfolio configuration with the resolved ticker (with leverage/expense)
        st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['stocks'][index]['ticker'] = resolved_ticker
        
        # IMPORTANT: Force UI update by setting the widget's session_state value
        # This ensures the resolved ticker is displayed immediately in the text_input
        st.session_state[key] = resolved_ticker
        
        # Auto-disable dividends for negative leverage (inverse ETFs)
        if '?L=-' in resolved_ticker:
            st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['stocks'][index]['include_dividends'] = False
            # Also update the checkbox UI state
            div_key = f"multi_backtest_div_{st.session_state.multi_backtest_active_portfolio_index}_{index}"
            st.session_state[div_key] = False
        
        # Use the EXACT same method as "Special Long-Term Tickers" buttons (line 10001)
        # Set rerun flag instead of calling st.rerun() directly
        st.session_state.multi_backtest_rerun_flag = True
    except Exception:
        # Defensive: if portfolio index or structure changed, skip silently
        return


def update_stock_dividends(index):
    try:
        key = f"multi_backtest_div_{st.session_state.multi_backtest_active_portfolio_index}_{index}"
        val = st.session_state.get(key, None)
        if val is None:
            return
        st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['stocks'][index]['include_dividends'] = bool(val)
    except Exception:
        return

# Update active_portfolio
active_portfolio = st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]

# Initialize MA filter state - SPECIFIC TO EACH PORTFOLIO
ma_filter_key = f"multi_backtest_active_use_sma_filter_{st.session_state.multi_backtest_active_portfolio_index}"
ma_window_key = f"multi_backtest_active_ma_window_{st.session_state.multi_backtest_active_portfolio_index}"
ma_type_key = f"multi_backtest_active_ma_type_{st.session_state.multi_backtest_active_portfolio_index}"
if ma_filter_key not in st.session_state:
    st.session_state[ma_filter_key] = active_portfolio.get('use_sma_filter', False)
if ma_window_key not in st.session_state:
    st.session_state[ma_window_key] = active_portfolio.get('sma_window', 200)
if ma_type_key not in st.session_state:
    st.session_state[ma_type_key] = active_portfolio.get('ma_type', 'SMA')

for i in range(len(active_portfolio['stocks'])):
    stock = active_portfolio['stocks'][i]
    col_t, col_a, col_d, col_sma, col_b = st.columns([0.2, 0.2, 0.25, 0.25, 0.1])
    with col_t:
        ticker_key = f"multi_backtest_ticker_{st.session_state.multi_backtest_active_portfolio_index}_{i}"
        # Always sync the session state with the portfolio config to show resolved ticker
        st.session_state[ticker_key] = stock['ticker']
        st.text_input("Ticker", key=ticker_key, label_visibility="visible", on_change=update_stock_ticker, args=(i,))
    with col_a:
        use_mom = st.session_state.get('multi_backtest_active_use_momentum', active_portfolio.get('use_momentum', True))
        if not use_mom:
            alloc_key = f"multi_backtest_alloc_input_{st.session_state.multi_backtest_active_portfolio_index}_{i}"
            if alloc_key not in st.session_state:
                st.session_state[alloc_key] = int(stock['allocation'] * 100)
            st.number_input("Allocation %", min_value=0, step=1, format="%d", key=alloc_key, label_visibility="visible", on_change=update_stock_allocation, args=(i,))
            if st.session_state[alloc_key] != int(stock['allocation'] * 100):
                st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['stocks'][i]['allocation'] = st.session_state[alloc_key] / 100.0
        else:
            # Show Max Cap % field when momentum is active
            max_cap_key = f"multi_backtest_max_cap_{st.session_state.multi_backtest_active_portfolio_index}_{i}"
            # Ensure max_allocation_percent key exists
            if 'max_allocation_percent' not in stock:
                stock['max_allocation_percent'] = None
            
            if max_cap_key not in st.session_state:
                st.session_state[max_cap_key] = int(stock['max_allocation_percent']) if stock['max_allocation_percent'] is not None else 0
            
            max_cap_value = st.number_input(
                "Max Cap %", 
                min_value=0, 
                max_value=100,
                step=1, 
                format="%d", 
                key=max_cap_key, 
                label_visibility="visible",
                help="Individual cap for this ticker (0 = no cap, uses global cap if enabled). This overrides the Min and Max Threshold filters for this specific ticker."
            )
            
            # Update the portfolio config
            if max_cap_value > 0:
                st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['stocks'][i]['max_allocation_percent'] = float(max_cap_value)
            else:
                st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['stocks'][i]['max_allocation_percent'] = None
    with col_d:
        div_key = f"multi_backtest_div_{st.session_state.multi_backtest_active_portfolio_index}_{i}"
        # Ensure include_dividends key exists with default value
        if 'include_dividends' not in stock:
            stock['include_dividends'] = True
        
        # Auto-disable dividends for negative leverage (inverse ETFs) ONLY on first display
        # Don't override if user has explicitly set a value
        if '?L=-' in stock['ticker'] and div_key not in st.session_state:
            stock['include_dividends'] = False
        
        if div_key not in st.session_state:
            st.session_state[div_key] = stock['include_dividends']
        st.checkbox("Reinvest Dividends", key=div_key)
        if st.session_state[div_key] != stock['include_dividends']:
            st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['stocks'][i]['include_dividends'] = st.session_state[div_key]
    
    with col_sma:
        # SMA Filter selection - EXACT SAME LOGIC AS DIVIDENDS
        ma_filter_key = f"multi_backtest_active_use_sma_filter_{st.session_state.multi_backtest_active_portfolio_index}"
        if st.session_state.get(ma_filter_key, False):
            sma_key = f"multi_backtest_include_sma_{st.session_state.multi_backtest_active_portfolio_index}_{i}"
            # Ensure include_in_sma_filter key exists with default value
            if 'include_in_sma_filter' not in stock:
                stock['include_in_sma_filter'] = True
            
            if sma_key not in st.session_state:
                st.session_state[sma_key] = stock['include_in_sma_filter']
            st.checkbox("Include in MA Filter", key=sma_key, help="Uncheck to exclude this ticker from the Moving Average filter")
            if st.session_state[sma_key] != stock['include_in_sma_filter']:
                st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['stocks'][i]['include_in_sma_filter'] = st.session_state[sma_key]
            
            # MA Reference Ticker - allows using another ticker's MA for filtering
            ma_ref_key = f"multi_backtest_ma_reference_{st.session_state.multi_backtest_active_portfolio_index}_{i}"
            if 'ma_reference_ticker' not in stock:
                stock['ma_reference_ticker'] = ""  # Empty = use own ticker
            
            # Always sync the session state with the portfolio config to show resolved ticker
            st.session_state[ma_ref_key] = stock.get('ma_reference_ticker', '')
            
            st.text_input(
                "MA Reference Ticker",
                key=ma_ref_key,
                placeholder=f"Leave empty for {stock['ticker']}",
                help=f"Optional: Use another ticker's MA (e.g., SPY for SSO, QQQ for TQQQ). Leave empty to use {stock['ticker']}'s own MA.",
                label_visibility="visible",
                on_change=update_ma_reference_ticker,
                args=(i,)
            )
            
        else:
            st.write("")
        
    with col_b:
        st.write("")
        if st.button("Remove", key=f"multi_backtest_rem_stock_{st.session_state.multi_backtest_active_portfolio_index}_{i}", on_click=remove_stock_callback, args=(i,)):
            pass

if st.button("Add Ticker", on_click=add_stock_callback):
    pass

# Bulk Leverage Controls
with st.expander("üîß Bulk Leverage Controls", expanded=False):
    def apply_bulk_leverage_callback():
        """Apply leverage and expense ratio to selected tickers in the current portfolio"""
        try:
            portfolio_index = st.session_state.multi_backtest_active_portfolio_index
            portfolio = st.session_state.multi_backtest_portfolio_configs[portfolio_index]
            
            leverage_value = st.session_state.get('bulk_leverage_value', 1.0)
            expense_ratio_value = st.session_state.get('bulk_expense_ratio_value', 1.0)
            selected_tickers = st.session_state.get('bulk_selected_tickers', [])
            
            # Check if any tickers are selected
            if not selected_tickers:
                st.toast("‚ö†Ô∏è Please select at least one ticker to apply leverage to.")
                return
            
            applied_count = 0
            for i, stock in enumerate(portfolio['stocks']):
                current_ticker = stock['ticker']
                
                # Check if this ticker should be modified
                base_ticker, _, _ = parse_ticker_parameters(current_ticker)
                if base_ticker in selected_tickers or current_ticker in selected_tickers:
                    # Create new ticker with leverage and expense ratio
                    new_ticker = base_ticker
                    if leverage_value != 1.0:
                        new_ticker += f"?L={leverage_value}"
                    if expense_ratio_value != 0.0:
                        new_ticker += f"?E={expense_ratio_value}"
                    
                    # Update the ticker in the portfolio
                    st.session_state.multi_backtest_portfolio_configs[portfolio_index]['stocks'][i]['ticker'] = new_ticker
                
                    # Update the session state for the text input
                    ticker_key = f"multi_backtest_ticker_{portfolio_index}_{i}"
                    st.session_state[ticker_key] = new_ticker
                    
                    # If leverage is negative (short position), uncheck dividends checkbox
                    # User can manually re-check it if desired
                    if leverage_value < 0:
                        st.session_state.multi_backtest_portfolio_configs[portfolio_index]['stocks'][i]['include_dividends'] = False
                        div_key = f"multi_backtest_div_{portfolio_index}_{i}"
                        st.session_state[div_key] = False
                    
                    applied_count += 1
            
            if applied_count > 0:
                st.toast(f"‚úÖ Applied {leverage_value}x leverage and {expense_ratio_value}% expense ratio to {applied_count} ticker(s)!")
            else:
                st.warning("‚ö†Ô∏è No tickers were selected for modification.")
            
        except Exception as e:
            st.error(f"Error applying bulk leverage: {str(e)}")

    def remove_bulk_leverage_callback():
        """Remove all leverage and expense ratio from selected tickers"""
        try:
            portfolio_index = st.session_state.multi_backtest_active_portfolio_index
            portfolio = st.session_state.multi_backtest_portfolio_configs[portfolio_index]
            selected_tickers = st.session_state.get('bulk_selected_tickers', [])
            
            # Check if any tickers are selected
            if not selected_tickers:
                st.toast("‚ö†Ô∏è Please select at least one ticker to remove leverage from.")
                return
            
            removed_count = 0
            for i, stock in enumerate(portfolio['stocks']):
                current_ticker = stock['ticker']
                
                # Check if this ticker should be modified
                base_ticker, _, _ = parse_ticker_parameters(current_ticker)
                if base_ticker in selected_tickers or current_ticker in selected_tickers:
                    # Update the ticker to base ticker (no leverage, no expense ratio)
                    st.session_state.multi_backtest_portfolio_configs[portfolio_index]['stocks'][i]['ticker'] = base_ticker
                    
                    # Update the session state for the text input
                    ticker_key = f"multi_backtest_ticker_{portfolio_index}_{i}"
                    st.session_state[ticker_key] = base_ticker
                    
                    removed_count += 1
            
            if removed_count > 0:
                st.toast(f"‚úÖ Removed leverage and expense ratio from {removed_count} ticker(s)!")
            else:
                st.warning("‚ö†Ô∏è No tickers were selected for modification.")
            
        except Exception as e:
            st.error(f"Error removing leverage: {str(e)}")

    # Get current portfolio tickers for selection
    portfolio_index = st.session_state.multi_backtest_active_portfolio_index
    portfolio = st.session_state.multi_backtest_portfolio_configs[portfolio_index]
    available_tickers = [stock['ticker'] for stock in portfolio['stocks']]
    
    # Initialize selected tickers if not exists
    if 'bulk_selected_tickers' not in st.session_state:
        st.session_state.bulk_selected_tickers = []
    
    # Ticker selection interface
    st.markdown("**Select Tickers to Modify:**")
    
    # Quick selection buttons
    col_quick1, col_quick2 = st.columns([1, 1])
    
    with col_quick1:
        if st.button("Select All", key="page1_select_all_tickers"):
            st.session_state.bulk_selected_tickers = available_tickers.copy()
            st.rerun()
    
    with col_quick2:
        if st.button("Clear Selection", key="page1_clear_all_tickers"):
            st.session_state.bulk_selected_tickers = []
            st.rerun()
    
    # Individual ticker selection
    if available_tickers:
        st.markdown("**Individual Ticker Selection:**")
        
        # Create checkboxes for each ticker
        for i, ticker in enumerate(available_tickers):
            base_ticker, leverage, expense = parse_ticker_parameters(ticker)
            display_text = f"{base_ticker}" if base_ticker else f"{ticker}"
            if leverage != 1.0 or expense > 0.0:
                display_text += f" (L:{leverage}x, E:{expense}%)"
            
            # Ensure display_text is never empty (accessibility requirement)
            if not display_text or display_text.strip() == "":
                display_text = f"Ticker {i+1}"
            
            # Use checkbox state directly
            checkbox_key = f"page1_bulk_ticker_select_{i}"
            is_checked = st.checkbox(
                display_text, 
                value=ticker in st.session_state.bulk_selected_tickers,
                key=checkbox_key
            )
            
            # Update selection based on checkbox state
            if is_checked and ticker not in st.session_state.bulk_selected_tickers:
                st.session_state.bulk_selected_tickers.append(ticker)
            elif not is_checked and ticker in st.session_state.bulk_selected_tickers:
                st.session_state.bulk_selected_tickers.remove(ticker)
    else:
        st.info("No tickers available in the current portfolio.")
    
    # Show selected tickers count
    selected_count = len(st.session_state.bulk_selected_tickers)
    if selected_count > 0:
        st.success(f"üìä {selected_count} ticker(s) selected for bulk operations")
    else:
        st.warning("‚ö†Ô∏è No tickers selected - please select tickers before applying bulk operations")

    # Bulk leverage controls
    st.markdown("---")
    st.markdown("**Leverage & Expense Ratio Settings:**")
    
    col1, col2, col3, col4 = st.columns([1, 1, 1, 1])

    with col1:
        st.number_input(
            "Leverage",
            value=2.0,
            step=0.1,
            format="%.1f",
            key="bulk_leverage_value",
            help="Leverage multiplier (e.g., 2.0 for 2x leverage, -3.0 for -3x inverse)"
        )

    with col2:
        st.number_input(
            "Expense Ratio (%)",
            value=1.0,
            step=0.01,
            format="%.2f",
            key="bulk_expense_ratio_value",
            help="Annual expense ratio in percentage (e.g., 0.84 for 0.84%, can be negative)"
        )

    with col3:
        if st.button("Apply to Selected", on_click=apply_bulk_leverage_callback, type="primary"):
            pass

    with col4:
        if st.button("Remove from Selected", on_click=remove_bulk_leverage_callback, type="secondary"):
            pass

# Special tickers and leverage guide sections
with st.expander("The Power of Sticking to One Strategy", expanded=False):
    st.markdown("""
    ### The Power of Sticking to One Strategy
    In investing, consistency almost always beats constant change. Many investors believe that switching strategies frequently will help them capture small incremental gains, but the data tells a very different story.
    ### The Performance Gap is Real
    A study by DALBAR, Inc. (1985-2015) found that the average equity fund investor earned just 3.66% annually while the S&P 500 returned 11.06% annually. This represents a performance penalty of over 7 percentage points per year.
    Research by Morningstar, Inc. (2013-2022) revealed that investors underperformed by an average of 1.7 percentage points annually due to timing decisions.
    In the study by Terrence Barber and Brad Odean (2000) tracking 66,465 households (1991-1996), the 20% most active traders earned 11.4% annually, while the market returned 17.9%.
    A study by J.P. Morgan Asset Management shows that if an investor in the S&P 500 from July 2004 to July 2024 missed the 10 best days, their annualized return dropped from 10.5% to 6.2%; missing the 20 best days dropped it to 3.6%, and missing 30 best days to 1.4%. *(JPMorgan)*
    Another study (1994-2024) found that missing the best 30 days dropped the annual return of the S&P 500 from 8.0% to 1.8%, and missing the best 50 days resulted in a negative return of ‚Äì0.86%. *(Wells Fargo Advisors)*
    ### The Bottom Line
    Over multiple decades and market cycles, those who stay disciplined with a simple, well-understood strategy tend to outperform 80 to 90% of active investors across all time horizons.
    Master one strategy and stick with it. Constantly changing direction not only increases risk and stress, it almost always lowers returns. In investing, patience and consistency are the real sources of alpha.
    """)

# Special Tickers Section
if 'special_tickers_force_open_once' not in st.session_state:
    st.session_state.special_tickers_force_open_once = False

force_open_special_tickers = st.session_state.special_tickers_force_open_once

with st.expander("üéØ Special Long-Term Tickers", expanded=force_open_special_tickers):
    st.markdown("**Quick access to ticker aliases that the system accepts:**")
    
    # Get the actual ticker aliases from the function
    aliases = get_ticker_aliases()
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown("**üìà Stock Indices**")
        stock_mapping = {
            'S&P 500 (No Dividend) (1927+)': ('SPYND', '^GSPC'),
            'S&P 500 (Total Return) (1988+)': ('SPYTR', '^SP500TR'), 
            'NASDAQ (No Dividend) (1971+)': ('QQQND', '^IXIC'),
            'NASDAQ 100 (1985+)': ('NDX', '^NDX'),
            'Dow Jones (1992+)': ('DOW', '^DJI')
        }
        
        for name, (alias, ticker) in stock_mapping.items():
            if st.button(f"‚ûï {name}", key=f"add_stock_{ticker}", help=f"Add {alias} ‚Üí {ticker}"):
                # Ensure portfolio configs exist
                if 'multi_backtest_portfolio_configs' not in st.session_state:
                    st.session_state.multi_backtest_portfolio_configs = default_configs
                if 'multi_backtest_active_portfolio_index' not in st.session_state:
                    st.session_state.multi_backtest_active_portfolio_index = 0
                
                portfolio_index = st.session_state.multi_backtest_active_portfolio_index
                # Resolve the alias to the actual Yahoo ticker before storing
                resolved_ticker = resolve_ticker_alias(alias)
                st.session_state.multi_backtest_portfolio_configs[portfolio_index]['stocks'].append({
                    'ticker': resolved_ticker,  # Add the resolved Yahoo ticker
                    'allocation': 0.0, 
                    'include_dividends': True
                })
                # Keep expander open and rerun immediately
                st.session_state.special_tickers_force_open_once = True
                st.rerun()
    
    with col2:
        st.markdown("**üè≠ Sector Indices**")
        sector_mapping = {
            'Technology (XLK) (1990+)': ('XLKND', '^SP500-45'),
            'Healthcare (XLV) (1990+)': ('XLVND', '^SP500-35'),
            'Consumer Staples (XLP) (1990+)': ('XLPND', '^SP500-30'),
            'Financials (XLF) (1990+)': ('XLFND', '^SP500-40'),
            'Energy (XLE) (1990+)': ('XLEND', '^SP500-10'),
            'Industrials (XLI) (1990+)': ('XLIND', '^SP500-20'),
            'Consumer Discretionary (XLY) (1990+)': ('XLYND', '^SP500-25'),
            'Materials (XLB) (1990+)': ('XLBND', '^SP500-15'),
            'Utilities (XLU) (1990+)': ('XLUND', '^SP500-55'),
            'Real Estate (XLRE) (1990+)': ('XLREND', '^SP500-60'),
            'Communication Services (XLC) (1990+)': ('XLCND', '^SP500-50')
        }
        
        for name, (alias, ticker) in sector_mapping.items():
            if st.button(f"‚ûï {name}", key=f"add_sector_{ticker}", help=f"Add {alias} ‚Üí {ticker}"):
                # Ensure portfolio configs exist
                if 'multi_backtest_portfolio_configs' not in st.session_state:
                    st.session_state.multi_backtest_portfolio_configs = default_configs
                if 'multi_backtest_active_portfolio_index' not in st.session_state:
                    st.session_state.multi_backtest_active_portfolio_index = 0
                
                portfolio_index = st.session_state.multi_backtest_active_portfolio_index
                # Resolve the alias to the actual Yahoo ticker before storing
                resolved_ticker = resolve_ticker_alias(alias)
                st.session_state.multi_backtest_portfolio_configs[portfolio_index]['stocks'].append({
                    'ticker': resolved_ticker,  # Add the resolved Yahoo ticker
                    'allocation': 0.0, 
                    'include_dividends': True
                })
                # Keep expander open and rerun immediately
                st.session_state.special_tickers_force_open_once = True
                st.rerun()
    
    with col3:
        st.markdown("**üî¨ Synthetic Tickers**")
        synthetic_tickers = {
            # Ordered by asset class: Stocks ‚Üí Bonds ‚Üí Gold ‚Üí Managed Futures ‚Üí Bitcoin
            'Complete S&P 500 Simulation (1885+)': ('SPYSIM', 'SPYSIM_COMPLETE'),
            'Dynamic S&P 500 Top 20 (Historical)': ('SP500TOP20', 'SP500TOP20'),
            'Cash Simulator (ZEROX)': ('ZEROX', 'ZEROX'),
            'Complete TBILL Dataset (1948+)': ('TBILL', 'TBILL_COMPLETE'),
            'Complete IEF Dataset (1962+)': ('IEFTR', 'IEF_COMPLETE'),
            'Complete TLT Dataset (1962+)': ('TLTTR', 'TLT_COMPLETE'),
            'Complete ZROZ Dataset (1962+)': ('ZROZX', 'ZROZ_COMPLETE'),
            'Complete Gold Simulation (1968+)': ('GOLDSIM', 'GOLDSIM_COMPLETE'),
            'Complete Gold Dataset (1975+)': ('GOLDX', 'GOLD_COMPLETE'),
            'Complete KMLM Dataset (1992+)': ('KMLMX', 'KMLM_COMPLETE'),
            'Complete DBMF Dataset (2000+)': ('DBMFX', 'DBMF_COMPLETE'),
            'Complete Bitcoin Dataset (2010+)': ('BITCOINX', 'BTC_COMPLETE'),
            
            # Leveraged & Inverse ETFs (Synthetic) - NASDAQ-100 versions
            'Simulated TQQQ (3x QQQ) (1985+)': ('TQQQND', '^NDX?L=3?E=0.95'),
            'Simulated QLD (2x QQQ) (1985+)': ('QLDND', '^NDX?L=2?E=0.95'),
            'Simulated PSQ (-1x QQQ) (1985+)': ('PSQND', '^NDX?L=-1?E=0.95'),
            'Simulated QID (-2x QQQ) (1985+)': ('QIDND', '^NDX?L=-2?E=0.95'),
            'Simulated SQQQ (-3x QQQ) (1985+)': ('SQQQND', '^NDX?L=-3?E=0.95'),
            
            # Leveraged & Inverse ETFs (Synthetic) - NASDAQ Composite versions (longer history)
            'Simulated TQQQ-IXIC (3x IXIC) (1971+)': ('TQQQIXIC', '^IXIC?L=3?E=0.95'),
            'Simulated QLD-IXIC (2x IXIC) (1971+)': ('QLDIXIC', '^IXIC?L=2?E=0.95'),
            'Simulated PSQ-IXIC (-1x IXIC) (1971+)': ('PSQIXIC', '^IXIC?L=-1?E=0.95'),
            'Simulated QID-IXIC (-2x IXIC) (1971+)': ('QIDIXIC', '^IXIC?L=-2?E=0.95'),
            'Simulated SQQQ-IXIC (-3x IXIC) (1971+)': ('SQQQIXIC', '^IXIC?L=-3?E=0.95'),
            
            # S&P 500 leveraged/inverse (unchanged)
            'Simulated SPXL (3x SPY) (1988+)': ('SPXLTR', '^SP500TR?L=3?E=1.00'),
            'Simulated UPRO (3x SPY) (1988+)': ('UPROTR', '^SP500TR?L=3?E=0.91'),
            'Simulated SSO (2x SPY) (1988+)': ('SSOTR', '^SP500TR?L=2?E=0.91'),
            'Simulated SH (-1x SPY) (1927+)': ('SHND', '^GSPC?L=-1?E=0.89'),
            'Simulated SDS (-2x SPY) (1927+)': ('SDSND', '^GSPC?L=-2?E=0.91'),
            'Simulated SPXU (-3x SPY) (1927+)': ('SPXUND', '^GSPC?L=-3?E=1.00')
        }
        
        for name, (alias, ticker) in synthetic_tickers.items():
            # Custom help text for different ticker types
            if alias == 'SP500TOP20':
                help_text = "Add SP500TOP20 ‚Üí SP500TOP20 - BETA ticker: Dynamic portfolio of top 20 S&P 500 companies rebalanced annually based on historical market cap data"
            elif alias == 'ZEROX':
                help_text = "Add ZEROX ‚Üí ZEROX - Cash Simulator: Simulates a cash position that does nothing (no price movement, no dividends)"
            elif 'IXIC' in ticker:
                # Special warning for IXIC versions
                help_text = f"Add {alias} ‚Üí {ticker} ‚ö†Ô∏è WARNING: This tracks NASDAQ Composite (broader index), NOT NASDAQ-100 like the real ETF!"
            else:
                help_text = f"Add {alias} ‚Üí {ticker}"
            
            if st.button(f"‚ûï {name}", key=f"add_synthetic_{ticker}", help=help_text):
                portfolio_index = st.session_state.multi_backtest_active_portfolio_index
                # Resolve the alias to the actual ticker before storing
                resolved_ticker = resolve_ticker_alias(alias)
                # Auto-disable dividends for negative leverage (inverse ETFs)
                include_divs = False if '?L=-' in resolved_ticker else True
                st.session_state.multi_backtest_portfolio_configs[portfolio_index]['stocks'].append({
                    'ticker': resolved_ticker,  # Add the resolved ticker
                    'allocation': 0.0, 
                    'include_divs': include_divs,
                    'include_in_sma_filter': True
                })
                # Keep expander open and rerun immediately
                st.session_state.special_tickers_force_open_once = True
                st.rerun()
    
    st.markdown("---")
    
    # Ticker Aliases Section INSIDE the expander
    st.markdown("**üí° Ticker Aliases:** You can also use these shortcuts in the text input below:")
    st.markdown("- `SPX` ‚Üí `^GSPC` (S&P 500 Price, 1927+), `SPXTR` ‚Üí `^SP500TR` (S&P 500 Total Return, 1988+)")
    st.markdown("- `SPYTR` ‚Üí `^SP500TR` (S&P 500 Total Return, 1988+), `QQQTR` ‚Üí `^NDX` (NASDAQ 100, 1985+)")
    st.markdown("- `TLTETF` ‚Üí `TLT` (20+ Year Treasury ETF, 2002+), `IEFETF` ‚Üí `IEF` (7-10 Year Treasury ETF, 2002+)")
    st.markdown("- `TLTTR` ‚Üí `TLT_COMPLETE` (Complete TLT Dataset, 1962+), `IEFTR` ‚Üí `IEF_COMPLETE` (Complete IEF Dataset, 1962+)")
    st.markdown("- `ZROZX` ‚Üí `ZROZ_COMPLETE` (Complete ZROZ Dataset, 1962+), `GOVZTR` ‚Üí `GOVZ` (25+ Year Treasury STRIPS, 2020+)")
    st.markdown("- `TNX` ‚Üí `^TNX` (10Y Treasury Yield, 1962+), `TYX` ‚Üí `^TYX` (30Y Treasury Yield, 1977+)")
    st.markdown("- `TBILL3M` ‚Üí `^IRX` (3M Treasury Yield, 1960+), `SHY` ‚Üí `SHY` (1-3 Year Treasury ETF, 2002+)")
    st.markdown("- `ZEROX` ‚Üí `ZERO` (Cash doing nothing), `SPYSIM` ‚Üí `SPYSIM_COMPLETE` (Complete S&P 500 Simulation, 1885+), `SP500TOP20` ‚Üí `SP500TOP20` (Dynamic S&P 500 Top 20, Historical), `TBILL` ‚Üí `TBILL_COMPLETE` (Complete TBILL Dataset, 1948+), `IEFTR` ‚Üí `IEF_COMPLETE` (Complete IEF Dataset, 1962+), `TLTTR` ‚Üí `TLT_COMPLETE` (Complete TLT Dataset, 1962+), `ZROZX` ‚Üí `ZROZ_COMPLETE` (Complete ZROZ Dataset, 1962+), `GOLDSIM` ‚Üí `GOLDSIM_COMPLETE` (Complete Gold Simulation, 1968+), `GOLDX` ‚Üí `GOLD_COMPLETE` (Complete Gold Dataset, 1975+), `KMLMX` ‚Üí `KMLM_COMPLETE` (Complete KMLM Dataset, 1992+), `DBMFX` ‚Üí `DBMF_COMPLETE` (Complete DBMF Dataset, 2000+), `BITCOINX` ‚Üí `BTC_COMPLETE` (Complete Bitcoin Dataset, 2010+)")

if force_open_special_tickers:
    st.session_state.special_tickers_force_open_once = False

with st.expander("‚ö° Leverage Guide", expanded=False):
    st.markdown("""
    **Leverage Format:** Use `TICKER?L=N` where N is the leverage multiplier
    
    **Examples:**
    - **SPY?L=2** - 2x leveraged S&P 500
    - **QQQ?L=3** - 3x leveraged NASDAQ-100  
    - **TLT?L=2** - 2x leveraged 20+ Year Treasury
    
    **Important Notes:**
    - **Daily Reset:** Leverage resets daily (like real leveraged ETFs)
    - **Cost Drag:** Includes daily cost drag = (leverage - 1) √ó risk-free rate
    - **Volatility Decay:** High volatility can cause significant decay over time
    - **Risk Warning:** Leveraged products are high-risk and can lose value quickly
    
    **Real Leveraged ETFs for Reference:**
    - **SSO** - 2x S&P 500 (ProShares)
    - **UPRO** - 3x S&P 500 (ProShares)
    - **TQQQ** - 3x NASDAQ-100 (ProShares)
    - **TMF** - 3x 20+ Year Treasury (Direxion)
    
    **Best Practices:**
    - Use for short-term strategies or hedging
    - Avoid holding for extended periods due to decay
    - Consider the underlying asset's volatility
    - Monitor risk-free rate changes affecting cost drag
    """)


# Bulk ticker input section - FIXED VERSION
with st.expander("üìù Bulk Ticker Input", expanded=False):
    st.markdown("**Enter multiple tickers separated by spaces or commas:**")
    
    # Initialize bulk ticker input in session state
    if 'multi_backtest_bulk_tickers' not in st.session_state:
        st.session_state.multi_backtest_bulk_tickers = ""
    
    # Auto-populate bulk ticker input with current tickers (only if user hasn't entered anything)
    portfolio_index = st.session_state.multi_backtest_active_portfolio_index
    current_tickers = [stock['ticker'] for stock in st.session_state.multi_backtest_portfolio_configs[portfolio_index]['stocks'] if stock['ticker']]
    if current_tickers:
        current_ticker_string = ' '.join(current_tickers)
        # Only auto-populate if the bulk ticker field is empty or matches the current portfolio
        if not st.session_state.multi_backtest_bulk_tickers or st.session_state.multi_backtest_bulk_tickers == current_ticker_string:
            st.session_state.multi_backtest_bulk_tickers = current_ticker_string
    
    # Text area for bulk ticker input
    bulk_tickers = st.text_area(
        "Tickers (e.g., SPY QQQ GLD TLT or SPY,QQQ,GLD,TLT)",
        value=st.session_state.multi_backtest_bulk_tickers,
        key="multi_backtest_bulk_ticker_input",
        height=100,
        help="Enter ticker symbols separated by spaces or commas. Choose 'Replace All' to replace all tickers or 'Add to Existing' to add new tickers."
    )
    
    # Action buttons
    col_replace, col_add, col_fetch, col_copy = st.columns([1, 1, 1, 1])
    
    with col_replace:
        if st.button("üîÑ Replace All", key="multi_backtest_fill_tickers_btn", type="secondary"):
            if bulk_tickers.strip():
                # Parse tickers (split by comma or space)
                ticker_list = []
            for ticker in bulk_tickers.replace(',', ' ').split():
                ticker = ticker.strip().upper()
                if ticker:
                    # Special conversion for Berkshire Hathaway tickers for Yahoo Finance compatibility
                    if ticker == 'BRK.B':
                        ticker = 'BRK-B'
                    elif ticker == 'BRK.A':
                        ticker = 'BRK-A'
                    ticker_list.append(ticker)
            
            if ticker_list:
                portfolio_index = st.session_state.multi_backtest_active_portfolio_index
                current_stocks = st.session_state.multi_backtest_portfolio_configs[portfolio_index]['stocks'].copy()
                
                # Replace tickers - new ones get 0% allocation
                new_stocks = []
                
                for i, ticker in enumerate(ticker_list):
                    if i < len(current_stocks):
                        # Use existing allocation if available
                        new_stocks.append({
                            'ticker': ticker,
                            'allocation': current_stocks[i]['allocation'],
                            'include_dividends': current_stocks[i]['include_dividends']
                        })
                    else:
                        # New tickers get 0% allocation
                        new_stocks.append({
                            'ticker': ticker,
                            'allocation': 0.0,
                            'include_dividends': True
                        })
                
                # Update the portfolio with new stocks
                st.session_state.multi_backtest_portfolio_configs[portfolio_index]['stocks'] = new_stocks
                
                # Update the active_portfolio reference to match session state
                active_portfolio['stocks'] = new_stocks
                
                # Clear any existing session state keys for individual ticker inputs to force refresh
                for key in list(st.session_state.keys()):
                    if key.startswith(f"multi_backtest_ticker_{portfolio_index}_") or key.startswith(f"multi_backtest_alloc_{portfolio_index}_"):
                        del st.session_state[key]
                
                    st.success(f"‚úÖ Replaced all tickers with: {', '.join(ticker_list)}")
                st.info("üí° **Note:** Existing allocations preserved. Adjust allocations manually if needed.")
                
                # Force immediate rerun to refresh the UI
                st.rerun()
            else:
                    st.warning("‚ö†Ô∏è No valid tickers found in input.")
    
    with col_add:
        if st.button("‚ûï Add to Existing", key="multi_backtest_add_tickers_btn", type="secondary"):
            if bulk_tickers.strip():
                # Parse tickers (split by comma or space)
                ticker_list = []
                for ticker in bulk_tickers.replace(',', ' ').split():
                    ticker = ticker.strip().upper()
                    if ticker:
                        # Special conversion for Berkshire Hathaway tickers for Yahoo Finance compatibility
                        if ticker == 'BRK.B':
                            ticker = 'BRK-B'
                        elif ticker == 'BRK.A':
                            ticker = 'BRK-A'
                        ticker_list.append(ticker)
                
                if ticker_list:
                    portfolio_index = st.session_state.multi_backtest_active_portfolio_index
                    current_stocks = st.session_state.multi_backtest_portfolio_configs[portfolio_index]['stocks'].copy()
                    
                    # Add new tickers to existing ones
                    for ticker in ticker_list:
                        # Check if ticker already exists
                        ticker_exists = any(stock['ticker'] == ticker for stock in current_stocks)
                        if not ticker_exists:
                            current_stocks.append({
                                'ticker': ticker,
                                'allocation': 0.0,
                                'include_dividends': True
                            })
                    
                    # Update the portfolio with combined stocks
                    st.session_state.multi_backtest_portfolio_configs[portfolio_index]['stocks'] = current_stocks
                    
                    # Update the active_portfolio reference to match session state
                    active_portfolio['stocks'] = current_stocks
                    
                    # Clear any existing session state keys for individual ticker inputs to force refresh
                    for key in list(st.session_state.keys()):
                        if key.startswith(f"multi_backtest_ticker_{portfolio_index}_") or key.startswith(f"multi_backtest_alloc_{portfolio_index}_"):
                            del st.session_state[key]
                    
                    st.success(f"‚úÖ Added new tickers: {', '.join(ticker_list)}")
                    st.info("üí° **Note:** New tickers added with 0% allocation. Adjust allocations manually if needed.")
                    
                    # Force immediate rerun to refresh the UI
                    st.rerun()
                else:
                    st.warning("‚ö†Ô∏è No valid tickers found in input.")
    
    with col_fetch:
        if st.button("üîç Fetch Tickers", key="multi_backtest_fetch_tickers_btn", type="secondary"):
            # Get current tickers from the active portfolio
            portfolio_index = st.session_state.multi_backtest_active_portfolio_index
            current_tickers = [stock['ticker'] for stock in st.session_state.multi_backtest_portfolio_configs[portfolio_index]['stocks'] if stock['ticker']]
            
            if current_tickers:
                # Update the bulk ticker input with current tickers
                current_ticker_string = ' '.join(current_tickers)
                st.session_state.multi_backtest_bulk_tickers = current_ticker_string
                st.success(f"‚úÖ Fetched {len(current_tickers)} tickers: {current_ticker_string}")
                st.rerun()
            else:
                st.warning("‚ö†Ô∏è No tickers found in the current portfolio.")
    
    with col_copy:
        if bulk_tickers.strip():
            # Create a custom button with direct copy functionality
            import streamlit.components.v1 as components
            
            # JavaScript function to copy and show feedback
            copy_js = f"""
            <script>
            function copyTickers() {{
                navigator.clipboard.writeText({json.dumps(bulk_tickers.strip())}).then(function() {{
                    // Show success feedback
                    const button = document.querySelector('#copy-tickers-btn');
                    const originalText = button.innerHTML;
                    button.innerHTML = '‚úÖ Copied!';
                    button.style.backgroundColor = '#28a745';
                    setTimeout(function() {{
                        button.innerHTML = originalText;
                        button.style.backgroundColor = '';
                    }}, 2000);
                }}).catch(function(err) {{
                    alert('Failed to copy: ' + err);
                }});
            }}
            </script>
            <button id="copy-tickers-btn" onclick="copyTickers()" style="
                background-color: #6c757d;
                color: white;
                border: none;
                padding: 8px 16px;
                border-radius: 4px;
                cursor: pointer;
                width: 100%;
                font-size: 14px;
            ">üìã Copy</button>
            """
            components.html(copy_js, height=50)
        else:
            st.button("üìã Copy", key="multi_backtest_copy_tickers_btn", type="secondary", disabled=True)
            st.warning("‚ö†Ô∏è No tickers to copy. Please enter some tickers first.")

# Leverage Summary Section
leveraged_tickers = []
for stock in active_portfolio['stocks']:
    if "?L=" in stock['ticker'] or "?E=" in stock['ticker']:
        try:
            base_ticker, leverage, expense_ratio = parse_ticker_parameters(stock['ticker'])
            leveraged_tickers.append((base_ticker, leverage))
        except:
            pass

if leveraged_tickers:
    st.markdown("---")
    st.markdown("### üöÄ Leverage Summary")
    
    # Get risk-free rate for drag calculation
    try:
        risk_free_rates = get_risk_free_rate_robust([pd.Timestamp.now()])
        daily_rf = risk_free_rates.iloc[0] if len(risk_free_rates) > 0 else 0.000105
        annual_rf = daily_rf * 365.25 * 100  # Convert daily to annual percentage
    except:
        daily_rf = 0.000105  # fallback
        annual_rf = 3.86  # fallback annual rate
    
    # Group by leverage level
    leverage_groups = {}
    for base_ticker, leverage in leveraged_tickers:
        if leverage not in leverage_groups:
            leverage_groups[leverage] = []
        leverage_groups[leverage].append(base_ticker)
    
    for leverage in sorted(leverage_groups.keys()):
        base_tickers = leverage_groups[leverage]
        daily_drag = (leverage - 1) * daily_rf * 100
        st.markdown(f"üöÄ **{leverage}x leverage** on {', '.join(base_tickers)}")
        st.markdown(f"üìâ **Daily drag:** {daily_drag:.3f}% (RF: {annual_rf:.2f}%)")

st.subheader("Strategy")
if "multi_backtest_active_use_momentum" not in st.session_state:
    st.session_state["multi_backtest_active_use_momentum"] = parse_bool_from_json(active_portfolio.get('use_momentum', False), False)
if "multi_backtest_active_use_targeted_rebalancing" not in st.session_state:
    st.session_state["multi_backtest_active_use_targeted_rebalancing"] = parse_bool_from_json(active_portfolio.get('use_targeted_rebalancing', False), False)
# Only show momentum strategy if targeted rebalancing is disabled
if not st.session_state.get("multi_backtest_active_use_targeted_rebalancing", False):
    st.checkbox("Use Momentum Strategy", key="multi_backtest_active_use_momentum", on_change=update_use_momentum, help="Enables momentum-based weighting of stocks.")
    
else:
    # Hide momentum strategy when targeted rebalancing is enabled
    # Don't modify session state directly - let the checkbox handle it
    # st.session_state["multi_backtest_active_use_momentum"] = False
    # Also hide SMA filter when targeted rebalancing is enabled
    # st.session_state["multi_backtest_active_use_sma_filter"] = False
    pass

if st.session_state.get('multi_backtest_active_use_momentum', active_portfolio.get('use_momentum', True)):
    st.markdown("---")
    col_mom_options, col_beta_vol = st.columns(2)
    with col_mom_options:
        st.markdown("**Momentum Strategy Options**")
        
        # CRITICAL: Sync session state BEFORE creating selectboxes to avoid double-click issue
        momentum_key = f"multi_backtest_momentum_strategy_{st.session_state.multi_backtest_active_portfolio_index}"
        negative_momentum_key = f"multi_backtest_negative_momentum_strategy_{st.session_state.multi_backtest_active_portfolio_index}"
        
        if 'multi_backtest_active_momentum_strategy' in st.session_state:
            # Update both session state and portfolio config
            st.session_state[momentum_key] = st.session_state['multi_backtest_active_momentum_strategy']
            active_portfolio['momentum_strategy'] = st.session_state['multi_backtest_active_momentum_strategy']
            # Clear the temp session state to prevent conflicts
            del st.session_state['multi_backtest_active_momentum_strategy']
        
        if 'multi_backtest_active_negative_momentum_strategy' in st.session_state:
            # Update both session state and portfolio config
            st.session_state[negative_momentum_key] = st.session_state['multi_backtest_active_negative_momentum_strategy']
            active_portfolio['negative_momentum_strategy'] = st.session_state['multi_backtest_active_negative_momentum_strategy']
            # Clear the temp session state to prevent conflicts
            del st.session_state['multi_backtest_active_negative_momentum_strategy']
        
        momentum_strategy = st.selectbox(
            "Momentum strategy when NOT all negative:",
            ["Classic", "Relative Momentum", "Near-Zero Symmetry"],
            index=["Classic", "Relative Momentum", "Near-Zero Symmetry"].index(active_portfolio.get('momentum_strategy', 'Classic')),
            key=f"multi_backtest_momentum_strategy_{st.session_state.multi_backtest_active_portfolio_index}",
            help="Classic: Uses absolute momentum values. Only assets with positive momentum get allocated, weighted by their momentum strength. Assets with negative momentum get 0% allocation.\n\nRelative Momentum: Shifts all momentum scores to be positive by adding an offset, then allocates proportionally. This ensures all assets get some allocation even when all have negative momentum.\n\nNear-Zero Symmetry: Creates a neutral zone around 0% momentum (¬±5%). Assets in this zone get similar allocations, while negative assets get progressively compressed allocations."
        )
        # Check if this is SP500TOP20 to set default to Relative instead of Cash
        is_sp500top20 = any(is_special_dynamic_ticker(stock['ticker']) for stock in active_portfolio.get('stocks', []))
        default_negative_strategy = 'Relative momentum' if is_sp500top20 else 'Cash'
        
        # Get current value from portfolio config
        current_negative_strategy = active_portfolio.get('negative_momentum_strategy', default_negative_strategy)
        
        negative_momentum_strategy = st.selectbox(
            "Strategy when ALL momentum scores are negative:",
            ["Cash", "Equal weight", "Relative momentum", "Near-Zero Symmetry"],
            index=["Cash", "Equal weight", "Relative momentum", "Near-Zero Symmetry"].index(current_negative_strategy),
            key=f"multi_backtest_negative_momentum_strategy_{st.session_state.multi_backtest_active_portfolio_index}",
            help="Cash: All assets get 0% allocation, portfolio goes to 100% cash when all momentum scores are negative.\n\nEqual weight: All assets get equal allocation (1/n) regardless of their negative momentum values.\n\nRelative momentum: Shifts all negative momentum scores to be positive by adding an offset, then allocates proportionally based on relative performance.\n\nNear-Zero Symmetry: Creates a neutral zone around 0% momentum (¬±5%). Assets in this zone get similar allocations, while more negative assets get progressively compressed allocations."
        )
        
        # Show warning for SP500TOP20 if Cash is selected
        if is_sp500top20 and negative_momentum_strategy == 'Cash':
            st.warning("‚ö†Ô∏è **SP500TOP20 detected!** Cash strategy does not work yet and needs fixing. Please select 'Relative momentum' or 'Equal weight' instead.")
        active_portfolio['momentum_strategy'] = momentum_strategy
        active_portfolio['negative_momentum_strategy'] = negative_momentum_strategy
        
        st.markdown("---")
        
        # Equal Weight option - SAME PATTERN AS MAX ALLOCATION
        # ALWAYS sync equal weight settings from portfolio (not just if not present)
        st.session_state["multi_backtest_active_use_equal_weight"] = active_portfolio.get('use_equal_weight', False)
        st.session_state["multi_backtest_active_equal_weight_n_tickers"] = active_portfolio.get('equal_weight_n_tickers', 10)
        
        st.checkbox(
            "Equal Weight Top N Tickers",
            key="multi_backtest_active_use_equal_weight",
            on_change=update_use_equal_weight,
            help="When enabled, takes the top N tickers by momentum weight and assigns them equal weights (1/N each). The momentum strategy is still used to select and rank the tickers."
        )
        
        if st.session_state.get("multi_backtest_active_use_equal_weight", False):
            st.number_input(
                "Number of Top Tickers to Equal Weight",
                min_value=1,
                max_value=100,
                key="multi_backtest_active_equal_weight_n_tickers",
                on_change=update_equal_weight_n_tickers,
                help="Select the top N tickers by momentum weight to receive equal allocation."
            )
        
        st.markdown("---")
        
        # Limit to Top N option - SAME PATTERN AS EQUAL WEIGHT
        # ALWAYS sync limit to top N settings from portfolio (not just if not present)
        st.session_state["multi_backtest_active_use_limit_to_top_n"] = active_portfolio.get('use_limit_to_top_n', False)
        st.session_state["multi_backtest_active_limit_to_top_n_tickers"] = active_portfolio.get('limit_to_top_n_tickers', 10)
        
        st.checkbox(
            "Limit to Top N Tickers",
            key="multi_backtest_active_use_limit_to_top_n",
            on_change=update_use_limit_to_top_n,
            help="When enabled, takes the top N tickers by momentum weight and keeps their proportional weights (unlike equal weight). The momentum strategy is still used to select and rank the tickers."
        )
        
        if st.session_state.get("multi_backtest_active_use_limit_to_top_n", False):
            st.number_input(
                "Number of Top Tickers to Keep",
                min_value=1,
                max_value=100,
                key="multi_backtest_active_limit_to_top_n_tickers",
                on_change=update_limit_to_top_n_tickers,
                help="Select the top N tickers by momentum weight to keep (with proportional weights)."
            )
        
        st.markdown("üí° **Note:** These options control how weights are assigned based on momentum scores.")

    with col_beta_vol:
        if "multi_backtest_active_calc_beta" not in st.session_state:
            st.session_state["multi_backtest_active_calc_beta"] = parse_bool_from_json(active_portfolio.get('calc_beta', False), False)
        st.checkbox("Include Beta in momentum weighting", key="multi_backtest_active_calc_beta", on_change=update_calc_beta, help="Penalizes high-beta stocks by reducing their allocation. Stocks with Beta > 1.0 (more volatile than market) get lower weights, while stocks with Beta < 1.0 (less volatile) get higher weights. This reduces portfolio risk by favoring stable stocks.")
        # Reset Beta button
        if st.button("Reset Beta", key=f"multi_backtest_reset_beta_btn_{st.session_state.multi_backtest_active_portfolio_index}", on_click=reset_beta_callback):
            pass
        if st.session_state.get('multi_backtest_active_calc_beta', False):
            # Always ensure widgets have the correct values when beta is enabled
            # Check for saved settings first, then use portfolio values, then defaults
            if 'saved_beta_settings' in active_portfolio:
                saved_settings = active_portfolio['saved_beta_settings']
                st.session_state["multi_backtest_active_beta_window"] = saved_settings.get('beta_window_days', 365)
                st.session_state["multi_backtest_active_beta_exclude"] = saved_settings.get('exclude_days_beta', 30)
            else:
                st.session_state["multi_backtest_active_beta_window"] = active_portfolio.get('beta_window_days', 365)
                st.session_state["multi_backtest_active_beta_exclude"] = active_portfolio.get('exclude_days_beta', 30)
            st.number_input("Beta Lookback (days)", min_value=1, key="multi_backtest_active_beta_window", on_change=update_beta_window)
            st.number_input("Beta Exclude (days)", min_value=0, key="multi_backtest_active_beta_exclude", on_change=update_beta_exclude)
        if "multi_backtest_active_calc_vol" not in st.session_state:
            st.session_state["multi_backtest_active_calc_vol"] = parse_bool_from_json(active_portfolio.get('calc_volatility', False), False)
        st.checkbox("Include Volatility in momentum weighting", key="multi_backtest_active_calc_vol", on_change=update_calc_vol, help="Penalizes high-volatility stocks by reducing their allocation. Stocks with high price swings get lower weights, while stable stocks get higher weights. This reduces portfolio risk by favoring less volatile investments.")
        # Reset Volatility button
        if st.button("Reset Volatility", key=f"multi_backtest_reset_vol_btn_{st.session_state.multi_backtest_active_portfolio_index}", on_click=reset_vol_callback):
            pass
        if st.session_state.get('multi_backtest_active_calc_vol', False):
            # Always ensure widgets have the correct values when volatility is enabled
            # Check for saved settings first, then use portfolio values, then defaults
            if 'saved_vol_settings' in active_portfolio:
                saved_settings = active_portfolio['saved_vol_settings']
                st.session_state["multi_backtest_active_vol_window"] = saved_settings.get('vol_window_days', 365)
                st.session_state["multi_backtest_active_vol_exclude"] = saved_settings.get('exclude_days_vol', 30)
            else:
                st.session_state["multi_backtest_active_vol_window"] = active_portfolio.get('vol_window_days', 365)
                st.session_state["multi_backtest_active_vol_exclude"] = active_portfolio.get('exclude_days_vol', 30)
            st.number_input("Volatility Lookback (days)", min_value=1, key="multi_backtest_active_vol_window", on_change=update_vol_window)
            st.number_input("Volatility Exclude (days)", min_value=0, key="multi_backtest_active_vol_exclude", on_change=update_vol_exclude)
    
    st.markdown("---")
    st.subheader("Momentum Windows")
    col_reset, col_norm, col_addrem = st.columns([0.4, 0.4, 0.2])
    with col_reset:
        if st.button("Reset Momentum Windows", on_click=reset_momentum_windows_callback):
            pass
    with col_norm:
        if st.button("Normalize Weights to 100%", on_click=normalize_momentum_weights_callback):
            pass
    with col_addrem:
        if st.button("Add Window", on_click=add_momentum_window_callback):
            pass
        if st.button("Remove Window", on_click=remove_momentum_window_callback):
            pass

    total_weight = sum(w['weight'] for w in active_portfolio['momentum_windows'])
    if abs(total_weight - 1.0) > 0.001:
        st.warning(f"Current total weight is {total_weight*100:.2f}%, not 100%. Click 'Normalize Weights' to fix.")
    else:
        st.success(f"Total weight is {total_weight*100:.2f}%.")

    def update_momentum_lookback(index):
        st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['momentum_windows'][index]['lookback'] = st.session_state[f"multi_backtest_lookback_active_{index}"]

    def update_momentum_exclude(index):
        st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['momentum_windows'][index]['exclude'] = st.session_state[f"multi_backtest_exclude_active_{index}"]
    
    def update_momentum_weight(index):
        st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['momentum_windows'][index]['weight'] = st.session_state[f"multi_backtest_weight_input_active_{index}"] / 100.0

    # Allow the user to remove momentum windows down to zero.
    # Previously the UI forced a minimum of 3 windows which prevented removing them.
    # If no windows exist, show an informational message and allow adding via the button.
    if len(active_portfolio.get('momentum_windows', [])) == 0:
        st.info("No momentum windows configured. Click 'Add Window' to create momentum lookback windows.")
    col_headers = st.columns(3)
    with col_headers[0]:
        st.markdown("**Lookback (days)**")
    with col_headers[1]:
        st.markdown("**Exclude (days)**")
    with col_headers[2]:
        st.markdown("**Weight %**")

    for j in range(len(active_portfolio['momentum_windows'])):
        with st.container():
            col_mw1, col_mw2, col_mw3 = st.columns(3)
            lookback_key = f"multi_backtest_lookback_active_{j}"
            exclude_key = f"multi_backtest_exclude_active_{j}"
            weight_key = f"multi_backtest_weight_input_active_{j}"
            if lookback_key not in st.session_state:
                # Convert lookback to integer to match min_value type
                momentum_windows = active_portfolio.get('momentum_windows', [])
                if j < len(momentum_windows):
                    st.session_state[lookback_key] = int(momentum_windows[j]['lookback'])
                else:
                    st.session_state[lookback_key] = 30  # Default fallback
            if exclude_key not in st.session_state:
                # Convert exclude to integer to match min_value type
                momentum_windows = active_portfolio.get('momentum_windows', [])
                if j < len(momentum_windows):
                    st.session_state[exclude_key] = int(momentum_windows[j]['exclude'])
                else:
                    st.session_state[exclude_key] = 0  # Default fallback
            if weight_key not in st.session_state:
                # Sanitize weight to prevent StreamlitValueAboveMaxError
                momentum_windows = active_portfolio.get('momentum_windows', [])
                if j < len(momentum_windows):
                    weight = momentum_windows[j]['weight']
                else:
                    weight = 0.1  # Default fallback
                if isinstance(weight, (int, float)):
                    # If weight is already a percentage (e.g., 50 for 50%), use it directly
                    if weight > 1.0:
                        # Cap at 100% and use as percentage
                        weight_percentage = min(weight, 100.0)
                    else:
                        # Convert decimal to percentage
                        weight_percentage = weight * 100.0
                else:
                    # Invalid weight, set to default
                    weight_percentage = 10.0
                st.session_state[weight_key] = int(weight_percentage)
            with col_mw1:
                st.number_input(f"Lookback {j+1}", min_value=1, key=lookback_key, label_visibility="collapsed")
                if st.session_state[lookback_key] != active_portfolio['momentum_windows'][j]['lookback']:
                    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['momentum_windows'][j]['lookback'] = st.session_state[lookback_key]
            with col_mw2:
                st.number_input(f"Exclude {j+1}", min_value=0, key=exclude_key, label_visibility="collapsed")
                if st.session_state[exclude_key] != active_portfolio['momentum_windows'][j]['exclude']:
                    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['momentum_windows'][j]['exclude'] = st.session_state[exclude_key]
            with col_mw3:
                st.number_input(f"Weight {j+1}", min_value=0, max_value=100, step=1, format="%d", key=weight_key, label_visibility="collapsed")
                # Update the portfolio weight when the widget value changes
                if st.session_state[weight_key] != int(active_portfolio['momentum_windows'][j]['weight'] * 100.0):
                    st.session_state.multi_backtest_portfolio_configs[st.session_state.multi_backtest_active_portfolio_index]['momentum_windows'][j]['weight'] = st.session_state[weight_key] / 100.0
    
    # Minimal Threshold Filter Section
    st.markdown("---")
    st.subheader("Minimal Threshold Filter")
    
    # ALWAYS sync threshold settings from portfolio (not just if not present)
    st.session_state["multi_backtest_active_use_threshold"] = active_portfolio.get('use_minimal_threshold', False)
    st.session_state["multi_backtest_active_threshold_percent"] = active_portfolio.get('minimal_threshold_percent', 4.0)
    
    st.checkbox(
        "Enable Minimal Threshold Filter", 
        key="multi_backtest_active_use_threshold", 
        on_change=update_use_threshold,
        help="Exclude stocks with allocations below the threshold percentage and normalize remaining allocations to 100%"
    )
    
    if st.session_state.get("multi_backtest_active_use_threshold", False):
        st.number_input(
            "Minimal Threshold (%)", 
            min_value=0.1, 
            max_value=50.0, 
            step=0.1,
            key="multi_backtest_active_threshold_percent", 
            on_change=update_threshold_percent,
            help="Stocks with allocations below this percentage will be excluded and their weight redistributed to remaining stocks"
        )
    
    # Maximum Allocation Filter Section
    st.markdown("---")
    st.subheader("Maximum Allocation Filter")
    
    # ALWAYS sync max allocation settings from portfolio (not just if not present)
    st.session_state["multi_backtest_active_use_max_allocation"] = active_portfolio.get('use_max_allocation', False)
    st.session_state["multi_backtest_active_max_allocation_percent"] = active_portfolio.get('max_allocation_percent', 20.0)
    
    st.checkbox(
        "Enable Maximum Allocation Filter", 
        key="multi_backtest_active_use_max_allocation", 
        on_change=update_use_max_allocation,
        help="Cap individual stock allocations at the maximum percentage and redistribute excess weight proportionally"
    )
    
    if st.session_state.get("multi_backtest_active_use_max_allocation", False):
        st.number_input(
            "Maximum Allocation (%)", 
            min_value=0.1, 
            max_value=100.0, 
            step=0.1,
            key="multi_backtest_active_max_allocation_percent", 
            on_change=update_max_allocation_percent,
            help="Individual stocks cannot exceed this allocation percentage. Excess weight will be redistributed proportionally to other stocks"
        )
else:
    # Don't clear momentum_windows - they should persist when momentum is disabled
    # so they're available when momentum is re-enabled or for variant generation
    pass

# MA Filter Section - SIMPLE STYLE LIKE MINIMAL THRESHOLD AND MAX ALLOCATION
# Only show MA filter if targeted rebalancing is disabled
if not st.session_state.get("multi_backtest_active_use_targeted_rebalancing", False):
    st.markdown("---")
    st.subheader("MA Filter")

    # Initialize MA filter state - SPECIFIC TO EACH PORTFOLIO
    ma_filter_key = f"multi_backtest_active_use_sma_filter_{st.session_state.multi_backtest_active_portfolio_index}"
    ma_window_key = f"multi_backtest_active_ma_window_{st.session_state.multi_backtest_active_portfolio_index}"
    ma_type_key = f"multi_backtest_active_ma_type_{st.session_state.multi_backtest_active_portfolio_index}"
    # FORCE sync with current portfolio values (like momentum checkbox does)
    st.session_state[ma_filter_key] = active_portfolio.get('use_sma_filter', False)
    st.session_state[ma_window_key] = active_portfolio.get('sma_window', 200)
    st.session_state[ma_type_key] = active_portfolio.get('ma_type', 'SMA')

    # MA Filter options - LEFT ALIGNED STYLE
    st.checkbox("Enable MA Filter", 
                key=ma_filter_key,
                on_change=update_use_sma_filter,
                help="MA Filter means the tickers with MA filter will be excluded when price below MA at rebalancing. This helps avoid buying assets that are in a downtrend.")

    # MA Type and Window (only show when MA filter is enabled)
    if st.session_state.get(ma_filter_key, False):
        col_ma1, col_ma2 = st.columns(2)
        
        with col_ma1:
            ma_type = st.selectbox("MA Type", 
                                   options=["SMA", "EMA"], 
                                   index=0 if st.session_state.get(ma_type_key, "SMA") == "SMA" else 1,
                                   key=f"ma_type_main_{st.session_state.multi_backtest_active_portfolio_index}",
                                   help="SMA (Simple Moving Average): Equal weight to all prices in the window. EMA (Exponential Moving Average): More weight to recent prices, reacts faster to price changes.")
            st.session_state[ma_type_key] = ma_type
        
        with col_ma2:
            ma_window = st.number_input("MA Window (days)", 
                                       value=st.session_state.get(ma_window_key, 200),
                                       min_value=1,
                                       max_value=1000,
                                       key=f"ma_window_main_{st.session_state.multi_backtest_active_portfolio_index}",
                                       help="Number of days to calculate the moving average. Longer windows = smoother trend, shorter windows = more responsive to price changes.")
            st.session_state[ma_window_key] = ma_window
        
        # MA Multiplier - USING WORKING LOGIC FROM TEST WIDGET
        portfolio_index = st.session_state.multi_backtest_active_portfolio_index
        actual_portfolio = st.session_state.multi_backtest_portfolio_configs[portfolio_index]
        
        # Initialize MA Multiplier widget only if it doesn't exist yet
        ma_multiplier_key = f"ma_multiplier_working_{portfolio_index}"
        if ma_multiplier_key not in st.session_state:
            st.session_state[ma_multiplier_key] = actual_portfolio.get('ma_multiplier', 1.48)
        
        ma_multiplier = st.number_input("MA Multiplier", 
                                       value=st.session_state[ma_multiplier_key],
                                       min_value=1.0,
                                       max_value=3.0,
                                       step=0.01,
                                       key=ma_multiplier_key,
                                       help="Multiplier to convert market days to calendar days. 1.48 means 200 market days = 296 calendar days (accounts for weekends and holidays).")
        
        # Update portfolio with widget value (widget controls portfolio)
        actual_portfolio['ma_multiplier'] = ma_multiplier
        
        # New option for immediate rebalancing on MA cross
        ma_cross_rebalance_key = f"multi_backtest_active_ma_cross_rebalance_{st.session_state.multi_backtest_active_portfolio_index}"
        
        # Initialize the new option if not exists - PRESERVE EXISTING VALUE
        if ma_cross_rebalance_key not in st.session_state:
            st.session_state[ma_cross_rebalance_key] = active_portfolio.get('ma_cross_rebalance', False)
        else:
            # Preserve existing session state value and sync with portfolio
            current_value = st.session_state[ma_cross_rebalance_key]
            active_portfolio['ma_cross_rebalance'] = current_value
        
        st.checkbox("Immediate Rebalance on MA Cross", 
                   key=ma_cross_rebalance_key,
                   on_change=update_ma_cross_rebalance,
                   help="Rebalance portfolio immediately when any ticker crosses its moving average, in addition to regular rebalancing schedule. This allows faster response to trend changes.")
        
        # Store the new option in active portfolio - ALWAYS sync
        active_portfolio['ma_cross_rebalance'] = st.session_state.get(ma_cross_rebalance_key, False)
        
        # Anti-whipsaw options (only show when MA cross rebalancing is enabled)
        if st.session_state.get(ma_cross_rebalance_key, False):
            st.markdown("**Anti-Whipsaw Settings:**")
            
            col_band, col_delay = st.columns(2)
            
            with col_band:
                # Tolerance band percentage
                ma_tolerance_key = f"multi_backtest_active_ma_tolerance_{st.session_state.multi_backtest_active_portfolio_index}"
                if ma_tolerance_key not in st.session_state:
                    st.session_state[ma_tolerance_key] = active_portfolio.get('ma_tolerance_percent', 2.0)
                
                # MA Multiplier - RECONSTRUCTED (no complex sync)
                
                ma_tolerance = st.number_input("Tolerance Band (%)", 
                                             value=st.session_state.get(ma_tolerance_key, 2.0),
                                             min_value=0.0,
                                             max_value=10.0,
                                             step=0.1,
                                             key=f"ma_tolerance_input_{st.session_state.multi_backtest_active_portfolio_index}",
                                             help="Tolerance band around the moving average. Only trigger rebalancing if price moves beyond this percentage from the MA. Prevents whipsaw from small price fluctuations.")
                st.session_state[ma_tolerance_key] = ma_tolerance
            
            with col_delay:
                # Confirmation delay in days
                ma_delay_key = f"multi_backtest_active_ma_delay_{st.session_state.multi_backtest_active_portfolio_index}"
                if ma_delay_key not in st.session_state:
                    st.session_state[ma_delay_key] = active_portfolio.get('ma_confirmation_days', 3)
                
                # MA Multiplier - RECONSTRUCTED (no complex sync)
                
                ma_delay = st.number_input("Confirmation Delay (days)", 
                                        value=st.session_state.get(ma_delay_key, 3),
                                        min_value=0,
                                        max_value=10,
                                        step=1,
                                        key=f"ma_delay_input_{st.session_state.multi_backtest_active_portfolio_index}",
                                        help="Number of days to wait before confirming an MA cross. Prevents false signals from temporary price movements. Higher values = more conservative approach.")
                st.session_state[ma_delay_key] = ma_delay
            
            # Store the anti-whipsaw settings in active portfolio
            active_portfolio['ma_tolerance_percent'] = st.session_state.get(ma_tolerance_key, 2.0)
            active_portfolio['ma_confirmation_days'] = st.session_state.get(ma_delay_key, 3)

    # Store MA filter state in active portfolio - USING PORTFOLIO-SPECIFIC KEYS
    active_portfolio['use_sma_filter'] = st.session_state.get(ma_filter_key, False)
    active_portfolio['ma_type'] = st.session_state.get(ma_type_key, "SMA")
    active_portfolio['sma_window'] = st.session_state.get(ma_window_key, 200)
    # MA Multiplier - RECONSTRUCTED (no complex sync)
else:
    # Hide MA filter when targeted rebalancing is enabled
    # Don't modify session state directly - let the checkbox handle it
    # st.session_state["multi_backtest_active_use_sma_filter"] = False
    active_portfolio['use_sma_filter'] = False

# Targeted Rebalancing Section
# Only show targeted rebalancing if MA filter AND momentum are disabled
ma_filter_key = f"multi_backtest_active_use_sma_filter_{st.session_state.multi_backtest_active_portfolio_index}"
if not st.session_state.get(ma_filter_key, False) and not st.session_state.get('multi_backtest_active_use_momentum', False):
    st.markdown("---")
    st.subheader("Targeted Rebalancing")

    # Initialize targeted rebalancing state
    if "multi_backtest_active_use_targeted_rebalancing" not in st.session_state:
        st.session_state["multi_backtest_active_use_targeted_rebalancing"] = active_portfolio.get('use_targeted_rebalancing', False)

    # Show targeted rebalancing checkbox (only visible when both momentum and MA filter are disabled)
    st.checkbox(
        "Enable Targeted Rebalancing", 
        key="multi_backtest_active_use_targeted_rebalancing", 
        on_change=update_use_targeted_rebalancing,
        help="Rebalance at the next scheduled rebalancing date when ticker allocations exceed min/max thresholds. Does not trigger immediate rebalancing, only checks thresholds on rebalance dates."
    )

    # Update active portfolio with current targeted rebalancing state
    active_portfolio['use_targeted_rebalancing'] = st.session_state.get("multi_backtest_active_use_targeted_rebalancing", False)

    if st.session_state.get("multi_backtest_active_use_targeted_rebalancing", False):
        st.markdown("**Configure per-ticker allocation limits:**")
        st.markdown("üí° *Example: TQQQ 70-40% means if TQQQ goes above 70%, sell to buy others; if below 40%, buy TQQQ with others*")
    
        # Get current tickers
        stocks_list = active_portfolio.get('stocks', [])
        current_tickers = [s['ticker'] for s in stocks_list if s.get('ticker')]
        
        if current_tickers:
            # Initialize targeted rebalancing settings for each ticker
            if 'targeted_rebalancing_settings' not in active_portfolio:
                active_portfolio['targeted_rebalancing_settings'] = {}
            
            for ticker in current_tickers:
                if ticker not in active_portfolio.get('targeted_rebalancing_settings', {}):
                    if 'targeted_rebalancing_settings' not in active_portfolio:
                        active_portfolio['targeted_rebalancing_settings'] = {}
                    active_portfolio['targeted_rebalancing_settings'][ticker] = {
                        'enabled': False,
                        'min_allocation': 0.0,
                        'max_allocation': 100.0
                    }
            
            # Create columns for ticker settings
            cols = st.columns(min(len(current_tickers), 3))
            
            for i, ticker in enumerate(current_tickers):
                with cols[i % 3]:
                    st.markdown(f"**{ticker}**")
                    
                    # Enable/disable for this ticker
                    enabled_key = f"multi_backtest_targeted_rebalancing_enabled_{ticker}_{st.session_state.multi_backtest_active_portfolio_index}"
                    if enabled_key not in st.session_state:
                        st.session_state[enabled_key] = active_portfolio['targeted_rebalancing_settings'][ticker]['enabled']
                    
                    enabled = st.checkbox(
                        "Enable", 
                        key=enabled_key,
                        help=f"Enable targeted rebalancing for {ticker}"
                    )
                    active_portfolio['targeted_rebalancing_settings'][ticker]['enabled'] = enabled
                    
                    if enabled:
                        # Max allocation (on top)
                        max_key = f"multi_backtest_targeted_rebalancing_max_{ticker}_{st.session_state.multi_backtest_active_portfolio_index}"
                        if max_key not in st.session_state:
                            st.session_state[max_key] = active_portfolio['targeted_rebalancing_settings'][ticker]['max_allocation']
                        
                        max_allocation = st.number_input(
                            "Max %", 
                            min_value=0.0, 
                            max_value=100.0, 
                            step=0.1,
                            key=max_key,
                            help=f"Maximum allocation percentage for {ticker}"
                        )
                        active_portfolio['targeted_rebalancing_settings'][ticker]['max_allocation'] = max_allocation
                        
                        # Min allocation (below)
                        min_key = f"multi_backtest_targeted_rebalancing_min_{ticker}_{st.session_state.multi_backtest_active_portfolio_index}"
                        if min_key not in st.session_state:
                            st.session_state[min_key] = active_portfolio['targeted_rebalancing_settings'][ticker]['min_allocation']
                        
                        min_allocation = st.number_input(
                            "Min %", 
                            min_value=0.0, 
                            max_value=100.0, 
                            step=0.1,
                            key=min_key,
                            help=f"Minimum allocation percentage for {ticker}"
                        )
                        active_portfolio['targeted_rebalancing_settings'][ticker]['min_allocation'] = min_allocation
                        
                        # Validation
                        if min_allocation >= max_allocation:
                            st.error(f"Min % must be less than Max % for {ticker}")
        else:
            st.info("Add tickers to configure targeted rebalancing settings.")
else:
    # Hide targeted rebalancing when MA filter is enabled
    # Don't modify session state directly - let the checkbox handle it
    # st.session_state["multi_backtest_active_use_targeted_rebalancing"] = False
    active_portfolio['use_targeted_rebalancing'] = False

with st.expander("JSON Configuration (Copy & Paste)", expanded=False):
    # Clean portfolio config for export by removing unused settings
    cleaned_config = active_portfolio.copy()
    cleaned_config.pop('use_relative_momentum', None)
    cleaned_config.pop('equal_if_all_negative', None)
    # Update global settings from session state
    cleaned_config['start_with'] = st.session_state.get('multi_backtest_start_with', 'all')
    cleaned_config['first_rebalance_strategy'] = st.session_state.get('multi_backtest_first_rebalance_strategy', 'momentum_window_complete')
    
    # Update custom dates from global session state if enabled
    if st.session_state.get('multi_backtest_use_custom_dates', False):
        cleaned_config['start_date_user'] = st.session_state.get('multi_backtest_start_date')
        cleaned_config['end_date_user'] = st.session_state.get('multi_backtest_end_date')
    
    # Update targeted rebalancing settings from session state
    cleaned_config['use_targeted_rebalancing'] = st.session_state.get('multi_backtest_active_use_targeted_rebalancing', False)
    cleaned_config['targeted_rebalancing_settings'] = active_portfolio.get('targeted_rebalancing_settings', {})
    
    # Use portfolio-specific MA Filter keys
    portfolio_index = st.session_state.multi_backtest_active_portfolio_index
    ma_filter_key = f"multi_backtest_active_use_sma_filter_{portfolio_index}"
    ma_window_key = f"multi_backtest_active_ma_window_{portfolio_index}"
    ma_type_key = f"multi_backtest_active_ma_type_{portfolio_index}"
    cleaned_config['use_sma_filter'] = st.session_state.get(ma_filter_key, False)
    cleaned_config['sma_window'] = st.session_state.get(ma_window_key, 200)
    cleaned_config['ma_type'] = st.session_state.get(ma_type_key, 'SMA')
    # MA Multiplier is handled by the widget itself
    
    # Add MA cross rebalance setting
    ma_cross_rebalance_key = f"multi_backtest_active_ma_cross_rebalance_{portfolio_index}"
    cleaned_config['ma_cross_rebalance'] = st.session_state.get(ma_cross_rebalance_key, False)
    
    # Add anti-whipsaw settings
    ma_tolerance_key = f"multi_backtest_active_ma_tolerance_{portfolio_index}"
    ma_delay_key = f"multi_backtest_active_ma_delay_{portfolio_index}"
    cleaned_config['ma_tolerance_percent'] = st.session_state.get(ma_tolerance_key, 2.0)
    cleaned_config['ma_confirmation_days'] = st.session_state.get(ma_delay_key, 3)
    
    # Also update the active portfolio to keep it in sync
    active_portfolio['use_targeted_rebalancing'] = st.session_state.get('multi_backtest_active_use_targeted_rebalancing', False)
    active_portfolio['use_sma_filter'] = st.session_state.get(ma_filter_key, False)
    active_portfolio['sma_window'] = st.session_state.get(ma_window_key, 200)
    active_portfolio['ma_type'] = st.session_state.get(ma_type_key, 'SMA')
    # MA Multiplier - RECONSTRUCTED (no complex sync)
    
    # Convert date objects to strings for JSON serialization
    if cleaned_config.get('start_date_user') is not None:
        cleaned_config['start_date_user'] = cleaned_config['start_date_user'].isoformat() if hasattr(cleaned_config['start_date_user'], 'isoformat') else str(cleaned_config['start_date_user'])
    if cleaned_config.get('end_date_user') is not None:
        cleaned_config['end_date_user'] = cleaned_config['end_date_user'].isoformat() if hasattr(cleaned_config['end_date_user'], 'isoformat') else str(cleaned_config['end_date_user'])
    
    config_json = json.dumps(cleaned_config, indent=4)
    st.code(config_json, language='json')
    # Fixed JSON copy button
    import streamlit.components.v1 as components
    copy_html = f"""
    <button onclick='navigator.clipboard.writeText({json.dumps(config_json)});' style='margin-bottom:10px;'>Copy to Clipboard</button>
    """
    components.html(copy_html, height=40)
    
    # Add PDF download button for individual portfolio JSON
    def generate_individual_json_pdf(custom_name=""):
        """Generate a PDF with pure JSON content only for easy CTRL+A / CTRL+V copying."""
        from reportlab.lib.pagesizes import letter, A4
        from reportlab.platypus import SimpleDocTemplate, Preformatted
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        import io
        from datetime import datetime
        
        # Create PDF buffer
        buffer = io.BytesIO()
        
        # Add proper PDF metadata
        portfolio_name = active_portfolio.get('name', 'Portfolio')
        
        # Use custom name if provided, otherwise use portfolio name
        if custom_name.strip():
            title = f"Multi Backtest - {custom_name.strip()} - JSON Configuration"
            subject = f"JSON Configuration: {custom_name.strip()}"
        else:
            title = f"Multi Backtest - {portfolio_name} - JSON Configuration"
            subject = f"JSON Configuration for {portfolio_name}"
        
        doc = SimpleDocTemplate(
            buffer, 
            pagesize=A4, 
            rightMargin=36, 
            leftMargin=36, 
            topMargin=36, 
            bottomMargin=36,
            title=title,
            author="Portfolio Backtest System",
            subject=subject,
            creator="Multi Backtest Application"
        )
        story = []
        
        # Pure JSON style - just monospace text
        json_style = ParagraphStyle(
            'PureJSONStyle',
            fontName='Courier',
            fontSize=10,
            leading=12,
            leftIndent=0,
            rightIndent=0,
            spaceAfter=0,
            spaceBefore=0
        )
        
        # Add only the JSON content - no headers, no instructions, just pure JSON
        json_lines = config_json.split('\n')
        for line in json_lines:
            story.append(Preformatted(line, json_style))
        
        # Build PDF
        doc.build(story)
        pdf_data = buffer.getvalue()
        buffer.close()
        
        return pdf_data
    
    # Optional custom PDF name for individual portfolio
    custom_individual_pdf_name = st.text_input(
        "üìù Custom Portfolio JSON PDF Name (optional):", 
        value="",
        placeholder=f"e.g., {active_portfolio.get('name', 'Portfolio')} Configuration, Custom Setup Analysis",
        help="Leave empty to use automatic naming based on portfolio name",
        key="multi_individual_custom_pdf_name"
    )
    
    if st.button("üìÑ Download JSON as PDF", help="Download a PDF containing the JSON configuration for easy copying", key="multi_individual_json_pdf_btn"):
        try:
            pdf_data = generate_individual_json_pdf(custom_individual_pdf_name)
            
            # Generate filename based on custom name or default
            if custom_individual_pdf_name.strip():
                clean_name = custom_individual_pdf_name.strip().replace(' ', '_').replace('/', '_').replace('\\', '_')
                filename = f"{clean_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
            else:
                filename = f"multi_portfolio_{active_portfolio.get('name', 'portfolio').replace(' ', '_')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
            
            st.download_button(
                label="üíæ Download Portfolio JSON PDF",
                data=pdf_data,
                file_name=filename,
                mime="application/pdf",
                key="multi_individual_json_pdf_download"
            )
            st.success("PDF generated successfully! Click the download button above.")
        except Exception as e:
            st.error(f"Error generating PDF: {str(e)}")
    
    st.text_area("Paste JSON Here to Update Portfolio", key="multi_backtest_paste_json_text", height=200)
    st.button("Update with Pasted JSON", on_click=paste_json_callback)
    
    # Add PDF drag and drop functionality
    st.markdown("**OR** üìé **Drag & Drop JSON PDF:**")
    
    def extract_json_from_pdf(pdf_file):
        """Extract JSON content from a PDF file."""
        try:
            # Try pdfplumber first (more reliable)
            try:
                import pdfplumber
                import io
                
                # Read PDF content with pdfplumber
                pdf_bytes = io.BytesIO(pdf_file.read())
                text_content = ""
                
                with pdfplumber.open(pdf_bytes) as pdf:
                    for page in pdf.pages:
                        text_content += page.extract_text() or ""
                        
            except ImportError:
                # Fallback to PyPDF2 if pdfplumber not available
                try:
                    import PyPDF2
                    import io
                    
                    # Reset file pointer
                    pdf_file.seek(0)
                    pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
                    
                    # Extract text from all pages
                    text_content = ""
                    for page in pdf_reader.pages:
                        text_content += page.extract_text()
                        
                except ImportError:
                    return None, "PDF extraction libraries not available. Please install 'pip install PyPDF2' or 'pip install pdfplumber'"
            
            # Clean up the text and try to parse as JSON
            cleaned_text = text_content.strip()
            
            # Try to parse as JSON
            import json
            json_data = json.loads(cleaned_text)
            return json_data, None
            
        except json.JSONDecodeError as e:
            return None, f"Invalid JSON in PDF: {str(e)}"
        except Exception as e:
            return None, str(e)
    
    uploaded_pdf = st.file_uploader(
        "Drop your JSON PDF here", 
        type=['pdf'], 
        help="Upload a JSON PDF file generated by this app to automatically load the configuration",
        key="multi_individual_pdf_upload"
    )
    
    if uploaded_pdf is not None:
        json_data, error = extract_json_from_pdf(uploaded_pdf)
        if json_data:
            # Store the extracted JSON in a different session state key to avoid widget conflicts
            st.session_state["multi_backtest_extracted_json"] = json.dumps(json_data, indent=4)
            st.success(f"‚úÖ Successfully extracted JSON from {uploaded_pdf.name}")
            st.info("üëá Click the button below to load the JSON into the text area.")
            def load_extracted_json():
                st.session_state["multi_backtest_paste_json_text"] = st.session_state["multi_backtest_extracted_json"]
            
            st.button("üìã Load Extracted JSON", key="load_extracted_json", on_click=load_extracted_json)
        else:
            st.error(f"‚ùå Failed to extract JSON from PDF: {error}")
            st.info("üí° Make sure the PDF contains valid JSON content (generated by this app)")

    # End of regular portfolio editing interface

# Validation constants
_TOTAL_TOL = 1.0
_ALLOC_TOL = 1.0

# Cancel Run Button
if st.sidebar.button("üõë Cancel Run", type="secondary", use_container_width=True, help="Stop current backtest execution gracefully"):
    st.session_state.hard_kill_requested = True
    st.toast("üõë **CANCELLING** - Stopping backtest execution...", icon="‚èπÔ∏è")
    st.rerun()

# Emergency Stop Button (Second Option)
if st.sidebar.button("üõë EMERGENCY STOP", type="secondary", use_container_width=True, help="Stop backtest gracefully - Use when backtest is running normally"):
    st.toast("üõë **EMERGENCY STOP** - Stopping backtest gracefully...", icon="‚èπÔ∏è")
    st.session_state.hard_kill_requested = True
    st.rerun()

# Emergency Kill Button (Last Resort)
if st.sidebar.button("üö® EMERGENCY KILL", type="secondary", use_container_width=True, help="Force terminate all processes immediately - Use for crashes, freezes, or unresponsive states"):
    st.toast("üö® **EMERGENCY KILL** - Force terminating all processes...", icon="üí•")
    emergency_kill()


# Move Run Backtest to the left sidebar to make it conspicuous and separate from config
if st.sidebar.button("üöÄ Run Backtest", type="primary", use_container_width=True):
    # Reset kill request when starting new backtest
    st.session_state.hard_kill_requested = False
    
    # Pre-backtest validation check for all portfolios
    configs_to_run = st.session_state.multi_backtest_portfolio_configs
    valid_configs = True
    validation_errors = []
    
    for cfg in configs_to_run:
        # Check if this is a fusion portfolio
        is_fusion = 'fusion_portfolio' in cfg and cfg['fusion_portfolio'].get('enabled', False)
        if is_fusion:
            fusion_config = cfg['fusion_portfolio']
            selected_portfolios = fusion_config.get('selected_portfolios', [])
            allocations = fusion_config.get('allocations', {})
            
            # Validate fusion portfolio
            if not selected_portfolios:
                validation_errors.append(f"Fusion portfolio '{cfg['name']}' has no portfolios selected")
                valid_configs = False
            else:
                # Check if all selected portfolios exist
                available_portfolio_names = [p['name'] for p in configs_to_run]
                for portfolio_name in selected_portfolios:
                    if portfolio_name not in available_portfolio_names:
                        validation_errors.append(f"Fusion portfolio '{cfg['name']}' references non-existent portfolio '{portfolio_name}'")
                        valid_configs = False
                
                # Check if allocations sum to 1.0
                total_allocation = sum(allocations.values())
                if abs(total_allocation - 1.0) > 0.01:
                    validation_errors.append(f"Fusion portfolio '{cfg['name']}' total allocation is {total_allocation*100:.2f}% (must be 100%)")
                    valid_configs = False
        elif not is_fusion:
            # Regular portfolio validation (only if not a fusion portfolio)
            if cfg['use_momentum']:
                total_momentum_weight = sum(w['weight'] for w in cfg['momentum_windows'])
                if abs(total_momentum_weight - 1.0) > (_TOTAL_TOL / 100.0):
                    validation_errors.append(f"Portfolio '{cfg['name']}' has momentum enabled but the total momentum weight is {total_momentum_weight*100:.2f}% (must be 100%)")
                    valid_configs = False
            else:
                valid_stocks_for_cfg = [s for s in cfg['stocks'] if s['ticker']]
                total_stock_allocation = sum(s['allocation'] for s in valid_stocks_for_cfg)
                if abs(total_stock_allocation - 1.0) > (_ALLOC_TOL / 100.0):
                    validation_errors.append(f"Portfolio '{cfg['name']}' is not using momentum, but the total ticker allocation is {total_stock_allocation*100:.2f}% (must be 100%)")
                    valid_configs = False
                
    if not valid_configs:
        for error in validation_errors:
            st.error(error)
        # Don't run the backtest, but continue showing the UI
        pass
    else:
        # Show standalone popup notification that code is really running
        st.toast("**Code is running!** Starting backtest...", icon="üöÄ")
        
        progress_bar = st.empty()
        progress_bar.progress(0, text="Initializing multi-portfolio backtest...")
        
        # Emergency stop button will be added during actual backtest execution
        
        # Check for kill request
        check_kill_request()
        
        # Get all tickers first
        all_tickers = sorted(list(set(s['ticker'] for cfg in st.session_state.multi_backtest_portfolio_configs for s in cfg['stocks'] if s['ticker']) | set(cfg['benchmark_ticker'] for cfg in st.session_state.multi_backtest_portfolio_configs if 'benchmark_ticker' in cfg)))
        all_tickers = [t for t in all_tickers if t]
        
        # CRITICAL FIX: Add base tickers for leveraged tickers to ensure dividend data is available
        base_tickers_to_add = set()
        for ticker in all_tickers:
            if "?L=" in ticker or "?E=" in ticker:
                base_ticker, leverage, expense_ratio = parse_ticker_parameters(ticker)
                base_tickers_to_add.add(base_ticker)

        # Add base tickers to the list if they're not already there
        for base_ticker in base_tickers_to_add:
            if base_ticker not in all_tickers:
                all_tickers.append(base_ticker)
        
        # CRITICAL FIX: Add MA reference tickers to ensure they are downloaded
        ma_reference_tickers_to_add = set()
        for cfg in st.session_state.multi_backtest_portfolio_configs:
            # Only collect MA reference tickers if MA filter is enabled
            if cfg.get('use_sma_filter', False):
                for stock in cfg.get('stocks', []):
                    ma_ref_ticker = stock.get('ma_reference_ticker', '').strip()
                    # If a custom reference ticker is specified (not empty)
                    if ma_ref_ticker:
                        # Resolve aliases (e.g., TLTTR -> TLT_COMPLETE, GOLDX -> GOLD_COMPLETE)
                        resolved_ma_ref = resolve_ticker_alias(ma_ref_ticker)
                        if resolved_ma_ref not in all_tickers:
                            ma_reference_tickers_to_add.add(resolved_ma_ref)
        
        # Add MA reference tickers to the download list
        for ma_ref_ticker in ma_reference_tickers_to_add:
            if ma_ref_ticker not in all_tickers:
                all_tickers.append(ma_ref_ticker)
        
        
        # BULLETPROOF VALIDATION: Check for empty ticker list first
        if not all_tickers:
            st.error("‚ùå **No valid tickers found!** Please add at least one ticker to your portfolios before running the backtest.")
            progress_bar.empty()
            st.session_state.multi_all_results = None
            st.session_state.multi_all_allocations = None
            st.session_state.multi_all_metrics = None
            st.stop()
        
        buffer = io.StringIO()
        with contextlib.redirect_stdout(buffer):
            data = {}
            invalid_tickers = []
            
            # Handle special dynamic tickers - expand them to individual tickers
            special_tickers = [t for t in all_tickers if is_special_dynamic_ticker(t)]
            individual_tickers_to_download = set()
            
            for special_ticker in special_tickers:
                dynamic_data = get_dynamic_portfolio_data(special_ticker)
                if dynamic_data:
                    individual_tickers_to_download.update(dynamic_data['tickers'])
            
            # Combine regular tickers with individual tickers from special tickers
            all_tickers_to_download = set(all_tickers) | individual_tickers_to_download
            # Remove special tickers from download list (we'll handle them separately)
            all_tickers_to_download = [t for t in all_tickers_to_download if not is_special_dynamic_ticker(t)]
            
            total_downloads = len(all_tickers_to_download) + len(special_tickers)
            download_count = 0
            
            # OPTIMIZED: Batch download with smart fallback
            progress_text = f"Downloading data for {len(all_tickers_to_download)} tickers (batch mode)..."
            progress_bar.progress(0.1, text=progress_text)
            
            # Check for kill request before batch
            check_kill_request()
            
            # Use batch download for all regular tickers (much faster!)
            batch_results = get_multiple_tickers_batch(list(all_tickers_to_download), period="max", auto_adjust=False)
            
            # Process batch results
            for t in all_tickers_to_download:
                download_count += 1
                progress_text = f"Processing {t} ({download_count}/{total_downloads})..."
                progress_bar.progress(download_count / total_downloads, text=progress_text)
                
                hist = batch_results.get(t, pd.DataFrame())
                
                if hist.empty:
                    invalid_tickers.append(t)
                    continue
                
                try:
                    # Force tz-naive for hist (like Backtest_Engine.py)
                    hist = hist.copy()
                    hist.index = hist.index.tz_localize(None)
                    
                    hist["Price_change"] = hist["Close"].pct_change(fill_method=None).fillna(0)
                    data[t] = hist
                except Exception as e:
                    invalid_tickers.append(t)
            
            # Add special tickers to data with placeholder (they'll be handled in backtest)
            for special_ticker in special_tickers:
                download_count += 1
                progress_text = f"Processing special ticker {special_ticker} ({download_count}/{total_downloads})..."
                progress_bar.progress(download_count / total_downloads, text=progress_text)
                data[special_ticker] = "special_dynamic_ticker"
            # Display invalid ticker warnings in Streamlit UI
            if invalid_tickers:
                # Separate portfolio tickers from benchmark tickers
                portfolio_tickers = set(s['ticker'] for cfg in st.session_state.multi_backtest_portfolio_configs for s in cfg['stocks'] if s['ticker'])
                benchmark_tickers = set(cfg.get('benchmark_ticker') for cfg in st.session_state.multi_backtest_portfolio_configs if 'benchmark_ticker' in cfg)
                
                # Filter out special tickers from invalid list since they don't need data download
                portfolio_invalid = [t for t in invalid_tickers if t in portfolio_tickers and not is_special_dynamic_ticker(t)]
                benchmark_invalid = [t for t in invalid_tickers if t in benchmark_tickers and not is_special_dynamic_ticker(t)]
                
                if portfolio_invalid:
                    st.warning(f"The following portfolio tickers are invalid and will be skipped: {', '.join(portfolio_invalid)}")
                if benchmark_invalid:
                    st.warning(f"The following benchmark tickers are invalid and will be skipped: {', '.join(benchmark_invalid)}")
            
            # BULLETPROOF VALIDATION: Check for valid tickers and stop gracefully if none
            # But don't count special tickers as invalid
            special_tickers_in_portfolio = [t for t in all_tickers if is_special_dynamic_ticker(t)]
            regular_tickers = [t for t in all_tickers if not is_special_dynamic_ticker(t)]
            valid_regular_tickers = [t for t in regular_tickers if t in data]
            
            if not data and not special_tickers_in_portfolio:
                if invalid_tickers and len(invalid_tickers) == len(regular_tickers):
                    st.error(f"‚ùå **No valid tickers found!** All regular tickers are invalid: {', '.join(invalid_tickers)}. Please check your ticker symbols and try again.")
                else:
                    st.error("‚ùå **No valid tickers found!** No data downloaded; aborting.")
                progress_bar.empty()
                st.session_state.multi_all_results = None
                st.session_state.multi_all_allocations = None
                st.session_state.multi_all_metrics = None
                st.stop()
            else:
                # Persist raw downloaded price data so later recomputations can access benchmark series
                st.session_state.multi_backtest_raw_data = data
                # Determine common date range for all portfolios (filter out special ticker placeholders)
                valid_data_frames = [df for df in data.values() if not isinstance(df, str)]
                if valid_data_frames:
                    common_start = max(df.first_valid_index() for df in valid_data_frames)
                    common_end = min(df.last_valid_index() for df in valid_data_frames)
                else:
                    # Fallback if no valid data frames (e.g., only special tickers)
                    # Use a reasonable default date range for special tickers
                    common_start = pd.Timestamp('1989-01-01')  # Start of S&P 500 data
                    common_end = pd.Timestamp.now()
                
                # Get all portfolio tickers (excluding benchmarks)
                all_portfolio_tickers = set()
                for cfg in st.session_state.multi_backtest_portfolio_configs:
                    portfolio_tickers = [s['ticker'] for s in cfg['stocks'] if s['ticker']]
                    all_portfolio_tickers.update(portfolio_tickers)
                
                # Check for non-USD tickers and display currency warning
                check_currency_warning(list(all_portfolio_tickers))
                
                # Determine final start date based on global start_with setting
                # Filter to only valid tickers that exist in data
                valid_portfolio_tickers = [t for t in all_portfolio_tickers if t in data]
                
                if not valid_portfolio_tickers:
                    st.error("‚ùå **No valid tickers found!** None of your portfolio tickers have data available. Please check your ticker symbols and try again.")
                    progress_bar.empty()
                    st.session_state.multi_all_results = None
                    st.session_state.multi_all_allocations = None
                    st.session_state.multi_all_metrics = None
                    st.stop()
                
                global_start_with = st.session_state.get('multi_backtest_start_with', 'all')
                if global_start_with == 'all':
                    # Filter out special ticker placeholders when calculating start date
                    valid_ticker_data = [data[t] for t in valid_portfolio_tickers if not isinstance(data[t], str)]
                    if valid_ticker_data:
                        final_start = max(df.first_valid_index() for df in valid_ticker_data)
                    else:
                        # Fallback for special tickers only - use a reasonable start date
                        final_start = pd.Timestamp('1989-01-01')
                else:  # global_start_with == 'oldest'
                    # For 'oldest', we need to find the portfolio that starts the LATEST
                    # (has the most recent earliest asset), then use that portfolio's earliest asset
                    portfolio_earliest_dates = {}
                    for cfg in st.session_state.multi_backtest_portfolio_configs:
                        portfolio_tickers = [stock['ticker'] for stock in cfg.get('stocks', []) if stock['ticker']]
                        valid_portfolio_tickers_for_cfg = [t for t in portfolio_tickers if t in data]
                        if valid_portfolio_tickers_for_cfg:
                            # Find the earliest asset in this portfolio (filter out special ticker placeholders)
                            valid_ticker_data_for_cfg = [data[t] for t in valid_portfolio_tickers_for_cfg if not isinstance(data[t], str)]
                            if valid_ticker_data_for_cfg:
                                portfolio_earliest = min(df.first_valid_index() for df in valid_ticker_data_for_cfg)
                                portfolio_earliest_dates[cfg['name']] = portfolio_earliest
                    
                    if portfolio_earliest_dates:
                        # Find the portfolio with the LATEST earliest asset
                        latest_starting_portfolio = max(portfolio_earliest_dates.items(), key=lambda x: x[1])
                        final_start = latest_starting_portfolio[1]
                    else:
                        # Fallback to original logic (filter out special ticker placeholders)
                        valid_ticker_data = [data[t] for t in valid_portfolio_tickers if not isinstance(data[t], str)]
                        if valid_ticker_data:
                            final_start = min(df.first_valid_index() for df in valid_ticker_data)
                        else:
                            # Fallback for special tickers only - use a reasonable start date
                            final_start = pd.Timestamp('1989-01-01')
                
                # Apply user date constraints if any
                for cfg in st.session_state.multi_backtest_portfolio_configs:
                    if cfg.get('start_date_user'):
                        user_start = pd.to_datetime(cfg['start_date_user'])
                        final_start = max(final_start, user_start)
                    if cfg.get('end_date_user'):
                        user_end = pd.to_datetime(cfg['end_date_user'])
                        common_end = min(common_end, user_end)
                
                if final_start > common_end:
                    problematic_ranges = []
                    for ticker, df in data.items():
                        if isinstance(df, pd.DataFrame):
                            first_idx = df.first_valid_index()
                            last_idx = df.last_valid_index()
                            if first_idx is not None and first_idx > common_end:
                                problematic_ranges.append(f"{ticker}: starts {first_idx.date()} (after {common_end.date()})")
                            elif last_idx is not None and last_idx < final_start:
                                problematic_ranges.append(f"{ticker}: ends {last_idx.date()} (before {final_start.date()})")
                    if problematic_ranges:
                        st.warning("Data availability issue detected for:\n- " + "\n- ".join(problematic_ranges))
                    st.error(f"Start date {final_start.date()} is after end date {common_end.date()}. Cannot proceed.")
                    st.stop()
                
                # Create simulation index for the entire period
                simulation_index = pd.date_range(start=final_start, end=common_end, freq='D')
                
                # Reindex all data to the simulation period (all tickers that have data)
                data_reindexed = {}
                # Process ALL tickers in data, not just all_tickers (to include individual tickers from special tickers)
                for t in data.keys():
                    if t in data:  # Only process tickers that have data
                        ticker_data = data[t]
                        # Skip special ticker placeholders (they'll be handled in special backtest functions)
                        if isinstance(ticker_data, str):
                            data_reindexed[t] = ticker_data  # Keep as string for special handling
                        else:
                            # Regular ticker data - reindex it
                            df = ticker_data.reindex(simulation_index)
                            df["Close"] = df["Close"].ffill()
                            df["Dividends"] = df["Dividends"].fillna(0)
                            df["Price_change"] = df["Close"].pct_change(fill_method=None).fillna(0)
                            data_reindexed[t] = df
                
                
                progress_bar.progress(1.0, text="Executing multi-portfolio backtest analysis...")
                
                # Emergency stop is now handled by the existing emergency_kill function
                
                # =============================================================================
                # SIMPLE, FAST, AND RELIABLE PORTFOLIO PROCESSING (CACHED VERSION)
                # =============================================================================
                
                # Initialize results storage
                all_results = {}
                all_drawdowns = {}
                all_stats = {}
                all_allocations = {}
                all_metrics = {}
                portfolio_key_map = {}
                successful_portfolios = 0
                failed_portfolios = []
                
                st.info(f"**Processing {len(st.session_state.multi_backtest_portfolio_configs)} portfolios (with 4h ticker cache)...**")
                
                # Start timing for performance measurement
                import time as time_module
                start_time = time_module.time()
                
                # Separate regular and fusion portfolios for two-phase processing
                regular_portfolios = []
                fusion_portfolios = []
                
                for i, cfg in enumerate(st.session_state.multi_backtest_portfolio_configs, start=1):
                    if 'fusion_portfolio' in cfg and cfg['fusion_portfolio'].get('enabled', False):
                        fusion_portfolios.append((i, cfg))
                    else:
                        regular_portfolios.append((i, cfg))
                
                # Process portfolios in parallel for maximum speed
                def process_single_regular_portfolio(args):
                    """Process a single regular portfolio - designed for parallel execution"""
                    i, cfg = args
                    try:
                        # Suppress Streamlit warnings in threads
                        import warnings
                        import logging
                        warnings.filterwarnings('ignore', message='.*ScriptRunContext.*')
                        logging.getLogger("streamlit.runtime.scriptrunner.script_runner").setLevel(logging.ERROR)
                        
                        # Check for kill request immediately
                        if st.session_state.get('hard_kill_requested', False):
                            return {
                                'index': i,
                                'success': False,
                                'error': 'Kill requested before processing'
                            }
                        
                        # Set a global kill flag for this thread
                        import threading
                        threading.current_thread().kill_requested = False
                        
                        # Add a more aggressive kill check mechanism
                        def check_kill_request():
                            return st.session_state.get('hard_kill_requested', False)
                        
                        # Check kill request every 5 iterations in the main processing loop
                        kill_check_counter = 0
                        
                        # Add kill check in the main processing loop
                        def check_kill_in_loop():
                            nonlocal kill_check_counter
                            kill_check_counter += 1
                            if kill_check_counter % 5 == 0:
                                return check_kill_request()
                            return False
                        
                        name = cfg.get('name', f'Portfolio {i}')
                        
                        # Check if this portfolio contains a special dynamic ticker
                        has_special_ticker = any(is_special_dynamic_ticker(stock['ticker']) for stock in cfg['stocks'])
                        
                        if has_special_ticker:
                            # Use year-aware backtest for dynamic tickers
                            total_series, total_series_no_additions, historical_allocations, historical_metrics, today_weights_map = single_backtest_year_aware(cfg, simulation_index, data_reindexed)
                        else:
                            # Regular backtest for normal tickers
                            total_series, total_series_no_additions, historical_allocations, historical_metrics = single_backtest(cfg, simulation_index, data_reindexed)
                        # Compute today_weights_map for regular portfolios
                        today_weights_map = {}
                        try:
                            alloc_dates = sorted(list(historical_allocations.keys()))
                            if alloc_dates:
                                final_d = alloc_dates[-1]
                                metrics_local = historical_metrics
                                
                                # Check if momentum is used for this portfolio
                                use_momentum = cfg.get('use_momentum', True)
                                
                                if final_d in metrics_local:
                                    if use_momentum:
                                        # Extract Calculated_Weight if present (momentum-based)
                                        weights = {t: v.get('Calculated_Weight', 0) for t, v in metrics_local[final_d].items()}
                                        # Normalize (ensure sums to 1 excluding CASH)
                                        sumw = sum(w for k, w in weights.items() if k != 'CASH')
                                        if sumw > 0:
                                            norm = {k: (w / sumw) if k != 'CASH' else weights.get('CASH', 0) for k, w in weights.items()}
                                        else:
                                            norm = weights
                                        today_weights_map = norm
                                    else:
                                        # Use user-defined allocations from portfolio config
                                        today_weights_map = {}
                                        for stock in cfg.get('stocks', []):
                                            ticker = stock.get('ticker', '').strip()
                                            if ticker:
                                                today_weights_map[ticker] = stock.get('allocation', 0)
                                        
                                        # Apply MA filter even when momentum is disabled
                                        if cfg.get('use_sma_filter', False):
                                            ma_window = cfg.get('sma_window', 200)
                                            ma_type = cfg.get('ma_type', 'SMA')
                                            # Get list of current tickers (excluding CASH)
                                            current_tickers = [t for t in today_weights_map.keys() if t != 'CASH']
                                            
                                            # Apply MA filter using data_reindexed (ULTRA OPTIMIZED!)
                                            try:
                                                # ULTRA FAST: Use precomputed filter results if available!
                                                if hasattr(cfg, '_ma_filter_data') and cfg._ma_filter_data is not None:
                                                    filtered_tickers = [t for t in current_tickers if cfg._ma_filter_data.get(final_d, {}).get(t, True)]
                                                    excluded_assets = {t: f"Below MA" for t in current_tickers if t not in filtered_tickers}
                                                else:
                                                    # Fallback to original method if not precomputed
                                                    filtered_tickers, excluded_assets = filter_assets_by_ma(current_tickers, data_reindexed, final_d, ma_window, ma_type, cfg, cfg.get('stocks', []))
                                                
                                                # Redistribute allocations of excluded tickers
                                                if excluded_assets:
                                                    excluded_ticker_list = list(excluded_assets.keys())
                                                    excluded_allocation = sum(today_weights_map.get(t, 0) for t in excluded_ticker_list)
                                                    
                                                    # Remove excluded tickers
                                                    for excluded_ticker in excluded_ticker_list:
                                                        if excluded_ticker in today_weights_map:
                                                            del today_weights_map[excluded_ticker]
                                                    
                                                    # Redistribute to remaining tickers
                                                    remaining_tickers = [t for t in today_weights_map.keys() if t != 'CASH']
                                                    if remaining_tickers:
                                                        remaining_allocation = sum(today_weights_map.get(t, 0) for t in remaining_tickers)
                                                        if remaining_allocation > 0:
                                                            for ticker in remaining_tickers:
                                                                proportion = today_weights_map[ticker] / remaining_allocation
                                                                today_weights_map[ticker] += excluded_allocation * proportion
                                                        else:
                                                            # Equal distribution
                                                            equal_allocation = excluded_allocation / len(remaining_tickers)
                                                            for ticker in remaining_tickers:
                                                                today_weights_map[ticker] = equal_allocation
                                                    else:
                                                        # No remaining tickers, all goes to CASH
                                                        today_weights_map = {'CASH': 1.0}
                                            except Exception as e:
                                                # If MA filter fails, keep original allocations
                                                pass
                                        
                                        # Add CASH if needed (after MA filter)
                                        if 'CASH' not in today_weights_map:
                                            total_alloc = sum(today_weights_map.values())
                                            if total_alloc < 1.0:
                                                today_weights_map['CASH'] = 1.0 - total_alloc
                                            else:
                                                today_weights_map['CASH'] = 0
                                        
                                        # For targeted rebalancing: check if rebalancing would be triggered today
                                        # If no rebalancing needed, show current allocation instead of target allocation
                                        if cfg.get('use_targeted_rebalancing', False):
                                            # Get current allocation from historical_allocations (drifted)
                                            current_alloc = historical_allocations.get(final_d, {})
                                            
                                            # Check if any threshold is exceeded
                                            targeted_settings = cfg.get('targeted_rebalancing_settings', {})
                                            threshold_exceeded = False
                                            
                                            for ticker in current_alloc.keys():
                                                if ticker != 'CASH' and ticker in targeted_settings and targeted_settings[ticker].get('enabled', False):
                                                    current_allocation_pct = current_alloc.get(ticker, 0) * 100
                                                    max_threshold = targeted_settings[ticker].get('max_allocation', 100.0)
                                                    min_threshold = targeted_settings[ticker].get('min_allocation', 0.0)
                                                    
                                                    # Check if allocation exceeds max or falls below min threshold
                                                    if current_allocation_pct > max_threshold or current_allocation_pct < min_threshold:
                                                        threshold_exceeded = True
                                                        break
                                            
                                            # If no threshold exceeded, use current (drifted) allocation instead of target
                                            if not threshold_exceeded and current_alloc:
                                                today_weights_map = current_alloc.copy()
                                
                                else:
                                    # Fallback: use allocation snapshot at final date
                                    final_alloc = historical_allocations.get(final_d, {})
                                    noncash = {k: v for k, v in final_alloc.items() if k != 'CASH'}
                                    s = sum(noncash.values())
                                    if s > 0:
                                        norm = {k: (v / s) for k, v in noncash.items()}
                                        norm['CASH'] = final_alloc.get('CASH', 0)
                                    else:
                                        norm = final_alloc
                                        today_weights_map = norm
                        except Exception as e:
                            # If computation fails, use user-defined allocations as fallback
                            today_weights_map = {}
                            for stock in cfg.get('stocks', []):
                                ticker = stock.get('ticker', '').strip()
                                if ticker:
                                    today_weights_map[ticker] = stock.get('allocation', 0)
                            
                            # Apply MA filter even in fallback case when momentum is disabled
                            if not cfg.get('use_momentum', True) and cfg.get('use_sma_filter', False):
                                try:
                                    ma_window = cfg.get('sma_window', 200)
                                    ma_type = cfg.get('ma_type', 'SMA')
                                    current_tickers = [t for t in today_weights_map.keys() if t != 'CASH']
                                    
                                    if alloc_dates:
                                        final_d = alloc_dates[-1]
                                        # ULTRA FAST: Use precomputed filter results if available!
                                        if hasattr(cfg, '_ma_filter_data') and cfg._ma_filter_data is not None:
                                            filtered_tickers = [t for t in current_tickers if cfg._ma_filter_data.get(final_d, {}).get(t, True)]
                                            excluded_assets = {t: f"Below MA" for t in current_tickers if t not in filtered_tickers}
                                        else:
                                            # Fallback to original method if not precomputed
                                            filtered_tickers, excluded_assets = filter_assets_by_ma(current_tickers, data_reindexed, final_d, ma_window, ma_type, cfg, cfg.get('stocks', []))
                                        
                                        if excluded_assets:
                                            excluded_ticker_list = list(excluded_assets.keys())
                                            excluded_allocation = sum(today_weights_map.get(t, 0) for t in excluded_ticker_list)
                                            
                                            for excluded_ticker in excluded_ticker_list:
                                                if excluded_ticker in today_weights_map:
                                                    del today_weights_map[excluded_ticker]
                                            
                                            remaining_tickers = [t for t in today_weights_map.keys() if t != 'CASH']
                                            if remaining_tickers:
                                                remaining_allocation = sum(today_weights_map.get(t, 0) for t in remaining_tickers)
                                                if remaining_allocation > 0:
                                                    for ticker in remaining_tickers:
                                                        proportion = today_weights_map[ticker] / remaining_allocation
                                                        today_weights_map[ticker] += excluded_allocation * proportion
                                                else:
                                                    equal_allocation = excluded_allocation / len(remaining_tickers)
                                                    for ticker in remaining_tickers:
                                                        today_weights_map[ticker] = equal_allocation
                                            else:
                                                today_weights_map = {'CASH': 1.0}
                                except:
                                    pass  # If MA filter fails, keep original allocations
                            
                            # Add CASH if needed
                            if 'CASH' not in today_weights_map:
                                total_alloc = sum(today_weights_map.values())
                                if total_alloc < 1.0:
                                    today_weights_map['CASH'] = 1.0 - total_alloc
                                else:
                                    today_weights_map['CASH'] = 0
                        
                        if total_series is not None and len(total_series) > 0:
                            # Prepare results for this portfolio
                            result = {
                                'index': i-1,  # 0-based index for mapping
                                'name': name,
                            'success': True,
                                'no_additions': total_series_no_additions,
                                'with_additions': total_series,
                                'today_weights_map': today_weights_map,
                            'historical_allocations': historical_allocations,
                                'historical_metrics': historical_metrics
                            }
                            
                            # --- CASH FLOW LOGIC FOR MWRR (stored for later calculation) ---
                            # Track cash flows as pandas Series indexed by date
                            cash_flows = pd.Series(0.0, index=total_series.index)
                            # Initial investment: negative cash flow on first date
                            if len(total_series.index) > 0:
                                cash_flows.iloc[0] = -cfg.get('initial_value', 0)
                            # Periodic additions: negative cash flow on their respective dates
                            dates_added = get_dates_by_freq(cfg.get('added_frequency'), total_series.index[0], total_series.index[-1], total_series.index)
                            for d in dates_added:
                                if d in cash_flows.index and d != cash_flows.index[0]:
                                    cash_flows.loc[d] -= cfg.get('added_amount', 0)
                            # Final value: positive cash flow on last date for MWRR
                            if len(total_series.index) > 0:
                                cash_flows.iloc[-1] += total_series.iloc[-1]
                            
                            # Store cash flows and portfolio values for MWRR calculation
                            result['cash_flows'] = cash_flows
                            result['portfolio_values'] = total_series
                            result['success'] = True
                            
                            return result
                        else:
                            return {
                                'index': i-1,
                                'name': name,
                                'success': False,
                                'error': "Empty results from backtest"
                            }
                            
                    except Exception as e:
                        return {
                            'index': i-1,
                            'name': cfg.get('name', f'Portfolio {i}'),
                            'success': False,
                            'error': str(e)
                        }
                
                def process_single_fusion_portfolio(args):
                    """Process a single fusion portfolio - runs after regular portfolios are complete"""
                    i, cfg, all_configs = args
                    try:
                        name = cfg.get('name', f'Portfolio {i}')
                        
                        # Debug: Check if all_configs is available
                        if not all_configs:
                            return {
                                'index': i-1,
                                'name': name,
                                'success': False,
                                'error': "No portfolio configs available for fusion portfolio"
                            }
                        
                        # Run fusion portfolio backtest - pass the entire fusion portfolio config
                        total_series, total_series_no_additions, historical_allocations, historical_metrics, today_weights_map, current_alloc, current_weights_map = fusion_portfolio_backtest(
                            cfg, all_configs, simulation_index, data_reindexed
                        )
                        
                        if total_series is not None and len(total_series) > 0:
                            # Prepare results for this portfolio
                            result = {
                                'index': i-1,  # 0-based index for mapping
                                'name': name,
                            'success': True,
                                'no_additions': total_series_no_additions,
                                'with_additions': total_series,
                                'today_weights_map': today_weights_map,
                            'historical_allocations': historical_allocations,
                            'historical_metrics': historical_metrics,
                                'current_alloc': current_alloc,
                                'current_weights_map': current_weights_map
                            }
                            
                            # --- CASH FLOW LOGIC FOR MWRR (stored for later calculation) ---
                            # Track cash flows as pandas Series indexed by date
                            cash_flows = pd.Series(0.0, index=total_series.index)
                            # Initial investment: negative cash flow on first date
                            if len(total_series.index) > 0:
                                cash_flows.iloc[0] = -cfg.get('initial_value', 0)
                            # Periodic additions: negative cash flow on their respective dates
                            dates_added = get_dates_by_freq(cfg.get('added_frequency'), total_series.index[0], total_series.index[-1], total_series.index)
                            for d in dates_added:
                                if d in cash_flows.index and d != cash_flows.index[0]:
                                    cash_flows.loc[d] -= cfg.get('added_amount', 0)
                            # Final value: positive cash flow on last date for MWRR
                            if len(total_series.index) > 0:
                                cash_flows.iloc[-1] += total_series.iloc[-1]
                            
                            # Store cash flows and portfolio values for MWRR calculation
                            result['cash_flows'] = cash_flows
                            result['portfolio_values'] = total_series
                            result['success'] = True
                            
                            return result
                        else:
                            return {
                                'index': i-1,
                                'name': name,
                                'success': False,
                                'error': "Empty results from fusion backtest"
                            }
                            
                    except Exception as e:
                        return {
                            'index': i-1,
                            'name': cfg.get('name', f'Portfolio {i}'),
                            'success': False,
                            'error': f"Fusion backtest error: {str(e)}"
                        }
                
                # Determine number of workers (optimized for threading)
                import os
                # Use fewer workers to minimize Streamlit threading overhead
                max_workers = min(2, os.cpu_count() or 2)  # Max 2 workers for stability
                
                # Enable parallel processing for 3+ portfolios (threading can help with I/O bound tasks)
                total_portfolios = len(regular_portfolios) + len(fusion_portfolios)
                if total_portfolios < 3:
                    # Sequential for small datasets - threading overhead not worth it
                    st.session_state.use_parallel_processing = False
                elif total_portfolios > 15:
                    # Limit workers for very large datasets
                    max_workers = 1
                
                # PHASE 1: Process regular portfolios first
                if regular_portfolios:
                    # Check for kill request before Phase 1
                    check_kill_request()
                    
                    processing_mode = "parallel" if st.session_state.get('use_parallel_processing', True) and len(regular_portfolios) > 1 else "sequential"
                    worker_info = f" using {max_workers} workers" if processing_mode == "parallel" else ""
                    st.info(f"**Phase 1: Processing {len(regular_portfolios)} regular portfolios in {processing_mode} mode{worker_info}...**")
                    
                    if st.session_state.get('use_parallel_processing', True) and len(regular_portfolios) > 1:
                        # Process regular portfolios in parallel using optimized threading
                        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                            # Submit all regular portfolio tasks
                            future_to_index = {executor.submit(process_single_regular_portfolio, args): args[0] for args in regular_portfolios}
                            
                            # Collect results as they complete
                            completed_count = 0
                            for future in concurrent.futures.as_completed(future_to_index):
                                # Check for kill request before processing each result
                                if st.session_state.get('hard_kill_requested', False):
                                    print("üõë Hard kill requested - stopping regular portfolio processing")
                                    # Cancel remaining futures
                                    for f in future_to_index:
                                        f.cancel()
                                    break
                                
                                completed_count += 1
                                progress_percent = completed_count / len(regular_portfolios)
                                progress_bar.progress(progress_percent, text=f"Phase 1: Completed {completed_count}/{len(regular_portfolios)} regular portfolios...")
                                
                                result = future.result()
                                
                                if result['success']:
                                    # Ensure unique key for storage
                                    base_name = result['name']
                                    unique_name = base_name
                                    suffix = 1
                                    while unique_name in all_results or unique_name in all_allocations:
                                        unique_name = f"{base_name} ({suffix})"
                                        suffix += 1
                                    
                                    # Store results
                                    all_results[unique_name] = {
                                        'no_additions': result['no_additions'],
                                        'with_additions': result['with_additions'],
                                        'today_weights_map': result['today_weights_map'],
                                        'cash_flows': result['cash_flows'],
                                        'portfolio_values': result['portfolio_values']
                                    }
                                    
                                    all_allocations[unique_name] = result['historical_allocations']
                                    all_metrics[unique_name] = result['historical_metrics']
                                    portfolio_key_map[result['index']] = unique_name
                                    successful_portfolios += 1
                                else:
                                    # Regular portfolio failed - silently continue
                                    pass
                    else:
                        # Process regular portfolios sequentially
                        for i, args in enumerate(regular_portfolios, start=1):
                            # Check for kill request during sequential processing
                            check_kill_request()
                            
                            progress_percent = i / len(regular_portfolios)
                            progress_bar.progress(progress_percent, text=f"Phase 1: Processing regular portfolio {i}/{len(regular_portfolios)}: {args[1].get('name', f'Portfolio {i}')}")
                            
                            result = process_single_regular_portfolio(args)
                            
                            if result['success']:
                                # Ensure unique key for storage
                                base_name = result['name']
                                unique_name = base_name
                                suffix = 1
                                while unique_name in all_results or unique_name in all_allocations:
                                    unique_name = f"{base_name} ({suffix})"
                                    suffix += 1
                                
                                # Store results
                                all_results[unique_name] = {
                                    'no_additions': result['no_additions'],
                                    'with_additions': result['with_additions'],
                                    'today_weights_map': result['today_weights_map'],
                                    'cash_flows': result['cash_flows'],
                                    'portfolio_values': result['portfolio_values']
                                }
                                
                                all_allocations[unique_name] = result['historical_allocations']
                                all_metrics[unique_name] = result['historical_metrics']
                                portfolio_key_map[result['index']] = unique_name
                                successful_portfolios += 1
                            else:
                                # Regular portfolio failed - silently continue
                                pass
                
                # PHASE 2: Process fusion portfolios after regular portfolios are complete
                if fusion_portfolios:
                    # Check for kill request before Phase 2
                    check_kill_request()
                    
                    processing_mode = "parallel" if st.session_state.get('use_parallel_processing', True) and len(fusion_portfolios) > 1 else "sequential"
                    worker_info = f" using {max_workers} workers" if processing_mode == "parallel" else ""
                    st.info(f"**Phase 2: Processing {len(fusion_portfolios)} fusion portfolios in {processing_mode} mode{worker_info} (depends on regular portfolios)...**")
                    
                    if st.session_state.get('use_parallel_processing', True) and len(fusion_portfolios) > 1:
                        # Process fusion portfolios in parallel using optimized threading
                        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                            # Submit all fusion portfolio tasks - pass only regular portfolios for fusion dependencies
                            regular_configs = [cfg for cfg in st.session_state.multi_backtest_portfolio_configs if not cfg.get('fusion_portfolio', {}).get('enabled', False)]
                            fusion_args = [(i, cfg, regular_configs) for i, cfg in fusion_portfolios]
                            future_to_index = {executor.submit(process_single_fusion_portfolio, args): args[0] for args in fusion_args}
                            
                            # Collect results as they complete
                            completed_count = 0
                            for future in concurrent.futures.as_completed(future_to_index):
                                # Check for kill request before processing each result
                                if st.session_state.get('hard_kill_requested', False):
                                    print("üõë Hard kill requested - stopping fusion portfolio processing")
                                    # Cancel remaining futures
                                    for f in future_to_index:
                                        f.cancel()
                                    break
                                
                                completed_count += 1
                                progress_percent = completed_count / len(fusion_portfolios)
                                progress_bar.progress(progress_percent, text=f"Phase 2: Completed {completed_count}/{len(fusion_portfolios)} fusion portfolios...")
                                
                                result = future.result()
                                
                                if result['success']:
                                    # Ensure unique key for storage
                                    base_name = result['name']
                                    unique_name = base_name
                                    suffix = 1
                                    while unique_name in all_results or unique_name in all_allocations:
                                        unique_name = f"{base_name} ({suffix})"
                                        suffix += 1
                                    
                                    # Store results
                                    all_results[unique_name] = {
                                        'no_additions': result['no_additions'],
                                        'with_additions': result['with_additions'],
                                        'today_weights_map': result['today_weights_map'],
                                        'cash_flows': result['cash_flows'],
                                        'portfolio_values': result['portfolio_values'],
                                        'current_alloc': result['current_alloc'],
                                        'current_weights_map': result['current_weights_map']
                                    }
                                    
                                    all_allocations[unique_name] = result['historical_allocations']
                                    all_metrics[unique_name] = result['historical_metrics']
                                    portfolio_key_map[result['index']] = unique_name
                                    successful_portfolios += 1
                                else:
                                    # Fusion portfolio failed - silently continue
                                    pass
                    else:
                        # Process fusion portfolios sequentially
                        for i, args in enumerate(fusion_portfolios, start=1):
                            # Check for kill request during sequential processing
                            check_kill_request()
                            
                            progress_percent = i / len(fusion_portfolios)
                            progress_bar.progress(progress_percent, text=f"Phase 2: Processing fusion portfolio {i}/{len(fusion_portfolios)}: {args[1].get('name', f'Portfolio {i}')}")
                            
                            # Add only regular portfolios for fusion dependencies
                            regular_configs = [cfg for cfg in st.session_state.multi_backtest_portfolio_configs if not cfg.get('fusion_portfolio', {}).get('enabled', False)]
                            fusion_args = (args[0], args[1], regular_configs)
                            result = process_single_fusion_portfolio(fusion_args)
                            
                            if result['success']:
                                # Ensure unique key for storage
                                base_name = result['name']
                                unique_name = base_name
                                suffix = 1
                                while unique_name in all_results or unique_name in all_allocations:
                                    unique_name = f"{base_name} ({suffix})"
                                    suffix += 1
                                
                                # Store results
                                all_results[unique_name] = {
                                    'no_additions': result['no_additions'],
                                    'with_additions': result['with_additions'],
                                    'today_weights_map': result['today_weights_map'],
                                    'cash_flows': result['cash_flows'],
                                    'portfolio_values': result['portfolio_values'],
                                    'current_alloc': result['current_alloc'],
                                    'current_weights_map': result['current_weights_map']
                                }
                                
                                all_allocations[unique_name] = result['historical_allocations']
                                all_metrics[unique_name] = result['historical_metrics']
                                portfolio_key_map[result['index']] = unique_name
                            successful_portfolios += 1
                        else:
                            # Fusion portfolio failed - silently continue
                            pass
                
                # Final progress update
                progress_bar.progress(1.0, text="Portfolio processing completed!")
                
                # Calculate and display performance metrics
                end_time = time_module.time()
                total_time = end_time - start_time
                avg_time_per_portfolio = total_time / len(st.session_state.multi_backtest_portfolio_configs) if st.session_state.multi_backtest_portfolio_configs else 0
                
                # Show results summary with performance info
                if successful_portfolios > 0:
                    processing_mode = "parallel" if st.session_state.get('use_parallel_processing', True) and total_portfolios > 1 else "sequential"
                    phase_info = f" (Phase 1: {len(regular_portfolios)} regular, Phase 2: {len(fusion_portfolios)} fusion)" if fusion_portfolios else f" ({len(regular_portfolios)} regular portfolios only)"
                    st.success(f"**Successfully processed {successful_portfolios}/{len(st.session_state.multi_backtest_portfolio_configs)} portfolios in {processing_mode} mode{phase_info}**")
                    st.info(f"**Performance:** Total time: {total_time:.2f}s | Average per portfolio: {avg_time_per_portfolio:.2f}s | Mode: {processing_mode.upper()}")
                    
                    # Display API call counter
                    api_calls = st.session_state.get('api_call_count', 0)
                    st.info(f"**API Calls Made:** {api_calls} total calls to Yahoo Finance")
                else:
                    st.error("‚ùå **No portfolios were processed successfully!** Please check your configuration.")
                
                # Memory cleanup
                import gc
                gc.collect()
                
                # Final kill check before completion
                check_kill_request()
                
            progress_bar.empty()
            
            # --- CALCULATE MWRR FOR ALL PORTFOLIOS AFTER LOOP COMPLETES ---
            for unique_name, results in all_results.items():
                if 'cash_flows' in results and 'portfolio_values' in results:
                    cash_flows = results['cash_flows']
                    portfolio_values = results['portfolio_values']
                    # Calculate MWRR with complete cash flow series
                    mwrr = calculate_mwrr(portfolio_values, cash_flows, portfolio_values.index)
                    # Add MWRR to the stats
                    if unique_name in all_stats:
                        all_stats[unique_name]["MWRR"] = mwrr
                    # Clean up temporary data
                    del results['cash_flows']
                    del results['portfolio_values']
                else:
                    if unique_name in all_stats:
                        all_stats[unique_name]["MWRR"] = np.nan
            # CRITICAL: Maintain portfolio order from portfolio_configs
            portfolio_order = [cfg['name'] for cfg in st.session_state.multi_backtest_portfolio_configs if cfg['name'] in all_stats]
            stats_df = pd.DataFrame({name: all_stats[name] for name in portfolio_order}).T
            def fmt_pct(x):
                if isinstance(x, (int, float)) and pd.notna(x):
                    return f"{x*100:.2f}%"
                if isinstance(x, str):
                    return x
                return "N/A"
            def fmt_num(x, prec=3):
                if isinstance(x, (int, float)) and pd.notna(x):
                    return f"{x:.3f}"
                if isinstance(x, str):
                    return x
                return "N/A"
            if not stats_df.empty:
                stats_df_display = stats_df.copy()
                stats_df_display.rename(columns={'MaxDrawdown': 'Max Drawdown', 'UlcerIndex': 'Ulcer Index'}, inplace=True)
                stats_df_display['Total Return'] = stats_df_display['Total Return'].apply(lambda x: fmt_pct(x))
                stats_df_display['CAGR'] = stats_df_display['CAGR'].apply(lambda x: fmt_pct(x))
                stats_df_display['Max Drawdown'] = stats_df_display['Max Drawdown'].apply(lambda x: fmt_pct(x))
                stats_df_display['Volatility'] = stats_df_display['Volatility'].apply(lambda x: fmt_pct(x))
                # Ensure MWRR is the last column, Beta immediately before it, Total Return at the very end
                if 'Beta' in stats_df_display.columns and 'MWRR' in stats_df_display.columns and 'Total Return' in stats_df_display.columns:
                    cols = list(stats_df_display.columns)
                    # Remove Beta, MWRR, and Total Return
                    beta_col = cols.pop(cols.index('Beta'))
                    mwrr_col = cols.pop(cols.index('MWRR'))
                    total_return_col = cols.pop(cols.index('Total Return'))
                    # Insert Beta before MWRR, then Total Return at the very end
                    cols.append(beta_col)
                    cols.append(mwrr_col)
                    cols.append(total_return_col)
                    stats_df_display = stats_df_display[cols]
                # MWRR is already a percentage from calculate_mwrr, format it properly
                if 'MWRR' in stats_df_display.columns:
                    stats_df_display['MWRR'] = stats_df_display['MWRR'].apply(lambda x: f"{x:.2f}%" if isinstance(x, (int, float)) and pd.notna(x) else "N/A")
                stats_df_display['Sharpe'] = stats_df_display['Sharpe'].apply(lambda x: fmt_num(x))
                stats_df_display['Sortino'] = stats_df_display['Sortino'].apply(lambda x: fmt_num(x))
                stats_df_display['Ulcer Index'] = stats_df_display['Ulcer Index'].apply(lambda x: fmt_num(x))
                stats_df_display['UPI'] = stats_df_display['UPI'].apply(lambda x: fmt_num(x))
                if 'Beta' in stats_df_display.columns:
                    stats_df_display['Beta'] = stats_df_display['Beta'].apply(lambda x: fmt_num(x))
            else:
                pass
            # Yearly performance section (interactive table below)
            all_years = {}
            for name, ser in all_results.items():
                # Use the with-additions series for yearly performance (user requested)
                yearly = ser['with_additions'].resample('YE').last()
                all_years[name] = yearly
            years = sorted(list(set(y.year for ser in all_years.values() for y in ser.index)))
            names = list(all_years.keys())
            
            # Print console log yearly table correctly
            col_width = 22
            header_format = "{:<6} |" + "".join([" {:^" + str(col_width*2+1) + "} |" for _ in names])
            row_format = "{:<6} |" + "".join([" {:>" + str(col_width) + "} {:>" + str(col_width) + "} |" for _ in names])
            
            
            for y in years:
                row_items = [f"{y}"]
                for nm in names:
                    ser = all_years[nm]
                    ser_year = ser[ser.index.year == y]
                    
                    # Corrected logic for yearly performance calculation
                    start_val_for_year = None
                    if y == min(years):
                        config_for_name = next((c for c in st.session_state.multi_backtest_portfolio_configs if c['name'] == nm), None)
                        if config_for_name:
                            initial_val_of_config = config_for_name['initial_value']
                            if initial_val_of_config > 0:
                                start_val_for_year = initial_val_of_config
                    else:
                        prev_year = y - 1
                        prev_ser_year = all_years[nm][all_years[nm].index.year == prev_year]
                        if not prev_ser_year.empty:
                            start_val_for_year = prev_ser_year.iloc[-1]
                        
                    if not ser_year.empty and start_val_for_year is not None:
                        end_val = ser_year.iloc[-1]
                        if start_val_for_year > 0:
                            pct = f"{(end_val - start_val_for_year) / start_val_for_year * 100:.2f}%"
                            final_val = f"${end_val:,.2f}"
                        else:
                            pct = "N/A"
                            final_val = "N/A"
                    else:
                        pct = "N/A"
                        final_val = "N/A"
                        
                    row_items.extend([pct, final_val])
    
            # console output captured previously is no longer shown on the page
            # Create today_weights_map for all portfolios
            today_weights_map = {}
            for unique_name, results in all_results.items():
                if isinstance(results, dict):
                    if 'today_weights_map' in results:
                        today_weights_map[unique_name] = results['today_weights_map']
            
            # Get last rebalance dates for all portfolios from actual allocation data
            last_rebalance_dates = {}
            for portfolio_name in st.session_state.multi_backtest_portfolio_configs:
                portfolio_name = portfolio_name.get('name', 'Unknown')
                
                # Get the actual allocation data for this portfolio
                if portfolio_name in all_allocations:
                    allocs_for_portfolio = all_allocations[portfolio_name]
                    if allocs_for_portfolio:
                        # Get sorted allocation dates (same logic as real code)
                        alloc_dates = sorted(list(allocs_for_portfolio.keys()))
                        if len(alloc_dates) > 1:
                            # Use second to last date (same as real timer code)
                            last_rebalance_dates[portfolio_name] = alloc_dates[-2]
                        elif len(alloc_dates) == 1:
                            # Use the only available date
                            last_rebalance_dates[portfolio_name] = alloc_dates[-1]
                        else:
                            # No allocation data available
                            last_rebalance_dates[portfolio_name] = None
                    else:
                        last_rebalance_dates[portfolio_name] = None
                else:
                    last_rebalance_dates[portfolio_name] = None
            
            st.session_state.multi_backtest_snapshot_data = {
                'raw_data': data_reindexed,
                'portfolio_configs': st.session_state.multi_backtest_portfolio_configs,
                'all_allocations': all_allocations,
                'all_metrics': all_metrics,
                'today_weights_map': today_weights_map,
                'last_rebalance_dates': last_rebalance_dates
            }
            
            # Create allocation tables for ALL portfolios automatically for PDF export
            try:
                raw_data = st.session_state.get('multi_backtest_raw_data', {})
                
                for portfolio_name, today_weights in today_weights_map.items():
                    if today_weights:
                        # Get portfolio configuration for calculations
                        portfolio_configs = st.session_state.multi_backtest_portfolio_configs
                        portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == portfolio_name), None)
                        
                        if portfolio_cfg:
                            # Get portfolio value
                            portfolio_value = float(portfolio_cfg.get('initial_value', 0) or 0)
                            
                            # Get current portfolio value from backtest results
                            if 'multi_all_results' in st.session_state and st.session_state.multi_all_results:
                                portfolio_results = st.session_state.multi_all_results.get(portfolio_name)
                                if portfolio_results:
                                    if isinstance(portfolio_results, dict) and 'with_additions' in portfolio_results:
                                        final_value = portfolio_results['with_additions'].iloc[-1]
                                        if not pd.isna(final_value) and final_value > 0:
                                            portfolio_value = float(final_value)
                                    elif isinstance(portfolio_results, dict) and 'no_additions' in portfolio_results:
                                        final_value = portfolio_results['no_additions'].iloc[-1]
                                        if not pd.isna(final_value) and final_value > 0:
                                            portfolio_value = float(final_value)
                                    elif isinstance(portfolio_results, pd.Series):
                                        latest_value = portfolio_results.iloc[-1]
                                        if not pd.isna(latest_value) and latest_value > 0:
                                            portfolio_value = float(latest_value)
                            
                            # Create allocation table data
                            rows = []
                            for tk in sorted(today_weights.keys()):
                                alloc_pct = float(today_weights.get(tk, 0))
                                if tk == 'CASH':
                                    price = None
                                    shares = 0.0
                                    total_val = portfolio_value * alloc_pct
                                else:
                                    df = raw_data.get(tk)
                                    price = None
                                    if isinstance(df, pd.DataFrame) and 'Close' in df.columns and not df['Close'].dropna().empty:
                                        try:
                                            price = float(df['Close'].iloc[-1])
                                        except Exception:
                                            price = None
                                    try:
                                        if price and price > 0:
                                            allocation_value = portfolio_value * alloc_pct
                                            shares = round(allocation_value / price, 1)
                                            total_val = shares * price
                                        else:
                                            shares = 0.0
                                            total_val = portfolio_value * alloc_pct
                                    except Exception:
                                        shares = 0.0
                                        total_val = portfolio_value * alloc_pct

                                pct_of_port = (total_val / portfolio_value * 100) if portfolio_value > 0 else 0
                                rows.append({
                                    'Ticker': tk,
                                    'Allocation %': round(alloc_pct * 100, 2),
                                    'Price ($)': round(price, 2) if price is not None else float('nan'),
                                    'Shares': round(shares, 2),
                                    'Total Value ($)': round(total_val, 2),
                                    '% of Portfolio': round(pct_of_port, 2),
                                })

                            df_table = pd.DataFrame(rows).set_index('Ticker')
                            df_display = df_table.copy()
                            
                            # Remove CASH if it has zero value
                            if 'CASH' in df_display.index:
                                cash_val = df_display.at['CASH', 'Total Value ($)']
                                if not (cash_val and not pd.isna(cash_val) and cash_val != 0):
                                    df_display = df_display.drop('CASH')
                            
                            # Create Plotly table figure with ticker column included
                            df_display_with_ticker = df_display.reset_index()
                            
                            # Format the data to ensure 2 decimal places for display
                            formatted_values = []
                            for col in df_display_with_ticker.columns:
                                if col in ['Price ($)', 'Total Value ($)', '% of Portfolio']:
                                    # Format monetary and percentage values to 2 decimal places
                                    formatted_values.append([f"{df_display_with_ticker[col][i]:.2f}" if pd.notna(df_display_with_ticker[col][i]) else "" for i in range(len(df_display_with_ticker))])
                                elif col == 'Shares':
                                    # Format shares to 1 decimal place
                                    formatted_values.append([f"{df_display_with_ticker[col][i]:.1f}" if pd.notna(df_display_with_ticker[col][i]) else "" for i in range(len(df_display_with_ticker))])
                                elif col == 'Allocation %':
                                    # Format allocation to 2 decimal places
                                    formatted_values.append([f"{df_display_with_ticker[col][i]:.2f}" if pd.notna(df_display_with_ticker[col][i]) else "" for i in range(len(df_display_with_ticker))])
                                else:
                                    # Keep other columns as is
                                    formatted_values.append([str(df_display_with_ticker[col][i]) if pd.notna(df_display_with_ticker[col][i]) else "" for i in range(len(df_display_with_ticker))])
                            
                            fig_alloc_table = go.Figure(data=[go.Table(
                                header=dict(values=list(df_display_with_ticker.columns),
                                           fill_color='paleturquoise',
                                           align='left',
                                           font=dict(size=12)),
                                cells=dict(values=formatted_values,
                                          fill_color='lavender',
                                          align='left',
                                          font=dict(size=11))
                            )])
                            fig_alloc_table.update_layout(
                                title=f"Target Allocation if Rebalanced Today - {portfolio_name}",
                                margin=dict(t=30, b=10, l=10, r=10),
                                height=400
                            )
                            table_key = f"alloc_table_{portfolio_name}"
                            st.session_state[table_key] = fig_alloc_table
            except Exception as e:
                pass
            
            # Create timer tables for ALL portfolios automatically for PDF export
            try:
                snapshot = st.session_state.get('multi_backtest_snapshot_data', {})
                last_rebalance_dates = snapshot.get('last_rebalance_dates', {})
                
                
                for portfolio_cfg in st.session_state.multi_backtest_portfolio_configs:
                    portfolio_name = portfolio_cfg.get('name', 'Unknown')
                    
                    # Get rebalancing frequency for this portfolio
                    rebal_freq = portfolio_cfg.get('rebalancing_frequency', 'none')
                    rebal_freq = rebal_freq.lower()
                    
                    # Map frequency names to what the function expects
                    frequency_mapping = {
                        'monthly': 'Monthly',
                        'weekly': 'Weekly',
                        'bi-weekly': 'Biweekly',
                        'biweekly': 'Biweekly',
                        'quarterly': 'Quarterly',
                        'semi-annually': 'Semiannually',
                        'semiannually': 'Semiannually',
                        'annually': 'Annually',
                        'yearly': 'Annually',
                        'market_day': 'market_day',
                        'calendar_day': 'calendar_day',
                        'never': 'Never',
                        'none': 'Never'
                    }
                    rebal_freq = frequency_mapping.get(rebal_freq, rebal_freq)
                    
                    # Get last rebalance date for this portfolio
                    last_rebal_date = last_rebalance_dates.get(portfolio_name)
                    
                    if rebal_freq != 'none':
                        # Ensure last_rebal_date is a naive datetime object if it exists
                        if last_rebal_date and isinstance(last_rebal_date, str):
                            last_rebal_date = pd.to_datetime(last_rebal_date)
                        if last_rebal_date and hasattr(last_rebal_date, 'tzinfo') and last_rebal_date.tzinfo is not None:
                            last_rebal_date = last_rebal_date.replace(tzinfo=None)
                        
                        # Calculate next rebalance for this portfolio using the actual last rebalance date
                        # This matches the "Last Rebalance Allocation" date shown in the UI
                        if last_rebal_date:
                            # Calculate the next rebalance date from the last rebalance date
                            if rebal_freq == 'market_day':
                                next_date_port = last_rebal_date.date() + timedelta(days=1)
                            elif rebal_freq == 'calendar_day':
                                next_date_port = last_rebal_date.date() + timedelta(days=1)
                            elif rebal_freq == 'week':
                                next_date_port = last_rebal_date.date() + timedelta(weeks=1)
                            elif rebal_freq == '2weeks':
                                next_date_port = last_rebal_date.date() + timedelta(weeks=2)
                            elif rebal_freq == 'month':
                                # Add one month
                                if last_rebal_date.date().month == 12:
                                    next_date_port = last_rebal_date.date().replace(year=last_rebal_date.date().year + 1, month=1)
                                else:
                                    next_date_port = last_rebal_date.date().replace(month=last_rebal_date.date().month + 1)
                            elif rebal_freq == 'quarter':
                                # Add 3 months
                                new_month = last_rebal_date.date().month + 3
                                if new_month > 12:
                                    next_date_port = last_rebal_date.date().replace(year=last_rebal_date.date().year + 1, month=new_month - 12)
                                else:
                                    next_date_port = last_rebal_date.date().replace(month=new_month)
                            elif rebal_freq == 'semi':
                                # Add 6 months
                                new_month = last_rebal_date.date().month + 6
                                if new_month > 12:
                                    next_date_port = last_rebal_date.date().replace(year=last_rebal_date.date().year + 1, month=new_month - 12)
                                else:
                                    next_date_port = last_rebal_date.date().replace(month=new_month)
                            elif rebal_freq == 'year':
                                next_date_port = last_rebal_date.date().replace(year=last_rebal_date.date().year + 1)
                            else:
                                next_date_port = None
                            
                            if next_date_port:
                                # Calculate time until next rebalance from the last rebalance date
                                time_diff = next_date_port - last_rebal_date.date()
                                time_until_port = time_diff.total_seconds() / (24 * 3600)  # Convert to days
                                next_rebalance_datetime_port = datetime.combine(next_date_port, datetime.min.time())
                            else:
                                time_until_port = None
                                next_rebalance_datetime_port = None
                        else:
                            next_date_port = None
                            time_until_port = None
                            next_rebalance_datetime_port = None
                        
                        
                        if next_date_port and time_until_port:
                            # Create timer data for this portfolio
                            timer_data_port = [
                                ['Time Until Next Rebalance', format_time_until(time_until_port)],
                                ['Target Rebalance Date', next_date_port.strftime("%B %d, %Y")],
                                ['Rebalancing Frequency', rebal_freq.replace('_', ' ').title()]
                            ]
                        else:
                            # Fallback timer data when calculation fails
                            timer_data_port = [
                                ['Last Rebalance Date', last_rebal_date.strftime("%B %d, %Y") if last_rebal_date else "Unknown"],
                                ['Rebalancing Frequency', rebal_freq.replace('_', ' ').title()],
                                ['Status', 'Timer calculation unavailable']
                            ]
                        
                        # Create timer table figure for this portfolio
                        fig_timer_port = go.Figure(data=[go.Table(
                            header=dict(
                                values=['Parameter', 'Value'],
                                fill_color='#2E86AB',
                                align='center',
                                font=dict(color='white', size=16, family='Arial Black')
                            ),
                            cells=dict(
                                values=[[row[0] for row in timer_data_port], [row[1] for row in timer_data_port]],
                                fill_color=[['#F8F9FA', '#FFFFFF'] * 2, ['#F8F9FA', '#FFFFFF'] * 2],
                                align='center',
                                font=dict(color='black', size=14, family='Arial'),
                                height=40
                            )
                        )])
                        
                        fig_timer_port.update_layout(
                            title=dict(
                                text=f"‚è∞ Next Rebalance Timer - {portfolio_name}",
                                x=0.5,
                                font=dict(size=18, color='#2E86AB', family='Arial Black')
                            ),
                            width=700,
                            height=250,
                            margin=dict(l=20, r=20, t=60, b=20)
                        )
                        
                        # Store in session state for PDF export
                        st.session_state[f'timer_table_{portfolio_name}'] = fig_timer_port
                    else:
                        pass
                else:
                    pass
            except Exception as e:
                import traceback
                traceback.print_exc()
            
            st.session_state.multi_all_results = all_results
            st.session_state.multi_backtest_all_drawdowns = all_drawdowns
            if 'stats_df_display' in locals():
                st.session_state.multi_backtest_stats_df_display = stats_df_display
            st.session_state.multi_backtest_all_years = all_years
            st.session_state.multi_all_allocations = all_allocations
            st.session_state.multi_all_metrics = all_metrics
            # Clear any previous sorting when new results are calculated
            st.session_state.final_stats_sorted_df = None
            # Save portfolio index -> unique key mapping so UI selectors can reference results reliably
            st.session_state.multi_backtest_portfolio_key_map = portfolio_key_map
            st.session_state.multi_backtest_ran = True
            
            # OPTIMIZATION: Pre-compute and cache allocation evolution charts for all portfolios
            st.info("Pre-computing charts for instant portfolio selection...")
            
            # Pre-compute and cache individual portfolio charts (guarded to avoid silent failures)
            try:
                precompute_individual_portfolio_charts()
            except Exception as e:
                st.warning(f"Post-processing (precompute) failed: {e}")
            # Create progress bar for subsequent processing (guarded)
            try:
                progress_bar = st.progress(0)
            except Exception as e:
                st.warning(f"Post-processing (progress bar) init failed: {e}")
                progress_bar = None
            
            # Get all available portfolio names for pre-computation
            available_portfolio_names = [cfg.get('name', 'Portfolio') for cfg in st.session_state.get('multi_backtest_portfolio_configs', [])]
            extra_names = [n for n in st.session_state.get('multi_all_results', {}).keys() if n not in available_portfolio_names]
            all_portfolio_names = available_portfolio_names + extra_names
            total_portfolios = len(all_portfolio_names)
            
            for i, portfolio_name in enumerate(all_portfolio_names):
                if portfolio_name in all_allocations:
                    try:
                        # Get allocation data for this portfolio
                        allocs_data = all_allocations[portfolio_name]
                        
                        # Check if this is a fusion portfolio and filter out fusion portfolio allocation data
                        portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
                        portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == portfolio_name), None)
                        is_fusion = portfolio_cfg and portfolio_cfg.get('fusion_portfolio', {}).get('enabled', False)
                        
                        if is_fusion:
                            # Remove fusion portfolio allocation data from individual stock allocations
                            filtered_allocs_data = {}
                            for date, alloc_dict in allocs_data.items():
                                filtered_alloc_dict = {k: v for k, v in alloc_dict.items() if k != '_FUSION_PORTFOLIOS_'}
                                filtered_allocs_data[date] = filtered_alloc_dict
                            allocs_data = filtered_allocs_data
                        
                        if allocs_data:
                            # Use cached function to create chart
                            fig_evolution = create_allocation_evolution_chart(portfolio_name, allocs_data)
                            if fig_evolution:
                                st.session_state[f'multi_allocation_evolution_chart_{portfolio_name}'] = fig_evolution
                    except Exception as e:
                        st.warning(f"Could not pre-compute chart for {portfolio_name}: {str(e)}")
                
                try:
                    if progress_bar is not None:
                        progress_bar.progress((i + 1) / total_portfolios)
                except Exception as e:
                    st.warning(f"Post-processing (progress update) failed: {e}")
            
            try:
                if progress_bar is not None:
                    progress_bar.empty()
            except Exception:
                pass
            st.success("Charts processed. Portfolio selection is now instantaneous.")

# Sidebar JSON export/import for ALL portfolios
def paste_all_json_callback():
    txt = st.session_state.get('multi_backtest_paste_all_json_text', '')
    if not txt:
        st.warning('No JSON provided')
        return
    try:
        # Use the SAME parsing logic as successful PDF extraction
        raw_text = txt
        
        # STEP 1: Try the exact same approach as PDF extraction (simple strip + parse)
        try:
            cleaned_text = raw_text.strip()
            obj = json.loads(cleaned_text)
            st.success("‚úÖ Multi-portfolio JSON parsed successfully using PDF-style parsing!")
        except json.JSONDecodeError:
            # STEP 2: If that fails, apply our advanced cleaning (fallback)
            st.info("üîß Simple parsing failed, applying advanced PDF extraction fixes...")
            
            json_text = raw_text
            import re
            
            # Fix broken portfolio name lines
            broken_pattern = r'"name":\s*"([^"]*?)"\s*"stocks":'
            json_text = re.sub(broken_pattern, r'"name": "\1", "stocks":', json_text)
            
            # Fix truncated names
            truncated_pattern = r'"name":\s*"([^"]*?)\s+"stocks":'
            json_text = re.sub(truncated_pattern, r'"name": "\1", "stocks":', json_text)
            
            # Fix missing opening brace for portfolio objects
            missing_brace_pattern = r'(},)\s*("name":)'
            json_text = re.sub(missing_brace_pattern, r'\1 {\n \2', json_text)
            
            obj = json.loads(json_text)
            st.success("‚úÖ Multi-portfolio JSON parsed successfully using advanced cleaning!")
        
        # Add missing fields for compatibility if they don't exist (based on page 3 logic)
        if isinstance(obj, list):
            for portfolio in obj:
                # Add missing fields with default values
                if 'collect_dividends_as_cash' not in portfolio:
                    portfolio['collect_dividends_as_cash'] = False
                if 'exclude_from_cashflow_sync' not in portfolio:
                    portfolio['exclude_from_cashflow_sync'] = False
                if 'exclude_from_rebalancing_sync' not in portfolio:
                    portfolio['exclude_from_rebalancing_sync'] = False
                # Only add missing fields if they don't exist in the JSON (like minimal_threshold)
                if 'use_minimal_threshold' not in portfolio:
                    portfolio['use_minimal_threshold'] = False
                if 'minimal_threshold_percent' not in portfolio:
                    portfolio['minimal_threshold_percent'] = 4.0
                # Don't override max_allocation values from JSON - preserve imported values like minimal_threshold
                # REMOVED: Don't force max_allocation values to preserve JSON values
                
                # Add missing anti-whipsaw fields with default values
                if 'ma_cross_rebalance' not in portfolio:
                    portfolio['ma_cross_rebalance'] = False
                if 'ma_tolerance_percent' not in portfolio:
                    portfolio['ma_tolerance_percent'] = 2.0
                if 'ma_confirmation_days' not in portfolio:
                    portfolio['ma_confirmation_days'] = 3
                if 'ma_multiplier' not in portfolio:
                    portfolio['ma_multiplier'] = 1.48  # Only default for new portfolios
                # Add missing equal weight fields with default values
                if 'use_equal_weight' not in portfolio:
                    portfolio['use_equal_weight'] = False
                if 'equal_weight_n_tickers' not in portfolio:
                    portfolio['equal_weight_n_tickers'] = 10
                # Add missing limit to top N fields with default values
                if 'use_limit_to_top_n' not in portfolio:
                    portfolio['use_limit_to_top_n'] = False
                if 'limit_to_top_n_tickers' not in portfolio:
                    portfolio['limit_to_top_n_tickers'] = 10
        
        if isinstance(obj, list):
            # Clear widget keys to force re-initialization
            widget_keys_to_clear = [
                "multi_backtest_active_name", "multi_backtest_active_initial", 
                "multi_backtest_active_added_amount", "multi_backtest_active_rebal_freq",
                "multi_backtest_active_add_freq", "multi_backtest_active_benchmark",
                "multi_backtest_active_use_momentum", "multi_backtest_active_collect_dividends_as_cash",
                "multi_backtest_start_with_radio", "multi_backtest_first_rebalance_strategy_radio"
            ]
            
            # Clear MA-related widget keys to force re-initialization with imported values
            ma_widget_keys_to_clear = [
                "multi_backtest_active_use_sma_filter", "multi_backtest_active_ma_window", 
                "multi_backtest_active_ma_type", "multi_backtest_active_ma_multiplier",
                "multi_backtest_active_ma_cross_rebalance", "multi_backtest_active_ma_tolerance",
                "multi_backtest_active_ma_delay"
            ]
            for key in ma_widget_keys_to_clear:
                # Clear all portfolio-specific keys for MA widgets
                keys_to_remove = [k for k in st.session_state.keys() if k.startswith(key)]
                for k in keys_to_remove:
                    del st.session_state[k]
            for key in widget_keys_to_clear:
                if key in st.session_state:
                    del st.session_state[key]
            # Force sync MA Multiplier widgets for all portfolios after JSON import
            for i, portfolio in enumerate(obj):
                if isinstance(portfolio, dict):
                    ma_multiplier_working_key = f"ma_multiplier_working_{i}"
                    st.session_state[ma_multiplier_working_key] = portfolio.get('ma_multiplier', 1.48)
            
            
            # NUCLEAR OPTION: FORCE REPLACE ALL EXISTING PORTFOLIOS
            st.session_state['multi_backtest_portfolio_configs'] = []  # CLEAR ALL EXISTING
            st.session_state['multi_backtest_fusion_portfolio_configs'] = []  # CLEAR ALL FUSION
            
            # Show nuclear power message
            st.success("üöÄ **NUCLEAR JSON IMPORT** - All existing portfolios cleared and replaced!")
            st.info("üí• **SURPUISSANT MODE** - MA multipliers will be forced to imported values!")
            
            # Process each portfolio configuration for Multi-Backtest page
            processed_configs = []
            for cfg in obj:
                if not isinstance(cfg, dict) or 'name' not in cfg:
                    st.error('Invalid portfolio configuration structure.')
                    return
                
                # Check if this is a fusion portfolio by looking for fusion_portfolio field
                is_fusion_portfolio = 'fusion_portfolio' in cfg and isinstance(cfg.get('fusion_portfolio'), dict)
                if is_fusion_portfolio:
                    fusion_config = cfg.get('fusion_portfolio', {})
                    st.info(f"üîó Detected fusion portfolio: {cfg.get('name', 'Unknown')}")
                    st.info(f"   Selected portfolios: {fusion_config.get('selected_portfolios', [])}")
                    st.info(f"   Allocations: {fusion_config.get('allocations', {})}")
                
                # Handle momentum strategy value mapping from other pages
                momentum_strategy = cfg.get('momentum_strategy', 'Classic')
                if momentum_strategy == 'Classic momentum':
                    momentum_strategy = 'Classic'
                elif momentum_strategy == 'Relative momentum':
                    momentum_strategy = 'Relative Momentum'
                elif momentum_strategy == 'Near-Zero Symmetry':
                    momentum_strategy = 'Near-Zero Symmetry'
                elif momentum_strategy not in ['Classic', 'Relative Momentum', 'Near-Zero Symmetry']:
                    momentum_strategy = 'Classic'  # Default fallback
                
                # Handle negative momentum strategy value mapping from other pages
                negative_momentum_strategy = cfg.get('negative_momentum_strategy', 'Cash')
                if negative_momentum_strategy == 'Go to cash':
                    negative_momentum_strategy = 'Cash'
                elif negative_momentum_strategy == 'Near-Zero Symmetry':
                    negative_momentum_strategy = 'Near-Zero Symmetry'
                elif negative_momentum_strategy not in ['Cash', 'Equal weight', 'Relative momentum', 'Near-Zero Symmetry']:
                    negative_momentum_strategy = 'Cash'  # Default fallback
                
                # Handle stocks field - convert from legacy format if needed
                stocks = cfg.get('stocks', [])
                if not stocks and 'tickers' in cfg:
                    # Convert legacy format (tickers, allocs, divs) to stocks format
                    tickers = cfg.get('tickers', [])
                    allocs = cfg.get('allocs', [])
                    divs = cfg.get('divs', [])
                    stocks = []
                    
                    # Ensure we have valid arrays
                    if tickers and isinstance(tickers, list):
                        for i in range(len(tickers)):
                            if tickers[i] and tickers[i].strip():  # Check for non-empty ticker
                                # Convert allocation from percentage (0-100) to decimal (0.0-1.0) format
                                allocation = 0.0
                                if i < len(allocs) and allocs[i] is not None:
                                    alloc_value = float(allocs[i])
                                    if alloc_value > 1.0:
                                        # Already in percentage format, convert to decimal
                                        allocation = alloc_value / 100.0
                                    else:
                                        # Already in decimal format, use as is
                                        allocation = alloc_value
                                
                                stock = {
                                    'ticker': tickers[i].strip(),
                                    'allocation': allocation,
                                    'include_dividends': bool(divs[i]) if i < len(divs) and divs[i] is not None else True
                                }
                                stocks.append(stock)
                
                # Sanitize momentum window weights to prevent StreamlitValueAboveMaxError
                momentum_windows = cfg.get('momentum_windows', [])
                for window in momentum_windows:
                    if 'weight' in window:
                        weight = window['weight']
                        # If weight is a percentage (e.g., 50 for 50%), convert to decimal
                        if isinstance(weight, (int, float)) and weight > 1.0:
                            # Cap at 100% and convert to decimal
                            weight = min(weight, 100.0) / 100.0
                        elif isinstance(weight, (int, float)) and weight <= 1.0:
                            # Already in decimal format, ensure it's valid
                            weight = max(0.0, min(weight, 1.0))
                        else:
                            # Invalid weight, set to default
                            weight = 0.1
                        window['weight'] = weight
                
                # Debug: Show what we received for this portfolio
                if 'momentum_windows' in cfg:
                    st.info(f"Momentum windows for {cfg.get('name', 'Unknown')}: {cfg['momentum_windows']}")
                if 'use_momentum' in cfg:
                    st.info(f"Use momentum for {cfg.get('name', 'Unknown')}: {cfg['use_momentum']}")
                
                # Map frequency values from app.py format to Multi-Backtest format
                def map_frequency(freq):
                    if freq is None:
                        return 'Never'
                    freq_map = {
                        'Never': 'Never',
                        'Buy & Hold': 'Buy & Hold',
                        'Buy & Hold (Target)': 'Buy & Hold (Target)',
                        'Weekly': 'Weekly',
                        'Biweekly': 'Biweekly',
                        'Monthly': 'Monthly',
                        'Quarterly': 'Quarterly',
                        'Semiannually': 'Semiannually',
                        'Annually': 'Annually',
                        # Legacy format mapping
                        'none': 'Never',
                        'week': 'Weekly',
                        '2weeks': 'Biweekly',
                        'month': 'Monthly',
                        '3months': 'Quarterly',
                        '6months': 'Semiannually',
                        'year': 'Annually'
                    }
                    return freq_map.get(freq, 'Monthly')
                
                # Multi-Backtest page specific: ensure all required fields are present
                # and ignore fields that are specific to other pages
                use_momentum = parse_bool_from_json(cfg.get('use_momentum', True), True)
                use_minimal_threshold = parse_bool_from_json(cfg.get('use_minimal_threshold', False), False)
                use_max_allocation = parse_bool_from_json(cfg.get('use_max_allocation', False), False)
                calc_beta = parse_bool_from_json(cfg.get('calc_beta', False), False)
                calc_volatility = parse_bool_from_json(cfg.get('calc_volatility', True), True)
                collect_dividends_as_cash = parse_bool_from_json(cfg.get('collect_dividends_as_cash', False), False)
                exclude_from_cashflow_sync = parse_bool_from_json(cfg.get('exclude_from_cashflow_sync', False), False)
                exclude_from_rebalancing_sync = parse_bool_from_json(cfg.get('exclude_from_rebalancing_sync', False), False)
                use_targeted_rebalancing = parse_bool_from_json(cfg.get('use_targeted_rebalancing', False), False)
                use_sma_filter = parse_bool_from_json(cfg.get('use_sma_filter', False), False)
                use_equal_weight = parse_bool_from_json(cfg.get('use_equal_weight', False), False)
                use_limit_to_top_n = parse_bool_from_json(cfg.get('use_limit_to_top_n', False), False)
                ma_cross_rebalance = parse_bool_from_json(cfg.get('ma_cross_rebalance', False), False)

                multi_backtest_config = {
                    'name': cfg.get('name', 'New Portfolio'),
                    'stocks': stocks,
                    'benchmark_ticker': cfg.get('benchmark_ticker', '^GSPC'),
                    'initial_value': cfg.get('initial_value', 10000),
                    'added_amount': cfg.get('added_amount', 1000),
                    'added_frequency': map_frequency(cfg.get('added_frequency', 'Monthly')),
                    'rebalancing_frequency': map_frequency(cfg.get('rebalancing_frequency', 'Monthly')),
                    'start_date_user': parse_date_from_json(cfg.get('start_date_user')),
                    'end_date_user': parse_date_from_json(cfg.get('end_date_user')),
                    'start_with': cfg.get('start_with', 'all'),
                    'first_rebalance_strategy': cfg.get('first_rebalance_strategy', 'rebalancing_date'),
                    'use_momentum': use_momentum,
                    'momentum_strategy': momentum_strategy,
                    'negative_momentum_strategy': negative_momentum_strategy,
                    'momentum_windows': momentum_windows,
                    'use_minimal_threshold': use_minimal_threshold,
                    'minimal_threshold_percent': cfg.get('minimal_threshold_percent', 4.0),
                    'use_max_allocation': use_max_allocation,
                    'max_allocation_percent': cfg.get('max_allocation_percent', 20.0),
                    'calc_beta': calc_beta,
                    'calc_volatility': calc_volatility,
                    'beta_window_days': cfg.get('beta_window_days', 365),
                    'exclude_days_beta': cfg.get('exclude_days_beta', 30),
                    'vol_window_days': cfg.get('vol_window_days', 365),
                    'exclude_days_vol': cfg.get('exclude_days_vol', 30),
                    'collect_dividends_as_cash': collect_dividends_as_cash,
                    # Preserve sync exclusion settings from imported JSON
                    'exclude_from_cashflow_sync': exclude_from_cashflow_sync,
                    'exclude_from_rebalancing_sync': exclude_from_rebalancing_sync,
                    'use_targeted_rebalancing': use_targeted_rebalancing,
                    'targeted_rebalancing_settings': cfg.get('targeted_rebalancing_settings', {}),
                    'use_sma_filter': use_sma_filter,
                    'sma_window': cfg.get('sma_window', 200),
                    'ma_type': cfg.get('ma_type', 'SMA'),
                    'ma_cross_rebalance': ma_cross_rebalance,
                    'ma_tolerance_percent': cfg.get('ma_tolerance_percent', 2.0),
                    'ma_confirmation_days': cfg.get('ma_confirmation_days', 3),
                    'use_equal_weight': use_equal_weight,
                    'equal_weight_n_tickers': cfg.get('equal_weight_n_tickers', 10),
                    'use_limit_to_top_n': use_limit_to_top_n,
                    'limit_to_top_n_tickers': cfg.get('limit_to_top_n_tickers', 10),
                    # Preserve fusion portfolio configuration if present
                    'fusion_portfolio': cfg.get('fusion_portfolio', {'enabled': False, 'selected_portfolios': [], 'allocations': {}}),
                    # Note: Ignoring Backtest Engine specific fields like 'portfolio_drag_pct', 'use_custom_dates', etc.
                }
                processed_configs.append(multi_backtest_config)
            
            st.session_state.multi_backtest_portfolio_configs = processed_configs
            
            # Count and report fusion portfolios
            fusion_portfolios = [cfg for cfg in processed_configs if cfg.get('fusion_portfolio', {}).get('enabled', False)]
            if fusion_portfolios:
                st.success(f"‚úÖ Successfully imported {len(fusion_portfolios)} fusion portfolio(s):")
                for fusion_cfg in fusion_portfolios:
                    fusion_name = fusion_cfg.get('name', 'Unknown')
                    selected_portfolios = fusion_cfg.get('fusion_portfolio', {}).get('selected_portfolios', [])
                    st.success(f"   üîó {fusion_name} (combines: {', '.join(selected_portfolios)})")
            
            # Update global date widgets based on imported portfolios (use first portfolio's dates as global)
            if processed_configs:
                first_portfolio = processed_configs[0]
                imported_start_date = first_portfolio.get('start_date_user')
                imported_end_date = first_portfolio.get('end_date_user')
                
                if imported_start_date is not None:
                    st.session_state["multi_backtest_start_date"] = imported_start_date
                if imported_end_date is not None:
                    st.session_state["multi_backtest_end_date"] = imported_end_date
                
                # Update custom dates checkbox based on imported dates
                has_imported_dates = imported_start_date is not None or imported_end_date is not None
                st.session_state["multi_backtest_use_custom_dates"] = has_imported_dates
            
            # Handle global start_with setting from imported JSON
            if processed_configs and 'start_with' in processed_configs[0]:
                # Handle start_with value mapping from other pages
                start_with = processed_configs[0]['start_with']
                if start_with == 'first':
                    start_with = 'oldest'  # Map 'first' to 'oldest' (closest equivalent)
                elif start_with not in ['all', 'oldest']:
                    start_with = 'all'  # Default fallback
                st.session_state['_import_start_with'] = start_with
            
            # Handle global first_rebalance_strategy setting from imported JSON
            if processed_configs and 'first_rebalance_strategy' in processed_configs[0]:
                st.session_state['_import_first_rebalance_strategy'] = processed_configs[0]['first_rebalance_strategy']
            
            # Reset active selection and derived mappings so the UI reflects the new configs
            if processed_configs:
                st.session_state.multi_backtest_active_portfolio_index = 0
                st.session_state.multi_backtest_portfolio_selector = processed_configs[0].get('name', '')
                # Mirror several active_* widget defaults so the UI selectboxes/inputs update
                st.session_state['multi_backtest_active_name'] = processed_configs[0].get('name', '')
                st.session_state['multi_backtest_active_initial'] = int(processed_configs[0].get('initial_value', 0) or 0)
                st.session_state['multi_backtest_active_added_amount'] = int(processed_configs[0].get('added_amount', 0) or 0)
                st.session_state['multi_backtest_active_rebal_freq'] = processed_configs[0].get('rebalancing_frequency', 'none')
                st.session_state['multi_backtest_active_add_freq'] = processed_configs[0].get('added_frequency', 'none')
                st.session_state['multi_backtest_active_benchmark'] = processed_configs[0].get('benchmark_ticker', '')
                st.session_state['multi_backtest_active_use_momentum'] = parse_bool_from_json(processed_configs[0].get('use_momentum', True), True)
                st.session_state['multi_backtest_active_collect_dividends_as_cash'] = parse_bool_from_json(processed_configs[0].get('collect_dividends_as_cash', False), False)
                st.session_state['multi_backtest_active_use_targeted_rebalancing'] = parse_bool_from_json(processed_configs[0].get('use_targeted_rebalancing', False), False)
                
                # Use portfolio-specific MA Filter keys (for first portfolio, index 0)
                st.session_state['multi_backtest_active_use_sma_filter_0'] = bool(processed_configs[0].get('use_sma_filter', False))
                st.session_state['multi_backtest_active_ma_window_0'] = processed_configs[0].get('sma_window', 200)
                st.session_state['multi_backtest_active_ma_type_0'] = processed_configs[0].get('ma_type', 'SMA')
                st.session_state['multi_backtest_active_ma_multiplier_0'] = processed_configs[0].get('ma_multiplier', 1.48)
                st.session_state['multi_backtest_active_ma_cross_rebalance_0'] = bool(processed_configs[0].get('ma_cross_rebalance', False))
                st.session_state['multi_backtest_active_ma_tolerance_0'] = processed_configs[0].get('ma_tolerance_percent', 2.0)
                st.session_state['multi_backtest_active_ma_delay_0'] = processed_configs[0].get('ma_confirmation_days', 3)
                
                # Also initialize MA Filter keys for ALL imported portfolios
                for idx, cfg in enumerate(processed_configs):
                    st.session_state[f'multi_backtest_active_use_sma_filter_{idx}'] = parse_bool_from_json(cfg.get('use_sma_filter', False), False)
                    st.session_state[f'multi_backtest_active_ma_window_{idx}'] = cfg.get('sma_window', 200)
                    st.session_state[f'multi_backtest_active_ma_type_{idx}'] = cfg.get('ma_type', 'SMA')
                    st.session_state[f'multi_backtest_active_ma_multiplier_{idx}'] = cfg.get('ma_multiplier', 1.48)
                    st.session_state[f'multi_backtest_active_ma_cross_rebalance_{idx}'] = bool(cfg.get('ma_cross_rebalance', False))
                    st.session_state[f'multi_backtest_active_ma_tolerance_{idx}'] = cfg.get('ma_tolerance_percent', 2.0)
                    st.session_state[f'multi_backtest_active_ma_delay_{idx}'] = cfg.get('ma_confirmation_days', 3)
            else:
                st.session_state.multi_backtest_active_portfolio_index = None
                st.session_state.multi_backtest_portfolio_selector = ''
            st.session_state.multi_backtest_portfolio_key_map = {}
            st.session_state.multi_backtest_ran = False
            st.success('All portfolio configurations updated from JSON (Multi-Backtest page).')
            # Debug: Show final momentum windows for first portfolio
            if processed_configs:
                st.info(f"Final momentum windows for first portfolio: {processed_configs[0]['momentum_windows']}")
                st.info(f"Final use_momentum for first portfolio: {processed_configs[0]['use_momentum']}")
                st.info(f"Sync exclusions for first portfolio - Cash Flow: {processed_configs[0].get('exclude_from_cashflow_sync', False)}, Rebalancing: {processed_configs[0].get('exclude_from_rebalancing_sync', False)}")
            # Sync date widgets with the updated portfolio
            sync_date_widgets_with_portfolio()
            
            # Force a rerun so widgets rebuild with the new configs
            st.session_state.multi_backtest_rerun_flag = True
        else:
            st.error('JSON must be a list of portfolio configurations.')
    except Exception as e:
        st.error(f'Failed to parse JSON: {e}')


with st.sidebar.expander('All Portfolios JSON (Export / Import)', expanded=False):
    # Clean portfolio configs for export by removing unused settings
    def clean_portfolio_configs_for_export(configs):
        cleaned_configs = []
        for config in configs:
            cleaned_config = config.copy()
            # Remove unused settings that were cleaned up
            cleaned_config.pop('use_relative_momentum', None)
            cleaned_config.pop('equal_if_all_negative', None)
            # Update global settings from session state
            cleaned_config['start_with'] = st.session_state.get('multi_backtest_start_with', 'all')
            cleaned_config['first_rebalance_strategy'] = st.session_state.get('multi_backtest_first_rebalance_strategy', 'momentum_window_complete')
            
            # Update custom dates from global session state if enabled
            if st.session_state.get('multi_backtest_use_custom_dates', False):
                cleaned_config['start_date_user'] = st.session_state.get('multi_backtest_start_date')
                cleaned_config['end_date_user'] = st.session_state.get('multi_backtest_end_date')
            
            # Ensure threshold settings are included (read from current config)
            cleaned_config['use_minimal_threshold'] = config.get('use_minimal_threshold', False)
            cleaned_config['minimal_threshold_percent'] = config.get('minimal_threshold_percent', 4.0)
            cleaned_config['use_max_allocation'] = config.get('use_max_allocation', False)
            cleaned_config['max_allocation_percent'] = config.get('max_allocation_percent', 20.0)
            cleaned_config['use_sma_filter'] = config.get('use_sma_filter', False)
            cleaned_config['sma_window'] = config.get('sma_window', 200)
            cleaned_config['ma_type'] = config.get('ma_type', 'SMA')
            cleaned_config['ma_multiplier'] = config.get('ma_multiplier', 1.48)
            cleaned_config['ma_cross_rebalance'] = config.get('ma_cross_rebalance', False)
            cleaned_config['ma_tolerance_percent'] = config.get('ma_tolerance_percent', 2.0)
            cleaned_config['ma_confirmation_days'] = config.get('ma_confirmation_days', 3)
            # Ensure equal weight settings are included (read from current config) - same pattern as max_allocation
            cleaned_config['use_equal_weight'] = config.get('use_equal_weight', False)
            cleaned_config['equal_weight_n_tickers'] = config.get('equal_weight_n_tickers', 10)
            # Ensure limit to top N settings are included (read from current config) - same pattern as equal weight
            cleaned_config['use_limit_to_top_n'] = config.get('use_limit_to_top_n', False)
            cleaned_config['limit_to_top_n_tickers'] = config.get('limit_to_top_n_tickers', 10)
            
            # Convert date objects to strings for JSON serialization
            if cleaned_config.get('start_date_user') is not None:
                cleaned_config['start_date_user'] = cleaned_config['start_date_user'].isoformat() if hasattr(cleaned_config['start_date_user'], 'isoformat') else str(cleaned_config['start_date_user'])
            if cleaned_config.get('end_date_user') is not None:
                cleaned_config['end_date_user'] = cleaned_config['end_date_user'].isoformat() if hasattr(cleaned_config['end_date_user'], 'isoformat') else str(cleaned_config['end_date_user'])
            
            cleaned_configs.append(cleaned_config)
        return cleaned_configs
    
    cleaned_configs = clean_portfolio_configs_for_export(st.session_state.get('multi_backtest_portfolio_configs', []))
    all_json = json.dumps(cleaned_configs, indent=2)
    st.code(all_json, language='json')
    import streamlit.components.v1 as components
    copy_html_all = f"""
    <button onclick='navigator.clipboard.writeText({json.dumps(all_json)});' style='margin-bottom:10px;'>Copy All Configs to Clipboard</button>
    """
    components.html(copy_html_all, height=40)
    
    # Add PDF download button for JSON
    def generate_json_pdf(custom_name=""):
        """Generate a PDF with pure JSON content only for easy CTRL+A / CTRL+V copying."""
        from reportlab.lib.pagesizes import letter, A4
        from reportlab.platypus import SimpleDocTemplate, Preformatted
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        import io
        from datetime import datetime
        
        # Create PDF buffer
        buffer = io.BytesIO()
        
        # Add proper PDF metadata
        portfolio_count = len(st.session_state.get('multi_backtest_portfolio_configs', []))
        
        # Use custom name if provided, otherwise use default
        if custom_name.strip():
            title = f"Multi Backtest - {custom_name.strip()} - JSON Configuration"
            subject = f"JSON Configuration for Multi Backtest: {custom_name.strip()} ({portfolio_count} portfolios)"
        else:
            title = f"Multi Backtest - All Portfolios ({portfolio_count}) - JSON Configuration"
            subject = f"JSON Configuration for {portfolio_count} Multi Backtest Portfolios"
        
        doc = SimpleDocTemplate(
            buffer, 
            pagesize=A4, 
            rightMargin=36, 
            leftMargin=36, 
            topMargin=36, 
            bottomMargin=36,
            title=title,
            author="Portfolio Backtest System",
            subject=subject,
            creator="Multi Backtest Application"
        )
        story = []
        
        # Pure JSON style - just monospace text
        json_style = ParagraphStyle(
            'PureJSONStyle',
            fontName='Courier',
            fontSize=10,
            leading=12,
            leftIndent=0,
            rightIndent=0,
            spaceAfter=0,
            spaceBefore=0
        )
        
        # Add only the JSON content - no headers, no instructions, just pure JSON
        json_lines = all_json.split('\n')
        for line in json_lines:
            story.append(Preformatted(line, json_style))
        
        # Build PDF
        doc.build(story)
        pdf_data = buffer.getvalue()
        buffer.close()
        
        return pdf_data
    
    # Optional custom PDF name
    custom_pdf_name = st.text_input(
        "üìù Custom PDF Name (optional):", 
        value="",
        placeholder="e.g., Tech vs Conservative Comparison, Q4 2024 Analysis, etc.",
        help="Leave empty to use automatic naming: 'Multi Backtest - All Portfolios (X) - JSON Configuration'",
        key="multi_backtest_custom_pdf_name"
    )
    
    if st.button("üìÑ Download JSON as PDF", help="Download a PDF containing the JSON configuration for easy copying", key="multi_backtest_json_pdf_btn"):
        try:
            pdf_data = generate_json_pdf(custom_pdf_name)
            
            # Generate filename based on custom name or default
            if custom_pdf_name.strip():
                clean_name = custom_pdf_name.strip().replace(' ', '_').replace('/', '_').replace('\\', '_')
                filename = f"{clean_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
            else:
                filename = f"multi_backtest_configs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
            
            st.download_button(
                label="üíæ Download Multi Backtest JSON PDF",
                data=pdf_data,
                file_name=filename,
                mime="application/pdf",
                key="multi_backtest_json_pdf_download"
            )
            st.success("PDF generated successfully! Click the download button above.")
        except Exception as e:
            st.error(f"Error generating PDF: {str(e)}")
    
    st.text_area('Paste JSON Here to Replace All Portfolios', key='multi_backtest_paste_all_json_text', height=240)
    st.button('Update All Portfolios from JSON', on_click=paste_all_json_callback)
    
    # Add PDF drag and drop functionality for all portfolios
    st.markdown("**OR** üìé **Drag & Drop JSON PDF:**")
    
    def extract_json_from_pdf_all(pdf_file):
        """Extract JSON content from a PDF file."""
        try:
            # Try pdfplumber first (more reliable)
            try:
                import pdfplumber
                import io
                
                # Read PDF content with pdfplumber
                pdf_bytes = io.BytesIO(pdf_file.read())
                text_content = ""
                
                with pdfplumber.open(pdf_bytes) as pdf:
                    for page in pdf.pages:
                        text_content += page.extract_text() or ""
                        
            except ImportError:
                # Fallback to PyPDF2 if pdfplumber not available
                try:
                    import PyPDF2
                    import io
                    
                    # Reset file pointer
                    pdf_file.seek(0)
                    pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
                    
                    # Extract text from all pages
                    text_content = ""
                    for page in pdf_reader.pages:
                        text_content += page.extract_text()
                        
                except ImportError:
                    return None, "PDF extraction libraries not available. Please install 'pip install PyPDF2' or 'pip install pdfplumber'"
            
            # Clean up the text and try to parse as JSON
            cleaned_text = text_content.strip()
            
            # Try to parse as JSON
            import json
            json_data = json.loads(cleaned_text)
            return json_data, None
            
        except json.JSONDecodeError as e:
            return None, f"Invalid JSON in PDF: {str(e)}"
        except Exception as e:
            return None, str(e)
    
    uploaded_pdf_all = st.file_uploader(
        "Drop your All Portfolios JSON PDF here", 
        type=['pdf'], 
        help="Upload a JSON PDF file containing all portfolio configurations",
        key="multi_all_pdf_upload"
    )
    
    if uploaded_pdf_all is not None:
        json_data, error = extract_json_from_pdf_all(uploaded_pdf_all)
        if json_data:
            # Store the extracted JSON in a different session state key to avoid widget conflicts
            st.session_state["multi_backtest_extracted_json_all"] = json.dumps(json_data, indent=2)
            st.success(f"‚úÖ Successfully extracted JSON from {uploaded_pdf_all.name}")
            st.info("üëá Click the button below to load the JSON into the text area.")
            def load_extracted_json_all():
                st.session_state["multi_backtest_paste_all_json_text"] = st.session_state["multi_backtest_extracted_json_all"]
            
            st.button("üìã Load Extracted JSON", key="load_extracted_json_all", on_click=load_extracted_json_all)
        else:
            st.error(f"‚ùå Failed to extract JSON from PDF: {error}")
            st.info("üí° Make sure the PDF contains valid JSON content (generated by this app)")

if 'multi_backtest_ran' in st.session_state and st.session_state.multi_backtest_ran:
    if 'multi_all_results' in st.session_state and st.session_state.multi_all_results:
        # Use the no-additions series for all display and calculations
        first_date = min(series['no_additions'].index.min() for series in st.session_state.multi_all_results.values())
        last_date = max(series['no_additions'].index.max() for series in st.session_state.multi_all_results.values())
        st.subheader(f"Results for Backtest Period: {first_date.strftime('%Y-%m-%d')} to {last_date.strftime('%Y-%m-%d')}")

        # Chart options in columns
        col1, col2 = st.columns(2)
        
        # Hover mode option with error handling
        with col1:
            try:
                show_closest_only = st.checkbox(
                    "Show Only Closest Portfolio on Hover",
                    value=False,
                    help="When enabled, hovering will show only the portfolio line closest to your cursor instead of all portfolios.",
                    key="multi_chart_closest_hover"
                )
            except Exception as e:
                st.warning(f"Error with hover checkbox: {e}")
                show_closest_only = False
        
        # Log scale option
        with col2:
            try:
                use_log_scale = st.checkbox(
                    "Use Log Scale for Y-Axis",
                    value=False,
                    help="When enabled, the Y-axis will use logarithmic scale, which is useful for comparing portfolios with very different performance ranges.",
                    key="multi_chart_log_scale"
                )
            except Exception as e:
                st.warning(f"Error with log scale checkbox: {e}")
                use_log_scale = False
        
        fig1 = go.Figure()
        # CRITICAL: Maintain portfolio order from portfolio_configs
        portfolio_order = [cfg['name'] for cfg in st.session_state.multi_backtest_portfolio_configs if cfg['name'] in st.session_state.multi_all_results]
        for name in portfolio_order:
            series_dict = st.session_state.multi_all_results[name]
            try:
                # Plot the series that includes added cash (with_additions) for comparison
                series_to_plot = series_dict['with_additions'] if isinstance(series_dict, dict) and 'with_additions' in series_dict else series_dict
                
                # Validate data before plotting
                if series_to_plot is None or len(series_to_plot) == 0:
                    st.warning(f"‚ö†Ô∏è No data available for portfolio: {name}")
                    continue
                
                # Convert timestamp index to proper datetime for plotting - ensure it's actually datetime format
                if hasattr(series_to_plot.index, 'to_pydatetime'):
                    x_dates = series_to_plot.index.to_pydatetime()
                else:
                    x_dates = pd.to_datetime(series_to_plot.index)
                
                # Validate x_dates and values
                if len(x_dates) != len(series_to_plot.values):
                    st.warning(f"‚ö†Ô∏è Data length mismatch for portfolio: {name}")
                    continue
                    
                # Set hover mode based on user preference with fallback
                try:
                    current_hover_mode = "closest" if show_closest_only else "x unified"
                except NameError:
                    current_hover_mode = "x unified"
                
                fig1.add_trace(go.Scatter(
                    x=x_dates, 
                    y=series_to_plot.values, 
                    mode='lines', 
                    name=name,
                    hovertemplate=f"<b>{name}</b><br>Portfolio Value: $%{{y:,.2f}}<br>Date: %{{x|%Y-%m-%d}}<extra></extra>" if show_closest_only else f"<b>{name}</b><br>Portfolio Value: $%{{y:,.2f}}<br>Date: %{{x|%Y-%m-%d}}<extra></extra>",
                    hoverinfo='text'
                ))
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Error plotting portfolio {name}: {str(e)}")
                continue
        # Set hover mode based on user preference with fallback
        try:
            hover_mode = "closest" if show_closest_only else "x unified"
        except NameError:
            # Fallback if show_closest_only is not defined
            hover_mode = "x unified"
        
        fig1.update_layout(
            title="Backtest Comparison ‚Äî Portfolio Value (with cash additions)",
            xaxis_title="Date",
            legend_title="Portfolios",
            hovermode=hover_mode,
            template="plotly_dark",
            yaxis_tickprefix="$",
            yaxis_tickformat=",.0f",
            # No width/height restrictions - let them be responsive like other plots
            xaxis=dict(
                type='date',  # Explicitly set as date type
                tickformat="%Y-%m-%d",  # Proper date format
                tickmode="auto",
                nticks=10,  # Reasonable number of ticks
                tickangle=45,  # Angle labels for better readability
                automargin=True,  # Ensure labels fit
                range=None  # Let Plotly auto-range to ensure perfect alignment
            ),
            # Improve legend layout to prevent name truncation
            legend=dict(
                orientation="h",
                yanchor="top",
                y=1.05,
                xanchor="center",
                x=0.5,
                font=dict(size=10),
                itemwidth=30
            ),
            margin=dict(t=120, l=80, r=80, b=80),  # Standardized margins for alignment
            height=600,  # Taller height to prevent crushing
            yaxis=dict(
                title="Portfolio Value ($)", 
                title_standoff=20,
                side="left",
                position=0.0,  # Force left alignment for perfect positioning
                type="log" if use_log_scale else "linear",  # Use log scale if checkbox is checked
                tickmode="array" if use_log_scale else "auto",  # Use array mode for log scale to control ticks
                tickvals=[10000, 50000, 100000, 500000, 1000000] if use_log_scale else None,  # Define specific tick positions for log scale
                ticktext=["$10K", "$50K", "$100K", "$500K", "$1M"] if use_log_scale else None,  # Shorter labels for log scale
                nticks=5 if use_log_scale else None  # Limit number of ticks for log scale
            )
        )
        st.plotly_chart(fig1, use_container_width=True, key="multi_performance_chart")
        # Store in session state for PDF export
        st.session_state.fig1 = fig1

        fig2 = go.Figure()
        # CRITICAL: Maintain portfolio order from portfolio_configs (same as fig1)
        for name in portfolio_order:
            series_dict = st.session_state.multi_all_results[name]
            try:
                # Use the no-additions series for drawdown calculation (pure portfolio performance)
                series_to_plot = series_dict['no_additions'] if isinstance(series_dict, dict) and 'no_additions' in series_dict else series_dict
                
                # Validate data before processing
                if series_to_plot is None or len(series_to_plot) == 0:
                    st.warning(f"‚ö†Ô∏è No data available for drawdown calculation: {name}")
                    continue
                
                # Calculate drawdown for this series
                values = series_to_plot.values
                if len(values) == 0:
                    continue
                    
                peak = np.maximum.accumulate(values)
                drawdowns = (values - peak) / np.where(peak == 0, 1, peak) * 100  # Convert to percentage
                
                # Convert timestamp index to proper datetime for plotting - ensure it's actually datetime format
                if hasattr(series_to_plot.index, 'to_pydatetime'):
                    x_dates = series_to_plot.index.to_pydatetime()
                else:
                    x_dates = pd.to_datetime(series_to_plot.index)
                
                # Validate x_dates and drawdowns
                if len(x_dates) != len(drawdowns):
                    st.warning(f"‚ö†Ô∏è Data length mismatch for drawdown: {name}")
                    continue
                    
                # Set hover mode based on user preference with fallback
                try:
                    current_hover_mode_dd = "closest" if show_closest_only else "x unified"
                except NameError:
                    current_hover_mode_dd = "x unified"
                
                fig2.add_trace(go.Scatter(
                    x=x_dates, 
                    y=drawdowns, 
                    mode='lines', 
                    name=name,
                    hovertemplate=f"<b>{name}</b><br>Drawdown: %{{y:.2f}}%<br>Date: %{{x|%Y-%m-%d}}<extra></extra>" if show_closest_only else f"<b>{name}</b><br>Drawdown: %{{y:.2f}}%<br>Date: %{{x|%Y-%m-%d}}<extra></extra>",
                    hoverinfo='text'
                ))
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Error calculating drawdown for portfolio {name}: {str(e)}")
                continue
        fig2.update_layout(
            title="Backtest Comparison (Max Drawdown)",
            xaxis_title="Date",
            legend_title="Portfolios",
            hovermode=hover_mode if 'hover_mode' in locals() else "x unified",  # Use the same hover mode as the main chart
            template="plotly_dark",
            # No width/height restrictions - let them be responsive like other plots
            xaxis=dict(
                type='date',  # Explicitly set as date type
                tickformat="%Y-%m-%d",  # Proper date format
                tickmode="auto",
                nticks=10,  # Reasonable number of ticks
                tickangle=45,  # Angle labels for better readability
                automargin=True,  # Ensure labels fit
                range=None  # Let Plotly auto-range to ensure perfect alignment
            ),
            # Improve legend layout to prevent name truncation
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="center",
                x=0.5,
                font=dict(size=10),
                itemwidth=30
            ),
            margin=dict(t=80, l=80, r=80, b=120),  # More space at bottom for legend
            height=600,  # Taller height to prevent crushing
            yaxis=dict(
                title="Drawdown (%)", 
                title_standoff=20,
                side="left",
                position=0.0  # Force left alignment for perfect positioning
            )
        )
        
        
        st.plotly_chart(fig2, use_container_width=True, key="multi_drawdown_chart")
        # Store in session state for PDF export
        st.session_state.fig2 = fig2

        # VIX Index Plot (for correlation with drawdowns)
        fig_vix = go.Figure()
        try:
            # Get VIX data for the same date range
            vix_data = get_batch_download_with_cache('^VIX', start=first_date, end=last_date, progress=False)
            st.session_state.api_call_count += 1
            
            # VIX data has multi-level columns, need to access it properly
            # The structure is ('Close', '^VIX') instead of just 'Close'
            if ('Close', '^VIX') in vix_data.columns:
                vix_close = vix_data[('Close', '^VIX')].dropna()
            else:
                # Fallback to regular Close column
                vix_close = vix_data['Close'].dropna()
            
            # Add flat line before VIX data starts (like interest rates do)
            if len(vix_close) > 0:
                first_vix_date = vix_close.index[0]
                first_vix_value = vix_close.iloc[0]
                
                # If VIX data starts after our backtest period, add flat line
                if first_vix_date > pd.Timestamp(first_date):
                    # Create flat line from start to first VIX date
                    flat_dates = pd.date_range(start=first_date, end=first_vix_date, freq='D')
                    fig_vix.add_trace(go.Scatter(
                        x=flat_dates, 
                        y=[first_vix_value] * len(flat_dates), 
                        mode='lines', 
                        name='VIX Index (Pre-Data)', 
                        line=dict(color='red', dash='dash'),
                        hovertemplate='<b>VIX Index (Pre-Data)</b><br>' +
                                     'Date: %{x}<br>' +
                                     'VIX: %{y:.2f}<br>' +
                                     '<extra></extra>'
                    ))
            
            # Add actual VIX data
            fig_vix.add_trace(go.Scatter(
                x=vix_close.index, 
                y=vix_close.values, 
                mode='lines', 
                name='VIX Index', 
                line=dict(color='red'),
                hovertemplate='<b>VIX Index</b><br>' +
                             'Date: %{x}<br>' +
                             'VIX: %{y:.2f}<br>' +
                             '<extra></extra>'
            ))
            
        except Exception as e:
            # Fallback: create a simple line at default VIX if fetching fails
            x_dates = pd.date_range(start=first_date, end=last_date, freq='D')
            fig_vix.add_trace(go.Scatter(
                x=x_dates, 
                y=[20.0] * len(x_dates), 
                mode='lines', 
                name='VIX Index (Default)', 
                line=dict(color='red')
            ))
        
        fig_vix.update_layout(
            title="VIX Index (Fear Gauge)",
            xaxis_title="Date",
            legend_title="Index",
            hovermode="x unified",
            template="plotly_dark",
            # EXACT same formatting as the other plots
            xaxis=dict(
                type='date',  # Explicitly set as date type
                tickformat="%Y-%m-%d",  # Proper date format
                tickmode="auto",
                nticks=10,  # Reasonable number of ticks
                tickangle=45,  # Angle labels for better readability
                automargin=True,  # Ensure labels fit
                range=None  # Let Plotly auto-range to ensure perfect alignment
            ),
            legend=dict(
                orientation="h",  # Horizontal legend
                yanchor="top",
                y=1.15,
                xanchor="center",
                x=0.5
            ),
            margin=dict(t=120, l=80, r=80, b=80),  # Standardized margins for alignment
            height=600,  # Same height as the other plots
            yaxis=dict(
                title="VIX Level", 
                title_standoff=20,
                side="left",
                position=0.0,  # Force left alignment for perfect positioning
                range=[0, 80] if 'vix_close' in locals() and len(vix_close) > 0 else [0, 80]
            )
        )
        st.plotly_chart(fig_vix, use_container_width=True, key="vix_chart")
        # Store in session state for PDF export
        st.session_state.fig_vix = fig_vix

        # Fourth plot: Daily Risk-Free Rate (13-Week Treasury)
        fig3 = go.Figure()
        try:
            # Get risk-free rate data for the same date range
            risk_free_rates = get_risk_free_rate_robust(pd.date_range(start=first_date, end=last_date, freq='D'))
            
            # Convert timestamp index to proper datetime for plotting
            if hasattr(risk_free_rates.index, 'to_pydatetime'):
                x_dates = risk_free_rates.index.to_pydatetime()
            else:
                x_dates = pd.to_datetime(risk_free_rates.index)
            
            # Convert to daily basis points for display (multiply by 10000)
            daily_rates_bp = risk_free_rates * 10000
            
            fig3.add_trace(go.Scatter(
                x=x_dates, 
                y=daily_rates_bp.values, 
                mode='lines', 
                name='Daily Risk-Free Rate', 
                line=dict(color='#00ff88'),
                hovertemplate='<b>Daily Risk-Free Rate</b><br>' +
                             'Date: %{x}<br>' +
                             'Rate: %{y:.2f} bps<br>' +
                             '<extra></extra>'
            ))
            
        except Exception as e:
            # Fallback: create a simple line at default rate if risk-free rate fetching fails
            x_dates = pd.date_range(start=first_date, end=last_date, freq='D')
            default_daily_bp = 0.02 / 365.25 * 10000  # Convert 2% annual to daily basis points
            fig3.add_trace(go.Scatter(
                x=x_dates, 
                y=[default_daily_bp] * len(x_dates), 
                mode='lines', 
                name='Daily Risk-Free Rate (Default)', 
                line=dict(color='#00ff88')
            ))
        
        fig3.update_layout(
            title="Daily Risk-Free Rate (13-Week Treasury)",
            xaxis_title="Date",
            legend_title="Rate",
            hovermode="x unified",
            template="plotly_dark",
            # EXACT same formatting as the other two plots
            xaxis=dict(
                type='date',  # Explicitly set as date type
                tickformat="%Y-%m-%d",  # Proper date format
                tickmode="auto",
                nticks=10,  # Reasonable number of ticks
                tickangle=45,  # Angle labels for better readability
                automargin=True,  # Ensure labels fit
                range=None  # Let Plotly auto-range to ensure perfect alignment
            ),
            legend=dict(
                orientation="h",  # Horizontal legend
                yanchor="top",
                y=1.15,
                xanchor="center",
                x=0.5
            ),
            margin=dict(t=120, l=80, r=80, b=80),  # Standardized margins for alignment
            height=600,  # Same height as the other plots
            yaxis=dict(
                title="Daily Risk-Free Rate (basis points)", 
                title_standoff=20,
                side="left",
                position=0.0,  # Force left alignment for perfect positioning
                range=[0, max(daily_rates_bp) * 1.1] if 'daily_rates_bp' in locals() and len(daily_rates_bp) > 0 else [0, 2]
            )
        )
        st.plotly_chart(fig3, use_container_width=True, key="multi_daily_risk_free_chart")
        # Store in session state for PDF export
        st.session_state.fig3 = fig3

        # Fourth plot: Annualized Risk-Free Rate (13-Week Treasury)
        fig4 = go.Figure()
        try:
            # Get risk-free rate data for the same date range
            risk_free_rates = get_risk_free_rate_robust(pd.date_range(start=first_date, end=last_date, freq='D'))
            
            # Convert timestamp index to proper datetime for plotting
            if hasattr(risk_free_rates.index, 'to_pydatetime'):
                x_dates = risk_free_rates.index.to_pydatetime()
            else:
                x_dates = pd.to_datetime(risk_free_rates.index)
            
            # Convert to annualized percentage for display
            # Daily rate to annual: (1 + daily_rate)^365.25 - 1
            annual_rates = ((1 + risk_free_rates) ** 365.25 - 1) * 100
            
            fig4.add_trace(go.Scatter(
                x=x_dates, 
                y=annual_rates.values, 
                mode='lines', 
                name='Annualized Risk-Free Rate', 
                line=dict(color='#ff8800'),
                hovertemplate='<b>Annualized Risk-Free Rate</b><br>' +
                             'Date: %{x}<br>' +
                             'Rate: %{y:.2f}%<br>' +
                             '<extra></extra>'
            ))
            
        except Exception as e:
            # Fallback: create a simple line at 2% if risk-free rate fetching fails
            x_dates = pd.date_range(start=first_date, end=last_date, freq='D')
            fig4.add_trace(go.Scatter(
                x=x_dates, 
                y=[2.0] * len(x_dates), 
                mode='lines', 
                name='Annualized Risk-Free Rate (Default)', 
                line=dict(color='#ff8800')
            ))
        
        fig4.update_layout(
            title="Annualized Risk-Free Rate (13-Week Treasury)",
            xaxis_title="Date",
            legend_title="Rate",
            hovermode="x unified",
            template="plotly_dark",
            # EXACT same formatting as the other plots
            xaxis=dict(
                type='date',  # Explicitly set as date type
                tickformat="%Y-%m-%d",  # Proper date format
                tickmode="auto",
                nticks=10,  # Reasonable number of ticks
                tickangle=45,  # Angle labels for better readability
                automargin=True,  # Ensure labels fit
                range=None  # Let Plotly auto-range to ensure perfect alignment
            ),
            legend=dict(
                orientation="h",  # Horizontal legend
                yanchor="top",
                y=1.15,
                xanchor="center",
                x=0.5
            ),
            margin=dict(t=120, l=80, r=80, b=80),  # Standardized margins for alignment
            height=600,  # Same height as the other plots
            yaxis=dict(
                title="Annualized Risk-Free Rate (%)", 
                title_standoff=20,
                side="left",
                position=0.0,  # Force left alignment for perfect positioning
                range=[0, max(annual_rates) * 1.1] if 'annual_rates' in locals() and len(annual_rates) > 0 else [0, 6]
            )
        )
        st.plotly_chart(fig4, use_container_width=True, key="multi_annual_risk_free_chart")
        # Store in session state for PDF export
        st.session_state.fig4 = fig4

        # Multi-Portfolio PE Ratio Comparison (moved after Risk Free Rate charts)
        st.markdown("---")
        st.markdown("**üìä Multi-Portfolio PE Ratio Comparison**")
        st.warning("‚ö†Ô∏è **Work in Progress:** PE ratio calculations are currently using current PE ratios only. Historical PE evolution is not yet implemented and may not be fully accurate.")
        
        try:
            # Create multi-portfolio PE ratio chart
            fig_pe_multi = go.Figure()
            
            # Get all available portfolio names
            available_portfolio_names = [cfg.get('name', 'Portfolio') for cfg in st.session_state.get('multi_backtest_portfolio_configs', [])]
            extra_names = [n for n in st.session_state.get('multi_all_results', {}).keys() if n not in available_portfolio_names]
            all_portfolio_names = available_portfolio_names + extra_names
            
            # Color palette for different portfolios
            colors = [
                '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',
                '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf',
                '#aec7e8', '#ffbb78', '#98df8a', '#ff9896', '#c5b0d5'
            ]
            
            # Collect PE data for all portfolios
            all_pe_data = {}
            portfolio_pe_series = {}
            
            for i, portfolio_name in enumerate(all_portfolio_names):
                allocs_data = st.session_state.multi_all_allocations.get(portfolio_name, {})
                
                if allocs_data:
                    # Get all unique tickers for this portfolio (exclude CASH)
                    all_tickers = set()
                    for date, allocs in allocs_data.items():
                        for ticker in allocs.keys():
                            if ticker is not None and ticker != 'CASH':
                                all_tickers.add(ticker)
                    all_tickers = sorted(list(all_tickers))
                    
                    if all_tickers:
                        # Fetch PE data for all tickers (cached per portfolio)
                        # Use batch download for PE data (much faster!)
                        pe_data = get_multiple_tickers_info_batch(all_tickers)
                        # Extract PE ratios from batch results
                        pe_data = {ticker: info.get('trailingPE', None) for ticker, info in pe_data.items() if info.get('trailingPE') is not None and info.get('trailingPE') > 0}
                        
                        # Initialize historical PE data as empty (placeholder for future implementation)
                        historical_pe_data = {}
                        
                        if pe_data:
                            # Calculate weighted average PE for this portfolio
                            total_weighted_pe = 0
                            total_weight = 0
                            
                            for date, allocs in allocs_data.items():
                                for ticker, weight in allocs.items():
                                    if ticker in pe_data and ticker != 'CASH':
                                        total_weighted_pe += pe_data[ticker] * weight
                                        total_weight += weight
                            
                            if total_weight > 0:
                                avg_pe = total_weighted_pe / total_weight
                                all_pe_data[portfolio_name] = avg_pe
                                
                                # Create a simple time series for visualization (using backtest dates)
                                if st.session_state.multi_all_results.get(portfolio_name):
                                    series_data = st.session_state.multi_all_results[portfolio_name]
                                    if isinstance(series_data, dict) and 'with_additions' in series_data:
                                        dates = series_data['with_additions'].index
                                    else:
                                        dates = series_data.index if hasattr(series_data, 'index') else []
                                    
                                    if len(dates) > 0:
                                        # Create PE series with constant value (since we only have current PE)
                                        pe_series = pd.Series([avg_pe] * len(dates), index=dates)
                                        portfolio_pe_series[portfolio_name] = pe_series
                                        
                                        # Add to chart
                                        fig_pe_multi.add_trace(go.Scatter(
                                            x=dates,
                                            y=pe_series.values,
                                            mode='lines',
                                            name=portfolio_name,
                                            line=dict(color=colors[i % len(colors)], width=2),
                                            hovertemplate=f'<b>{portfolio_name}</b><br>PE Ratio: %{{y:.2f}}<br>Date: %{{x|%Y-%m-%d}}<extra></extra>'
                                        ))
            
            # Update layout
            fig_pe_multi.update_layout(
                title="Multi-Portfolio PE Ratio Comparison",
                xaxis_title="Date",
                yaxis_title="PE Ratio",
                legend_title="Portfolios",
                hovermode="x unified",
                template="plotly_dark",
                height=600,
                xaxis=dict(
                    type='date',
                    tickformat="%Y-%m-%d",
                    tickmode="auto",
                    nticks=10,
                    tickangle=45,
                    automargin=True
                ),
                legend=dict(
                    orientation="h",
                    yanchor="top",
                    y=1.15,
                    xanchor="center",
                    x=0.5
                ),
                margin=dict(t=120, l=80, r=80, b=80)
            )
            
            # Store in session state and display
            st.session_state.fig_pe_multi = fig_pe_multi
            
            if portfolio_pe_series:
                st.plotly_chart(st.session_state.fig_pe_multi, use_container_width=True)
                
            else:
                st.warning("No PE ratio data available for any portfolios.")
                
        except Exception as e:
            st.error(f"Error creating multi-portfolio PE ratio chart: {str(e)}")

        # --- Variation summary chart: compares total return, CAGR, volatility and max drawdown across portfolios ---
        try:
            def get_no_additions_series(obj):
                return obj['no_additions'] if isinstance(obj, dict) and 'no_additions' in obj else obj if isinstance(obj, pd.Series) else None

            metrics_summary = {}
            for name, series_obj in st.session_state.multi_all_results.items():
                ser_no = get_no_additions_series(series_obj)
                if ser_no is None or len(ser_no) < 2:
                    continue
                vals = ser_no.values
                dates = ser_no.index
                # Total return over the period
                try:
                    total_return = (vals[-1] / vals[0] - 1) * 100 if vals[0] and not np.isnan(vals[0]) else np.nan
                except Exception:
                    total_return = np.nan

                # CAGR, volatility, max drawdown (convert to percent for display)
                try:
                    cagr = calculate_cagr(vals, dates)
                except Exception:
                    cagr = np.nan
                try:
                    returns = pd.Series(vals, index=dates).pct_change().fillna(0)
                    vol = calculate_volatility(returns)
                except Exception:
                    vol = np.nan
                try:
                    max_dd, _ = calculate_max_drawdown(vals)
                except Exception:
                    max_dd = np.nan

                metrics_summary[name] = {
                    'Total Return': total_return,
                    'CAGR': (cagr * 100) if isinstance(cagr, (int, float)) and not np.isnan(cagr) else np.nan,
                    'Volatility': (vol * 100) if isinstance(vol, (int, float)) and not np.isnan(vol) else np.nan,
                    'Max Drawdown': (max_dd * 100) if isinstance(max_dd, (int, float)) and not np.isnan(max_dd) else np.nan,
                }

            if metrics_summary:
                df_metrics = pd.DataFrame(metrics_summary).T
                # Ensure numeric columns
                for c in df_metrics.columns:
                    df_metrics[c] = pd.to_numeric(df_metrics[c], errors='coerce')

                # Create grouped bar chart
                fig_metrics = go.Figure()
                metric_order = ['Total Return', 'CAGR', 'Volatility', 'Max Drawdown']
                colors = ['#1f77b4', '#2ca02c', '#ff7f0e', '#d62728']
                for i, metric in enumerate(metric_order):
                    if metric in df_metrics.columns:
                        y_values = df_metrics[metric].values
                        
                        # Transform values for symmetric log-like display
                        # Positive values: log scale, Negative values: -log(abs(value))
                        transformed_values = []
                        for val in y_values:
                            if pd.isna(val):
                                transformed_values.append(np.nan)
                            elif val > 0:
                                transformed_values.append(np.log10(val + 1))  # +1 to handle 0
                            elif val < 0:
                                transformed_values.append(-np.log10(abs(val) + 1))  # Negative log for negative values
                            else:  # val == 0
                                transformed_values.append(0)
                        
                        fig_metrics.add_trace(go.Bar(
                            x=df_metrics.index,
                            y=transformed_values,
                            name=metric,
                            marker_color=colors[i % len(colors)],
                            text=[f"{v:.2f}%" if not pd.isna(v) else 'N/A' for v in y_values],
                            textposition='auto',
                            showlegend=True
                        ))

                fig_metrics.update_layout(
                    title='Portfolio Variation Summary (percent)',
                    barmode='group',
                    template='plotly_dark',
                    yaxis=dict(
                        title='Percent (Log Scale)', 
                        ticksuffix='%',
                        showticklabels=False,  # Remove Y-axis tick labels
                        # Linear scale since we transformed the values manually
                    ),
                    legend=dict(
                        orientation="h",
                        yanchor="bottom",
                        y=1.02,
                        xanchor="right",
                        x=1,
                        font=dict(size=10)
                    ),
                    height=520,
                    margin=dict(l=60, r=40, t=80, b=120),
                )

                st.plotly_chart(fig_metrics, use_container_width=True, key="multi_metrics_chart")
        except Exception as e:
            pass

        # --- Monthly returns heatmap: rows = portfolios, columns = Year-Month, values = monthly % change ---
        try:
            # Build a DataFrame of monthly returns for each portfolio
            monthly_returns = {}
            # CRITICAL: Maintain portfolio order from portfolio_configs
            portfolio_order_monthly = [cfg['name'] for cfg in st.session_state.multi_backtest_portfolio_configs if cfg['name'] in st.session_state.multi_all_results]
            for name in portfolio_order_monthly:
                series_obj = st.session_state.multi_all_results[name]
                ser_no = series_obj['no_additions'] if isinstance(series_obj, dict) and 'no_additions' in series_obj else series_obj if isinstance(series_obj, pd.Series) else None
                if ser_no is None or len(ser_no) < 2:
                    continue
                # Resample to month-end and compute percent change
                try:
                    # Use month-end resample with 'ME' alias to avoid FutureWarning; keep as DatetimeIndex
                    ser_month = ser_no.resample('ME').last()
                    pct_month = ser_month.pct_change().dropna() * 100
                    # label months as 'YYYY-MM' using DatetimeIndex to avoid PeriodArray conversion
                    pct_month.index = pct_month.index.strftime('%Y-%m')
                    monthly_returns[name] = pct_month
                except Exception:
                    continue

            if monthly_returns:
                # Align indexes (months) across portfolios
                all_months = sorted(list({m for ser in monthly_returns.values() for m in ser.index}))
                heat_data = pd.DataFrame(index=list(monthly_returns.keys()), columns=all_months)
                for name, ser in monthly_returns.items():
                    for m, v in ser.items():
                        heat_data.at[name, m] = v
                heat_data = heat_data.astype(float)

                # Create heatmap with Plotly
                fig_heat = go.Figure(data=go.Heatmap(
                    z=heat_data.values,
                    x=heat_data.columns.astype(str),
                    y=heat_data.index.astype(str),
                    colorscale='RdYlGn',
                    colorbar=dict(title='Monthly %'),
                    hovertemplate='Portfolio: %{y}<br>Month: %{x}<br>Return: %{z:.2f}%<extra></extra>'
                ))
                fig_heat.update_layout(
                    title='Monthly Returns Heatmap (rows=portfolios, columns=year-month)',
                    xaxis_nticks=20,
                    template='plotly_dark',
                    height=400
                )
                st.plotly_chart(fig_heat, use_container_width=True, key="multi_heatmap_chart")
        except Exception as e:
            pass

        # Recompute Final Performance Statistics from stored results to ensure they use the no-additions series
        if 'multi_all_results' in st.session_state and st.session_state.multi_all_results:
            # Helper to extract no-additions series whether stored as dict or Series
            def get_no_additions(series_or_dict):
                return series_or_dict['no_additions'] if isinstance(series_or_dict, dict) and 'no_additions' in series_or_dict else series_or_dict

            # MWRR will be calculated fresh for each portfolio in the recomputation loop

            recomputed_stats = {}

            def scale_pct(val):
                if val is None or (isinstance(val, (int, float)) and np.isnan(val)):
                    return np.nan
                if isinstance(val, str):
                    return val  # Return strings as-is (like "N/A")
                if isinstance(val, (int, float)) and -1.5 < val < 1.5:
                    return val * 100
                return val

            def clamp_stat(val, stat_type):
                if val is None or (isinstance(val, float) and np.isnan(val)):
                    return "N/A"
                v = scale_pct(val)
                
                # If scale_pct returned a string (like "N/A"), return it as-is
                if isinstance(v, str):
                    return v
                
                # Apply specific scaling for Total Return before clamping
                if stat_type == "Total Return":
                    # Total Return is now always in percentage format for both positive and negative CAGR
                    # No conversion needed - already in percentage format
                    pass
                
                # Clamping logic - separate Total Return from other percentage stats
                if stat_type in ["CAGR", "Volatility", "MWRR"]:
                    if isinstance(v, (int, float)) and v > 100:
                        return "N/A"
                elif stat_type == "Total Return":
                    # Allow negative total returns - no clamping needed
                    pass
                elif stat_type == "MaxDrawdown":
                    if isinstance(v, (int, float)) and (v < -100 or v > 0):
                        return "N/A"
                
                return f"{v:.2f}%" if stat_type in ["CAGR", "MaxDrawdown", "Volatility", "MWRR", "Total Return"] else f"{v:.3f}" if isinstance(v, float) else v

            # CRITICAL: Maintain portfolio order from portfolio_configs
            portfolio_order_recomputed = [cfg['name'] for cfg in st.session_state.multi_backtest_portfolio_configs if cfg['name'] in st.session_state.multi_all_results]
            for name in portfolio_order_recomputed:
                series_obj = st.session_state.multi_all_results[name]
                ser_noadd = get_no_additions(series_obj)
                if ser_noadd is None or len(ser_noadd) < 2:
                    recomputed_stats[name] = {
                        "Total Return": "N/A",
                        "CAGR": "N/A",
                        "MaxDrawdown": "N/A",
                        "Volatility": "N/A",
                        "Sharpe": "N/A",
                        "Sortino": "N/A",
                        "UlcerIndex": "N/A",
                        "UPI": "N/A",
                        "Beta": "N/A",
                        "MWRR": "N/A",
                        # Final values with and without additions (if available)
                        "Final Value (with)": (series_obj['with_additions'].iloc[-1] if isinstance(series_obj, dict) and 'with_additions' in series_obj and len(series_obj['with_additions'])>0 else "N/A"),
                        "Final Value (no_additions)": (ser_noadd.iloc[-1] if isinstance(ser_noadd, pd.Series) and len(ser_noadd)>0 else "N/A")
                    }
                    continue

                stats_values = ser_noadd.values
                stats_dates = ser_noadd.index
                stats_returns = pd.Series(stats_values, index=stats_dates).pct_change().fillna(0)
                
                # Calculate total return (no additions)
                total_return = None
                if len(stats_values) > 0:
                    initial_val = stats_values[0]
                    final_val = stats_values[-1]
                    if initial_val > 0:
                        # Calculate CAGR first to determine which formula to use
                        cagr_temp = calculate_cagr(stats_values, stats_dates)
                        if cagr_temp < 0:
                            # If CAGR is negative: use DIFFERENT formula
                            total_return = (final_val / initial_val - 1) * 100  # Return as percentage
                        else:
                            # If CAGR is positive: use NORMAL calculation with * 100
                            total_return = (final_val / initial_val - 1) * 100  # Return as percentage
                
                cagr = calculate_cagr(stats_values, stats_dates)
                max_dd, drawdowns = calculate_max_drawdown(stats_values)
                vol = calculate_volatility(stats_returns)
                
                # Use 2% annual risk-free rate (same as Backtest_Engine.py default)
                risk_free_rate = 0.02
                sharpe = calculate_sharpe(stats_returns, risk_free_rate)
                sortino = calculate_sortino(stats_returns, risk_free_rate)
                ulcer = calculate_ulcer_index(pd.Series(stats_values, index=stats_dates))
                upi = calculate_upi(cagr, ulcer)
                # Compute Beta based on the no-additions portfolio returns and the portfolio's benchmark (if available)
                beta = np.nan
                # Find the portfolio config to get benchmark ticker
                cfg_for_name = next((c for c in st.session_state.multi_backtest_portfolio_configs if c['name'] == name), None)
                if cfg_for_name:
                    bench_ticker = cfg_for_name.get('benchmark_ticker')
                    raw_data = st.session_state.get('multi_backtest_raw_data')
                    if bench_ticker and raw_data and bench_ticker in raw_data:
                        # get benchmark price_change series aligned to ser_noadd index
                        try:
                            bench_df = raw_data[bench_ticker].reindex(ser_noadd.index)
                            if 'Price_change' in bench_df.columns:
                                bench_returns = bench_df['Price_change'].fillna(0)
                            else:
                                bench_returns = bench_df['Close'].pct_change().fillna(0)

                            portfolio_returns = pd.Series(stats_values, index=stats_dates).pct_change().fillna(0)
                            common_idx = portfolio_returns.index.intersection(bench_returns.index)
                            if len(common_idx) >= 2:
                                pr = portfolio_returns.reindex(common_idx).dropna()
                                br = bench_returns.reindex(common_idx).dropna()
                                common_idx2 = pr.index.intersection(br.index)
                                if len(common_idx2) >= 2 and br.loc[common_idx2].var() != 0:
                                    cov = pr.loc[common_idx2].cov(br.loc[common_idx2])
                                    var = br.loc[common_idx2].var()
                                    beta = cov / var
                        except Exception as e:
                            pass
                
                # Calculate MWRR for this portfolio using the complete cash flow series
                mwrr_val = np.nan  # Use NaN instead of "N/A" string
                if isinstance(series_obj, dict) and 'with_additions' in series_obj:
                    portfolio_values = series_obj['with_additions']
                    # Reconstruct cash flows for this portfolio
                    cfg_for_name = next((c for c in st.session_state.multi_backtest_portfolio_configs if c['name'] == name), None)
                    if cfg_for_name and len(portfolio_values) > 0:
                        cash_flows = pd.Series(0.0, index=portfolio_values.index)
                        # Initial investment: negative cash flow on first date
                        cash_flows.iloc[0] = -cfg_for_name.get('initial_value', 0)
                        # Periodic additions: negative cash flow on their respective dates
                        dates_added = get_dates_by_freq(cfg_for_name.get('added_frequency'), portfolio_values.index[0], portfolio_values.index[-1], portfolio_values.index)
                        for d in dates_added:
                            if d in cash_flows.index and d != cash_flows.index[0]:
                                cash_flows.loc[d] -= cfg_for_name.get('added_amount', 0)
                        # Final value: positive cash flow on last date for MWRR
                        cash_flows.iloc[-1] += portfolio_values.iloc[-1]
                        # Calculate MWRR
                        mwrr = calculate_mwrr(portfolio_values, cash_flows, portfolio_values.index)
                        mwrr_val = mwrr

                # Calculate total money added for this portfolio
                total_money_added = np.nan  # Use NaN instead of "N/A" string
                cfg_for_name = next((c for c in st.session_state.multi_backtest_portfolio_configs if c['name'] == name), None)
                if cfg_for_name and isinstance(ser_noadd, pd.Series) and len(ser_noadd) > 0:
                    total_money_added = calculate_total_money_added(cfg_for_name, ser_noadd.index[0], ser_noadd.index[-1])
                
                # Calculate total return based on total money contributed
                total_return_contributed = np.nan  # Use NaN instead of "N/A" string
                if isinstance(series_obj, dict) and 'with_additions' in series_obj and len(series_obj['with_additions']) > 0:
                    final_value_with_additions = series_obj['with_additions'].iloc[-1]
                    if isinstance(total_money_added, (int, float)) and total_money_added > 0:
                        total_return_contributed = (final_value_with_additions / total_money_added - 1) * 100  # Return as percentage

                recomputed_stats[name] = {
                    "Total Return": clamp_stat(total_return, "Total Return"),
                    "Total Return (Contributed)": clamp_stat(total_return_contributed, "Total Return"),
                    "CAGR": clamp_stat(cagr, "CAGR"),
                    "MaxDrawdown": clamp_stat(max_dd, "MaxDrawdown"),
                    "Volatility": clamp_stat(vol, "Volatility"),
                    "Sharpe": clamp_stat(sharpe / 100 if isinstance(sharpe, (int, float)) and pd.notna(sharpe) else sharpe, "Sharpe"),
                    "Sortino": clamp_stat(sortino / 100 if isinstance(sortino, (int, float)) and pd.notna(sortino) else sortino, "Sortino"),
                    "UlcerIndex": clamp_stat(ulcer, "UlcerIndex"),
                    "UPI": clamp_stat(upi / 100 if isinstance(upi, (int, float)) and pd.notna(upi) else upi, "UPI"),
                    "Beta": clamp_stat(beta / 100 if isinstance(beta, (int, float)) and pd.notna(beta) else beta, "Beta"),
                    "MWRR": mwrr_val,
                    # Final values with and without additions
                    "Final Value (with)": (series_obj['with_additions'].iloc[-1] if isinstance(series_obj, dict) and 'with_additions' in series_obj and len(series_obj['with_additions'])>0 else np.nan),
                    "Final Value (no_additions)": (ser_noadd.iloc[-1] if isinstance(ser_noadd, pd.Series) and len(ser_noadd)>0 else np.nan),
                    "Total Money Added": total_money_added
                }

            stats_df_display = pd.DataFrame(recomputed_stats).T
            # Move final value columns to the front and format them as currency
            cols = list(stats_df_display.columns)
            fv_with = 'Final Value (with)'
            fv_no = 'Final Value (no_additions)'
            front = [c for c in [fv_with, fv_no] if c in cols]
            for c in front:
                cols.remove(c)
            cols = front + cols
            stats_df_display = stats_df_display[cols]
            # Rename and format columns to be more descriptive
            stats_df_display.rename(columns={
                'MaxDrawdown': 'Max Drawdown', 
                'UlcerIndex': 'Ulcer Index',
                'Final Value (with)': 'Final Portfolio Value',
                'Final Value (no_additions)': 'Final Value (No Contributions)',
                'Total Return (Contributed)': 'Total Return (All Money)'
            }, inplace=True)
            # Ensure ordering: MWRR after CAGR, Total Return columns after MWRR, then risk metrics, then Beta and Total Money Added at the end
            cols = list(stats_df_display.columns)
            if 'MWRR' in cols and 'Total Return' in cols and 'Total Return (All Money)' in cols and 'Beta' in cols and 'Total Money Added' in cols:
                # Remove the columns we want to reorder
                cols.remove('MWRR'); cols.remove('Total Return'); cols.remove('Total Return (All Money)'); cols.remove('Beta'); cols.remove('Total Money Added')
                
                # Find the position after CAGR to insert MWRR and Total Return columns
                cagr_index = cols.index('CAGR') if 'CAGR' in cols else 0
                insert_position = cagr_index + 1
                
                # Insert MWRR and Total Return columns after CAGR
                cols.insert(insert_position, 'MWRR')
                cols.insert(insert_position + 1, 'Total Return')
                cols.insert(insert_position + 2, 'Total Return (All Money)')
                
                # Add Beta and Total Money Added at the end
                cols.extend(['Beta', 'Total Money Added'])
                stats_df_display = stats_df_display[cols]

            # Display start and end dates next to the title
            col_title, col_dates = st.columns([2, 1])
            with col_title:
                st.subheader("Final Performance Statistics")
            with col_dates:
                if 'multi_all_results' in st.session_state and st.session_state.multi_all_results:
                    # Get the first portfolio's dates (they should all be the same)
                    first_portfolio = next(iter(st.session_state.multi_all_results.values()))
                    if isinstance(first_portfolio, dict) and 'no_additions' in first_portfolio:
                        series = first_portfolio['no_additions']
                        if hasattr(series, 'index') and len(series.index) > 0:
                            start_date = series.index[0].strftime('%Y-%m-%d')
                            end_date = series.index[-1].strftime('%Y-%m-%d')
                            st.markdown(f"**üìÖ Period:** {start_date} to {end_date}")
                        else:
                            st.markdown("**üìÖ Period:** N/A")
                    else:
                        st.markdown("**üìÖ Period:** N/A")
                else:
                    st.markdown("**üìÖ Period:** N/A")
            # Format currency for final value columns if present
            fmt_map_display = {}
            if 'Final Portfolio Value' in stats_df_display.columns:
                fmt_map_display['Final Portfolio Value'] = '${:,.2f}'
            if 'Final Value (No Contributions)' in stats_df_display.columns:
                fmt_map_display['Final Value (No Contributions)'] = '${:,.2f}'
            if 'Total Money Added' in stats_df_display.columns:
                fmt_map_display['Total Money Added'] = '${:,.2f}'
            # Format MWRR as percentage - but only if it contains numeric data
            if 'MWRR' in stats_df_display.columns:
                # Check if MWRR column has any non-N/A values
                mwrr_has_numeric = False
                for value in stats_df_display['MWRR']:
                    if pd.notna(value) and value != 'N/A' and value != '':
                        try:
                            float(value)
                            mwrr_has_numeric = True
                            break
                        except (ValueError, TypeError):
                            pass
                if mwrr_has_numeric:
                    fmt_map_display['MWRR'] = '{:.2f}%'
            
            # Create tooltips for each column
            tooltip_data = {
                'Total Return': 'Return based on initial investment only. Formula: (Final Value / Initial Investment) - 1',
                'Total Return (All Money)': 'Return based on all money contributed. Formula: (Final Portfolio Value / Total Money Added) - 1',
                'CAGR': 'Compound Annual Growth Rate. Average annual return over the entire period.',
                'Max Drawdown': 'Largest peak-to-trough decline. Shows the worst loss from a peak.',
                'Volatility': 'Standard deviation of returns. Measures price variability.',
                'Sharpe': 'Excess return per unit of total volatility. >1 good, >2 very good, >3 excellent.',
                'Sortino': 'Excess return per unit of downside volatility. >1 good, >2 very good, >3 excellent.',
                'Ulcer Index': 'Average depth of drawdowns. <5 excellent, 5-10 moderate, >10 high.',
                'UPI': 'Ulcer Performance Index. Excess return relative to Ulcer Index. >1 good, >2 very good, >3 excellent.',
                'Beta': 'Portfolio volatility relative to benchmark. <1 less volatile, >1 more volatile than market.',
                'MWRR': 'Money-Weighted Rate of Return. Accounts for timing and size of cash flows.',
                'Final Portfolio Value': 'Final value including all contributions and investment returns.',
                'Final Value (No Contributions)': 'Final Value (No Contributions) - What $10,000 would grow to over the selected period using CAGR',
                'Total Money Added': 'Total amount of money contributed (initial + periodic additions).'
            }
            
            # Clean the dataframe to handle problematic values before styling
            stats_df_clean = stats_df_display.copy()
            
            # Replace problematic values that can't be formatted
            for col in stats_df_clean.columns:
                for idx in stats_df_clean.index:
                    value = stats_df_clean.loc[idx, col]
                    if pd.isna(value) or value is None or value == 'N/A' or value == '':
                        stats_df_clean.loc[idx, col] = 'N/A'
                    elif isinstance(value, str) and value.strip() == '':
                        stats_df_clean.loc[idx, col] = 'N/A'
            
            # Create a safe formatting map that only includes numeric columns
            safe_fmt_map = {}
            has_problematic_data = False
            
            # Check if any column has problematic data
            for col in stats_df_clean.columns:
                for value in stats_df_clean[col]:
                    if pd.isna(value) or value == 'N/A' or value == '':
                        has_problematic_data = True
                        break
                if has_problematic_data:
                    break
            
            # Only apply formatting if no problematic data
            if not has_problematic_data:
                for col, fmt in fmt_map_display.items():
                    if col in stats_df_clean.columns:
                        # Check if the column contains numeric data
                        numeric_count = 0
                        total_count = 0
                        for value in stats_df_clean[col]:
                            if pd.notna(value) and value != 'N/A' and value != '':
                                total_count += 1
                                try:
                                    float(value)
                                    numeric_count += 1
                                except (ValueError, TypeError):
                                    pass
                        
                        # Only apply formatting if most values are numeric
                        if total_count > 0 and numeric_count / total_count > 0.5:
                            safe_fmt_map[col] = fmt
            
            # Use sorted dataframe if available, otherwise use original
            sorted_df = st.session_state.get('final_stats_sorted_df', None)
            display_df = sorted_df if sorted_df is not None else stats_df_clean
            
            # Add tooltips to the dataframe
            if safe_fmt_map and not has_problematic_data:
                try:
                    styled_df = display_df.style.format(safe_fmt_map)
                except Exception as e:
                    styled_df = display_df
            else:
                # Skip styling entirely if there's problematic data
                styled_df = display_df
            
            # Add tooltips using HTML
            tooltip_html = "<div style='background-color: #1e1e1e; color: white; padding: 10px; border-radius: 5px; font-size: 12px;'>"
            tooltip_html += "<b>Column Definitions:</b><br><br>"
            for col, tooltip in tooltip_data.items():
                if col in display_df.columns:
                    tooltip_html += f"<b>{col}:</b> {tooltip}<br><br>"
            tooltip_html += "</div>"
            
            # Display tooltip info
            with st.expander("‚ÑπÔ∏è Column Definitions", expanded=False):
                st.markdown(tooltip_html, unsafe_allow_html=True)
            
            # Add sorting controls
            col1, col2, col3 = st.columns([1, 1, 1])
            with col1:
                sort_column = st.selectbox(
                    "Sort by:",
                    options=stats_df_clean.columns.tolist(),
                    index=0,
                    key="final_stats_sort_column",
                    help="Select a column to sort the table numerically"
                )
            with col2:
                if st.button("‚¨áÔ∏è Sort ‚Üì", key="final_stats_sort_desc_button", help="Sort table in descending order (highest to lowest values)"):
                    sorted_df = sort_dataframe_numerically(stats_df_clean, sort_column, ascending=False)
                    st.session_state.final_stats_sorted_df = sorted_df
                    st.rerun()
            with col3:
                if st.button("‚¨ÜÔ∏è Sort ‚Üë", key="final_stats_sort_asc_button", help="Sort table in ascending order (lowest to highest values)"):
                    sorted_df = sort_dataframe_numerically(stats_df_clean, sort_column, ascending=True)
                    st.session_state.final_stats_sorted_df = sorted_df
                    st.rerun()
            
            # Display the dataframe with multiple fallback options
            try:
                st.dataframe(styled_df, use_container_width=True)
            except Exception as e1:
                try:
                    st.dataframe(stats_df_clean, use_container_width=True)
                except Exception as e2:
                    # Last resort: convert all values to strings
                    stats_df_strings = stats_df_clean.astype(str)
                    st.dataframe(stats_df_strings, use_container_width=True)
            
            # Store the statistics table as a Plotly figure for PDF export
            try:
                import plotly.graph_objects as go
                # Create a Plotly table from the stats DataFrame with MUCH better formatting
                # Format the values to remove excessive decimals with proper error handling
                formatted_values = []
                for col in stats_df_display.columns:
                    col_values = []
                    for name in stats_df_display.index:
                        value = stats_df_display.loc[name, col]
                        
                        # Handle NaN, None, and string values
                        if pd.isna(value) or value is None or value == 'N/A' or value == '':
                            col_values.append('N/A')
                            continue
                        
                        try:
                            if 'Portfolio Value' in col or 'Final Value' in col:
                                # Portfolio values: full numbers only (no decimals)
                                col_values.append(f"${float(value):,.0f}")
                            elif 'MWRR' in col:
                                # MWRR: max 2 decimal places
                                col_values.append(f"{float(value):.2f}%")
                            elif 'Total Money Added' in col:
                                # Money added: full numbers only
                                col_values.append(f"${float(value):,.0f}")
                            else:
                                # For other numeric columns, try to format as float
                                try:
                                    float_val = float(value)
                                    if 'Ratio' in col or 'Index' in col:
                                        col_values.append(f"{float_val:.3f}")
                                    elif 'Drawdown' in col or 'Volatility' in col or 'CAGR' in col:
                                        col_values.append(f"{float_val:.2f}%")
                                    else:
                                        col_values.append(f"{float_val:.2f}")
                                except (ValueError, TypeError):
                                    # If conversion fails, keep original value
                                    col_values.append(str(value))
                        except (ValueError, TypeError):
                            # If any conversion fails, use original value
                            col_values.append(str(value))
                    
                    formatted_values.append(col_values)
                
                fig_stats = go.Figure(data=[go.Table(
                    header=dict(
                        values=['Portfolio'] + list(stats_df_display.columns),
                        fill_color='rgb(51, 102, 153)',
                        align='center',
                        font=dict(color='white', size=14, family='Arial Black')  # Bigger, bolder font
                    ),
                    cells=dict(
                        values=[stats_df_display.index] + formatted_values,
                        fill_color='rgb(242, 242, 242)',
                        align='center',
                        font=dict(color='black', size=12, family='Arial'),  # Bigger font
                        height=35  # Taller cells for better readability
                    ),
                    columnwidth=[0.15] + [0.85/len(stats_df_display.columns)] * len(stats_df_display.columns)  # Portfolio column wider, others equal
                )])
                fig_stats.update_layout(
                    title="Final Performance Statistics",
                    title_x=0.5,
                    width=2000,  # Much wider to fit all columns
                    height=600,   # Taller for better spacing
                    margin=dict(l=20, r=20, t=50, b=20)  # Better margins
                )
                st.session_state.fig_stats = fig_stats
            except Exception as e:
                pass

        # Focused Performance Analysis with Date Range
        # Initialize session state variables first
        if 'focused_analysis_results' not in st.session_state:
            st.session_state.focused_analysis_results = None
        if 'focused_analysis_show_essential' not in st.session_state:
            st.session_state.focused_analysis_show_essential = False
        if 'focused_analysis_period' not in st.session_state:
            st.session_state.focused_analysis_period = None
        if 'focused_analysis_start_date' not in st.session_state:
            st.session_state.focused_analysis_start_date = None
        if 'focused_analysis_end_date' not in st.session_state:
            st.session_state.focused_analysis_end_date = None
        if 'focused_analysis_sorted_df' not in st.session_state:
            st.session_state.focused_analysis_sorted_df = None
        if 'final_stats_sorted_df' not in st.session_state:
            st.session_state.final_stats_sorted_df = None
        
        # Date range controls
        col_date1, col_date2, col_metrics = st.columns([1, 1, 1])
        
        # Get the earliest and latest available dates from backtest data
        min_date = None
        max_date = None
        if 'multi_all_results' in st.session_state and st.session_state.multi_all_results:
            # Use the same reliable method as used elsewhere in the code
            try:
                first_date = min(series['no_additions'].index.min() for series in st.session_state.multi_all_results.values() if 'no_additions' in series)
                last_date = max(series['no_additions'].index.max() for series in st.session_state.multi_all_results.values() if 'no_additions' in series)
                min_date = first_date.date()
                max_date = last_date.date()
            except (ValueError, KeyError, AttributeError):
                # Fallback to the previous method if the above fails
                all_dates = []
                for portfolio_name, results in st.session_state.multi_all_results.items():
                    if isinstance(results, dict) and 'no_additions' in results:
                        series = results['no_additions']
                        if hasattr(series, 'index') and len(series.index) > 0:
                            all_dates.extend(series.index.tolist())
                
                if all_dates:
                    min_date = min(all_dates).date()
                    max_date = max(all_dates).date()
        
        with col_date1:
            # Check if we need to update the date range due to new portfolio data
            current_min_date = min_date if min_date else datetime.date(1900, 1, 1)
            current_max_date = max_date if max_date else datetime.date.today()
            
            # Update session state if the available date range has changed
            if 'focused_analysis_available_min_date' not in st.session_state:
                st.session_state.focused_analysis_available_min_date = current_min_date
                st.session_state.focused_analysis_available_max_date = current_max_date
            elif (st.session_state.focused_analysis_available_min_date != current_min_date or 
                  st.session_state.focused_analysis_available_max_date != current_max_date):
                # Date range has changed, update session state and reset selected dates
                st.session_state.focused_analysis_available_min_date = current_min_date
                st.session_state.focused_analysis_available_max_date = current_max_date
                st.session_state.focused_analysis_start_date = current_min_date
                st.session_state.focused_analysis_end_date = current_max_date
            
            # Initialize start date in session state with fallback and validation
            if st.session_state.focused_analysis_start_date is None:
                st.session_state.focused_analysis_start_date = current_min_date
            
            # Ensure the start date is valid and within bounds
            start_date_value = st.session_state.focused_analysis_start_date
            if start_date_value is None:
                start_date_value = current_min_date
            else:
                # Convert to datetime.date if it's a pandas Timestamp or other datetime-like object
                try:
                    if hasattr(start_date_value, 'date'):
                        start_date_value = start_date_value.date()
                    elif not isinstance(start_date_value, datetime.date):
                        start_date_value = pd.to_datetime(start_date_value).date()
                except:
                    start_date_value = current_min_date
                
                # Check bounds after conversion
                if start_date_value < current_min_date:
                    start_date_value = current_min_date
                elif start_date_value > current_max_date:
                    start_date_value = current_max_date
            
            start_date = st.date_input(
                "Start Date", 
                value=start_date_value,
                min_value=current_min_date,
                max_value=current_max_date,
                key="focused_analysis_start_date_input",
                help="Start date for focused performance analysis"
            )
            
            # Store the selected start date in session state
            if start_date != st.session_state.focused_analysis_start_date:
                st.session_state.focused_analysis_start_date = start_date
        
        with col_date2:
            # Initialize end date in session state with fallback and validation
            if st.session_state.focused_analysis_end_date is None:
                st.session_state.focused_analysis_end_date = current_max_date
            
            # Ensure the end date is valid and within bounds
            end_date_value = st.session_state.focused_analysis_end_date
            if end_date_value is None:
                end_date_value = current_max_date
            else:
                # Convert to datetime.date if it's a pandas Timestamp or other datetime-like object
                try:
                    if hasattr(end_date_value, 'date'):
                        end_date_value = end_date_value.date()
                    elif not isinstance(end_date_value, datetime.date):
                        end_date_value = pd.to_datetime(end_date_value).date()
                except:
                    end_date_value = current_max_date
                
                # Check bounds after conversion
                if end_date_value < current_min_date:
                    end_date_value = current_min_date
                elif end_date_value > current_max_date:
                    end_date_value = current_max_date
            
            end_date = st.date_input(
                "End Date", 
                value=end_date_value,
                min_value=current_min_date,
                max_value=current_max_date,
                key="focused_analysis_end_date_input",
                help="End date for focused performance analysis"
            )
            
            # Store the selected end date in session state
            if end_date != st.session_state.focused_analysis_end_date:
                st.session_state.focused_analysis_end_date = end_date
        
        with col_metrics:
            show_essential_only = st.checkbox(
                "Essential Metrics Only", 
                value=False,
                help="Show only CAGR, Max Drawdown, Volatility, and Total Return for quick analysis"
            )
        
        # Add title after date inputs are defined
        st.subheader("üìä Focused Performance Analysis")
        
        # Calculate Analysis Button
        calculate_analysis = st.button(
            "üìä Calculate Analysis", 
            type="primary",
            use_container_width=True,
            help="Click to generate the focused performance analysis with your selected date range"
        )
        
        # Session state variables are already initialized above
        
        # Update session state when essential metrics checkbox changes
        if show_essential_only != st.session_state.focused_analysis_show_essential:
            st.session_state.focused_analysis_show_essential = show_essential_only
            # Recalculate if we have existing results
            if st.session_state.focused_analysis_results is not None:
                calculate_analysis = True
        
        # Calculate focused performance metrics only when button is clicked
        if calculate_analysis and start_date and end_date and 'multi_all_results' in st.session_state and st.session_state.multi_all_results:
            focused_stats = {}
            
            for portfolio_name, results in st.session_state.multi_all_results.items():
                if isinstance(results, dict) and 'no_additions' in results:
                    series = results['no_additions']
                    if hasattr(series, 'index') and len(series.index) > 0:
                        # Filter series by date range
                        # Convert dates to datetime for proper comparison
                        start_datetime = pd.to_datetime(start_date)
                        end_datetime = pd.to_datetime(end_date) + pd.Timedelta(days=1)  # Include the end date
                        mask = (series.index >= start_datetime) & (series.index < end_datetime)
                        filtered_series = series[mask]
                        
                        if len(filtered_series) > 1:
                            # Calculate returns with ffill compatibility
                            returns = filtered_series.pct_change().fillna(0)
                            
                            if len(returns) > 0:
                                # Smart weekend filter for win/loss rates
                                zero_rate = (abs(returns) < 1e-5).mean()
                                if zero_rate > 0.25:  # If more than 25% are zero (likely weekends)
                                    # Filter to include only non-zero returns or returns on weekdays
                                    weekday_mask = returns.index.weekday < 5  # Monday=0, Friday=4
                                    non_zero_mask = abs(returns) > 1e-5
                                    smart_mask = weekday_mask | non_zero_mask
                                    returns = returns[smart_mask]
                                
                                # Calculate metrics for the date range
                                # Use original returns (before smart filtering) for consistency with Final Performance Statistics
                                original_returns = filtered_series.pct_change().fillna(0)
                                cagr = calculate_cagr(filtered_series, filtered_series.index)
                                volatility = calculate_volatility(original_returns)
                                sharpe = calculate_sharpe(original_returns, 0.02)  # 2% risk-free rate
                                sortino = calculate_sortino(original_returns, 0.02)
                                
                                # Calculate max drawdown using original returns
                                cumulative = (1 + original_returns).cumprod()
                                running_max = cumulative.expanding().max()
                                drawdown = (cumulative - running_max) / running_max
                                max_drawdown = drawdown.min()
                                
                                # Calculate Ulcer Index using original returns
                                ulcer_index = np.sqrt((drawdown ** 2).mean()) * 100
                                
                                # Calculate UPI
                                upi = calculate_upi(cagr, ulcer_index) if ulcer_index > 0 else np.nan
                                
                                # Calculate Beta (same method as Final Performance Statistics)
                                beta = np.nan
                                cfg_for_name = next((c for c in st.session_state.multi_backtest_portfolio_configs if c['name'] == portfolio_name), None)
                                if cfg_for_name:
                                    bench_ticker = cfg_for_name.get('benchmark_ticker')
                                    raw_data = st.session_state.get('multi_backtest_raw_data')
                                    if bench_ticker and raw_data and bench_ticker in raw_data:
                                        try:
                                            bench_df = raw_data[bench_ticker].reindex(filtered_series.index)
                                            if 'Price_change' in bench_df.columns:
                                                bench_returns = bench_df['Price_change'].fillna(0)
                                            else:
                                                bench_returns = bench_df['Close'].pct_change().fillna(0)

                                            portfolio_returns = original_returns # Use original returns like Final Performance Statistics
                                            common_idx = portfolio_returns.index.intersection(bench_returns.index)
                                            if len(common_idx) >= 2:
                                                pr = portfolio_returns.reindex(common_idx).dropna()
                                                br = bench_returns.reindex(common_idx).dropna()
                                                common_idx2 = pr.index.intersection(br.index)
                                                if len(common_idx2) >= 2 and br.loc[common_idx2].var() != 0:
                                                    cov = pr.loc[common_idx2].cov(br.loc[common_idx2])
                                                    var = br.loc[common_idx2].var()
                                                    beta = cov / var
                                        except Exception as e:
                                            pass
                                
                                # Calculate additional instantaneous metrics
                                total_return = (filtered_series.iloc[-1] / filtered_series.iloc[0] - 1)
                                final_value = filtered_series.iloc[-1]
                                # For no contributions, start with $10,000 and apply CAGR
                                years = (filtered_series.index[-1] - filtered_series.index[0]).days / 365.25
                                cagr = calculate_cagr(filtered_series, filtered_series.index)
                                final_value_no_contrib = 10000 * ((1 + cagr) ** years)
                                total_money_added = 0  # Not available in no_additions series
                                
                                # Calculate median drawdown
                                median_drawdown = drawdown.median()
                                
                                # Calculate win/loss rates (normalized to sum to 100%)
                                positive_returns = returns[returns > 1e-5]
                                negative_returns = returns[returns < -1e-5]
                                neutral_returns = returns[(returns >= -1e-5) & (returns <= 1e-5)]
                                
                                total_active = len(positive_returns) + len(negative_returns)
                                if total_active > 0:
                                    # Normalize to ensure win_rate + loss_rate = 100%
                                    win_rate = (len(positive_returns) / total_active) * 100
                                    loss_rate = (len(negative_returns) / total_active) * 100
                                else:
                                    win_rate = loss_rate = 0
                                
                                # Calculate median win/loss
                                median_win = positive_returns.median() * 100 if len(positive_returns) > 0 else 0
                                median_loss = negative_returns.median() * 100 if len(negative_returns) > 0 else 0
                                
                                # Calculate profit factor
                                gross_profit = positive_returns.sum() if len(positive_returns) > 0 else 0
                                gross_loss = abs(negative_returns.sum()) if len(negative_returns) > 0 else 0
                                profit_factor = gross_profit / gross_loss if gross_loss > 0 else np.inf
                                
                                # Calculate monthly returns for monthly metrics
                                monthly_returns = filtered_series.resample('M').last().pct_change().fillna(0) * 100
                                best_month = monthly_returns.max() if len(monthly_returns) > 0 else 0
                                worst_month = monthly_returns.min() if len(monthly_returns) > 0 else 0
                                median_monthly = monthly_returns.median() if len(monthly_returns) > 0 else 0
                                
                                # Calculate risk-adjusted ratios
                                calmar_ratio = (cagr * 100) / abs(max_drawdown * 100) if max_drawdown != 0 else np.nan
                                sterling_ratio = (cagr * 100) / abs(median_drawdown * 100) if median_drawdown != 0 else np.nan
                                recovery_factor = abs(total_return) / abs(max_drawdown) if max_drawdown != 0 else np.nan
                                
                                # Calculate tail ratio (95th percentile / 5th percentile)
                                tail_ratio = returns.quantile(0.95) / abs(returns.quantile(0.05)) if returns.quantile(0.05) != 0 else np.nan
                                
                                if show_essential_only:
                                    focused_stats[portfolio_name] = {
                                        'Total Return': total_return * 100,
                                        'CAGR': cagr * 100,
                                        'Max Drawdown': max_drawdown * 100,
                                        'Volatility': volatility * 100
                                    }
                                else:
                                    focused_stats[portfolio_name] = {
                                        'Total Return': total_return * 100,
                                        'CAGR': cagr * 100,
                                        'Max Drawdown': max_drawdown * 100,
                                        'Volatility': volatility * 100,
                                        'Sharpe': sharpe,
                                        'Sortino': sortino,
                                        'Ulcer Index': ulcer_index,
                                        'UPI': upi,
                                        'Beta': beta,
                                        'Final Value (No Contributions)': final_value_no_contrib,
                                        'Median Drawdown': median_drawdown * 100,
                                        'Win Rate': win_rate,
                                        'Loss Rate': loss_rate,
                                        'Median Win': median_win,
                                        'Median Loss': median_loss,
                                        'Profit Factor': profit_factor,
                                        'Best Month': best_month,
                                        'Worst Month': worst_month,
                                        'Median Monthly': median_monthly,
                                        'Calmar Ratio': calmar_ratio,
                                        'Sterling Ratio': sterling_ratio,
                                        'Recovery Factor': recovery_factor,
                                        'Tail Ratio': tail_ratio
                                    }
            
            if focused_stats:
                # Store results in session state
                st.session_state.focused_analysis_results = focused_stats
                st.session_state.focused_analysis_show_essential = show_essential_only
                st.session_state.focused_analysis_period = f"{start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}"
                # Clear any previous sorting when new results are calculated
                st.session_state.focused_analysis_sorted_df = None
                
                # Create focused stats DataFrame
                focused_df = pd.DataFrame.from_dict(focused_stats, orient='index')
                focused_df.index.name = 'Portfolio'
                
                # Format the DataFrame
                if show_essential_only:
                    focused_df['CAGR'] = focused_df['CAGR'].apply(lambda x: f"{x:.2f}%")
                    focused_df['Max Drawdown'] = focused_df['Max Drawdown'].apply(lambda x: f"{x:.2f}%")
                    focused_df['Volatility'] = focused_df['Volatility'].apply(lambda x: f"{x:.2f}%")
                    focused_df['Total Return'] = focused_df['Total Return'].apply(lambda x: f"{x:.2f}%")
                else:
                    # Format all columns
                    focused_df['CAGR'] = focused_df['CAGR'].apply(lambda x: f"{x:.2f}%")
                    focused_df['Max Drawdown'] = focused_df['Max Drawdown'].apply(lambda x: f"{x:.2f}%")
                    focused_df['Volatility'] = focused_df['Volatility'].apply(lambda x: f"{x:.2f}%")
                    focused_df['Sharpe'] = focused_df['Sharpe'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) else "N/A")
                    focused_df['Sortino'] = focused_df['Sortino'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) else "N/A")
                    focused_df['Ulcer Index'] = focused_df['Ulcer Index'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) else "N/A")
                    focused_df['UPI'] = focused_df['UPI'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) else "N/A")
                    focused_df['Beta'] = focused_df['Beta'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) else "N/A")
                    focused_df['Total Return'] = focused_df['Total Return'].apply(lambda x: f"{x:.2f}%")
                    focused_df['Final Value (No Contributions)'] = focused_df['Final Value (No Contributions)'].apply(lambda x: f"${x:,.2f}")
                    focused_df['Median Drawdown'] = focused_df['Median Drawdown'].apply(lambda x: f"{x:.2f}%")
                    focused_df['Win Rate'] = focused_df['Win Rate'].apply(lambda x: f"{x:.1f}%")
                    focused_df['Loss Rate'] = focused_df['Loss Rate'].apply(lambda x: f"{x:.1f}%")
                    focused_df['Median Win'] = focused_df['Median Win'].apply(lambda x: f"{x:.2f}%")
                    focused_df['Median Loss'] = focused_df['Median Loss'].apply(lambda x: f"{x:.2f}%")
                    focused_df['Profit Factor'] = focused_df['Profit Factor'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) and x != np.inf else "N/A")
                    focused_df['Best Month'] = focused_df['Best Month'].apply(lambda x: f"{x:.2f}%")
                    focused_df['Worst Month'] = focused_df['Worst Month'].apply(lambda x: f"{x:.2f}%")
                    focused_df['Median Monthly'] = focused_df['Median Monthly'].apply(lambda x: f"{x:.2f}%")
                    focused_df['Calmar Ratio'] = focused_df['Calmar Ratio'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) else "N/A")
                    focused_df['Sterling Ratio'] = focused_df['Sterling Ratio'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) else "N/A")
                    focused_df['Recovery Factor'] = focused_df['Recovery Factor'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) else "N/A")
                    focused_df['Tail Ratio'] = focused_df['Tail Ratio'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) else "N/A")
                
                # Add column definitions expander
                focused_tooltip_data = {
                    'Final Value (No Contributions)': 'Final Value (No Contributions) - What $10,000 would grow to over the selected period using CAGR',
                    'CAGR': 'Compound Annual Growth Rate - The annualized rate of return over the investment period',
                    'Max Drawdown': 'Maximum Drawdown - The largest peak-to-trough decline during the period',
                    'Volatility': 'Volatility - Standard deviation of returns, measuring price dispersion',
                    'Sharpe Ratio': 'Sharpe Ratio - Risk-adjusted return (excess return per unit of volatility)',
                    'Sortino Ratio': 'Sortino Ratio - Risk-adjusted return considering only downside volatility',
                    'Calmar Ratio': 'Calmar Ratio - Annual return divided by maximum drawdown',
                    'Sterling Ratio': 'Sterling Ratio - Average annual return divided by average drawdown',
                    'Recovery Factor': 'Recovery Factor - Net profit divided by maximum drawdown',
                    'Tail Ratio': 'Tail Ratio - 95th percentile return divided by 5th percentile return',
                    'Win Rate': 'Win Rate - Percentage of positive return periods',
                    'Loss Rate': 'Loss Rate - Percentage of negative return periods',
                    'Median Win': 'Median Win - Median return of positive periods',
                    'Median Loss': 'Median Loss - Median return of negative periods',
                    'Profit Factor': 'Profit Factor - Gross profit divided by gross loss',
                    'Best Month': 'Best Month - Highest single month return',
                    'Worst Month': 'Worst Month - Lowest single month return',
                    'Median Monthly': 'Median Monthly - Median monthly return',
                    'Median Drawdown': 'Median Drawdown - Median drawdown value'
                }
                
                # Create tooltip HTML
                focused_tooltip_html = "<div style='background-color: #1e1e1e; color: white; padding: 10px; border-radius: 5px; font-size: 12px;'>"
                focused_tooltip_html += "<b>Column Definitions:</b><br><br>"
                for col in focused_df.columns:
                    if col in focused_tooltip_data:
                        focused_tooltip_html += f"<b>{col}:</b> {focused_tooltip_data[col]}<br><br>"
                focused_tooltip_html += "</div>"
                
                # Display tooltip info
                with st.expander("‚ÑπÔ∏è Column Definitions", expanded=False):
                    st.markdown(focused_tooltip_html, unsafe_allow_html=True)
                
                # Add sorting controls for focused analysis
                col1, col2, col3 = st.columns([1, 1, 1])
                with col1:
                    focused_sort_column = st.selectbox(
                        "Sort by:",
                        options=focused_df.columns.tolist(),
                        index=0,
                        key="focused_analysis_sort_column",
                        help="Select a column to sort the table numerically"
                    )
                with col2:
                    if st.button("‚¨áÔ∏è Sort ‚Üì", key="focused_analysis_sort_desc_button", help="Sort table in descending order (highest to lowest values)"):
                        sorted_df = sort_dataframe_numerically(focused_df, focused_sort_column, ascending=False)
                        st.session_state.focused_analysis_sorted_df = sorted_df
                        st.rerun()
                with col3:
                    if st.button("‚¨ÜÔ∏è Sort ‚Üë", key="focused_analysis_sort_asc_button", help="Sort table in ascending order (lowest to highest values)"):
                        sorted_df = sort_dataframe_numerically(focused_df, focused_sort_column, ascending=True)
                        st.session_state.focused_analysis_sorted_df = sorted_df
                        st.rerun()
                
                # Display the focused table (use sorted version if available)
                sorted_df = st.session_state.get('focused_analysis_sorted_df', None)
                display_df = sorted_df if sorted_df is not None else focused_df
                st.dataframe(display_df, use_container_width=True)
                
                # Show date range info
                st.info(f"üìÖ **Analysis Period:** {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}")
            else:
                st.warning("‚ö†Ô∏è No data available for the selected date range. Please check your date selection.")
        elif st.session_state.focused_analysis_results is not None:
            # Display stored results even when not recalculating
            focused_stats = st.session_state.focused_analysis_results
            show_essential = st.session_state.focused_analysis_show_essential
            
            # Create focused stats DataFrame
            focused_df = pd.DataFrame.from_dict(focused_stats, orient='index')
            focused_df.index.name = 'Portfolio'
            
            # Format the DataFrame based on current essential setting
            if show_essential_only:
                # Filter to only show essential columns
                essential_cols = ['Total Return', 'CAGR', 'Max Drawdown', 'Volatility']
                if all(col in focused_df.columns for col in essential_cols):
                    focused_df = focused_df[essential_cols]
                focused_df['Total Return'] = focused_df['Total Return'].apply(lambda x: f"{x:.2f}%")
                focused_df['CAGR'] = focused_df['CAGR'].apply(lambda x: f"{x:.2f}%")
                focused_df['Max Drawdown'] = focused_df['Max Drawdown'].apply(lambda x: f"{x:.2f}%")
                focused_df['Volatility'] = focused_df['Volatility'].apply(lambda x: f"{x:.2f}%")
            else:
                # Format all columns
                focused_df['CAGR'] = focused_df['CAGR'].apply(lambda x: f"{x:.2f}%")
                focused_df['Max Drawdown'] = focused_df['Max Drawdown'].apply(lambda x: f"{x:.2f}%")
                focused_df['Volatility'] = focused_df['Volatility'].apply(lambda x: f"{x:.2f}%")
                if 'Sharpe' in focused_df.columns:
                    focused_df['Sharpe'] = focused_df['Sharpe'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) else "N/A")
                if 'Sortino' in focused_df.columns:
                    focused_df['Sortino'] = focused_df['Sortino'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) else "N/A")
                if 'Ulcer Index' in focused_df.columns:
                    focused_df['Ulcer Index'] = focused_df['Ulcer Index'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) else "N/A")
                if 'UPI' in focused_df.columns:
                    focused_df['UPI'] = focused_df['UPI'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) else "N/A")
                if 'Total Return' in focused_df.columns:
                    focused_df['Total Return'] = focused_df['Total Return'].apply(lambda x: f"{x:.2f}%")
                if 'Final Value (No Contributions)' in focused_df.columns:
                    focused_df['Final Value (No Contributions)'] = focused_df['Final Value (No Contributions)'].apply(lambda x: f"${x:,.2f}")
                if 'Median Drawdown' in focused_df.columns:
                    focused_df['Median Drawdown'] = focused_df['Median Drawdown'].apply(lambda x: f"{x:.2f}%")
                if 'Win Rate' in focused_df.columns:
                    focused_df['Win Rate'] = focused_df['Win Rate'].apply(lambda x: f"{x:.1f}%")
                if 'Loss Rate' in focused_df.columns:
                    focused_df['Loss Rate'] = focused_df['Loss Rate'].apply(lambda x: f"{x:.1f}%")
                if 'Median Win' in focused_df.columns:
                    focused_df['Median Win'] = focused_df['Median Win'].apply(lambda x: f"{x:.2f}%")
                if 'Median Loss' in focused_df.columns:
                    focused_df['Median Loss'] = focused_df['Median Loss'].apply(lambda x: f"{x:.2f}%")
                if 'Profit Factor' in focused_df.columns:
                    focused_df['Profit Factor'] = focused_df['Profit Factor'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) and x != np.inf else "N/A")
                if 'Best Month' in focused_df.columns:
                    focused_df['Best Month'] = focused_df['Best Month'].apply(lambda x: f"{x:.2f}%")
                if 'Worst Month' in focused_df.columns:
                    focused_df['Worst Month'] = focused_df['Worst Month'].apply(lambda x: f"{x:.2f}%")
                if 'Median Monthly' in focused_df.columns:
                    focused_df['Median Monthly'] = focused_df['Median Monthly'].apply(lambda x: f"{x:.2f}%")
                if 'Calmar Ratio' in focused_df.columns:
                    focused_df['Calmar Ratio'] = focused_df['Calmar Ratio'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) else "N/A")
                if 'Sterling Ratio' in focused_df.columns:
                    focused_df['Sterling Ratio'] = focused_df['Sterling Ratio'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) else "N/A")
                if 'Recovery Factor' in focused_df.columns:
                    focused_df['Recovery Factor'] = focused_df['Recovery Factor'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) else "N/A")
                if 'Tail Ratio' in focused_df.columns:
                    focused_df['Tail Ratio'] = focused_df['Tail Ratio'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) else "N/A")
            
            # Add column definitions expander
            focused_tooltip_data = {
                'Final Value (No Contributions)': 'Final Value (No Contributions) - What $10,000 would grow to over the selected period using CAGR',
                'CAGR': 'Compound Annual Growth Rate - The annualized rate of return over the investment period',
                'Max Drawdown': 'Maximum Drawdown - The largest peak-to-trough decline during the period',
                'Volatility': 'Volatility - Standard deviation of returns, measuring price dispersion',
                'Sharpe Ratio': 'Sharpe Ratio - Risk-adjusted return (excess return per unit of volatility)',
                'Sortino Ratio': 'Sortino Ratio - Risk-adjusted return considering only downside volatility',
                'Calmar Ratio': 'Calmar Ratio - Annual return divided by maximum drawdown',
                'Sterling Ratio': 'Sterling Ratio - Average annual return divided by average drawdown',
                'Recovery Factor': 'Recovery Factor - Net profit divided by maximum drawdown',
                'Tail Ratio': 'Tail Ratio - 95th percentile return divided by 5th percentile return',
                'Win Rate': 'Win Rate - Percentage of positive return periods',
                'Loss Rate': 'Loss Rate - Percentage of negative return periods',
                'Median Win': 'Median Win - Median return of positive periods',
                'Median Loss': 'Median Loss - Median return of negative periods',
                'Profit Factor': 'Profit Factor - Gross profit divided by gross loss',
                'Best Month': 'Best Month - Highest single month return',
                'Worst Month': 'Worst Month - Lowest single month return',
                'Median Monthly': 'Median Monthly - Median monthly return',
                'Median Drawdown': 'Median Drawdown - Median drawdown value'
            }
            
            # Create tooltip HTML
            focused_tooltip_html = "<div style='background-color: #1e1e1e; color: white; padding: 10px; border-radius: 5px; font-size: 12px;'>"
            focused_tooltip_html += "<b>Column Definitions:</b><br><br>"
            for col in focused_df.columns:
                if col in focused_tooltip_data:
                    focused_tooltip_html += f"<b>{col}:</b> {focused_tooltip_data[col]}<br><br>"
            focused_tooltip_html += "</div>"
            
            # Display tooltip info
            with st.expander("‚ÑπÔ∏è Column Definitions", expanded=False):
                st.markdown(focused_tooltip_html, unsafe_allow_html=True)
            
            # Add sorting controls for focused analysis
            col1, col2, col3 = st.columns([1, 1, 1])
            with col1:
                focused_sort_column = st.selectbox(
                    "Sort by:",
                    options=focused_df.columns.tolist(),
                    index=0,
                    key="focused_analysis_sort_column_2",
                    help="Select a column to sort the table numerically"
                )
            with col2:
                if st.button("‚¨áÔ∏è Sort ‚Üì", key="focused_analysis_sort_desc_button_2", help="Sort table in descending order (highest to lowest values)"):
                    sorted_df = sort_dataframe_numerically(focused_df, focused_sort_column, ascending=False)
                    st.session_state.focused_analysis_sorted_df = sorted_df
                    st.rerun()
            with col3:
                if st.button("‚¨ÜÔ∏è Sort ‚Üë", key="focused_analysis_sort_asc_button_2", help="Sort table in ascending order (lowest to highest values)"):
                    sorted_df = sort_dataframe_numerically(focused_df, focused_sort_column, ascending=True)
                    st.session_state.focused_analysis_sorted_df = sorted_df
                    st.rerun()
            
            # Display the focused table (use sorted version if available)
            sorted_df = st.session_state.get('focused_analysis_sorted_df', None)
            display_df = sorted_df if sorted_df is not None else focused_df
            st.dataframe(display_df, use_container_width=True)
            
            # Show date range info
            if st.session_state.focused_analysis_period is not None:
                st.info(f"üìÖ **Analysis Period:** {st.session_state.focused_analysis_period}")
        elif not calculate_analysis:
            st.info("üëÜ **Select your date range above and click 'Calculate Analysis' to generate the focused performance metrics.**")
        else:
            st.warning("‚ö†Ô∏è Please ensure you have portfolio data loaded and valid date range selected.")


        # Portfolio Configuration Comparison Table
        st.subheader("Portfolio Configuration Comparison")
        
        # Create configuration comparison dataframe
        config_data = {}
        for cfg in st.session_state.multi_backtest_portfolio_configs:
            portfolio_name = cfg.get('name', 'Unknown')
            
            # Extract configuration details
            config_data[portfolio_name] = {
                'Initial Investment': f"${cfg.get('initial_value', 0):,.2f}",
                'Added Amount': f"${cfg.get('added_amount', 0):,.2f}",
                'Added Frequency': cfg.get('added_frequency', 'None'),
                'Rebalancing Frequency': cfg.get('rebalancing_frequency', 'None'),
                'Use Momentum': 'Yes' if cfg.get('use_momentum', False) else 'No',
                'Momentum Strategy': cfg.get('momentum_strategy', 'N/A'),
                'Negative Momentum Strategy': cfg.get('negative_momentum_strategy', 'N/A'),
                'Number of Stocks': len(cfg.get('stocks', [])),
                'Stocks': ', '.join([s.get('ticker', '') for s in cfg.get('stocks', [])]),
                'Benchmark': cfg.get('benchmark_ticker', 'N/A'),
                'Momentum Windows': str(cfg.get('momentum_windows', [])),
                'Beta Enabled': 'Yes' if cfg.get('calc_beta', False) else 'No',
                'Volatility Enabled': 'Yes' if cfg.get('calc_volatility', False) else 'No',
                'Beta Window': f"{cfg.get('beta_window_days', 0)}-{cfg.get('exclude_days_beta', 0)}" if cfg.get('calc_beta', False) else 'N/A',
                'Volatility Window': f"{cfg.get('vol_window_days', 0)}-{cfg.get('exclude_days_vol', 0)}" if cfg.get('calc_volatility', False) else 'N/A',
                'Minimal Threshold': f"{cfg.get('minimal_threshold_percent', 4.0):.1f}%" if cfg.get('use_minimal_threshold', False) else 'Disabled',
                'Maximum Allocation': f"{cfg.get('max_allocation_percent', 20.0):.1f}%" if cfg.get('use_max_allocation', False) else 'Disabled',
                'MA Filter': 'Yes' if cfg.get('use_sma_filter', False) else 'No',
                'MA Type': cfg.get('ma_type', 'SMA'),
                'MA Window': f"{cfg.get('sma_window', 200)} days",
                'MA Multiplier': f"{cfg.get('ma_multiplier', 1.48):.4f}",
                'MA Cross Rebalancing': 'Yes' if cfg.get('ma_cross_rebalance', False) else 'No',
                'MA Tolerance Band': f"{cfg.get('ma_tolerance_percent', 2.0):.1f}%" if cfg.get('ma_cross_rebalance', False) else 'N/A',
                'MA Confirmation Days': f"{cfg.get('ma_confirmation_days', 3)} days" if cfg.get('ma_cross_rebalance', False) else 'N/A'
            }
        
        config_df = pd.DataFrame(config_data).T
        
        # Format the configuration table
        st.dataframe(config_df, use_container_width=True)

        st.subheader("Yearly Performance (Interactive Table)")
        all_years = st.session_state.multi_backtest_all_years
        years = sorted(list(set(y.year for ser in all_years.values() for y in ser.index)))
        # Order portfolio columns according to the portfolio_configs order so new portfolios are added to the right
        names = [cfg['name'] for cfg in st.session_state.multi_backtest_portfolio_configs if cfg.get('name') in all_years]

        # Corrected yearly table creation
        df_yearly_pct_data = {}
        df_yearly_final_data = {}
        for name in names:
            pct_list = []
            final_list = []
            # with-additions yearly series (used for final values)
            ser_with = all_years.get(name) if isinstance(all_years, dict) else None
            # no-additions yearly series (used for percent-change to avoid skew)
            ser_noadd = None
            try:
                series_obj = st.session_state.multi_all_results.get(name)
                if isinstance(series_obj, dict) and 'no_additions' in series_obj:
                    ser_noadd = series_obj['no_additions'].resample('YE').last()
                elif isinstance(series_obj, pd.Series):
                    ser_noadd = series_obj.resample('YE').last()
            except Exception:
                ser_noadd = None

            for y in years:
                # get year slices
                ser_year_with = ser_with[ser_with.index.year == y] if ser_with is not None else pd.Series()
                ser_year_no = ser_noadd[ser_noadd.index.year == y] if ser_noadd is not None else pd.Series()

                start_val_for_year = None
                if y == min(years):
                    config_for_name = next((c for c in st.session_state.multi_backtest_portfolio_configs if c['name'] == name), None)
                    if config_for_name:
                        initial_val_of_config = config_for_name['initial_value']
                        if initial_val_of_config > 0:
                            start_val_for_year = initial_val_of_config
                else:
                    prev_year = y - 1
                    # Use no-additions previous year end as the start value for pct change
                    prev_ser_year_no = ser_noadd[ser_noadd.index.year == prev_year] if ser_noadd is not None else pd.Series()
                    if not prev_ser_year_no.empty:
                        start_val_for_year = prev_ser_year_no.iloc[-1]

                # Percent change computed from no-additions series
                if not ser_year_no.empty and start_val_for_year is not None:
                    end_val_no = ser_year_no.iloc[-1]
                    if start_val_for_year > 0:
                        pct_change = (end_val_no - start_val_for_year) / start_val_for_year * 100
                    else:
                        pct_change = np.nan
                else:
                    pct_change = np.nan

                # Final value displayed from with-additions series (if available)
                if not ser_year_with.empty:
                    final_value = ser_year_with.iloc[-1]
                else:
                    final_value = np.nan

                pct_list.append(pct_change)
                final_list.append(final_value)

            df_yearly_pct_data[f'{name} % Change'] = pct_list
            df_yearly_final_data[f'{name} Final Value'] = final_list

        df_yearly_pct = pd.DataFrame(df_yearly_pct_data, index=years)
        df_yearly_final = pd.DataFrame(df_yearly_final_data, index=years)
        # Build combined dataframe but preserve the desired column order (selected portfolio first)
        temp_combined = pd.concat([df_yearly_pct, df_yearly_final], axis=1)
        ordered_cols = []
        for nm in names:
            pct_col = f'{nm} % Change'
            val_col = f'{nm} Final Value'
            if pct_col in temp_combined.columns:
                ordered_cols.append(pct_col)
            if val_col in temp_combined.columns:
                ordered_cols.append(val_col)
        # Fallback: if nothing matched, use whatever columns exist
        if not ordered_cols:
            combined_df = temp_combined
        else:
            combined_df = temp_combined[ordered_cols]

        def color_gradient_stock(val):
            if isinstance(val, (int, float)):
                if val > 50:
                    return 'background-color: #004d00'
                elif val > 20:
                    return 'background-color: #1e8449'
                elif val > 5:
                    return 'background-color: #388e3c'
                elif val > 0:
                    return 'background-color: #66bb6a'
                elif val < -50:
                    return 'background-color: #7b0000'
                elif val < -20:
                    return 'background-color: #b22222'
                elif val < -5:
                    return 'background-color: #d32f2f'
                elif val < 0:
                    return 'background-color: #ef5350'
            return ''
        
        # Ensure columns and index are unique (pandas Styler requires unique labels)
        if combined_df.columns.duplicated().any():
            cols = list(combined_df.columns)
            seen = {}
            new_cols = []
            for c in cols:
                if c in seen:
                    seen[c] += 1
                    new_cols.append(f"{c} ({seen[c]})")
                else:
                    seen[c] = 0
                    new_cols.append(c)
            combined_df.columns = new_cols

        if combined_df.index.duplicated().any():
            idx = list(map(str, combined_df.index))
            seen_idx = {}
            new_idx = []
            for v in idx:
                if v in seen_idx:
                    seen_idx[v] += 1
                    new_idx.append(f"{v} ({seen_idx[v]})")
                else:
                    seen_idx[v] = 0
                    new_idx.append(v)
            combined_df.index = new_idx

        # Recompute percent and final value column lists after any renaming
        pct_cols = [col for col in combined_df.columns if '% Change' in col]
        final_val_cols = [col for col in combined_df.columns if 'Final Value' in col]

        # Coerce percent columns to numeric so formatting applies correctly
        for col in pct_cols:
            if col in combined_df.columns:
                try:
                    combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce')
                except TypeError:
                    # Unexpected column type (not Series/array). Try to coerce via pd.Series or fall back to NaN.
                    try:
                        combined_df[col] = pd.to_numeric(pd.Series(combined_df[col]), errors='coerce')
                    except Exception:
                        combined_df[col] = np.nan

        # Create combined format mapping: percent columns get '%' suffix, final value columns get currency
        fmt_map = {col: '{:,.2f}%' for col in pct_cols if col in combined_df.columns}
        fmt_map.update({col: '${:,.2f}' for col in final_val_cols if col in combined_df.columns})

        styler = combined_df.style
        # Color percent cells with a gradient and then apply formatting in one call
        if pct_cols:
            try:
                # Styler.map is the supported replacement for applymap
                styler = styler.map(color_gradient_stock, subset=pct_cols)
            except Exception:
                # If map still fails (edge cases), skip coloring to avoid breaking the page
                pass
        if fmt_map:
            styler = styler.format(fmt_map, na_rep='N/A')

        st.dataframe(styler, use_container_width=True, hide_index=False)

        # Yearly Robust Statistics (under the yearly table)
        try:
            yearly_stats_rows = []
            for nm in names:
                pct_col = f'{nm} % Change'
                if pct_col in combined_df.columns:
                    series = pd.to_numeric(combined_df[pct_col], errors='coerce')
                    series_clean = series.dropna()
                    total = len(series_clean)
                    positives = int((series_clean > 0).sum()) if total > 0 else 0
                    pos_pct = (positives / total) * 100 if total > 0 else np.nan
                    mean_ret = series_clean.mean() if total > 0 else np.nan
                    median_ret = series_clean.median() if total > 0 else np.nan
                    std_ret = series_clean.std(ddof=0) if total > 1 else np.nan

                    # Positive-only and negative-only yearly return stats
                    pos_series = series_clean[series_clean > 0]
                    neg_series = series_clean[series_clean < 0]
                    pos_mean = pos_series.mean() if len(pos_series) > 0 else np.nan
                    pos_median = pos_series.median() if len(pos_series) > 0 else np.nan
                    neg_mean = neg_series.mean() if len(neg_series) > 0 else np.nan
                    neg_median = neg_series.median() if len(neg_series) > 0 else np.nan

                    # Yearly volatility from monthly returns within each year (mean/median across years)
                    vol_year_mean = np.nan
                    vol_year_median = np.nan
                    vol_year_ann_mean = np.nan
                    vol_year_ann_median = np.nan
                    beta_year_mean = np.nan
                    beta_year_median = np.nan
                    try:
                        series_obj = st.session_state.multi_all_results.get(nm)
                        if isinstance(series_obj, dict) and 'no_additions' in series_obj:
                            ser_noadd_full = series_obj['no_additions']
                        else:
                            ser_noadd_full = series_obj if isinstance(series_obj, pd.Series) else None
                        if ser_noadd_full is not None and not ser_noadd_full.empty:
                            monthly_ser = ser_noadd_full.resample('M').last().pct_change().dropna()
                            if not monthly_ser.empty:
                                vols = monthly_ser.groupby([monthly_ser.index.year]).std(ddof=0)
                                if vols is not None and len(vols) > 0:
                                    vol_year_mean = float(vols.mean())
                                    vol_year_median = float(vols.median())
                                    vols_ann = vols * np.sqrt(12.0)
                                    vol_year_ann_mean = float(vols_ann.mean())
                                    vol_year_ann_median = float(vols_ann.median())
                                # Yearly beta from daily returns -> build benchmark daily series (like monthly section)
                                raw_data = st.session_state.get('multi_backtest_raw_data', {})
                                benchmark_ticker = None
                                if st.session_state.get('multi_backtest_portfolio_configs'):
                                    benchmark_ticker = st.session_state['multi_backtest_portfolio_configs'][0].get('benchmark_ticker', '^GSPC')
                                df_bench_local = raw_data.get(benchmark_ticker)
                                if isinstance(df_bench_local, pd.DataFrame):
                                    if 'Price_change' in df_bench_local.columns:
                                        bench_daily_full = df_bench_local['Price_change'].dropna()
                                    elif 'Price' in df_bench_local.columns:
                                        bench_daily_full = df_bench_local['Price'].pct_change().dropna()
                                    else:
                                        bench_daily_full = None
                                else:
                                    bench_daily_full = None
                                port_daily_full = ser_noadd_full.pct_change().dropna()
                                if bench_daily_full is not None and not port_daily_full.empty and not bench_daily_full.empty:
                                    df_join_y = pd.concat([port_daily_full.rename('p'), bench_daily_full.rename('b')], axis=1).dropna()
                                    if not df_join_y.empty:
                                        df_join_y['yr'] = df_join_y.index.year
                                        betas_y = []
                                        for yr, grp in df_join_y.groupby('yr'):
                                            if len(grp) >= 2 and grp['b'].var() > 0:
                                                betas_y.append(np.cov(grp['p'], grp['b'])[0, 1] / grp['b'].var())
                                        if betas_y:
                                            beta_year_mean = float(np.mean(betas_y))
                                            beta_year_median = float(np.median(betas_y))
                    except Exception:
                        pass

                    yearly_stats_rows.append([
                        nm,
                        positives,
                        f"{pos_pct:.2f}%" if not np.isnan(pos_pct) else 'N/A',
                        mean_ret,
                        median_ret,
                        std_ret,
                        pos_mean,
                        pos_median,
                        neg_mean,
                        neg_median,
                        vol_year_mean,
                        vol_year_median,
                        vol_year_ann_mean,
                        vol_year_ann_median,
                        beta_year_mean,
                        beta_year_median
                    ])
            if yearly_stats_rows:
                stats_df_yearly = pd.DataFrame(
                    yearly_stats_rows,
                    columns=[
                        'Portfolio',
                        'Positive Years',
                        '% Positive Years',
                        'Mean % Change',
                        'Median % Change',
                        'Std % Change',
                        'Mean % (Years > 0)',
                        'Median % (Years > 0)',
                        'Mean % (Years < 0)',
                        'Median % (Years < 0)',
                        'Vol Mean (per-year from monthly %)',
                        'Vol Median (per-year from monthly %)',
                        'Vol Mean (Annualized)',
                        'Vol Median (Annualized)',
                        'Beta Mean (Yearly)',
                        'Beta Median (Yearly)'
                    ]
                )
                # Format numeric columns
                fmt_cols = ['Mean % Change', 'Median % Change', 'Std % Change', 'Mean % (Years > 0)', 'Median % (Years > 0)', 'Mean % (Years < 0)', 'Median % (Years < 0)']
                for c in fmt_cols:
                    if c in stats_df_yearly.columns:
                        stats_df_yearly[c] = stats_df_yearly[c].apply(lambda x: f"{x:.2f}%" if pd.notna(x) else 'N/A')
                for c in ['Vol Mean (per-year from monthly %)', 'Vol Median (per-year from monthly %)', 'Vol Mean (Annualized)', 'Vol Median (Annualized)']:
                    if c in stats_df_yearly.columns:
                        stats_df_yearly[c] = stats_df_yearly[c].apply(lambda x: f"{(x*100):.2f}%" if pd.notna(x) else 'N/A')
                for c in ['Beta Mean (Yearly)', 'Beta Median (Yearly)']:
                    if c in stats_df_yearly.columns:
                        stats_df_yearly[c] = stats_df_yearly[c].apply(lambda x: f"{x:.3f}" if pd.notna(x) else 'N/A')
                st.markdown("**Yearly Robust Statistics**")
                st.dataframe(stats_df_yearly, use_container_width=True)
                with st.expander("Column Definitions", expanded=False):
                    st.markdown(
                        "- **Portfolio**: The portfolio identifier as configured in the app.\n"
                        "- **Positive Years**: Count of calendar years where the portfolio's end-of-year value is greater than the start-of-year value.\n"
                        "- **% Positive Years**: Positive Years divided by total evaluated years (√ó100).\n"
                        "- **Mean % Change**: Arithmetic average of yearly percentage returns across all years. Yearly % return for year y is (Value_end_y ‚àí Value_start_y) / Value_start_y √ó 100, computed using the no-additions series for the denominator logic.\n"
                        "- **Median % Change**: Median of the yearly percentage returns across all years.\n"
                        "- **Std % Change**: Standard deviation (population, ddof=0) of yearly percentage returns across all years.\n"
                        "- **Mean % (Years > 0)** / **Median % (Years > 0)**: Mean/median of yearly percentage returns restricted to years with positive return.\n"
                        "- **Mean % (Years < 0)** / **Median % (Years < 0)**: Mean/median of yearly percentage returns restricted to years with negative return.\n"
                        "- **Vol Mean (per-year from monthly %)** / **Vol Median (per-year from monthly %)**: For each year, compute the standard deviation of that year's monthly percentage returns; then report the mean/median of those per-year volatilities across all years (not annualized).\n"
                        "- **Vol Mean (Annualized)** / **Vol Median (Annualized)**: Same per-year monthly volatilities as above, but multiplied by ‚àö12 before aggregating (to annualize).\n"
                        "- **Beta Mean (Yearly)** / **Beta Median (Yearly)**: Using daily returns, compute beta for each calendar year as Cov(port, bench)/Var(bench) on that year's daily data; then report the mean/median across years."
                    )

                # Yearly Returns Bar Chart (grouped by portfolio)
                try:
                    import plotly.express as px
                    chart_rows = []
                    for i, y in enumerate(years):
                        for nm in names:
                            col = f'{nm} % Change'
                            if col in df_yearly_pct.columns:
                                val = df_yearly_pct.iloc[i][col]
                                if pd.notna(val):
                                    chart_rows.append({'Year': int(y), 'Portfolio': nm, 'Return %': float(val)})
                    if chart_rows:
                        chart_df = pd.DataFrame(chart_rows)
                        fig_yearly = px.bar(
                            chart_df,
                            x='Year', y='Return %', color='Portfolio', barmode='group',
                            title='Yearly Returns (%)'
                        )
                        fig_yearly.update_layout(
                            legend_title_text='Portfolio',
                            legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='left', x=0)
                        )
                        st.plotly_chart(fig_yearly, use_container_width=True)
                except Exception:
                    pass
        except Exception:
            pass

        # Monthly Performance Table
        st.subheader("Monthly Performance (Interactive Table)")
        # Use the original results data for monthly calculation, not the yearly resampled data
        all_results = st.session_state.multi_all_results
        # Get all available months from the original data
        all_months_data = {}
        for name, results in all_results.items():
            if isinstance(results, dict) and 'with_additions' in results:
                all_months_data[name] = results['with_additions']
            elif isinstance(results, pd.Series):
                all_months_data[name] = results
        
        # Extract all unique year-month combinations from the original data
        months = set()
        for ser in all_months_data.values():
            if not ser.empty:
                for date in ser.index:
                    months.add((date.year, date.month))
        months = sorted(list(months))
        
        # Order portfolio columns according to the portfolio_configs order so new portfolios are added to the right
        names = [cfg['name'] for cfg in st.session_state.multi_backtest_portfolio_configs if cfg.get('name') in all_months_data]

        # Monthly table creation
        df_monthly_pct_data = {}
        df_monthly_final_data = {}
        for name in names:
            pct_list = []
            final_list = []
            # with-additions monthly series (used for final values)
            ser_with = all_months_data.get(name) if isinstance(all_months_data, dict) else None
            # no-additions monthly series (used for percent-change to avoid skew)
            ser_noadd = None
            try:
                series_obj = st.session_state.multi_all_results.get(name)
                if isinstance(series_obj, dict) and 'no_additions' in series_obj:
                    ser_noadd = series_obj['no_additions'].resample('M').last()
                elif isinstance(series_obj, pd.Series):
                    ser_noadd = series_obj.resample('M').last()
            except Exception:
                ser_noadd = None

            for y, m in months:
                # get month slices
                ser_month_with = ser_with[(ser_with.index.year == y) & (ser_with.index.month == m)] if ser_with is not None else pd.Series()
                ser_month_no = ser_noadd[(ser_noadd.index.year == y) & (ser_noadd.index.month == m)] if ser_noadd is not None else pd.Series()

                start_val_for_month = None
                if (y, m) == min(months):
                    config_for_name = next((c for c in st.session_state.multi_backtest_portfolio_configs if c['name'] == name), None)
                    if config_for_name:
                        initial_val_of_config = config_for_name['initial_value']
                        if initial_val_of_config > 0:
                            start_val_for_month = initial_val_of_config
                else:
                    # Find previous month
                    prev_month_idx = months.index((y, m)) - 1
                    if prev_month_idx >= 0:
                        prev_y, prev_m = months[prev_month_idx]
                        # Use no-additions previous month end as the start value for pct change
                        prev_ser_month_no = ser_noadd[(ser_noadd.index.year == prev_y) & (ser_noadd.index.month == prev_m)] if ser_noadd is not None else pd.Series()
                        if not prev_ser_month_no.empty:
                            start_val_for_month = prev_ser_month_no.iloc[-1]

                # Percent change computed from no-additions series
                if not ser_month_no.empty and start_val_for_month is not None:
                    end_val_no = ser_month_no.iloc[-1]
                    if start_val_for_month > 0:
                        pct_change = (end_val_no - start_val_for_month) / start_val_for_month * 100
                    else:
                        pct_change = np.nan
                else:
                    pct_change = np.nan

                # Final value displayed from with-additions series (if available)
                if not ser_month_with.empty:
                    final_value = ser_month_with.iloc[-1]
                else:
                    final_value = np.nan

                pct_list.append(pct_change)
                final_list.append(final_value)

            df_monthly_pct_data[f'{name} % Change'] = pct_list
            df_monthly_final_data[f'{name} Final Value'] = final_list

        df_monthly_pct = pd.DataFrame(df_monthly_pct_data, index=[f"{y}-{m:02d}" for y, m in months])
        df_monthly_final = pd.DataFrame(df_monthly_final_data, index=[f"{y}-{m:02d}" for y, m in months])
        # Build combined dataframe but preserve the desired column order (selected portfolio first)
        temp_combined_monthly = pd.concat([df_monthly_pct, df_monthly_final], axis=1)
        ordered_cols_monthly = []
        for nm in names:
            pct_col = f'{nm} % Change'
            val_col = f'{nm} Final Value'
            if pct_col in temp_combined_monthly.columns:
                ordered_cols_monthly.append(pct_col)
            if val_col in temp_combined_monthly.columns:
                ordered_cols_monthly.append(val_col)
        # Fallback: if nothing matched, use whatever columns exist
        if not ordered_cols_monthly:
            combined_df_monthly = temp_combined_monthly
        else:
            combined_df_monthly = temp_combined_monthly[ordered_cols_monthly]

        # Ensure columns and index are unique (pandas Styler requires unique labels)
        if combined_df_monthly.columns.duplicated().any():
            cols = list(combined_df_monthly.columns)
            seen = {}
            new_cols = []
            for c in cols:
                if c in seen:
                    seen[c] += 1
                    new_cols.append(f"{c} ({seen[c]})")
                else:
                    seen[c] = 0
                    new_cols.append(c)
            combined_df_monthly.columns = new_cols

        if combined_df_monthly.index.duplicated().any():
            idx = list(map(str, combined_df_monthly.index))
            seen_idx = {}
            new_idx = []
            for v in idx:
                if v in seen_idx:
                    seen_idx[v] += 1
                    new_idx.append(f"{v} ({seen_idx[v]})")
                else:
                    seen_idx[v] = 0
                    new_idx.append(v)
            combined_df_monthly.index = new_idx

        # Recompute percent and final value column lists after any renaming
        pct_cols_monthly = [col for col in combined_df_monthly.columns if '% Change' in col]
        final_val_cols_monthly = [col for col in combined_df_monthly.columns if 'Final Value' in col]

        # Coerce percent columns to numeric so formatting applies correctly
        for col in pct_cols_monthly:
            if col in combined_df_monthly.columns:
                try:
                    combined_df_monthly[col] = pd.to_numeric(combined_df_monthly[col], errors='coerce')
                except TypeError:
                    # Unexpected column type (not Series/array). Try to coerce via pd.Series or fall back to NaN.
                    try:
                        combined_df_monthly[col] = pd.to_numeric(pd.Series(combined_df_monthly[col]), errors='coerce')
                    except Exception:
                        combined_df_monthly[col] = np.nan

        # Create combined format mapping: percent columns get '%' suffix, final value columns get currency
        fmt_map_monthly = {col: '{:,.2f}%' for col in pct_cols_monthly if col in combined_df_monthly.columns}
        fmt_map_monthly.update({col: '${:,.2f}' for col in final_val_cols_monthly if col in combined_df_monthly.columns})

        styler_monthly = combined_df_monthly.style
        # Color percent cells with a gradient and then apply formatting in one call
        if pct_cols_monthly:
            try:
                # Styler.map is the supported replacement for applymap
                styler_monthly = styler_monthly.map(color_gradient_stock, subset=pct_cols_monthly)
            except Exception:
                # If map still fails (edge cases), skip coloring to avoid breaking the page
                pass
        if fmt_map_monthly:
            styler_monthly = styler_monthly.format(fmt_map_monthly, na_rep='N/A')

        st.dataframe(styler_monthly, use_container_width=True, hide_index=False)

        # Monthly Robust Statistics (under the monthly table)
        try:
            monthly_stats_rows = []
            for nm in names:
                pct_col = f'{nm} % Change'
                if pct_col in combined_df_monthly.columns:
                    series = pd.to_numeric(combined_df_monthly[pct_col], errors='coerce')
                    series_clean = series.dropna()
                    total = len(series_clean)
                    positives = int((series_clean > 0).sum()) if total > 0 else 0
                    pos_pct = (positives / total) * 100 if total > 0 else np.nan
                    mean_ret = series_clean.mean() if total > 0 else np.nan
                    median_ret = series_clean.median() if total > 0 else np.nan
                    std_ret = series_clean.std(ddof=0) if total > 1 else np.nan

                    # Positive-only and negative-only monthly return stats
                    pos_series = series_clean[series_clean > 0]
                    neg_series = series_clean[series_clean < 0]
                    pos_mean = pos_series.mean() if len(pos_series) > 0 else np.nan
                    pos_median = pos_series.median() if len(pos_series) > 0 else np.nan
                    neg_mean = neg_series.mean() if len(neg_series) > 0 else np.nan
                    neg_median = neg_series.median() if len(neg_series) > 0 else np.nan

                    # Optional beta stats per month (mean/median) if benchmark data available
                    beta_mean = np.nan
                    beta_median = np.nan
                    vol_month_mean = np.nan
                    vol_month_median = np.nan
                    vol_month_ann_mean = np.nan
                    vol_month_ann_median = np.nan
                    try:
                        # Require benchmark raw data and portfolio daily values
                        raw_data = st.session_state.get('multi_backtest_raw_data', {})
                        benchmark_ticker = None
                        # Use the first portfolio config's benchmark (they typically share the same)
                        if st.session_state.get('multi_backtest_portfolio_configs'):
                            benchmark_ticker = st.session_state['multi_backtest_portfolio_configs'][0].get('benchmark_ticker', '^GSPC')
                        df_bench = raw_data.get(benchmark_ticker)
                        series_obj = st.session_state.multi_all_results.get(nm)
                        if df_bench is not None and isinstance(series_obj, (dict, pd.Series)):
                            if isinstance(series_obj, dict) and 'no_additions' in series_obj:
                                port_series = series_obj['no_additions']
                            else:
                                port_series = series_obj
                            # Compute daily returns
                            port_daily = port_series.pct_change().dropna()
                            # Monthly realized vol from daily returns: std per month of daily returns
                            if not port_daily.empty:
                                vol_by_month = port_daily.groupby([port_daily.index.to_period('M')]).std(ddof=0)
                                if vol_by_month is not None and len(vol_by_month) > 0:
                                    vol_month_mean = float(vol_by_month.mean())
                                    vol_month_median = float(vol_by_month.median())
                                    vol_by_month_ann = vol_by_month * np.sqrt(252.0)
                                    vol_month_ann_mean = float(vol_by_month_ann.mean())
                                    vol_month_ann_median = float(vol_by_month_ann.median())
                            if isinstance(df_bench, pd.DataFrame) and 'Price_change' in df_bench.columns:
                                bench_daily = df_bench['Price_change'].dropna()
                            else:
                                # Fallback: compute from Price if available
                                if isinstance(df_bench, pd.DataFrame) and 'Price' in df_bench.columns:
                                    bench_daily = df_bench['Price'].pct_change().dropna()
                                else:
                                    bench_daily = None

                            if bench_daily is not None and not port_daily.empty and not bench_daily.empty:
                                # Align indices
                                df_join = pd.concat([port_daily.rename('p'), bench_daily.rename('b')], axis=1).dropna()
                                if not df_join.empty:
                                    # Group by month and compute beta per month
                                    df_join['ym'] = df_join.index.to_period('M')
                                    betas = []
                                    for ym, grp in df_join.groupby('ym'):
                                        if len(grp) >= 2 and grp['b'].var() > 0:
                                            betas.append(np.cov(grp['p'], grp['b'])[0, 1] / grp['b'].var())
                                    if betas:
                                        beta_mean = float(np.mean(betas))
                                        beta_median = float(np.median(betas))
                    except Exception:
                        pass

                    monthly_stats_rows.append([
                        nm,
                        positives,
                        f"{pos_pct:.2f}%" if not np.isnan(pos_pct) else 'N/A',
                        mean_ret,
                        median_ret,
                        std_ret,
                        pos_mean,
                        pos_median,
                        neg_mean,
                        neg_median,
                        vol_month_mean,
                        vol_month_median,
                        vol_month_ann_mean,
                        vol_month_ann_median,
                        beta_mean,
                        beta_median
                    ])

            if monthly_stats_rows:
                stats_df_monthly = pd.DataFrame(
                    monthly_stats_rows,
                    columns=[
                        'Portfolio',
                        'Positive Months',
                        '% Positive Months',
                        'Mean % Change',
                        'Median % Change',
                        'Std % Change',
                        'Mean % (Months > 0)',
                        'Median % (Months > 0)',
                        'Mean % (Months < 0)',
                        'Median % (Months < 0)',
                        'Vol Mean (per-month from daily %)',
                        'Vol Median (per-month from daily %)',
                        'Vol Mean (Annualized)',
                        'Vol Median (Annualized)',
                        'Beta Mean (Monthly)',
                        'Beta Median (Monthly)'
                    ]
                )
                # Format numeric columns
                fmt_cols_pct = ['Mean % Change', 'Median % Change', 'Std % Change', 'Mean % (Months > 0)', 'Median % (Months > 0)', 'Mean % (Months < 0)', 'Median % (Months < 0)']
                for c in fmt_cols_pct:
                    if c in stats_df_monthly.columns:
                        stats_df_monthly[c] = stats_df_monthly[c].apply(lambda x: f"{x:.2f}%" if pd.notna(x) else 'N/A')
                for c in ['Vol Mean (per-month from daily %)', 'Vol Median (per-month from daily %)', 'Vol Mean (Annualized)', 'Vol Median (Annualized)']:
                    if c in stats_df_monthly.columns:
                        stats_df_monthly[c] = stats_df_monthly[c].apply(lambda x: f"{(x*100):.2f}%" if pd.notna(x) else 'N/A')
                for c in ['Beta Mean (Monthly)', 'Beta Median (Monthly)']:
                    if c in stats_df_monthly.columns:
                        stats_df_monthly[c] = stats_df_monthly[c].apply(lambda x: f"{x:.3f}" if pd.notna(x) else 'N/A')
                st.markdown("**Monthly Robust Statistics**")
                st.dataframe(stats_df_monthly, use_container_width=True)
                with st.expander("Column Definitions", expanded=False):
                    st.markdown(
                        "- **Portfolio**: The portfolio identifier as configured in the app.\n"
                        "- **Positive Months**: Count of months where the end-of-month value exceeds the start-of-month value.\n"
                        "- **% Positive Months**: Positive Months divided by total evaluated months (√ó100).\n"
                        "- **Mean % Change**: Arithmetic average of monthly percentage returns across all months. Monthly % return for month m is (Value_end_m ‚àí Value_start_m) / Value_start_m √ó 100, computed using the no-additions series for the denominator logic.\n"
                        "- **Median % Change**: Median of the monthly percentage returns across all months.\n"
                        "- **Std % Change**: Standard deviation (population, ddof=0) of monthly percentage returns across all months.\n"
                        "- **Mean % (Months > 0)** / **Median % (Months > 0)**: Mean/median of monthly percentage returns restricted to months with positive return.\n"
                        "- **Mean % (Months < 0)** / **Median % (Months < 0)**: Mean/median of monthly percentage returns restricted to months with negative return.\n"
                        "- **Vol Mean (per-month from daily %)** / **Vol Median (per-month from daily %)**: For each month, compute the standard deviation of that month's daily returns; then report the mean/median across all months (not annualized).\n"
                        "- **Vol Mean (Annualized)** / **Vol Median (Annualized)**: Same per-month daily volatilities as above, but multiplied by ‚àö252 before aggregating (to annualize).\n"
                        "- **Beta Mean (Monthly)** / **Beta Median (Monthly)**: Using daily returns, compute beta each month as Cov(port, bench)/Var(bench) on that month's daily data; then report the mean/median across months."
                    )
        except Exception:
            pass

        st.markdown("**Detailed Portfolio Information**")
        # Make the selector visually prominent
        st.markdown(
            "<div style='background:#0b1221;padding:12px;border-radius:8px;margin-bottom:8px;'>"
            "<div style='font-size:16px;font-weight:700;color:#ffffff;margin-bottom:6px;'>Select a portfolio for detailed view</div>"
            "</div>", unsafe_allow_html=True)

        # NUCLEAR APPROACH: Store selection by portfolio name, not display index
        portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
        
        # Get all available portfolio names
        available_portfolio_names = [cfg.get('name', 'Portfolio') for cfg in portfolio_configs]
        extra_names = [n for n in st.session_state.get('multi_all_results', {}).keys() if n not in available_portfolio_names]
        all_portfolio_names = available_portfolio_names + extra_names
        
        # Initialize persistent selection by name
        if "multi_backtest_selected_portfolio_name" not in st.session_state:
            st.session_state["multi_backtest_selected_portfolio_name"] = all_portfolio_names[0] if all_portfolio_names else "No portfolios"
        
        # Ensure the selected name is still valid
        if st.session_state["multi_backtest_selected_portfolio_name"] not in all_portfolio_names and all_portfolio_names:
            st.session_state["multi_backtest_selected_portfolio_name"] = all_portfolio_names[0]
        
        # Find the current selection index
        current_selection_index = 0
        if st.session_state["multi_backtest_selected_portfolio_name"] in all_portfolio_names:
            current_selection_index = all_portfolio_names.index(st.session_state["multi_backtest_selected_portfolio_name"])
        
        # Place the selectbox in its own column to make it larger/centered
        # Build a prominent action row: selector + colored 'View' button
        left_col, mid_col, right_col = st.columns([1, 3, 1])
        with mid_col:
            st.markdown("<div style='display:flex; gap:8px; align-items:center;'>", unsafe_allow_html=True)
            
            # Simplified selection logic - directly use portfolio names without complex parsing
            def update_selected_portfolio():
                selected_name = st.session_state.get("multi_backtest_detail_portfolio_selector")
                if selected_name:
                    st.session_state["multi_backtest_selected_portfolio_name"] = selected_name

            selected_portfolio_name = st.selectbox(
                "Select portfolio for details", 
                options=all_portfolio_names, 
                index=current_selection_index,
                key="multi_backtest_detail_portfolio_selector", 
                help='Choose which portfolio to inspect in detail', 
                label_visibility='collapsed',
                on_change=update_selected_portfolio,
                format_func=lambda x: x  # Display full names without truncation
            )
            # Add a prominent view button with a professional color
            view_clicked = st.button("View Details", key='view_details_btn')
            st.markdown("</div>", unsafe_allow_html=True)

        # Use the selected portfolio name directly (no more complex parsing needed)
        selected_portfolio_detail = selected_portfolio_name

        if selected_portfolio_detail:
            # Highlight the selected portfolio and optionally expand details when the View button is used
            st.markdown(f"<div style='padding:8px 12px;background:#04293a;border-radius:6px;margin-top:8px;'><strong style='color:#bde0fe;'>Showing details for:</strong> <span style='font-size:16px;color:#ffffff;margin-left:8px;'>{selected_portfolio_detail}</span></div>", unsafe_allow_html=True)
            if view_clicked:
                # No-op here; the detail panels below will render based on selected_portfolio_detail. Keep a small indicator
                st.success(f"Loaded details for {selected_portfolio_detail}")
            # Table 1: Historical Allocations - ULTRA-OPTIMIZED with comprehensive caching
            if 'individual_portfolio_cache' in st.session_state and selected_portfolio_detail in st.session_state.individual_portfolio_cache:
                st.markdown("---")
                st.markdown(f"**Historical Allocations for {selected_portfolio_detail}**")
                
                # Use processed data - INSTANT ACCESS!
                portfolio_cache = st.session_state.individual_portfolio_cache[selected_portfolio_detail]
                allocations_df_raw = portfolio_cache.get('allocations_df')
                all_tickers = portfolio_cache.get('allocations_tickers', [])
                
                if allocations_df_raw is not None:
                    # Corrected styling logic for alternating row colors (no green background for Historical Allocations)
                    def highlight_rows_by_index(s):
                        is_even_row = allocations_df_raw.index.get_loc(s.name) % 2 == 0
                        bg_color = 'background-color: #0e1117' if is_even_row else 'background-color: #262626'
                        return [f'{bg_color}; color: white;'] * len(s)

                    try:
                        # Check if dataframe is too large for styling
                        total_cells = allocations_df_raw.shape[0] * allocations_df_raw.shape[1]
                        if total_cells > 200000:  # Conservative limit
                            st.warning(f"Allocations table is very large ({total_cells:,} cells). Showing simplified view.")
                            # Show only recent data (last 100 rows)
                            recent_data = allocations_df_raw.tail(100)
                            st.dataframe(recent_data.round(0), use_container_width=True)
                            st.caption("Showing last 100 rows. Use filters to narrow down the data.")
                        else:
                            # Increase pandas styler limit for smaller datasets
                            pd.set_option("styler.render.max_elements", max(total_cells * 2, 500000))
                            styler = allocations_df_raw.style.apply(highlight_rows_by_index, axis=1)
                            styler.format('{:,.0f}%', na_rep='N/A')
                            st.dataframe(styler, use_container_width=True)
                    except Exception as e:
                        st.error(f"Error displaying allocations table: {str(e)}")
                        st.write("Raw allocations data (first 1000 rows):")
                        st.dataframe(allocations_df_raw.head(1000))
                else:
                    st.warning("No allocation data available for this portfolio.")

            # Table 2: Historical Shares and Position Values
            if selected_portfolio_detail in st.session_state.multi_all_allocations:
                st.markdown("---")
                st.markdown(f"**Historical Shares and Position Values for {selected_portfolio_detail}**")
                
                # Get allocation data and portfolio results
                allocation_data = st.session_state.multi_all_allocations[selected_portfolio_detail]
                portfolio_results = st.session_state.multi_all_results.get(selected_portfolio_detail)
                
                if allocation_data and portfolio_results:
                    # Get portfolio value series (with additions)
                    if isinstance(portfolio_results, dict) and 'with_additions' in portfolio_results:
                        portfolio_values = portfolio_results['with_additions']
                    elif isinstance(portfolio_results, pd.Series):
                        portfolio_values = portfolio_results
                    else:
                        portfolio_values = None
                    
                    # Get raw data for prices
                    raw_data = st.session_state.get('multi_backtest_raw_data', {})
                    
                    # Helper function to get price on or before a date
                    def get_price_on_date(df, target_date):
                        try:
                            available_dates = df.index[df.index <= target_date]
                            if len(available_dates) > 0:
                                closest_date = available_dates[-1]
                                return float(df.loc[closest_date, 'Close'])
                            return None
                        except Exception:
                            return None
                    
                    # Build historical shares and values data
                    shares_data = {}
                    values_data = {}
                    all_tickers_set = set()
                    
                    # Collect all tickers first
                    for date, alloc_dict in allocation_data.items():
                        all_tickers_set.update(alloc_dict.keys())
                    
                    # Remove None if present
                    all_tickers_set.discard(None)
                    all_tickers_list = sorted(list(all_tickers_set))
                    if 'CASH' in all_tickers_list:
                        all_tickers_list.remove('CASH')
                        all_tickers_list.append('CASH')
                    
                    # Determine rebalancing dates (same logic used elsewhere)
                    rebalancing_dates = []
                    try:
                        # Get portfolio config to read frequency
                        portfolio_configs_local = st.session_state.get('multi_backtest_portfolio_configs', [])
                        portfolio_cfg_local = next((cfg for cfg in portfolio_configs_local if cfg.get('name') == selected_portfolio_detail), None)
                        rebalancing_frequency = portfolio_cfg_local.get('rebalancing_frequency', 'none') if portfolio_cfg_local else 'none'
                        # Map to standard names
                        frequency_mapping = {
                            'monthly': 'Monthly',
                            'weekly': 'Weekly',
                            'bi-weekly': 'Biweekly',
                            'biweekly': 'Biweekly',
                            'quarterly': 'Quarterly',
                            'semi-annually': 'Semiannually',
                            'semiannually': 'Semiannually',
                            'annually': 'Annually',
                            'yearly': 'Annually',
                            'never': 'Never',
                            'none': 'Never',
                            'buy & hold': 'Buy & Hold',
                            'buy & hold (target)': 'Buy & Hold (Target)'
                        }
                        rb_freq_display = frequency_mapping.get(str(rebalancing_frequency).lower(), rebalancing_frequency)
                        # Determine sim_index from results
                        sim_index = None
                        if isinstance(portfolio_results, dict) and 'no_additions' in portfolio_results:
                            sim_index = portfolio_results['no_additions'].index
                        elif isinstance(portfolio_results, pd.Series):
                            sim_index = portfolio_results.index
                        # Get cached rebalancing dates
                        portfolio_rebalancing_dates = get_cached_rebalancing_dates(selected_portfolio_detail, rb_freq_display, sim_index)
                        # Filter to dates we have in allocation_data
                        if portfolio_rebalancing_dates:
                            rebalancing_dates = sorted([d for d in portfolio_rebalancing_dates if d in allocation_data])
                    except Exception:
                        rebalancing_dates = []
                    
                    # Fallback: if no rebalancing dates and frequency implies periodic rebalancing, use all allocation dates
                    if not rebalancing_dates:
                        if rb_freq_display not in ['Never', 'Buy & Hold', 'Buy & Hold (Target)']:
                            rebalancing_dates = sorted(allocation_data.keys())
                    
                    # Process only rebalancing dates
                    for date in rebalancing_dates:
                        alloc_dict = allocation_data[date]
                        
                        # Get portfolio value for this date
                        if portfolio_values is not None and date in portfolio_values.index:
                            portfolio_value = float(portfolio_values.loc[date])
                        else:
                            # Try to find closest date
                            if portfolio_values is not None:
                                available_dates = portfolio_values.index[portfolio_values.index <= date]
                                if len(available_dates) > 0:
                                    portfolio_value = float(portfolio_values.loc[available_dates[-1]])
                                else:
                                    portfolio_value = 0.0
                            else:
                                portfolio_value = 0.0
                        
                        shares_row = {}
                        values_row = {}
                        
                        for ticker in all_tickers_list:
                            # Get allocation percentage
                            alloc_value = alloc_dict.get(ticker, 0)
                            if isinstance(alloc_value, dict):
                                alloc_pct = float(alloc_value.get('allocation', alloc_value.get('weight', 0)))
                            else:
                                alloc_pct = float(alloc_value) if alloc_value is not None else 0.0
                            
                            if ticker == 'CASH':
                                shares_row[ticker] = 0.0
                                values_row[ticker] = portfolio_value * alloc_pct
                            else:
                                # Get price for this ticker on this date
                                df = raw_data.get(ticker)
                                price = None
                                if isinstance(df, pd.DataFrame) and 'Close' in df.columns:
                                    price = get_price_on_date(df, date)
                                
                                if price and price > 0:
                                    allocation_value = portfolio_value * alloc_pct
                                    shares = allocation_value / price
                                    shares_row[ticker] = round(shares, 2)
                                    values_row[ticker] = shares * price
                                else:
                                    shares_row[ticker] = 0.0
                                    values_row[ticker] = portfolio_value * alloc_pct
                        
                        shares_data[date] = shares_row
                        values_data[date] = values_row
                    
                    # Create DataFrames
                    shares_df = pd.DataFrame(shares_data).T
                    shares_df.index = pd.to_datetime(shares_df.index)
                    shares_df = shares_df.sort_index()
                    shares_df = shares_df.fillna(0.0)
                    shares_df = shares_df[all_tickers_list]
                    shares_df.index.name = "Date"
                    
                    values_df = pd.DataFrame(values_data).T
                    values_df.index = pd.to_datetime(values_df.index)
                    values_df = values_df.sort_index()
                    values_df = values_df.fillna(0.0)
                    values_df = values_df[all_tickers_list]
                    values_df.index.name = "Date"
                    
                    # Display Shares table
                    st.markdown("**Shares Held**")
                    try:
                        total_cells = shares_df.shape[0] * shares_df.shape[1]
                        if total_cells > 200000:
                            st.warning(f"Shares table is very large ({total_cells:,} cells). Showing simplified view.")
                            recent_data = shares_df.tail(100)
                            st.dataframe(recent_data, use_container_width=True)
                            st.caption("Showing last 100 rows. Use filters to narrow down the data.")
                        else:
                            pd.set_option("styler.render.max_elements", max(total_cells * 2, 500000))
                            
                            def highlight_shares_rows(s):
                                is_even_row = shares_df.index.get_loc(s.name) % 2 == 0
                                bg_color = 'background-color: #0e1117' if is_even_row else 'background-color: #262626'
                                return [f'{bg_color}; color: white;'] * len(s)
                            
                            styler = shares_df.style.apply(highlight_shares_rows, axis=1)
                            styler.format('{:,.2f}', na_rep='N/A')
                            st.dataframe(styler, use_container_width=True)
                    except Exception as e:
                        st.error(f"Error displaying shares table: {str(e)}")
                        st.dataframe(shares_df.head(1000))
                    
                    # Display Values table
                    st.markdown("**Position Values ($)**")
                    try:
                        total_cells = values_df.shape[0] * values_df.shape[1]
                        if total_cells > 200000:
                            st.warning(f"Values table is very large ({total_cells:,} cells). Showing simplified view.")
                            recent_data = values_df.tail(100)
                            st.dataframe(recent_data, use_container_width=True)
                            st.caption("Showing last 100 rows. Use filters to narrow down the data.")
                        else:
                            pd.set_option("styler.render.max_elements", max(total_cells * 2, 500000))
                            
                            def highlight_values_rows(s):
                                is_even_row = values_df.index.get_loc(s.name) % 2 == 0
                                bg_color = 'background-color: #0e1117' if is_even_row else 'background-color: #262626'
                                return [f'{bg_color}; color: white;'] * len(s)
                            
                            styler = values_df.style.apply(highlight_values_rows, axis=1)
                            styler.format('${:,.2f}', na_rep='N/A')
                            st.dataframe(styler, use_container_width=True)
                    except Exception as e:
                        st.error(f"Error displaying values table: {str(e)}")
                        st.dataframe(values_df.head(1000))
                    
                    # Table 2b: Realized and Unrealized Gains/Losses from Purchases vs Price Variations
                    st.markdown("---")
                    st.markdown(f"**Realized and Unrealized Gains/Losses Analysis for {selected_portfolio_detail}**")
                    st.markdown("*Shows gains/losses from purchases/sales vs price variations at each rebalance*")
                    
                    # IMPORTANT: Dividend handling affects interpretation.
                    # - If dividends are collected as cash (collect_dividends_as_cash=True), they behave like "new cash"
                    #   and will NOT create artificial realized gains in this analysis.
                    # - If dividends are reinvested, they increase position value and may appear as additional shares
                    #   between rebalances (because we infer shares from value/price snapshots).
                    portfolio_cfg_for_div = None
                    try:
                        portfolio_cfg_for_div = next(
                            (cfg for cfg in st.session_state.get('multi_backtest_portfolio_configs', [])
                             if cfg.get('name') == selected_portfolio_detail),
                            None
                        )
                    except Exception:
                        portfolio_cfg_for_div = None
                    collect_div_as_cash = bool(portfolio_cfg_for_div.get('collect_dividends_as_cash', False)) if portfolio_cfg_for_div else False
                    if collect_div_as_cash:
                        st.info("Dividends are **collected as cash** for this portfolio. In this analysis, dividends behave like **new cash** (added after gain/loss calculations, then reflected in the next rebalance snapshot).")
                    else:
                        st.warning("Dividends are currently **reinvested** for this portfolio. This analysis may show dividend reinvestment as **extra shares** between rebalances (because shares are inferred from value/price). If you want dividends treated exactly like new cash here, enable `collect_dividends_as_cash` in the portfolio config.")
                    
                    # Track average purchase price for each ticker (FIFO-like approach)
                    # We'll use weighted average cost basis
                    avg_purchase_price = {}  # {ticker: average_price}
                    realized_gains_data = {}  # {date: {ticker: realized_gain}}
                    unrealized_gains_data = {}  # {date: {ticker: unrealized_gain}}
                    total_realized_data = {}  # {date: total_realized}
                    total_unrealized_data = {}  # {date: total_unrealized}
                    
                    # Use the same rebalancing dates as above
                    sorted_dates = rebalancing_dates
                    
                    for i, date in enumerate(sorted_dates):
                        prev_date = sorted_dates[i-1] if i > 0 else None
                        prev_shares = shares_df.loc[prev_date] if prev_date is not None else pd.Series(0.0, index=all_tickers_list)
                        current_shares = shares_df.loc[date]
                        
                        # Get prices for this date
                        prices = {}
                        for ticker in all_tickers_list:
                            if ticker == 'CASH':
                                prices[ticker] = None
                            else:
                                df = raw_data.get(ticker)
                                if isinstance(df, pd.DataFrame) and 'Close' in df.columns:
                                    prices[ticker] = get_price_on_date(df, date)
                                else:
                                    prices[ticker] = None
                        
                        realized_row = {}
                        unrealized_row = {}
                        
                        # Get previous prices for comparison
                        prev_prices = {}
                        for ticker in all_tickers_list:
                            if ticker == 'CASH':
                                prev_prices[ticker] = None
                            else:
                                if prev_date:
                                    df = raw_data.get(ticker)
                                    if isinstance(df, pd.DataFrame) and 'Close' in df.columns:
                                        prev_prices[ticker] = get_price_on_date(df, prev_date)
                                    else:
                                        prev_prices[ticker] = None
                                else:
                                    prev_prices[ticker] = None
                        
                        # STEP 1: Calculate gains/losses on EXISTING shares (before new purchases)
                        # This handles sales and price variations on held positions
                        for ticker in all_tickers_list:
                            if ticker == 'CASH':
                                realized_row[ticker] = 0.0
                                unrealized_row[ticker] = 0.0
                                continue
                            
                            prev_shares_count = prev_shares.get(ticker, 0.0)
                            current_shares_count = current_shares.get(ticker, 0.0)
                            current_price = prices.get(ticker)
                            prev_price = prev_prices.get(ticker)
                            
                            if current_price is None or current_price <= 0:
                                realized_row[ticker] = 0.0
                                unrealized_row[ticker] = 0.0
                                continue
                            
                            # Initialize average purchase price if first time seeing this ticker
                            # This represents the weighted average cost basis of shares held
                            if ticker not in avg_purchase_price:
                                if prev_shares_count > 0:
                                    # We had shares before - need to estimate cost basis
                                    # Try to get it from previous period's value and shares
                                    if prev_date:
                                        prev_values = values_df.loc[prev_date] if prev_date in values_df.index else None
                                        if prev_values is not None and ticker in prev_values:
                                            prev_value = prev_values[ticker]
                                            if prev_value > 0 and prev_shares_count > 0:
                                                # Cost basis = previous value / previous shares
                                                avg_purchase_price[ticker] = prev_value / prev_shares_count
                                            elif prev_price and prev_price > 0:
                                                avg_purchase_price[ticker] = prev_price
                                            else:
                                                avg_purchase_price[ticker] = current_price if current_price > 0 else 0.0
                                        elif prev_price and prev_price > 0:
                                            avg_purchase_price[ticker] = prev_price
                                        else:
                                            avg_purchase_price[ticker] = current_price if current_price > 0 else 0.0
                                    elif prev_price and prev_price > 0:
                                        avg_purchase_price[ticker] = prev_price
                                    else:
                                        avg_purchase_price[ticker] = current_price if current_price > 0 else 0.0
                                elif current_shares_count > 0:
                                    # First purchase: use current price
                                    avg_purchase_price[ticker] = current_price if current_price > 0 else 0.0
                                else:
                                    avg_purchase_price[ticker] = 0.0
                            
                            # Calculate shares difference
                            shares_diff = current_shares_count - prev_shares_count
                            
                            # Handle sales (shares decreased) - this is a realized transaction
                            if shares_diff < 0:
                                # We sold shares
                                shares_sold = abs(shares_diff)
                                
                                # Calculate realized gain/loss PERIOD-BY-PERIOD (for isolated period analysis)
                                # Uses previous rebalance price as reference point for this period's performance
                                realized_gain = 0.0
                                
                                if prev_shares_count > 0 and current_price > 0:
                                    # Use previous price as the reference point (price at start of this period)
                                    # This gives us the gain/loss for THIS PERIOD ONLY (isolated analysis)
                                    if prev_price and prev_price > 0:
                                        # Realized gain/loss for this period = (sale_price - previous_price) * shares_sold
                                        # This shows what happened in THIS period only
                                        realized_gain = (current_price - prev_price) * shares_sold
                                    else:
                                        # Fallback: try to get reference price from previous value
                                        if prev_date and prev_date in values_df.index:
                                            prev_values = values_df.loc[prev_date]
                                            if ticker in prev_values and prev_values[ticker] > 0 and prev_shares_count > 0:
                                                # Use previous value / shares as reference price for this period
                                                reference_price = prev_values[ticker] / prev_shares_count
                                                realized_gain = (current_price - reference_price) * shares_sold
                                        elif avg_purchase_price.get(ticker, 0.0) > 0:
                                            # Last fallback: use avg purchase price
                                            realized_gain = (current_price - avg_purchase_price[ticker]) * shares_sold
                                
                                realized_row[ticker] = realized_gain
                                
                                # Unrealized gain for remaining shares (if any)
                                # Use previous price as cost basis (not avg_purchase_price) to show period-specific gain
                                if current_shares_count > 0:
                                    if prev_price and prev_price > 0:
                                        # Unrealized gain on remaining shares = (current_price - prev_price) * remaining_shares
                                        # This shows the price change on shares that were held (not sold)
                                        unrealized_gain = (current_price - prev_price) * current_shares_count
                                        unrealized_row[ticker] = unrealized_gain
                                    elif avg_purchase_price[ticker] > 0:
                                        # Fallback: use avg_purchase_price if prev_price not available
                                        unrealized_gain = (current_price - avg_purchase_price[ticker]) * current_shares_count
                                        unrealized_row[ticker] = unrealized_gain
                                    else:
                                        unrealized_row[ticker] = 0.0
                                else:
                                    unrealized_row[ticker] = 0.0
                                    # Sold all shares - reset average purchase price for next purchase
                                    avg_purchase_price[ticker] = 0.0
                            
                            # Handle no change or purchases - calculate unrealized gains on existing shares
                            else:
                                # No realized gain (no sales)
                                realized_row[ticker] = 0.0
                                
                                # Calculate unrealized gain on PREVIOUS shares (before new purchases)
                                # This shows the gain/loss from price variation on existing positions
                                if prev_shares_count > 0:
                                    # Use previous price as the cost basis for existing shares
                                    if prev_price and prev_price > 0:
                                        # Unrealized gain = (current_price - previous_price) * previous_shares
                                        # This is the gain/loss from price change on shares that existed before this rebalance
                                        unrealized_gain = (current_price - prev_price) * prev_shares_count
                                        unrealized_row[ticker] = unrealized_gain
                                    elif avg_purchase_price[ticker] > 0:
                                        # Fallback: use average purchase price if previous price not available
                                        unrealized_gain = (current_price - avg_purchase_price[ticker]) * prev_shares_count
                                        unrealized_row[ticker] = unrealized_gain
                                    else:
                                        unrealized_row[ticker] = 0.0
                                else:
                                    unrealized_row[ticker] = 0.0
                        
                        # STEP 2: AFTER calculating gains/losses, update average purchase price for new purchases
                        # This way new cash investments don't affect the gain/loss calculations
                        for ticker in all_tickers_list:
                            if ticker == 'CASH':
                                continue
                            
                            prev_shares_count = prev_shares.get(ticker, 0.0)
                            current_shares_count = current_shares.get(ticker, 0.0)
                            current_price = prices.get(ticker)
                            
                            if current_price is None or current_price <= 0:
                                continue
                            
                            shares_diff = current_shares_count - prev_shares_count
                            
                            # Handle purchases (shares increased) - update cost basis AFTER gain calculations
                            if shares_diff > 0:
                                # We bought more shares (could be from new cash or rebalancing)
                                shares_bought = shares_diff
                                
                                # Update average purchase price (weighted average) for next rebalance
                                if prev_shares_count > 0:
                                    # Get the cost basis for previous shares using avg_purchase_price (weighted average cost)
                                    if avg_purchase_price.get(ticker, 0.0) > 0:
                                        # Use the maintained average purchase price (this is the correct cost basis)
                                        prev_cost_basis = prev_shares_count * avg_purchase_price[ticker]
                                    elif prev_date and prev_date in values_df.index:
                                        # Fallback: calculate from previous value and shares
                                        prev_values = values_df.loc[prev_date]
                                        if ticker in prev_values and prev_values[ticker] > 0:
                                            prev_cost_basis = prev_values[ticker]
                                        elif prev_prices.get(ticker) and prev_prices.get(ticker) > 0:
                                            prev_cost_basis = prev_shares_count * prev_prices[ticker]
                                        else:
                                            prev_cost_basis = 0.0
                                    elif prev_prices.get(ticker) and prev_prices.get(ticker) > 0:
                                        prev_cost_basis = prev_shares_count * prev_prices[ticker]
                                    else:
                                        prev_cost_basis = 0.0
                                    
                                    # Weighted average: (old_shares * old_price + new_shares * new_price) / total_shares
                                    total_cost_new = shares_bought * current_price
                                    total_shares = current_shares_count
                                    if total_shares > 0:
                                        avg_purchase_price[ticker] = (prev_cost_basis + total_cost_new) / total_shares
                                    else:
                                        avg_purchase_price[ticker] = current_price
                                else:
                                    # First purchase or all shares were sold before
                                    avg_purchase_price[ticker] = current_price
                            
                            # If shares decreased (sale), avg_purchase_price stays the same (we already handled it above)
                            # If shares stayed the same, keep the same cost basis (don't reset it)
                            # The cost basis should only change when we buy new shares or sell all shares
                            # For next period, we'll use the same avg_purchase_price to calculate unrealized gains
                        
                        # Calculate totals for this rebalance period
                        total_realized = sum(realized_row.values())
                        total_unrealized = sum(unrealized_row.values())
                        
                        realized_gains_data[date] = realized_row
                        unrealized_gains_data[date] = unrealized_row
                        total_realized_data[date] = total_realized
                        total_unrealized_data[date] = total_unrealized
                    
                    # Create DataFrames for realized and unrealized gains
                    realized_df = pd.DataFrame(realized_gains_data).T
                    realized_df.index = pd.to_datetime(realized_df.index)
                    realized_df = realized_df.sort_index()
                    realized_df = realized_df.fillna(0.0)
                    # Ensure all tickers are present
                    for ticker in all_tickers_list:
                        if ticker not in realized_df.columns:
                            realized_df[ticker] = 0.0
                    realized_df = realized_df[all_tickers_list]
                    realized_df['TOTAL'] = realized_df.sum(axis=1)
                    
                    # Create period labels for index (prev_date - current_date)
                    # Keep original dates for year calculation
                    sorted_dates_list = sorted(rebalancing_dates)
                    period_labels = []
                    period_to_date_map = {}  # Map period label to original date
                    
                    for i, current_date in enumerate(sorted_dates_list):
                        if i > 0:
                            prev_date = sorted_dates_list[i-1]
                            # Format dates without time (YYYY-MM-DD)
                            prev_date_str = prev_date.strftime('%Y-%m-%d') if isinstance(prev_date, pd.Timestamp) else str(prev_date)[:10]
                            current_date_str = current_date.strftime('%Y-%m-%d') if isinstance(current_date, pd.Timestamp) else str(current_date)[:10]
                            period_label = f"{prev_date_str} - {current_date_str}"
                        else:
                            # First period: show start date only or use first date as reference
                            current_date_str = current_date.strftime('%Y-%m-%d') if isinstance(current_date, pd.Timestamp) else str(current_date)[:10]
                            period_label = f"{current_date_str} (start)"
                        period_labels.append((current_date, period_label))
                        period_to_date_map[period_label] = current_date
                    
                    # Create mapping from date to period label
                    period_map = {date: label for date, label in period_labels}
                    
                    # Store original dates mapping for annual aggregation
                    original_dates_for_realized = {label: date for date, label in period_labels}
                    
                    # Update index with period labels
                    new_index = [period_map.get(date, date.strftime('%Y-%m-%d') if isinstance(date, pd.Timestamp) else str(date)[:10]) 
                                 for date in realized_df.index]
                    realized_df.index = new_index
                    realized_df.index.name = "Period"
                    
                    unrealized_df = pd.DataFrame(unrealized_gains_data).T
                    unrealized_df.index = pd.to_datetime(unrealized_df.index)
                    unrealized_df = unrealized_df.sort_index()
                    unrealized_df = unrealized_df.fillna(0.0)
                    # Ensure all tickers are present
                    for ticker in all_tickers_list:
                        if ticker not in unrealized_df.columns:
                            unrealized_df[ticker] = 0.0
                    unrealized_df = unrealized_df[all_tickers_list]
                    unrealized_df['TOTAL'] = unrealized_df.sum(axis=1)
                    
                    # Store original dates mapping for unrealized as well
                    original_dates_for_unrealized = {label: date for date, label in period_labels}
                    
                    # Update index with period labels (same mapping)
                    new_index_unrealized = [period_map.get(date, date.strftime('%Y-%m-%d') if isinstance(date, pd.Timestamp) else str(date)[:10]) 
                                           for date in unrealized_df.index]
                    unrealized_df.index = new_index_unrealized
                    unrealized_df.index.name = "Period"
                    
                    # Display Realized Gains/Losses table
                    st.markdown("**Realized Gains/Losses (from Sales)**")
                    try:
                        total_cells = realized_df.shape[0] * realized_df.shape[1]
                        if total_cells > 500000:  # Increased limit from 200000 to 500000
                            st.warning(f"Realized gains table is very large ({total_cells:,} cells). Showing all data (may be slow to render).")
                        # Always show full dataframe - removed the limit restriction
                        pd.set_option("styler.render.max_elements", max(total_cells * 2, 1000000))
                        
                        if total_cells > 500000:
                            # For very large tables, show all but warn user
                            def highlight_realized_rows(s):
                                is_even_row = realized_df.index.get_loc(s.name) % 2 == 0
                                bg_color = 'background-color: #0e1117' if is_even_row else 'background-color: #262626'
                                return [f'{bg_color}; color: white;'] * len(s)
                            
                            styler = realized_df.style.apply(highlight_realized_rows, axis=1)
                            format_dict = {col: '${:,.2f}' for col in realized_df.columns if col != 'TOTAL'}
                            format_dict['TOTAL'] = '${:,.2f}'
                            styler.format(format_dict, na_rep='N/A')
                            st.dataframe(styler, use_container_width=True, height=600)
                        else:
                            pd.set_option("styler.render.max_elements", max(total_cells * 2, 500000))
                            
                            def highlight_realized_rows(s):
                                is_even_row = realized_df.index.get_loc(s.name) % 2 == 0
                                bg_color = 'background-color: #0e1117' if is_even_row else 'background-color: #262626'
                                return [f'{bg_color}; color: white;'] * len(s)
                            
                            styler = realized_df.style.apply(highlight_realized_rows, axis=1)
                            # Format all columns except TOTAL as currency
                            format_dict = {col: '${:,.2f}' for col in realized_df.columns if col != 'TOTAL'}
                            format_dict['TOTAL'] = '${:,.2f}'  # Also format TOTAL
                            styler.format(format_dict, na_rep='N/A')
                            st.dataframe(styler, use_container_width=True)
                    except Exception as e:
                        st.error(f"Error displaying realized gains table: {str(e)}")
                        st.dataframe(realized_df.head(1000))
                    
                    # Display Unrealized Gains/Losses table
                    st.markdown("**Unrealized Gains/Losses (from Price Variations)**")
                    try:
                        total_cells = unrealized_df.shape[0] * unrealized_df.shape[1]
                        if total_cells > 500000:  # Increased limit from 200000 to 500000
                            st.warning(f"Unrealized gains table is very large ({total_cells:,} cells). Showing all data (may be slow to render).")
                        # Always show full dataframe - removed the limit restriction
                        pd.set_option("styler.render.max_elements", max(total_cells * 2, 1000000))
                        
                        if total_cells > 500000:
                            # For very large tables, show all but warn user
                            def highlight_unrealized_rows(s):
                                is_even_row = unrealized_df.index.get_loc(s.name) % 2 == 0
                                bg_color = 'background-color: #0e1117' if is_even_row else 'background-color: #262626'
                                return [f'{bg_color}; color: white;'] * len(s)
                            
                            styler = unrealized_df.style.apply(highlight_unrealized_rows, axis=1)
                            format_dict = {col: '${:,.2f}' for col in unrealized_df.columns}
                            styler.format(format_dict, na_rep='N/A')
                            st.dataframe(styler, use_container_width=True, height=600)
                        else:
                            pd.set_option("styler.render.max_elements", max(total_cells * 2, 500000))
                            
                            def highlight_unrealized_rows(s):
                                is_even_row = unrealized_df.index.get_loc(s.name) % 2 == 0
                                bg_color = 'background-color: #0e1117' if is_even_row else 'background-color: #262626'
                                return [f'{bg_color}; color: white;'] * len(s)
                            
                            styler = unrealized_df.style.apply(highlight_unrealized_rows, axis=1)
                            # Format all columns as currency
                            format_dict = {col: '${:,.2f}' for col in unrealized_df.columns}
                            styler.format(format_dict, na_rep='N/A')
                            st.dataframe(styler, use_container_width=True)
                    except Exception as e:
                        st.error(f"Error displaying unrealized gains table: {str(e)}")
                        st.dataframe(unrealized_df.head(1000))
                    
                    st.info("üí° **Explanation:** Realized gains/losses occur when shares are sold. Unrealized gains/losses show paper gains/losses from price changes on held positions. The TOTAL column shows the sum for each rebalance period.")
                    
                    # Annual Summary Table for Tax Purposes
                    st.markdown("---")
                    st.markdown(f"**üìä Annual Gains/Losses Summary (for Tax Calculation) - {selected_portfolio_detail}**")
                    
                    # Group by year and sum
                    # Use original dates mapping to get the year
                    annual_realized = {}
                    annual_unrealized = {}
                    
                    # Map to get start and end dates for each period
                    period_start_end_map = {}
                    for i, (current_date, period_label) in enumerate(period_labels):
                        if i > 0:
                            prev_date = sorted_dates_list[i-1]
                            period_start_end_map[period_label] = (prev_date, current_date)
                        else:
                            # First period: use current_date as both start and end
                            period_start_end_map[period_label] = (current_date, current_date)
                    
                    for period_label in realized_df.index:
                        # Get start and end dates for this period
                        start_end = period_start_end_map.get(period_label)
                        if start_end is None:
                            continue
                        start_date, end_date = start_end
                        
                        # Get years
                        start_year = start_date.year if isinstance(start_date, pd.Timestamp) else pd.to_datetime(start_date).year
                        end_year = end_date.year if isinstance(end_date, pd.Timestamp) else pd.to_datetime(end_date).year
                        
                        # Include period in the year range it belongs to
                        # A period belongs to a year range "prev_year-year" if it starts in prev_year OR ends in year
                        # Example: "2025-01-01 - 2025-07-01" starts in 2025 ‚Üí belongs to "2025-2026" (year 2026)
                        #          "2025-07-01 - 2026-01-01" ends in 2026 ‚Üí belongs to "2025-2026" (year 2026)
                        # Rule: periods that start in year X are counted in year X+1 (which shows "X-(X+1)")
                        #       periods that end in year Y are counted in year Y (which shows "(Y-1)-Y")
                        if start_year < end_year:
                            # Period spans years: count in end year (shows as "(end_year-1)-end_year")
                            year = end_year
                        elif start_year == end_year:
                            # Period within same year: count in year+1 (shows as "year-(year+1)")
                            # This ensures periods starting in 2025 are in "2025-2026"
                            year = end_year + 1
                        else:
                            # Should not happen, but use end_year as fallback
                            year = end_year
                        
                        if year not in annual_realized:
                            annual_realized[year] = 0.0
                            annual_unrealized[year] = 0.0
                        
                        # Sum TOTAL column for each year
                        if 'TOTAL' in realized_df.columns:
                            annual_realized[year] += realized_df.loc[period_label, 'TOTAL']
                        else:
                            annual_realized[year] += realized_df.loc[period_label].sum()
                    
                    for period_label in unrealized_df.index:
                        # Get start and end dates for this period
                        start_end = period_start_end_map.get(period_label)
                        if start_end is None:
                            continue
                        start_date, end_date = start_end
                        
                        # Get years
                        start_year = start_date.year if isinstance(start_date, pd.Timestamp) else pd.to_datetime(start_date).year
                        end_year = end_date.year if isinstance(end_date, pd.Timestamp) else pd.to_datetime(end_date).year
                        
                        # Same logic as realized gains
                        if start_year < end_year:
                            # Period spans years: count in end year (shows as "(end_year-1)-end_year")
                            year = end_year
                        elif start_year == end_year:
                            # Period within same year: count in year+1 (shows as "year-(year+1)")
                            # This ensures periods starting in 2025 are in "2025-2026"
                            year = end_year + 1
                        else:
                            # Should not happen, but use end_year as fallback
                            year = end_year
                        
                        if year not in annual_unrealized:
                            annual_unrealized[year] = 0.0
                        
                        # Sum TOTAL column for each year
                        if 'TOTAL' in unrealized_df.columns:
                            annual_unrealized[year] += unrealized_df.loc[period_label, 'TOTAL']
                        else:
                            annual_unrealized[year] += unrealized_df.loc[period_label].sum()
                    
                    # Create annual summary DataFrame
                    all_years = sorted(set(list(annual_realized.keys()) + list(annual_unrealized.keys())))
                    annual_data = []
                    for year in all_years:
                        realized = annual_realized.get(year, 0.0)
                        unrealized = annual_unrealized.get(year, 0.0)
                        total = realized + unrealized
                        
                        # Calculate percentage of gains that are taxable (realized)
                        # Use absolute values to ensure percentage is always between 0 and 100%
                        abs_realized = abs(realized)
                        abs_unrealized = abs(unrealized)
                        abs_total = abs_realized + abs_unrealized
                        
                        if abs_total > 0.01:  # Total is significant (not near zero)
                            # Percentage = realized / (abs(realized) + abs(unrealized)) * 100
                            # This ensures the percentage is always between 0 and 100%
                            taxable_pct = (abs_realized / abs_total) * 100
                        else:  # Both are near zero
                            taxable_pct = 0.0
                        
                        # Create period label: previous year - current year (e.g., "2024-2025")
                        prev_year = year - 1
                        period_label = f"{prev_year}-{year}"
                        
                        annual_data.append({
                            'Period': period_label,
                            'Realized Gains/Losses ($)': realized,
                            'Unrealized Gains/Losses ($)': unrealized,
                            'Total (Realized + Unrealized) ($)': total,
                            '% Taxable (Realized)': taxable_pct
                        })
                    
                    annual_df = pd.DataFrame(annual_data)
                    annual_df = annual_df.set_index('Period')
                    
                    # Display annual table
                    try:
                        def highlight_annual_rows(s):
                            is_even_row = annual_df.index.get_loc(s.name) % 2 == 0
                            bg_color = 'background-color: #0e1117' if is_even_row else 'background-color: #262626'
                            return [f'{bg_color}; color: white;'] * len(s)
                        
                        styler = annual_df.style.apply(highlight_annual_rows, axis=1)
                        format_dict = {}
                        for col in annual_df.columns:
                            if '% Taxable' in col:
                                format_dict[col] = '{:,.1f}%'
                            else:
                                format_dict[col] = '${:,.2f}'
                        styler.format(format_dict, na_rep='N/A')
                        st.dataframe(styler, use_container_width=True)
                        
                        st.warning("‚ö†Ô∏è **IMPORTANT FOR TAXES:** Only **Realized Gains/Losses** are taxable. Unrealized gains/losses are NOT taxable until shares are sold. Use the 'Realized Gains/Losses ($)' column for your tax calculations.")
                        st.info("üí° **Note:** The 'Total (Realized + Unrealized)' column shows the total portfolio value change for the year (excluding dividends and new cash contributions). This is for reference only and does NOT represent taxable income.")
                        st.info("üìä **How it works:** This table sums ALL rebalancing periods within each year. Whether you rebalance monthly, quarterly, or annually, all realized and unrealized gains from all rebalance periods in that year are aggregated here.")
                    except Exception as e:
                        st.error(f"Error displaying annual summary table: {str(e)}")
                        st.dataframe(annual_df)
                else:
                    st.warning("No allocation or portfolio data available for shares and values table.")
            
            # Table 3: Momentum Metrics and Calculated Weights (moved after Historical Shares)
            if selected_portfolio_detail in st.session_state.multi_all_metrics:
                st.markdown("---")
                st.markdown(f"**Momentum Metrics and Calculated Weights for {selected_portfolio_detail}**")

                # Process metrics data directly - EXACT SAME AS PAGE 7
                metrics_records = []
                for date, tickers_data in st.session_state.multi_all_metrics[selected_portfolio_detail].items():
                    # For fusion portfolios, aggregate CASH entries before processing
                    portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
                    portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == selected_portfolio_detail), None)
                    is_fusion_portfolio = portfolio_cfg and portfolio_cfg.get('fusion_portfolio', {}).get('enabled', False)
                    
                    
                    if is_fusion_portfolio:
                        # Aggregate CASH entries for fusion portfolios
                        aggregated_tickers_data = {}
                        total_cash_weight = 0
                        cash_metrics = {}
                        
                        for ticker, data in tickers_data.items():
                            display_ticker = 'CASH' if ticker is None else ticker
                            if display_ticker == 'CASH':
                                # Aggregate CASH weights and metrics
                                total_cash_weight += data.get('Calculated_Weight', 0)
                                for metric_key, metric_value in data.items():
                                    if metric_key != 'Composite':
                                        if metric_key not in cash_metrics:
                                            cash_metrics[metric_key] = 0
                                        cash_metrics[metric_key] += metric_value
                            else:
                                # Keep non-CASH entries as-is
                                aggregated_tickers_data[display_ticker] = data
                        
                        # Add aggregated CASH entry if there's any cash
                        if total_cash_weight > 0:
                            aggregated_tickers_data['CASH'] = cash_metrics.copy()
                            aggregated_tickers_data['CASH']['Calculated_Weight'] = total_cash_weight
                        
                        tickers_data = aggregated_tickers_data
                    
                    # Add all asset lines
                    asset_weights = []
                    for ticker, data in tickers_data.items():
                        # Handle None ticker as CASH
                        display_ticker = 'CASH' if ticker is None else ticker
                        if display_ticker != 'CASH':
                            asset_weights.append(data.get('Calculated_Weight', 0))
                        # Filter out any internal-only keys (e.g., 'Composite') so they don't show in the UI
                        filtered_data = {k: v for k, v in (data or {}).items() if k != 'Composite'}
                        
                        # Check if momentum is used for this portfolio
                        portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
                        portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == selected_portfolio_detail), None)
                        use_momentum = portfolio_cfg.get('use_momentum', True) if portfolio_cfg else True
                        
                        # If momentum is not used, replace Calculated_Weight with target_allocation
                        if not use_momentum:
                            if 'target_allocation' in filtered_data:
                                filtered_data['Calculated_Weight'] = filtered_data['target_allocation']
                            else:
                                # If target_allocation is not available, use the entered allocations from portfolio_cfg
                                ticker_name = display_ticker if display_ticker != 'CASH' else None
                                if ticker_name and portfolio_cfg:
                                    # Find the stock in portfolio_cfg and use its allocation
                                    for stock in portfolio_cfg.get('stocks', []):
                                        if stock.get('ticker', '').strip() == ticker_name:
                                            filtered_data['Calculated_Weight'] = stock.get('allocation', 0)
                                            break
                                elif display_ticker == 'CASH' and portfolio_cfg:
                                    # For CASH, calculate the remaining allocation
                                    total_alloc = sum(stock.get('allocation', 0) for stock in portfolio_cfg.get('stocks', []))
                                    filtered_data['Calculated_Weight'] = max(0, 1.0 - total_alloc)
                        
                        record = {'Date': date, 'Ticker': display_ticker, **filtered_data}
                        metrics_records.append(record)
                        
                        # Add CASH row only if it's significant (more than 5% allocation) AND not a momentum portfolio
                        # This prevents showing CASH for small cash balances and momentum portfolios
                        portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
                        portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == selected_portfolio_detail), None)
                        use_momentum = portfolio_cfg.get('use_momentum', True) if portfolio_cfg else True
                        
                        # Don't add CASH for fusion portfolios - they handle it in aggregation
                        if not use_momentum and not is_fusion_portfolio:
                            total_calculated_weight = sum(asset_weights)
                            cash_allocation = 1.0 - total_calculated_weight
                            
                            if cash_allocation > 0.05:  # Only show CASH if it's more than 5%
                                cash_record = {'Date': date, 'Ticker': 'CASH', 'Calculated_Weight': cash_allocation}
                                metrics_records.append(cash_record)
                    
                    # For fusion portfolios, don't show individual CASH allocations - only show if it's a single portfolio
                    # Check if this is a fusion portfolio by looking at the portfolio config
                    portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
                    portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == selected_portfolio_detail), None)
                    is_fusion_portfolio = portfolio_cfg and portfolio_cfg.get('type') == 'fusion'
                    
                    if not is_fusion_portfolio:
                        # Only add CASH for individual portfolios, not fusion portfolios
                        allocs_for_portfolio = st.session_state.multi_all_allocations.get(selected_portfolio_detail) if 'multi_all_allocations' in st.session_state else None
                        if allocs_for_portfolio and date in allocs_for_portfolio:
                            cash_alloc = allocs_for_portfolio[date].get('CASH', 0)
                            if cash_alloc > 0:
                                # Check if CASH is already in metrics_records for this date
                                cash_exists = any(record['Date'] == date and record['Ticker'] == 'CASH' for record in metrics_records)
                                if not cash_exists:
                                    # Add CASH line to metrics
                                    use_momentum = portfolio_cfg.get('use_momentum', True) if portfolio_cfg else True
                                    
                                    if not use_momentum:
                                        # When momentum is not used, calculate CASH allocation from entered allocations
                                        total_alloc = sum(stock.get('allocation', 0) for stock in portfolio_cfg.get('stocks', []))
                                        cash_weight = max(0, 1.0 - total_alloc)
                                        cash_record = {'Date': date, 'Ticker': 'CASH', 'Calculated_Weight': cash_weight}
                                        metrics_records.append(cash_record)
                                    # For momentum portfolios, do NOT add CASH - let momentum strategy determine allocations
                    
                    # Add CASH line if fully allocated to cash (100%) or all asset weights are 0% (fallback logic)
                    cash_line_needed = False
                    if 'CASH' in tickers_data or None in tickers_data:
                        cash_data = tickers_data.get('CASH', tickers_data.get(None, {}))
                        cash_weight = cash_data.get('Calculated_Weight', 0)
                        if abs(cash_weight - 1.0) < 1e-6:  # 100% in decimal
                            cash_line_needed = True
                    if all(w == 0 for w in asset_weights) and asset_weights:
                        cash_line_needed = True
                    if cash_line_needed and 'CASH' not in [r['Ticker'] for r in metrics_records if r['Date'] == date]:
                        # If no explicit CASH data, create a default line
                        cash_record = {'Date': date, 'Ticker': 'CASH', 'Calculated_Weight': 1.0}
                        metrics_records.append(cash_record)
                
                if metrics_records:
                    metrics_df = pd.DataFrame(metrics_records)
                    
                    # Filter out CASH lines where Calculated_Weight is 0 for the last date
                    if 'Calculated_Weight' in metrics_df.columns:
                        # Get the last date
                        last_date = metrics_df['Date'].max()
                        # Remove CASH records where Calculated_Weight is 0 for the last date
                        mask = ~((metrics_df['Ticker'] == 'CASH') & (metrics_df['Date'] == last_date) & (metrics_df['Calculated_Weight'] == 0))
                        metrics_df = metrics_df[mask].reset_index(drop=True)
                    
                    if not metrics_df.empty:
                        # Ensure unique index by adding a counter if needed
                        if metrics_df.duplicated(subset=['Date', 'Ticker']).any():
                            # Add a counter to make indices unique
                            metrics_df['Counter'] = metrics_df.groupby(['Date', 'Ticker']).cumcount()
                            metrics_df['Ticker_Unique'] = metrics_df['Ticker'] + metrics_df['Counter'].astype(str)
                            metrics_df.set_index(['Date', 'Ticker_Unique'], inplace=True)
                        else:
                            metrics_df.set_index(['Date', 'Ticker'], inplace=True)
                    
                    metrics_df_display = metrics_df.copy()

                    # Ensure Momentum column exists and normalize to percent when present
                    if 'Momentum' in metrics_df_display.columns:
                        metrics_df_display['Momentum'] = metrics_df_display['Momentum'].fillna(0) * 100
                    else:
                        metrics_df_display['Momentum'] = np.nan

                    def color_momentum(val):
                        if isinstance(val, (int, float)):
                            color = 'green' if val > 0 else 'red'
                            return f'color: {color}'
                        # Force white color for None, NA, and other non-numeric values
                        return 'color: #FFFFFF; font-weight: bold;'
                    
                    def color_all_columns(val):
                        # Force white color for None, NA, and other non-numeric values in ALL columns
                        if pd.isna(val) or val == 'None' or val == 'NA' or val == '':
                            return 'color: #FFFFFF; font-weight: bold;'
                        if isinstance(val, (int, float)):
                            return ''  # Let default styling handle numeric values
                        return 'color: #FFFFFF; font-weight: bold;'  # Force white for any other text
                    
                    def highlight_metrics_rows(s):
                        date_str = s.name[0]
                        ticker_str = s.name[1]
                        # If this is the CASH row, use dark green background
                        if 'CASH' in ticker_str:
                            return ['background-color: #006400; color: white; font-weight: bold;' for _ in s]
                        # Otherwise, alternate row colors by date with WHITE TEXT
                        unique_dates = list(metrics_df_display.index.get_level_values(0).unique())
                        is_even = unique_dates.index(date_str) % 2 == 0
                        bg_color = 'background-color: #0e1117' if is_even else 'background-color: #262626'
                        return [f'{bg_color}; color: white;'] * len(s)

                    # Format Calculated_Weight as a percentage if present
                    if 'Calculated_Weight' in metrics_df_display.columns:
                        metrics_df_display['Calculated_Weight'] = metrics_df_display['Calculated_Weight'].fillna(0) * 100
                    # Convert Volatility from decimal (e.g., 0.20) to percent (20.0)
                    if 'Volatility' in metrics_df_display.columns:
                        metrics_df_display['Volatility'] = metrics_df_display['Volatility'].fillna(np.nan) * 100

                    # Add error handling for empty or invalid dataframes
                    if metrics_df_display.empty:
                        st.warning("No metrics data available for this portfolio.")
                    else:
                        try:
                            # Check if dataframe is too large for styling
                            total_cells = metrics_df_display.shape[0] * metrics_df_display.shape[1]
                            if total_cells > 200000:  # Conservative limit
                                st.warning(f"Metrics table is very large ({total_cells:,} cells). Showing simplified view.")
                                # Show only recent data (last 100 rows)
                                recent_data = metrics_df_display.tail(100)
                                st.dataframe(recent_data, use_container_width=True)
                                st.caption("Showing last 100 rows. Use filters to narrow down the data.")
                            else:
                                # Increase pandas styler limit for smaller datasets
                                pd.set_option("styler.render.max_elements", max(total_cells * 2, 500000))
                                
                                # Corrected styling logic for alternating row colors and momentum color
                                styler_metrics = metrics_df_display.style.apply(highlight_metrics_rows, axis=1)
                                if 'Momentum' in metrics_df_display.columns:
                                    styler_metrics = styler_metrics.map(color_momentum, subset=['Momentum'])
                                # Force white color for None/NA values in ALL columns
                                styler_metrics = styler_metrics.map(color_all_columns)

                                fmt_dict = {}
                                if 'Momentum' in metrics_df_display.columns:
                                    fmt_dict['Momentum'] = '{:,.0f}%'
                                if 'Beta' in metrics_df_display.columns:
                                    fmt_dict['Beta'] = '{:,.2f}'
                                if 'Volatility' in metrics_df_display.columns:
                                    fmt_dict['Volatility'] = '{:,.2f}%'
                                if 'Calculated_Weight' in metrics_df_display.columns:
                                    fmt_dict['Calculated_Weight'] = '{:,.0f}%'

                                if fmt_dict:
                                    styler_metrics = styler_metrics.format(fmt_dict)
                                
                                # NUCLEAR OPTION: Inject custom CSS to override Streamlit's stubborn styling
                                st.markdown("""
                                <style>
                                /* NUCLEAR CSS OVERRIDE - BEAT STREAMLIT INTO SUBMISSION */
                                .stDataFrame [data-testid="stDataFrame"] div[data-testid="stDataFrame"] table td,
                                .stDataFrame [data-testid="stDataFrame"] div[data-testid="stDataFrame"] table th,
                                .stDataFrame table td,
                                .stDataFrame table th {
                                    color: #FFFFFF !important;
                                    font-weight: bold !important;
                                    text-shadow: 1px 1px 2px black !important;
                                }
                                
                                /* Force ALL text in dataframes to be white */
                                .stDataFrame * {
                                    color: #FFFFFF !important;
                                }
                                </style>
                                """, unsafe_allow_html=True)

                                st.dataframe(styler_metrics, use_container_width=True)
                        except Exception as e:
                            st.error(f"Error displaying metrics table: {str(e)}")
                            st.write("Raw data (first 1000 rows):")
                            st.dataframe(metrics_df_display.head(1000))
                    
                    # Check if this portfolio uses momentum strategy and show note
                    portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
                    portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == selected_portfolio_detail), None)
                    is_momentum_portfolio = portfolio_cfg and portfolio_cfg.get('use_momentum', False)
                    
                    if not is_momentum_portfolio:
                        st.info("‚ÑπÔ∏è **Note:** This portfolio does not use momentum strategy. The momentum metrics table above is not used for allocation decisions and can be ignored.")
                    

            # PIE CHARTS SECTION - Show for ALL portfolios (moved outside allocation data condition)
            st.markdown("---")
            st.markdown(f"**üîÑ Rebalance as of Today ({pd.Timestamp.now().strftime('%Y-%m-%d')})**")
            
            # TARGET ALLOCATION IF REBALANCE TODAY - FROM SCRATCH USING ONLY MOMENTUM METRICS
            today_weights = {}
            
            # Get portfolio configuration
            portfolio_cfg = next((cfg for cfg in st.session_state.multi_backtest_portfolio_configs 
                               if cfg.get('name') == selected_portfolio_detail), None)
            use_momentum = portfolio_cfg.get('use_momentum', True) if portfolio_cfg else True
            
            if use_momentum:
                # MOMENTUM: Get data ONLY from Momentum Metrics table
                if selected_portfolio_detail in st.session_state.multi_all_metrics:
                    metrics_data = st.session_state.multi_all_metrics[selected_portfolio_detail]
                    
                    if metrics_data:
                        # Get the most recent date from Momentum Metrics
                        most_recent_date = max(metrics_data.keys())
                        most_recent_metrics = metrics_data[most_recent_date]
                        
                        # Extract ONLY Calculated_Weight from Momentum Metrics
                        for ticker, ticker_metrics in most_recent_metrics.items():
                            if isinstance(ticker_metrics, dict) and 'Calculated_Weight' in ticker_metrics:
                                weight = ticker_metrics.get('Calculated_Weight', 0)
                                if weight > 0:  # Only include positive weights
                                    today_weights[ticker] = weight
                        
                        # Add CASH if total < 1.0
                        total_weight = sum(today_weights.values())
                        if total_weight < 1.0:
                            today_weights['CASH'] = 1.0 - total_weight
            else:
                # NON-MOMENTUM: Use portfolio configuration
                if portfolio_cfg and portfolio_cfg.get('stocks'):
                    total_allocation = sum(stock.get('allocation', 0) for stock in portfolio_cfg['stocks'] if stock.get('ticker'))
                    
                    if total_allocation > 0:
                        for stock in portfolio_cfg['stocks']:
                            ticker = stock.get('ticker', '').strip()
                            allocation = stock.get('allocation', 0)
                            if ticker and allocation > 0:
                                today_weights[ticker] = allocation / total_allocation
            
            # Create labels and values for the plot
            labels_today = [k for k, v in sorted(today_weights.items(), key=lambda x: (-x[1], x[0])) if v > 0]
            vals_today = [float(today_weights[k]) * 100 for k in labels_today]
            
            # Handle case where momentum goes to cash (all assets have negative momentum)
            # If no labels or all values are very small, show 100% CASH
            if not labels_today or sum(vals_today) < 0.1:
                labels_today = ['CASH']
                vals_today = [100.0]
            
            # CALIBRATED TIMER - USING REAL DATA FROM PIE CHART
            st.markdown("---")
            st.markdown("**‚è∞ REBALANCING TIMER**")
            from datetime import datetime, timedelta
            
            # Get the real last rebalance date and portfolio config
            portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
            portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == selected_portfolio_detail), None)
            
            # Get the actual last rebalance date from allocation data (same as pie chart)
            if portfolio_cfg and selected_portfolio_detail in st.session_state.multi_all_allocations:
                allocation_data = st.session_state.multi_all_allocations[selected_portfolio_detail]
                if allocation_data:
                    alloc_dates = sorted(list(allocation_data.keys()))
                    if alloc_dates:
                        # Find the actual last rebalance date (exclude current/today date)
                        # Look for the last date that follows the rebalancing pattern
                        rebalancing_frequency = portfolio_cfg.get('rebalancing_frequency', 'none')
                        
                        # Map frequency to identify rebalancing pattern (same logic for all portfolios)
                        if rebalancing_frequency and rebalancing_frequency.lower() in ['annually', 'yearly', 'year']:
                            # For yearly, look for January 1st dates
                            rebalance_dates = [d for d in alloc_dates if d.month == 1 and d.day == 1]
                        elif rebalancing_frequency and rebalancing_frequency.lower() in ['monthly', 'month']:
                            # For monthly, look for 1st of month dates
                            rebalance_dates = [d for d in alloc_dates if d.day == 1]
                        elif rebalancing_frequency and rebalancing_frequency.lower() in ['quarterly', '3months']:
                            # For quarterly, look for 1st of quarter dates (Jan, Apr, Jul, Oct)
                            rebalance_dates = [d for d in alloc_dates if d.month in [1, 4, 7, 10] and d.day == 1]
                        elif rebalancing_frequency and rebalancing_frequency.lower() in ['semi-annually', 'semiannually', '6months']:
                            # For semi-annually, look for 1st of Jan and Jul
                            rebalance_dates = [d for d in alloc_dates if d.month in [1, 7] and d.day == 1]
                        elif rebalancing_frequency and rebalancing_frequency.lower() in ['weekly', 'week']:
                            # For weekly, use all dates (weekly rebalancing can be any day)
                            rebalance_dates = alloc_dates[:-1] if len(alloc_dates) > 1 else alloc_dates
                        elif rebalancing_frequency and rebalancing_frequency.lower() in ['bi-weekly', 'biweekly', '2weeks']:
                            # For bi-weekly, use all dates (bi-weekly rebalancing can be any day)
                            rebalance_dates = alloc_dates[:-1] if len(alloc_dates) > 1 else alloc_dates
                        elif rebalancing_frequency and rebalancing_frequency.lower() in ['market_day', 'calendar_day']:
                            # For daily rebalancing, use all dates
                            rebalance_dates = alloc_dates[:-1] if len(alloc_dates) > 1 else alloc_dates
                        else:
                            # No rebalancing or unknown frequency - use all dates except the last one
                            rebalance_dates = alloc_dates[:-1] if len(alloc_dates) > 1 else alloc_dates
                        
                        if rebalance_dates:
                            actual_last_rebal_date = rebalance_dates[-1]
                        else:
                            # Fallback to second-to-last date if no pattern found
                            actual_last_rebal_date = alloc_dates[-2] if len(alloc_dates) > 1 else alloc_dates[-1]
                        
                        # Get rebalancing frequency (same for all portfolios)
                        rebalancing_frequency = portfolio_cfg.get('rebalancing_frequency', 'none')
                        
                        # Map frequency names to what the function expects
                        frequency_mapping = {
                            'monthly': 'month',
                            'weekly': 'week',
                            'bi-weekly': '2weeks',
                            'biweekly': '2weeks',
                            'quarterly': '3months',
                            'semi-annually': '6months',
                            'semiannually': '6months',
                            'annually': 'year',
                            'yearly': 'year',
                            'market_day': 'market_day',
                            'calendar_day': 'calendar_day',
                            'never': 'none',
                            'none': 'none'
                        }
                        rebalancing_frequency = frequency_mapping.get(rebalancing_frequency.lower(), rebalancing_frequency)
                        
                        if rebalancing_frequency != 'none':
                            # Calculate next rebalance date using the actual last rebalance date
                            next_date, time_until, next_rebalance_datetime = calculate_next_rebalance_date(
                                rebalancing_frequency, actual_last_rebal_date
                            )
                    
                            if next_date and time_until:
                                # Calculate progress percentage using the actual last rebalance date
                                total_period = (next_rebalance_datetime - actual_last_rebal_date).total_seconds()
                                elapsed_period = (datetime.now() - actual_last_rebal_date).total_seconds()
                                progress_percentage = min(max((elapsed_period / total_period) * 100, 0), 100)
                                
                                # Format time until
                                total_seconds = int(time_until.total_seconds())
                                days_until = total_seconds // 86400
                                hours_until = (total_seconds % 86400) // 3600
                                minutes_until = (total_seconds % 3600) // 60
                                
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric(
                                        label="Time Until Next Rebalance",
                                        value=f"{days_until} days, {hours_until} hours, {minutes_until} minutes",
                                        delta=None
                                    )
                                with col2:
                                    st.metric(
                                        label="Target Rebalance Date",
                                        value=next_date.strftime("%B %d, %Y"),
                                        delta=None
                                    )
                                with col3:
                                    st.metric(
                                        label="Rebalancing Frequency",
                                        value=rebalancing_frequency.replace('_', ' ').title(),
                                        delta=None
                                    )
                                
                                # Add progress bar
                                st.markdown(f"**Progress to next rebalance: {progress_percentage:.1f}%**")
                                st.progress(progress_percentage / 100)
                            else:
                                st.info("No rebalancing scheduled")
                        else:
                            st.info("Rebalancing is disabled for this portfolio")
                    else:
                        st.info("No allocation data available")
            else:
                st.info("No portfolio configuration found")
            
            st.markdown("---")
            
            # Create the main "Target Allocation if Rebalanced Today" pie chart (CENTER)
            st.markdown(f"**Target Allocation if Rebalanced Today**")
            
            # Check if targeted rebalancing is enabled for this portfolio and show warning
            if portfolio_cfg and portfolio_cfg.get('use_targeted_rebalancing', False):
                targeted_settings = portfolio_cfg.get('targeted_rebalancing_settings', {})
                enabled_tickers = [ticker for ticker, settings in targeted_settings.items() if settings.get('enabled', False)]
                
                if enabled_tickers:
                    st.warning(f"""
                    ‚ö†Ô∏è **Important Notice for Targeted Rebalancing Strategy**
                    
                    This portfolio uses **Targeted Rebalancing** for: {', '.join(enabled_tickers)}
                    
                    **Unlike momentum strategies**, the "Target Allocation if Rebalanced Today" depends on the **backtest start date**. 
                    The allocation shown here reflects what would happen if rebalanced today based on the current portfolio state, 
                    but this is **not a standalone strategy** that can be copied independently.
                    
                    **Key Points:**
                    - The allocation depends on when the backtest started
                    - It's based on the current portfolio drift from initial allocations
                    - This is **not** a momentum-based allocation like other strategies
                    """)
            
            # Always use real-time calculation to ensure momentum metrics are used correctly
            # DON'T use cache here - we need fresh data from momentum metrics
            if labels_today and vals_today:
                fig_today = go.Figure(data=[go.Pie(
                    labels=labels_today,
                    values=vals_today,
                    hole=0.35
                )])
                fig_today.update_traces(textinfo='percent+label')
                fig_today.update_layout(template='plotly_dark', margin=dict(t=10), height=600)
                st.plotly_chart(fig_today, use_container_width=True, key=f"multi_today_{selected_portfolio_detail}")
                # Store in session state for PDF export
                st.session_state[f'pie_chart_{selected_portfolio_detail}'] = fig_today

            # Add the "Target Allocation if Rebalanced Today" table right under the main pie chart
            if selected_portfolio_detail in st.session_state.multi_all_allocations:
                allocation_data = st.session_state.multi_all_allocations[selected_portfolio_detail]
                if allocation_data:
                    # Get portfolio value for calculations
                    portfolio_value = get_portfolio_value(selected_portfolio_detail)
                    
                    # Get raw data for price calculations
                    raw_data = st.session_state.get('multi_backtest_raw_data', {})
                    
                    # Helper function to get price on or before a date
                    def _price_on_or_before(df, target_date):
                        try:
                            # Find the closest date on or before target_date
                            available_dates = df.index[df.index <= target_date]
                            if len(available_dates) > 0:
                                closest_date = available_dates[-1]
                                return float(df.loc[closest_date, 'Close'])
                            return None
                        except Exception:
                            return None
                    
                    # Create allocation table for "Target Allocation if Rebalanced Today"
                    def build_table_from_alloc_today(alloc_dict, price_date, label):
                        if not alloc_dict:
                            return
                        
                        rows = []
                        for tk in sorted(alloc_dict.keys()):
                            # Handle nested dictionary structure
                            alloc_value = alloc_dict.get(tk, 0)
                            if isinstance(alloc_value, dict):
                                # If it's a dictionary, try to get a numeric value from it
                                alloc_pct = float(alloc_value.get('allocation', alloc_value.get('weight', 0)))
                            else:
                                alloc_pct = float(alloc_value) if alloc_value is not None else 0.0
                            if tk == 'CASH':
                                price = None
                                shares = 0
                                total_val = portfolio_value * alloc_pct
                            else:
                                df = raw_data.get(tk)
                                price = None
                                if isinstance(df, pd.DataFrame) and 'Close' in df.columns and not df['Close'].dropna().empty:
                                    if price_date is None:
                                        # use latest price
                                        try:
                                            price = float(df['Close'].iloc[-1])
                                        except Exception:
                                            price = None
                                    else:
                                        price = _price_on_or_before(df, price_date)
                                try:
                                    if price and price > 0:
                                        allocation_value = portfolio_value * alloc_pct
                                        shares = round(allocation_value / price, 1)
                                        total_val = shares * price
                                    else:
                                        shares = 0.0
                                        total_val = portfolio_value * alloc_pct
                                except Exception:
                                    shares = 0.0
                                    total_val = portfolio_value * alloc_pct

                            pct_of_port = (total_val / portfolio_value * 100) if portfolio_value > 0 else 0
                            rows.append({
                                'Ticker': tk,
                                'Allocation %': alloc_pct * 100,
                                'Price ($)': price if price is not None else float('nan'),
                                'Shares': float(shares) if shares is not None else 0.0,
                                'Total Value ($)': total_val,
                                '% of Portfolio': pct_of_port,
                            })

                        df_table = pd.DataFrame(rows).set_index('Ticker')
                        # Decide whether to show CASH row: hide if Total Value is zero or Shares zero/NaN
                        df_display = df_table.copy()
                        show_cash = False
                        if 'CASH' in df_display.index:
                            cash_val = None
                            if 'Total Value ($)' in df_display.columns:
                                cash_val = df_display.at['CASH', 'Total Value ($)']
                            elif 'Shares' in df_display.columns:
                                cash_val = df_display.at['CASH', 'Shares']
                            try:
                                show_cash = bool(cash_val and not pd.isna(cash_val) and cash_val != 0)
                            except Exception:
                                show_cash = False
                            if not show_cash:
                                df_display = df_display.drop('CASH')

                        # formatting for display
                        fmt = {
                            'Allocation %': '{:,.1f}%',
                            'Price ($)': '${:,.2f}',
                            'Shares': '{:,.1f}',
                            'Total Value ($)': '${:,.2f}',
                            '% of Portfolio': '{:,.2f}%'
                        }
                        try:
                            st.markdown(f"**{label}**")
                            
                            # Add total row
                            total_alloc_pct = df_display['Allocation %'].sum()
                            total_value = df_display['Total Value ($)'].sum()
                            total_port_pct = df_display['% of Portfolio'].sum()

                            total_row = pd.DataFrame({
                                'Allocation %': [total_alloc_pct],
                                'Price ($)': [float('nan')],
                                'Shares': [float('nan')],
                                'Total Value ($)': [total_value],
                                '% of Portfolio': [total_port_pct]
                            }, index=['TOTAL'])

                            df_display = pd.concat([df_display, total_row])
                            
                            sty = df_display.style.format(fmt)
                            if 'CASH' in df_table.index and show_cash:
                                def _highlight_cash_row(s):
                                    if s.name == 'CASH':
                                        return ['background-color: #006400; color: white; font-weight: bold;' for _ in s]
                                    return [''] * len(s)
                                sty = sty.apply(_highlight_cash_row, axis=1)

                            # Highlight TOTAL row
                            def _highlight_total_row(s):
                                if s.name == 'TOTAL':
                                    return ['background-color: #1f4e79; color: white; font-weight: bold;' for _ in s]
                                return [''] * len(s)
                            sty = sty.apply(_highlight_total_row, axis=1)
                            
                            st.dataframe(sty, use_container_width=True)
                        except Exception:
                            st.dataframe(df_display, use_container_width=True)
                    
                    # Display the "Target Allocation if Rebalanced Today" table
                    build_table_from_alloc_today(today_weights, None, f"Target Allocation if Rebalanced Today")
                    
                    # Add Stock Purchase Calculator for Fusion Portfolios only
                    portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
                    portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == selected_portfolio_detail), None)
                    is_fusion = portfolio_cfg and portfolio_cfg.get('fusion_portfolio', {}).get('enabled', False)
                    
                    if is_fusion:
                        st.markdown("---")
                        st.markdown("**üí∞ Stock Purchase Calculator**")
                        st.caption("Enter a dollar amount to see exactly which stocks to buy based on the target allocation above")
                        
                        # Input dollar amount
                        col1, col2 = st.columns([1, 2])
                        with col1:
                            investment_amount = st.number_input(
                                "Investment Amount ($)",
                                min_value=0,
                                value=20000,
                                step=1000,
                                key=f"fusion_investment_{selected_portfolio_detail}"
                            )
                        
                        with col2:
                            st.caption("üí° This shows how to allocate your investment across all stocks in the fusion portfolio")
                        
                        # Calculate and display stock purchases
                        if today_weights and investment_amount > 0:
                            st.markdown("**üìä Stock Purchase Breakdown:**")
                            
                            # Get raw data for price calculations (same as target allocation table)
                            raw_data = st.session_state.get('multi_backtest_raw_data', {})
                            
                            # Create a dataframe with same columns as target allocation table
                            purchase_data = []
                            total_invested = 0
                            
                            for ticker, allocation_percent in today_weights.items():
                                if allocation_percent > 0:
                                    # Calculate dollar amount
                                    dollar_amount = investment_amount * allocation_percent
                                    total_invested += dollar_amount
                                    
                                    # Get current price (same logic as target allocation table)
                                    if ticker == 'CASH':
                                        price = None
                                        shares = 0.0
                                        total_val = dollar_amount
                                    else:
                                        df = raw_data.get(ticker)
                                        price = None
                                        if isinstance(df, pd.DataFrame) and 'Close' in df.columns and not df['Close'].dropna().empty:
                                            try:
                                                price = float(df['Close'].iloc[-1])  # Latest price
                                            except Exception:
                                                price = None
                                        
                                        if price and price > 0:
                                            shares = round(dollar_amount / price, 1)
                                            total_val = shares * price
                                        else:
                                            shares = 0.0
                                            total_val = dollar_amount
                                    
                                    # Calculate % of portfolio
                                    pct_of_port = (total_val / investment_amount * 100) if investment_amount > 0 else 0
                                    
                                    purchase_data.append({
                                        'Ticker': ticker,
                                        'Allocation %': f"{allocation_percent * 100:.1f}%",
                                        'Price ($)': f"${price:.2f}" if price is not None else "N/A",
                                        'Shares': float(shares) if shares is not None else 0.0,
                                        'Total Value ($)': f"${total_val:,.2f}",
                                        '% of Portfolio': f"{pct_of_port:.2f}%"
                                    })
                            
                            if purchase_data:
                                # Display as a nice table (same format as target allocation)
                                import pandas as pd
                                df = pd.DataFrame(purchase_data)
                                df_display = df.set_index('Ticker')
                                
                                # Add total row
                                total_row = {
                                    'Allocation %': '100.0%',
                                    'Price ($)': '',
                                    'Shares': 0.0,
                                    'Total Value ($)': f"${total_invested:,.2f}",
                                    '% of Portfolio': '100.00%'
                                }
                                df_display.loc['TOTAL'] = total_row
                                
                                st.dataframe(df_display, use_container_width=True)
                                
                                # Summary
                                stock_count = len([row for row in purchase_data if row['Ticker'] != 'CASH'])
                                st.success(f"‚úÖ **Total Investment**: ${total_invested:,.2f} across {stock_count} stocks")
                            else:
                                st.warning("No stock allocations found in target allocation.")
                        else:
                            st.info("Enter an investment amount to see stock purchase breakdown")

            # Other rebalancing plots (smaller, placed after the main one)
            st.markdown("---")
            st.markdown("**üìä Historical Rebalancing Comparison**")
            
            # Get allocation data for the two smaller pie charts
            if selected_portfolio_detail in st.session_state.multi_all_allocations:
                allocation_data = st.session_state.multi_all_allocations[selected_portfolio_detail]
                if allocation_data:
                    # Get dates
                    alloc_dates = sorted(list(allocation_data.keys()))
                    final_date = alloc_dates[-1] if alloc_dates else None
                    
                    # Get last rebalance date
                    last_rebal_date = None
                    if alloc_dates:
                        # Try to find the actual last rebalancing date
                        portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
                        portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == selected_portfolio_detail), None)
                        
                        if portfolio_cfg:
                            rebalancing_frequency = portfolio_cfg.get('rebalancing_frequency', 'Monthly')
                            # Map frequency names to what the function expects (capitalized as in page 1)
                            frequency_mapping = {
                                'monthly': 'Monthly',
                                'weekly': 'Weekly',
                                'bi-weekly': 'Biweekly',
                                'biweekly': 'Biweekly',
                                'quarterly': 'Quarterly',
                                'semi-annually': 'Semiannually',
                                'semiannually': 'Semiannually',
                                'annually': 'Annually',
                                'yearly': 'Annually',
                                'never': 'Never',
                                'none': 'Never'
                            }
                            rebalancing_frequency = frequency_mapping.get(rebalancing_frequency.lower(), rebalancing_frequency)
                            
                            if rebalancing_frequency != 'Never':
                                # Get sim_index from the portfolio results
                                sim_index = None
                                if 'multi_all_results' in st.session_state and st.session_state.multi_all_results:
                                    portfolio_results = st.session_state.multi_all_results.get(selected_portfolio_detail)
                                    if portfolio_results:
                                        if isinstance(portfolio_results, dict) and 'no_additions' in portfolio_results:
                                            sim_index = portfolio_results['no_additions'].index
                                        elif isinstance(portfolio_results, pd.Series):
                                            sim_index = portfolio_results.index
                                
                                if sim_index is not None:
                                    # Use cached rebalancing dates for better performance
                                    portfolio_rebalancing_dates = get_cached_rebalancing_dates(selected_portfolio_detail, rebalancing_frequency, sim_index)
                                    if portfolio_rebalancing_dates:
                                        # Find the last rebalancing date before or on the final date
                                        for date in reversed(sorted(portfolio_rebalancing_dates)):
                                            if date <= final_date:
                                                last_rebal_date = date
                                                break
                        
                        # Fallback to second-to-last date if no rebalancing date found
                        if not last_rebal_date and len(alloc_dates) > 1:
                            last_rebal_date = alloc_dates[-2]
                        elif not last_rebal_date:
                            last_rebal_date = alloc_dates[-1]
                    
                    # Get allocations for the two pie charts
                    if final_date and last_rebal_date:
                        final_alloc = allocation_data.get(final_date, {})
                        rebal_alloc = allocation_data.get(last_rebal_date, {})
                        
                        # For fusion portfolios, use current_weights_map for "Current Allocation"
                        if is_fusion:
                            # Get current_weights_map from the results
                            if selected_portfolio_detail in st.session_state.multi_all_results:
                                current_weights_map = st.session_state.multi_all_results[selected_portfolio_detail].get('current_weights_map', {})
                                if current_weights_map:
                                    # Use current_weights_map for "Current Allocation" (shows drifted allocation)
                                    valid_final = {k: v for k, v in current_weights_map.items() if isinstance(v, (int, float)) and not pd.isna(v)}
                                    labels_final = [k for k, v in sorted(valid_final.items(), key=lambda x: (-x[1], x[0])) if v > 0]
                                    vals_final = [float(valid_final[k]) * 100 for k in labels_final]
                                else:
                                    labels_final = []
                                    vals_final = []
                            else:
                                labels_final = []
                                vals_final = []
                        else:
                            # For regular portfolios, use final_alloc as before
                            if final_alloc and isinstance(final_alloc, dict):
                                # Filter out non-numeric values and ensure they're valid
                                valid_final = {k: v for k, v in final_alloc.items() if isinstance(v, (int, float)) and not pd.isna(v)}
                                
                                # NUCLEAR OPTION: Portfolio names are never stored, only individual stocks
                                
                                labels_final = [k for k, v in sorted(valid_final.items(), key=lambda x: (-x[1], x[0])) if v > 0]
                                vals_final = [float(valid_final[k]) * 100 for k in labels_final]
                            else:
                                labels_final = []
                                vals_final = []
                        
                        # Use the same prepare_bar_data function as page 2 for consistency
                        def prepare_bar_data(d):
                            labels = []
                            values = []
                            for k, v in sorted(d.items(), key=lambda x: (-x[1], x[0])):
                                try:
                                    val = float(v) * 100
                                    if val > 0:  # Only include tickers with allocation > 0%
                                        labels.append(k)
                                        values.append(val)
                                except Exception:
                                    pass  # Skip invalid values
                            return labels, values

                        if rebal_alloc and isinstance(rebal_alloc, dict):
                            labels_rebal, vals_rebal = prepare_bar_data(rebal_alloc)
                        else:
                            labels_rebal = []
                            vals_rebal = []
                        
                        # Use standard pie chart display for all portfolios - EXACT COPY FROM PAGE 2
                        col_plot1, col_plot2 = st.columns(2)
                        
                        with col_plot1:
                            st.markdown(f"**Target Allocation at Last Rebalance ({last_rebal_date.date()})**")
                            fig_rebal_small = go.Figure(data=[go.Pie(
                                labels=labels_rebal,
                                values=vals_rebal,
                                hole=0.35
                            )])
                            fig_rebal_small.update_traces(textinfo='percent+label')
                            fig_rebal_small.update_layout(template='plotly_dark', margin=dict(t=10))
                            st.plotly_chart(fig_rebal_small, key=f"alloc_rebal_small_{selected_portfolio_detail}")
                        
                        with col_plot2:
                            st.markdown(f"**Portfolio Evolution (Current Allocation)**")
                            fig_today_small = go.Figure(data=[go.Pie(
                                labels=labels_final,
                                values=vals_final,
                                hole=0.35
                            )])
                            fig_today_small.update_traces(textinfo='percent+label')
                            fig_today_small.update_layout(template='plotly_dark', margin=dict(t=10))
                            st.plotly_chart(fig_today_small, key=f"alloc_today_small_{selected_portfolio_detail}")
                    else:
                        st.warning("No allocation data available for pie charts.")
                else:
                    st.warning("No allocation data available for pie charts.")
            else:
                st.warning("No allocation data available for pie charts.")

            # Add the detailed allocation tables (missing from page 7)
            if selected_portfolio_detail in st.session_state.multi_all_allocations:
                allocation_data = st.session_state.multi_all_allocations[selected_portfolio_detail]
                if allocation_data:
                    # Get dates
                    alloc_dates = sorted(list(allocation_data.keys()))
                    final_date = alloc_dates[-1] if alloc_dates else None
                    
                    # Get last rebalance date
                    last_rebal_date = None
                    if alloc_dates:
                        # Try to find the actual last rebalancing date
                        portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
                        portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == selected_portfolio_detail), None)
                        
                        if portfolio_cfg:
                            rebalancing_frequency = portfolio_cfg.get('rebalancing_frequency', 'Monthly')
                            # Map frequency names to what the function expects (capitalized as in page 1)
                            frequency_mapping = {
                                'monthly': 'Monthly',
                                'weekly': 'Weekly',
                                'bi-weekly': 'Biweekly',
                                'biweekly': 'Biweekly',
                                'quarterly': 'Quarterly',
                                'semi-annually': 'Semiannually',
                                'semiannually': 'Semiannually',
                                'annually': 'Annually',
                                'yearly': 'Annually',
                                'never': 'Never',
                                'none': 'Never'
                            }
                            rebalancing_frequency = frequency_mapping.get(rebalancing_frequency.lower(), rebalancing_frequency)
                            
                            if rebalancing_frequency != 'Never':
                                # Get sim_index from the portfolio results
                                sim_index = None
                                if 'multi_all_results' in st.session_state and st.session_state.multi_all_results:
                                    portfolio_results = st.session_state.multi_all_results.get(selected_portfolio_detail)
                                    if portfolio_results:
                                        if isinstance(portfolio_results, dict) and 'no_additions' in portfolio_results:
                                            sim_index = portfolio_results['no_additions'].index
                                        elif isinstance(portfolio_results, pd.Series):
                                            sim_index = portfolio_results.index
                                
                                if sim_index is not None:
                                    # Use cached rebalancing dates for better performance
                                    portfolio_rebalancing_dates = get_cached_rebalancing_dates(selected_portfolio_detail, rebalancing_frequency, sim_index)
                                    if portfolio_rebalancing_dates:
                                        # Find the last rebalancing date before or on the final date
                                        for date in reversed(sorted(portfolio_rebalancing_dates)):
                                            if date <= final_date:
                                                last_rebal_date = date
                                                break
                        
                        # Fallback to second-to-last date if no rebalancing date found
                        if not last_rebal_date and len(alloc_dates) > 1:
                            last_rebal_date = alloc_dates[-2]
                        elif not last_rebal_date:
                            last_rebal_date = alloc_dates[-1]
                    
                    # Get allocations for the tables
                    if final_date and last_rebal_date:
                        final_alloc = allocation_data.get(final_date, {})
                        rebal_alloc = allocation_data.get(last_rebal_date, {})
                        
                        # Check if this is a fusion portfolio
                        portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
                        portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == selected_portfolio_detail), None)
                        is_fusion = portfolio_cfg and portfolio_cfg.get('fusion_portfolio', {}).get('enabled', False)
                        
                        # Get portfolio value for calculations
                        portfolio_value = get_portfolio_value(selected_portfolio_detail)
                        
                        # Get raw data for price calculations
                        raw_data = st.session_state.get('multi_backtest_raw_data', {})
                        
                        # Helper function to get price on or before a date
                        def _price_on_or_before(df, target_date):
                            try:
                                # Find the closest date on or before target_date
                                available_dates = df.index[df.index <= target_date]
                                if len(available_dates) > 0:
                                    closest_date = available_dates[-1]
                                    return float(df.loc[closest_date, 'Close'])
                                return None
                            except Exception:
                                return None
                        
                        # Create allocation tables
                        def build_table_from_alloc(alloc_dict, price_date, label):
                            if not alloc_dict:
                                return
                            
                            # For fusion portfolios, filter out portfolio names
                            filtered_alloc_dict = alloc_dict.copy()
                            if is_fusion:
                                # Get the list of portfolio names from the fusion config
                                portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
                                portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == selected_portfolio_detail), None)
                                if portfolio_cfg and portfolio_cfg.get('fusion_portfolio', {}).get('enabled', False):
                                    selected_portfolios = portfolio_cfg.get('fusion_portfolio', {}).get('selected_portfolios', [])
                                    # Remove any keys that match portfolio names
                                    filtered_alloc_dict = {k: v for k, v in filtered_alloc_dict.items() if k not in selected_portfolios}
                            
                            rows = []
                            for tk in sorted(filtered_alloc_dict.keys()):
                                # Handle nested dictionary structure
                                alloc_value = filtered_alloc_dict.get(tk, 0)
                                if isinstance(alloc_value, dict):
                                    # If it's a dictionary, try to get a numeric value from it
                                    alloc_pct = float(alloc_value.get('allocation', alloc_value.get('weight', 0)))
                                else:
                                    alloc_pct = float(alloc_value) if alloc_value is not None else 0.0
                                if tk == 'CASH':
                                    price = None
                                    shares = 0.0
                                    total_val = portfolio_value * alloc_pct
                                else:
                                    df = raw_data.get(tk)
                                    price = None
                                    if isinstance(df, pd.DataFrame) and 'Close' in df.columns and not df['Close'].dropna().empty:
                                        if price_date is None:
                                            # use latest price
                                            try:
                                                price = float(df['Close'].iloc[-1])
                                            except Exception:
                                                price = None
                                        else:
                                            price = _price_on_or_before(df, price_date)
                                    try:
                                        if price and price > 0:
                                            allocation_value = portfolio_value * alloc_pct
                                            shares = round(allocation_value / price, 1)
                                            total_val = shares * price
                                        else:
                                            shares = 0.0
                                            total_val = portfolio_value * alloc_pct
                                    except Exception:
                                        shares = 0.0
                                        total_val = portfolio_value * alloc_pct

                                pct_of_port = (total_val / portfolio_value * 100) if portfolio_value > 0 else 0
                                rows.append({
                                    'Ticker': tk,
                                    'Allocation %': alloc_pct * 100,
                                    'Price ($)': price if price is not None else float('nan'),
                                    'Shares': float(shares) if shares is not None else 0.0,
                                    'Total Value ($)': total_val,
                                    '% of Portfolio': pct_of_port,
                                })

                            df_table = pd.DataFrame(rows).set_index('Ticker')
                            # Decide whether to show CASH row: hide if Total Value is zero or Shares zero/NaN
                            df_display = df_table.copy()
                            show_cash = False
                            if 'CASH' in df_display.index:
                                cash_val = None
                                if 'Total Value ($)' in df_display.columns:
                                    cash_val = df_display.at['CASH', 'Total Value ($)']
                                elif 'Shares' in df_display.columns:
                                    cash_val = df_display.at['CASH', 'Shares']
                                try:
                                    show_cash = bool(cash_val and not pd.isna(cash_val) and cash_val != 0)
                                except Exception:
                                    show_cash = False
                                if not show_cash:
                                    df_display = df_display.drop('CASH')

                            # formatting for display
                            fmt = {
                                'Allocation %': '{:,.1f}%',
                                'Price ($)': '${:,.2f}',
                                'Shares': '{:,.1f}',
                                'Total Value ($)': '${:,.2f}',
                                '% of Portfolio': '{:,.2f}%'
                            }
                            try:
                                st.markdown(f"**{label}**")
                                
                                # Add total row
                                total_alloc_pct = df_display['Allocation %'].sum()
                                total_value = df_display['Total Value ($)'].sum()
                                total_port_pct = df_display['% of Portfolio'].sum()

                                total_row = pd.DataFrame({
                                    'Allocation %': [total_alloc_pct],
                                    'Price ($)': [float('nan')],
                                    'Shares': [float('nan')],
                                    'Total Value ($)': [total_value],
                                    '% of Portfolio': [total_port_pct]
                                }, index=['TOTAL'])

                                df_display = pd.concat([df_display, total_row])
                                
                                sty = df_display.style.format(fmt)
                                if 'CASH' in df_table.index and show_cash:
                                    def _highlight_cash_row(s):
                                        if s.name == 'CASH':
                                            return ['background-color: #006400; color: white; font-weight: bold;' for _ in s]
                                        return [''] * len(s)
                                    sty = sty.apply(_highlight_cash_row, axis=1)

                                # Highlight TOTAL row
                                def _highlight_total_row(s):
                                    if s.name == 'TOTAL':
                                        return ['background-color: #1f4e79; color: white; font-weight: bold;' for _ in s]
                                    return [''] * len(s)
                                sty = sty.apply(_highlight_total_row, axis=1)
                                
                                st.dataframe(sty, use_container_width=True)
                            except Exception:
                                st.dataframe(df_display, use_container_width=True)
                        
                        # Display the remaining two allocation tables
                        st.markdown("---")
                        st.markdown("**üìä Historical Allocation Tables**")
                        
                        # Last rebalance table (use last_rebal_date)
                        build_table_from_alloc(rebal_alloc, last_rebal_date, f"Target Allocation at Last Rebalance ({last_rebal_date.date()})")
                        
                        # Current / Today table (use final_date's latest available prices as of now)
                        build_table_from_alloc(final_alloc, None, f"Portfolio Evolution (Current Allocation)")

            # This section was moved earlier in the file - removing duplicate

            # Fusion Portfolio Ticker Allocations JSON Generator (only for fusion portfolios)
            # Check if this is a fusion portfolio
            portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
            portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == selected_portfolio_detail), None)
            is_fusion = portfolio_cfg and portfolio_cfg.get('fusion_portfolio', {}).get('enabled', False)
            
            if is_fusion:
                st.markdown("---")
                
                with st.expander("üìã Current Ticker Allocations JSON", expanded=False):
                    # Get "If Rebalanced Today" ticker allocations (EXACT same as the pie chart)
                    current_ticker_allocations = {}
                    
                    # Use the EXACT same logic as the "Target Allocation if Rebalanced Today" plot
                    snapshot = st.session_state.get('multi_backtest_snapshot_data', {})
                    today_weights_map = snapshot.get('today_weights_map', {}) if snapshot else {}
                    
                    if selected_portfolio_detail in today_weights_map:
                        current_ticker_allocations = today_weights_map.get(selected_portfolio_detail, {})
                    else:
                        # Fallback to current allocation if no stored weights found
                        if selected_portfolio_detail in st.session_state.multi_all_allocations:
                            allocation_data = st.session_state.multi_all_allocations[selected_portfolio_detail]
                            if allocation_data:
                                last_date = max(allocation_data.keys())
                                current_ticker_allocations = allocation_data[last_date]
                            else:
                                current_ticker_allocations = {}
                        else:
                            current_ticker_allocations = {}
                    
                    # Create JSON structure for Allocations page compatibility (always available for fusion portfolios)
                    # Get the actual fusion portfolio rebalancing frequency
                    portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
                    portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == selected_portfolio_detail), None)
                    fusion_frequency = portfolio_cfg.get('rebalancing_frequency', 'Monthly') if portfolio_cfg else 'Monthly'
                    
                    # Get MA multiplier from portfolio config if available
                    ma_multiplier_value = 1.48  # Default value
                    if portfolio_cfg:
                        ma_multiplier_value = portfolio_cfg.get('ma_multiplier', 1.48)
                    
                    portfolio_json = {
                        "name": f"{selected_portfolio_detail} - Ticker Breakdown",
                        "stocks": [],
                        "benchmark_ticker": "^GSPC",
                        "initial_value": 10000,
                        "added_amount": 0,
                        "added_frequency": "none",
                        "rebalancing_frequency": fusion_frequency,
                        "start_date_user": None,
                        "end_date_user": None,
                        "start_with": "all",
                        "use_momentum": False,
                        "momentum_strategy": "Classic",
                        "negative_momentum_strategy": "Cash",
                        "momentum_windows": [],
                        "calc_beta": False,
                        "calc_volatility": True,
                        "beta_window_days": 365,
                        "exclude_days_beta": 30,
                        "vol_window_days": 365,
                        "exclude_days_vol": 30,
                        "use_targeted_rebalancing": False,
                        "targeted_rebalancing_settings": {},
                        "ma_multiplier": ma_multiplier_value
                    }
                    
                    # Add tickers with their allocations
                    for ticker, allocation in current_ticker_allocations.items():
                        # Handle nested dictionary structure
                        if isinstance(allocation, dict):
                            # If it's a dictionary, try to get a numeric value from it
                            alloc_value = allocation.get('allocation', allocation.get('weight', 0))
                        else:
                            alloc_value = allocation if allocation is not None else 0
                    
                        # Convert to float and check if it's greater than 0
                        try:
                            alloc_float = float(alloc_value)
                            if ticker and ticker != 'CASH' and alloc_float > 0:
                                portfolio_json["stocks"].append({
                                    "ticker": ticker,
                                    "allocation": alloc_float,
                                    "include_dividends": True
                                })
                        except (ValueError, TypeError):
                            # Skip invalid values
                            continue
                    
                    # Add copy functionality (EXACT same as other JSON sections)
                    import json as json_module
                    json_string = json_module.dumps(portfolio_json, indent=2)
                    st.code(json_string, language='json')
                    
                    # Copy to clipboard functionality (EXACT same as other sections)
                    import streamlit.components.v1 as components
                    copy_html = f"""
                    <button onclick='navigator.clipboard.writeText({json.dumps(json_string)});' style='margin-bottom:10px;'>Copy All Configs to Clipboard</button>
                    """
                    components.html(copy_html, height=40)
                    
                    # Add PDF download button for JSON (EXACT same as other sections)
                    def generate_fusion_json_pdf(custom_name=""):
                        """Generate a PDF with pure JSON content only for easy CTRL+A / CTRL+V copying."""
                        from reportlab.lib.pagesizes import letter, A4
                        from reportlab.platypus import SimpleDocTemplate, Preformatted
                        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
                        import io
                        from datetime import datetime
                        
                        # Create PDF buffer
                        buffer = io.BytesIO()
                        
                        # Add proper PDF metadata
                        portfolio_name = selected_portfolio_detail
                        
                        # Use custom name if provided, otherwise use portfolio name
                        if custom_name.strip():
                            title = f"Multi Backtest - {custom_name.strip()} - JSON Configuration"
                            subject = f"JSON Configuration: {custom_name.strip()}"
                        else:
                            title = f"Multi Backtest - {portfolio_name} - JSON Configuration"
                            subject = f"JSON Configuration for {portfolio_name}"
                        
                        doc = SimpleDocTemplate(
                            buffer, 
                            pagesize=A4, 
                            rightMargin=36, 
                            leftMargin=36, 
                            topMargin=36, 
                            bottomMargin=36,
                            title=title,
                            author="Portfolio Backtest System",
                            subject=subject,
                            creator="Multi Backtest Application"
                        )
                        story = []
                        
                        # Pure JSON style - just monospace text
                        json_style = ParagraphStyle(
                            'PureJSONStyle',
                            fontName='Courier',
                            fontSize=10,
                            leading=12,
                            leftIndent=0,
                            rightIndent=0,
                            spaceAfter=0,
                            spaceBefore=0
                        )
                        
                        # Add only the JSON content - no headers, no instructions, just pure JSON
                        json_lines = json_string.split('\n')
                        for line in json_lines:
                            story.append(Preformatted(line, json_style))
                        
                        # Build PDF
                        doc.build(story)
                        pdf_data = buffer.getvalue()
                        buffer.close()
                        
                        return pdf_data
                    
                    # Optional custom PDF name (EXACT same as other sections)
                    custom_fusion_pdf_name = st.text_input(
                        "üìù Custom PDF Name (optional):", 
                        value="",
                        placeholder=f"e.g., {selected_portfolio_detail} Configuration, Fusion Setup Analysis",
                        help="Leave empty to use automatic naming based on portfolio name",
                        key=f"fusion_custom_pdf_name_{selected_portfolio_detail}"
                    )
                    
                    if st.button("üìÑ Download JSON as PDF", help="Download a PDF containing the JSON configuration for easy copying", key=f"fusion_json_pdf_btn_{selected_portfolio_detail}"):
                        try:
                            pdf_data = generate_fusion_json_pdf(custom_fusion_pdf_name)
                            
                            # Generate filename based on custom name or default
                            if custom_fusion_pdf_name.strip():
                                clean_name = custom_fusion_pdf_name.strip().replace(' ', '_').replace('/', '_').replace('\\', '_')
                                filename = f"{clean_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
                            else:
                                filename = f"fusion_portfolio_{selected_portfolio_detail.replace(' ', '_')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
                            
                            st.download_button(
                                label="üì• Download PDF",
                                data=pdf_data,
                                file_name=filename,
                                mime="application/pdf",
                                key=f"fusion_json_pdf_download_{selected_portfolio_detail}"
                            )
                            st.success("PDF generated successfully! Click the download button above.")
                        except Exception as e:
                            st.error(f"Error generating PDF: {str(e)}")

            # This section was moved earlier in the file - removing duplicate
            if False and selected_portfolio_detail in st.session_state.multi_all_metrics:
                st.markdown("---")
                st.markdown(f"**Momentum Metrics and Calculated Weights for {selected_portfolio_detail}**")

                metrics_records = []
                for date, tickers_data in st.session_state.multi_all_metrics[selected_portfolio_detail].items():
                    # For fusion portfolios, aggregate CASH entries before processing
                    portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
                    portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == selected_portfolio_detail), None)
                    is_fusion_portfolio = portfolio_cfg and portfolio_cfg.get('type') == 'fusion'
                    
                    if is_fusion_portfolio:
                        # Aggregate CASH entries for fusion portfolios
                        aggregated_tickers_data = {}
                        total_cash_weight = 0
                        cash_metrics = {}
                        
                        for ticker, data in tickers_data.items():
                            display_ticker = 'CASH' if ticker is None else ticker
                            if display_ticker == 'CASH':
                                # Aggregate CASH weights and metrics
                                total_cash_weight += data.get('Calculated_Weight', 0)
                                for metric_key, metric_value in data.items():
                                    if metric_key != 'Composite':
                                        if metric_key not in cash_metrics:
                                            cash_metrics[metric_key] = 0
                                        cash_metrics[metric_key] += metric_value
                            else:
                                # Keep non-CASH entries as-is
                                aggregated_tickers_data[display_ticker] = data
                        
                        # Add aggregated CASH entry if there's any cash
                        if total_cash_weight > 0:
                            aggregated_tickers_data['CASH'] = cash_metrics.copy()
                            aggregated_tickers_data['CASH']['Calculated_Weight'] = total_cash_weight
                        
                        tickers_data = aggregated_tickers_data
                    
                    # Add all asset lines
                    asset_weights = []
                    for ticker, data in tickers_data.items():
                        # Handle None ticker as CASH
                        display_ticker = 'CASH' if ticker is None else ticker
                        if display_ticker != 'CASH':
                            asset_weights.append(data.get('Calculated_Weight', 0))
                        # Filter out any internal-only keys (e.g., 'Composite') so they don't show in the UI
                        filtered_data = {k: v for k, v in (data or {}).items() if k != 'Composite'}
                        
                        # Check if momentum is used for this portfolio
                        portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
                        portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == selected_portfolio_detail), None)
                        use_momentum = portfolio_cfg.get('use_momentum', True) if portfolio_cfg else True
                        
                        # If momentum is not used, replace Calculated_Weight with target_allocation
                        if not use_momentum:
                            if 'target_allocation' in filtered_data:
                                filtered_data['Calculated_Weight'] = filtered_data['target_allocation']
                            else:
                                # If target_allocation is not available, use the entered allocations from portfolio_cfg
                                ticker_name = display_ticker if display_ticker != 'CASH' else None
                                if ticker_name and portfolio_cfg:
                                    # Find the stock in portfolio_cfg and use its allocation
                                    for stock in portfolio_cfg.get('stocks', []):
                                        if stock.get('ticker', '').strip() == ticker_name:
                                            filtered_data['Calculated_Weight'] = stock.get('allocation', 0)
                                            break
                                elif display_ticker == 'CASH' and portfolio_cfg:
                                    # For CASH, calculate the remaining allocation
                                    total_alloc = sum(stock.get('allocation', 0) for stock in portfolio_cfg.get('stocks', []))
                                    filtered_data['Calculated_Weight'] = max(0, 1.0 - total_alloc)
                        
                        record = {'Date': date, 'Ticker': display_ticker, **filtered_data}
                        metrics_records.append(record)
                        
                        # Add CASH row only if it's significant (more than 5% allocation) AND not a momentum portfolio
                        # This prevents showing CASH for small cash balances and momentum portfolios
                        portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
                        portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == selected_portfolio_detail), None)
                        use_momentum = portfolio_cfg.get('use_momentum', True) if portfolio_cfg else True
                        
                        # Don't add CASH for fusion portfolios - they handle it in aggregation
                        if not use_momentum and not is_fusion_portfolio:
                            total_calculated_weight = sum(asset_weights)
                            cash_allocation = 1.0 - total_calculated_weight
                            
                            if cash_allocation > 0.05:  # Only show CASH if it's more than 5%
                                cash_record = {'Date': date, 'Ticker': 'CASH', 'Calculated_Weight': cash_allocation}
                                metrics_records.append(cash_record)
                    
                    # Ensure CASH line is added if there's non-zero cash in allocations
                    # For fusion portfolios, don't show individual CASH allocations - only show if it's a single portfolio
                    # Check if this is a fusion portfolio by looking at the portfolio config
                    portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
                    portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == selected_portfolio_detail), None)
                    is_fusion_portfolio = portfolio_cfg and portfolio_cfg.get('type') == 'fusion'
                    
                    if not is_fusion_portfolio:
                        # Only add CASH for individual portfolios, not fusion portfolios
                        allocs_for_portfolio = st.session_state.multi_all_allocations.get(selected_portfolio_detail) if 'multi_all_allocations' in st.session_state else None
                        if allocs_for_portfolio and date in allocs_for_portfolio:
                            cash_alloc = allocs_for_portfolio[date].get('CASH', 0)
                            # Only add CASH if it's actually allocated (not just for momentum portfolios)
                            if cash_alloc > 0:
                                # Check if CASH is already in metrics_records for this date
                                cash_exists = any(record['Date'] == date and record['Ticker'] == 'CASH' for record in metrics_records)
                                if not cash_exists:
                                    # Add CASH line to metrics
                                    use_momentum = portfolio_cfg.get('use_momentum', True) if portfolio_cfg else True
                                    
                                    if not use_momentum:
                                        # When momentum is not used, calculate CASH allocation from entered allocations
                                        total_alloc = sum(stock.get('allocation', 0) for stock in portfolio_cfg.get('stocks', []))
                                        cash_weight = max(0, 1.0 - total_alloc)
                                        cash_record = {'Date': date, 'Ticker': 'CASH', 'Calculated_Weight': cash_weight}
                                    else:
                                        # For momentum portfolios, only add CASH if the momentum strategy actually allocated to cash
                                        cash_record = {'Date': date, 'Ticker': 'CASH', 'Calculated_Weight': cash_alloc}
                                    metrics_records.append(cash_record)
                    
                    # Add CASH line if fully allocated to cash (100%) or all asset weights are 0% (fallback logic)
                    cash_line_needed = False
                    if 'CASH' in tickers_data or None in tickers_data:
                        cash_data = tickers_data.get('CASH', tickers_data.get(None, {}))
                        cash_weight = cash_data.get('Calculated_Weight', 0)
                        if abs(cash_weight - 1.0) < 1e-6:  # 100% in decimal
                            cash_line_needed = True
                    if all(w == 0 for w in asset_weights) and asset_weights:
                        cash_line_needed = True
                    if cash_line_needed and 'CASH' not in [r['Ticker'] for r in metrics_records if r['Date'] == date]:
                        # If no explicit CASH data, create a default line
                        # If no explicit CASH data, create a default line
                        cash_record = {'Date': date, 'Ticker': 'CASH', 'Calculated_Weight': 1.0}
                        metrics_records.append(cash_record)

                if metrics_records:
                    metrics_df = pd.DataFrame(metrics_records)
                    
                    # Filter out CASH lines where Calculated_Weight is 0 for the last date
                    if 'Calculated_Weight' in metrics_df.columns:
                        # Get the last date
                        last_date = metrics_df['Date'].max()
                        # Remove CASH records where Calculated_Weight is 0 for the last date
                        mask = ~((metrics_df['Ticker'] == 'CASH') & (metrics_df['Date'] == last_date) & (metrics_df['Calculated_Weight'] == 0))
                        metrics_df = metrics_df[mask].reset_index(drop=True)
                    
                    if not metrics_df.empty:
                        # Ensure unique index by adding a counter if needed
                        if metrics_df.duplicated(subset=['Date', 'Ticker']).any():
                            # Add a counter to make indices unique
                            metrics_df['Counter'] = metrics_df.groupby(['Date', 'Ticker']).cumcount()
                            metrics_df['Ticker_Unique'] = metrics_df['Ticker'] + metrics_df['Counter'].astype(str)
                            metrics_df.set_index(['Date', 'Ticker_Unique'], inplace=True)
                        else:
                            metrics_df.set_index(['Date', 'Ticker'], inplace=True)
                        
                    metrics_df_display = metrics_df.copy()

                    # Ensure Momentum column exists and normalize to percent when present
                    if 'Momentum' in metrics_df_display.columns:
                        metrics_df_display['Momentum'] = metrics_df_display['Momentum'].fillna(0) * 100
                    else:
                        metrics_df_display['Momentum'] = np.nan

                    def color_momentum(val):
                        if isinstance(val, (int, float)):
                            color = 'green' if val > 0 else 'red'
                            return f'color: {color}'
                        # Force white color for None, NA, and other non-numeric values
                        return 'color: #FFFFFF; font-weight: bold;'
                    
                    def color_all_columns(val):
                        # Force white color for None, NA, and other non-numeric values in ALL columns
                        if pd.isna(val) or val == 'None' or val == 'NA' or val == '':
                            return 'color: #FFFFFF; font-weight: bold;'
                        if isinstance(val, (int, float)):
                            return ''  # Let default styling handle numeric values
                        return 'color: #FFFFFF; font-weight: bold;'  # Force white for any other text
                    
                    def highlight_metrics_rows(s):
                        date_str = s.name[0]
                        ticker_str = s.name[1]
                        # If this is the CASH row, use dark green background
                        if 'CASH' in ticker_str:
                            return ['background-color: #006400; color: white; font-weight: bold;' for _ in s]
                        # Otherwise, alternate row colors by date with WHITE TEXT
                        unique_dates = list(metrics_df_display.index.get_level_values(0).unique())
                        is_even = unique_dates.index(date_str) % 2 == 0
                        bg_color = 'background-color: #0e1117' if is_even else 'background-color: #262626'
                        return [f'{bg_color}; color: white;'] * len(s)

                    # Format Calculated_Weight as a percentage if present
                    if 'Calculated_Weight' in metrics_df_display.columns:
                        metrics_df_display['Calculated_Weight'] = metrics_df_display['Calculated_Weight'].fillna(0) * 100
                    # Convert Volatility from decimal (e.g., 0.20) to percent (20.0)
                    if 'Volatility' in metrics_df_display.columns:
                        metrics_df_display['Volatility'] = metrics_df_display['Volatility'].fillna(np.nan) * 100

                    # Corrected styling logic for alternating row colors and momentum color
                    styler_metrics = metrics_df_display.style.apply(highlight_metrics_rows, axis=1)
                    if 'Momentum' in metrics_df_display.columns:
                        styler_metrics = styler_metrics.map(color_momentum, subset=['Momentum'])
                    # Force white color for None/NA values in ALL columns
                    styler_metrics = styler_metrics.map(color_all_columns)

                    fmt_dict = {}
                    if 'Momentum' in metrics_df_display.columns:
                        fmt_dict['Momentum'] = '{:,.0f}%'
                    if 'Beta' in metrics_df_display.columns:
                        fmt_dict['Beta'] = '{:,.2f}'
                    if 'Volatility' in metrics_df_display.columns:
                        fmt_dict['Volatility'] = '{:,.2f}%'
                    if 'Calculated_Weight' in metrics_df_display.columns:
                        fmt_dict['Calculated_Weight'] = '{:,.0f}%'

                    if fmt_dict:
                        styler_metrics = styler_metrics.format(fmt_dict)
                    
                    # NUCLEAR OPTION: Inject custom CSS to override Streamlit's stubborn styling
                    st.markdown("""
                    <style>
                    /* NUCLEAR CSS OVERRIDE - BEAT STREAMLIT INTO SUBMISSION */
                    .stDataFrame [data-testid="stDataFrame"] div[data-testid="stDataFrame"] table td,
                    .stDataFrame [data-testid="stDataFrame"] div[data-testid="stDataFrame"] table th,
                    .stDataFrame table td,
                    .stDataFrame table th {
                        color: #FFFFFF !important;
                        font-weight: bold !important;
                        text-shadow: 1px 1px 2px black !important;
                    }
                    
                    /* Force ALL text in dataframes to be white */
                    .stDataFrame * {
                        color: #FFFFFF !important;
                    }
                    
                    /* Override any Streamlit bullshit */
                    .stDataFrame [data-testid="stDataFrame"] *,
                    .stDataFrame div[data-testid="stDataFrame"] * {
                        color: #FFFFFF !important;
                        font-weight: bold !important;
                    }
                    
                    /* Target EVERYTHING in the dataframe */
                    .stDataFrame table *,
                    .stDataFrame div table *,
                    .stDataFrame [data-testid="stDataFrame"] table *,
                    .stDataFrame [data-testid="stDataFrame"] div table * {
                        color: #FFFFFF !important;
                        font-weight: bold !important;
                    }
                    
                    /* Target all cells specifically */
                    .stDataFrame td,
                    .stDataFrame th,
                    .stDataFrame table td,
                    .stDataFrame table th {
                        color: #FFFFFF !important;
                        font-weight: bold !important;
                    }
                    
                    /* Target Streamlit's specific elements */
                    div[data-testid="stDataFrame"] table td,
                    div[data-testid="stDataFrame"] table th,
                    div[data-testid="stDataFrame"] div table td,
                    div[data-testid="stDataFrame"] div table th {
                        color: #FFFFFF !important;
                        font-weight: bold !important;
                    }
                    
                    /* Target everything with maximum specificity */
                    div[data-testid="stDataFrame"] *,
                    div[data-testid="stDataFrame"] div *,
                    div[data-testid="stDataFrame"] table *,
                    div[data-testid="stDataFrame"] div table * {
                        color: #FFFFFF !important;
                        font-weight: bold !important;
                    }
                    </style>
                    """, unsafe_allow_html=True)

                    st.dataframe(styler_metrics, use_container_width=True)

                                        # --- Allocation plots: Final allocation and last rebalance allocation ---
                    allocs_for_portfolio = st.session_state.multi_all_allocations.get(selected_portfolio_detail) if 'multi_all_allocations' in st.session_state else None
                    if allocs_for_portfolio:
                        try:
                            # Sort allocation dates
                            alloc_dates = sorted(list(allocs_for_portfolio.keys()))
                            if len(alloc_dates) == 0:
                                st.info("No allocation history available to plot.")
                            else:
                                final_date = alloc_dates[-1]
                                
                                # Check if this is a fusion portfolio for last rebalancing date calculation
                                portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
                                portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == selected_portfolio_detail), None)
                                is_fusion = portfolio_cfg and portfolio_cfg.get('fusion_portfolio', {}).get('enabled', False)
                                
                                if is_fusion:
                                    # For fusion portfolios, calculate the actual last fusion rebalancing date
                                    fusion_freq = portfolio_cfg.get('rebalancing_frequency', 'Monthly')
                                    
                                    # Map frequency names to what the function expects
                                    frequency_mapping = {
                                        'monthly': 'Monthly',
                                        'weekly': 'Weekly',
                                        'bi-weekly': 'Biweekly',
                                        'biweekly': 'Biweekly',
                                        'quarterly': 'Quarterly',
                                        'semi-annually': 'Semiannually',
                                        'semiannually': 'Semiannually',
                                        'annually': 'Annually',
                                        'yearly': 'Annually',
                                        'market_day': 'market_day',
                                        'calendar_day': 'calendar_day',
                                        'never': 'Never',
                                        'none': 'Never'
                                    }
                                    fusion_freq = frequency_mapping.get(fusion_freq.lower(), fusion_freq)
                                    
                                    # Calculate fusion rebalancing dates
                                    fusion_rebalancing_dates = set()
                                    
                                    if fusion_freq != 'none':
                                        current_date = alloc_dates[0]
                                        
                                        while current_date <= alloc_dates[-1]:
                                            fusion_rebalancing_dates.add(current_date)
                                            
                                            # Calculate next rebalancing date
                                            if fusion_freq == 'market_day':
                                                next_idx = alloc_dates.index(current_date) + 1 if current_date in alloc_dates else 0
                                                if next_idx < len(alloc_dates):
                                                    current_date = alloc_dates[next_idx]
                                                else:
                                                    break
                                            elif fusion_freq == 'calendar_day':
                                                current_date = current_date + pd.Timedelta(days=1)
                                            elif fusion_freq == 'week':
                                                current_date = current_date + pd.Timedelta(weeks=1)
                                            elif fusion_freq == '2weeks':
                                                current_date = current_date + pd.Timedelta(weeks=2)
                                            elif fusion_freq == 'month':
                                                try:
                                                    if current_date.month == 12:
                                                        current_date = current_date.replace(year=current_date.year + 1, month=1, day=1)
                                                    else:
                                                        current_date = current_date.replace(month=current_date.month + 1, day=1)
                                                except ValueError:
                                                    current_date = current_date.replace(day=1)
                                                    if current_date.month == 12:
                                                        current_date = current_date.replace(year=current_date.year + 1, month=1, day=1)
                                                    else:
                                                        current_date = current_date.replace(month=current_date.month + 1, day=1)
                                            elif fusion_freq == '3months':
                                                try:
                                                    new_month = current_date.month + 3
                                                    new_year = current_date.year + (new_month - 1) // 12
                                                    new_month = ((new_month - 1) % 12) + 1
                                                    current_date = current_date.replace(year=new_year, month=new_month, day=1)
                                                except ValueError:
                                                    current_date = current_date.replace(day=1)
                                                    new_month = current_date.month + 3
                                                    new_year = current_date.year + (new_month - 1) // 12
                                                    new_month = ((new_month - 1) % 12) + 1
                                                    current_date = current_date.replace(year=new_year, month=new_month, day=1)
                                            elif fusion_freq == '6months':
                                                try:
                                                    new_month = current_date.month + 6
                                                    new_year = current_date.year + (new_month - 1) // 12
                                                    new_month = ((new_month - 1) % 12) + 1
                                                    current_date = current_date.replace(year=new_year, month=new_month, day=1)
                                                except ValueError:
                                                    current_date = current_date.replace(day=1)
                                                    new_month = current_date.month + 6
                                                    new_year = current_date.year + (new_month - 1) // 12
                                                    new_month = ((new_month - 1) % 12) + 1
                                                    current_date = current_date.replace(year=new_year, month=new_month, day=1)
                                            elif fusion_freq == 'year':
                                                current_date = current_date.replace(year=current_date.year + 1, month=1, day=1)
                                            else:
                                                break
                                    
                                    fusion_rebalancing_dates = sorted(fusion_rebalancing_dates)
                                    
                                    # Find the last fusion rebalancing date before the final date
                                    last_fusion_rebal_date = None
                                    for date in reversed(fusion_rebalancing_dates):
                                        if date < final_date:
                                            last_fusion_rebal_date = date
                                            break
                                    
                                    if last_fusion_rebal_date:
                                        last_rebal_date = last_fusion_rebal_date
                                    else:
                                        last_rebal_date = alloc_dates[0]
                                else:
                                    # Use standard last rebalancing date calculation for regular portfolios
                                    # Find the actual last rebalancing date, not just the second-to-last date
                                    portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
                                    portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == selected_portfolio_detail), None)
                                    
                                    if portfolio_cfg:
                                        # Get the portfolio's rebalancing frequency
                                        rebalancing_frequency = portfolio_cfg.get('rebalancing_frequency', 'Monthly')
                                        
                                        # Map frequency names to what the function expects
                                        frequency_mapping = {
                                            'daily': 'market_day',
                                            'weekly': 'Weekly',
                                            'monthly': 'Monthly',
                                            'quarterly': 'Quarterly',
                                            'annually': 'Annually',
                                            'never': 'Never',
                                            'none': 'Never'
                                        }
                                        rebalancing_frequency = frequency_mapping.get(rebalancing_frequency.lower(), rebalancing_frequency)
                                        
                                        # Find the actual last rebalancing date
                                        last_rebal_date = None
                                        if rebalancing_frequency != 'Never':
                                            # Get sim_index from the portfolio results
                                            sim_index = None
                                            if 'multi_all_results' in st.session_state and st.session_state.multi_all_results:
                                                portfolio_results = st.session_state.multi_all_results.get(selected_portfolio_detail)
                                                if portfolio_results:
                                                    if isinstance(portfolio_results, dict) and 'no_additions' in portfolio_results:
                                                        sim_index = portfolio_results['no_additions'].index
                                                    elif isinstance(portfolio_results, pd.Series):
                                                        sim_index = portfolio_results.index
                                            
                                            if sim_index is not None:
                                                # Get all rebalancing dates for this portfolio
                                                portfolio_rebalancing_dates = get_dates_by_freq(rebalancing_frequency, sim_index[0], sim_index[-1], sim_index)
                                                if portfolio_rebalancing_dates:
                                                    # Find the last rebalancing date before the final date
                                                    for date in reversed(portfolio_rebalancing_dates):
                                                        if date < final_date:
                                                            last_rebal_date = date
                                                            break
                                        
                                        # Fallback to first date if no rebalancing date found
                                        if not last_rebal_date:
                                            last_rebal_date = alloc_dates[0]
                                    else:
                                        # Fallback to second-to-last date if no config found
                                        last_rebal_date = alloc_dates[-2] if len(alloc_dates) > 1 else alloc_dates[-1]

                                # Use individual stock allocations for all portfolios (including fusion)
                                # This shows how many of each stock you need
                                final_alloc = allocs_for_portfolio.get(final_date, {})
                                rebal_alloc = allocs_for_portfolio.get(last_rebal_date, {})
                                
                                # Remove the fusion portfolio allocation data from individual stock allocations
                                if is_fusion:
                                    final_alloc = {k: v for k, v in final_alloc.items() if k != '_FUSION_PORTFOLIOS_'}
                                    rebal_alloc = {k: v for k, v in rebal_alloc.items() if k != '_FUSION_PORTFOLIOS_'}

                                # Helper to prepare bar data
                                def prepare_bar_data(d):
                                    labels = []
                                    values = []
                                    for k, v in sorted(d.items(), key=lambda x: (-x[1], x[0])):
                                        labels.append(k)
                                        try:
                                            values.append(float(v) * 100)
                                        except Exception:
                                            values.append(0.0)
                                    return labels, values

                                labels_final, vals_final = prepare_bar_data(final_alloc)
                                labels_rebal, vals_rebal = prepare_bar_data(rebal_alloc)
                                

                                # Add timer for next rebalance date (EXACT copy from page 1)
                                
                                # FALLBACK TIMER - Always show this to test display
                                st.markdown("---")
                                st.markdown("**‚è∞ FALLBACK TIMER (Always Shows)**")
                                from datetime import datetime, timedelta
                                fallback_date = datetime.now() + timedelta(days=2)
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("Time Until Next Rebalance", "2 days, 0 hours, 0 minutes")
                                with col2:
                                    st.metric("Target Rebalance Date", fallback_date.strftime("%B %d, %Y"))
                                with col3:
                                    st.metric("Rebalancing Frequency", "Test")
                                st.info("This fallback timer should always show. If you see this, the timer display works.")
                                st.markdown("---")
                                try:
                                    # Get the last rebalance date from allocation history
                                    if len(alloc_dates) > 1:
                                        last_rebal_date_for_timer = alloc_dates[-2]  # Second to last date (excluding today/yesterday)
                                    else:
                                        last_rebal_date_for_timer = alloc_dates[-1] if alloc_dates else None
                                    
                                    
                                    # Get rebalancing frequency from portfolio config
                                    portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
                                    portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == selected_portfolio_detail), None)
                                    rebalancing_frequency = portfolio_cfg.get('rebalancing_frequency', 'none') if portfolio_cfg else 'none'
                                    # Convert to lowercase and map to function expectations
                                    rebalancing_frequency = rebalancing_frequency.lower()
                                    # Map frequency names to what the function expects
                                    frequency_mapping = {
                                        'monthly': 'Monthly',
                                        'weekly': 'Weekly',
                                        'bi-weekly': 'Biweekly',
                                        'biweekly': 'Biweekly',
                                        'quarterly': 'Quarterly',
                                        'semi-annually': 'Semiannually',
                                        'semiannually': 'Semiannually',
                                        'annually': 'Annually',
                                        'yearly': 'Annually',
                                        'market_day': 'market_day',
                                        'calendar_day': 'calendar_day',
                                        'never': 'Never',
                                        'none': 'Never'
                                    }
                                    rebalancing_frequency = frequency_mapping.get(rebalancing_frequency, rebalancing_frequency)
                                    
                                    
                                    if last_rebal_date_for_timer and rebalancing_frequency != 'none':
                                        # Ensure last_rebal_date_for_timer is a naive datetime object
                                        if isinstance(last_rebal_date_for_timer, str):
                                            last_rebal_date_for_timer = pd.to_datetime(last_rebal_date_for_timer)
                                        if hasattr(last_rebal_date_for_timer, 'tzinfo') and last_rebal_date_for_timer.tzinfo is not None:
                                            last_rebal_date_for_timer = last_rebal_date_for_timer.replace(tzinfo=None)
                                        
                                        next_date, time_until, next_rebalance_datetime = calculate_next_rebalance_date(
                                            rebalancing_frequency, last_rebal_date_for_timer
                                        )
                                        
                                        if next_date and time_until:
                                            st.markdown("---")
                                            
                                            if is_fusion:
                                                # For fusion portfolios, show TWO timers
                                                st.markdown("**‚è∞ Rebalancing Timers**")
                                                
                                                # Timer 1: Individual Portfolio Rebalancing (Stocks within portfolios)
                                                st.markdown("**üìä Individual Portfolio Rebalancing (Stocks within portfolios)**")
                                                col1, col2, col3 = st.columns(3)
                                                
                                                with col1:
                                                    st.metric(
                                                        label="Time Until Next Stock Rebalance",
                                                        value=format_time_until(time_until),
                                                        delta=None
                                                    )
                                                
                                                with col2:
                                                    st.metric(
                                                        label="Target Stock Rebalance Date",
                                                        value=next_date.strftime("%B %d, %Y"),
                                                        delta=None
                                                    )
                                                
                                                with col3:
                                                    st.metric(
                                                        label="Stock Rebalancing Frequency",
                                                        value=rebalancing_frequency.replace('_', ' ').title(),
                                                        delta=None
                                                    )
                                                
                                                # Timer 2: Fusion Portfolio Rebalancing (Between portfolios)
                                                st.markdown("**üîÑ Fusion Portfolio Rebalancing (Between portfolios)**")
                                                
                                                # Calculate fusion rebalancing timer
                                                fusion_freq = portfolio_cfg.get('rebalancing_frequency', 'Monthly')
                                                fusion_next_date, fusion_time_until, _ = calculate_next_rebalance_date(fusion_freq, last_rebal_date)
                                                
                                                if fusion_next_date:
                                                    
                                                    col4, col5, col6 = st.columns(3)
                                                    
                                                    with col4:
                                                        st.metric(
                                                            label="Time Until Next Portfolio Rebalance",
                                                            value=format_time_until(fusion_time_until),
                                                            delta=None
                                                        )
                                                    
                                                    with col5:
                                                        st.metric(
                                                            label="Target Portfolio Rebalance Date",
                                                            value=fusion_next_date.strftime("%B %d, %Y"),
                                                            delta=None
                                                        )
                                                    
                                                    with col6:
                                                        st.metric(
                                                            label="Portfolio Rebalancing Frequency",
                                                            value=fusion_freq.replace('_', ' ').title(),
                                                            delta=None
                                                        )
                                            else:
                                                # For regular portfolios, show single timer
                                                st.markdown("**‚è∞ Next Rebalance Timer**")
                                            
                                            # Create columns for timer display
                                            col1, col2, col3 = st.columns(3)
                                            
                                            with col1:
                                                st.metric(
                                                    label="Time Until Next Rebalance",
                                                    value=format_time_until(time_until),
                                                    delta=None
                                                )
                                            
                                            with col2:
                                                st.metric(
                                                    label="Target Rebalance Date",
                                                    value=next_date.strftime("%B %d, %Y"),
                                                    delta=None
                                                )
                                            
                                            with col3:
                                                st.metric(
                                                    label="Rebalancing Frequency",
                                                    value=rebalancing_frequency.replace('_', ' ').title(),
                                                    delta=None
                                                )
                                            
                                            # Add a progress bar showing progress to next rebalance
                                            if rebalancing_frequency in ['week', '2weeks', 'month', '3months', '6months', 'year']:
                                                # Calculate progress percentage
                                                if hasattr(last_rebal_date_for_timer, 'to_pydatetime'):
                                                    last_rebal_datetime = last_rebal_date_for_timer.to_pydatetime()
                                                else:
                                                    last_rebal_datetime = last_rebal_date_for_timer
                                                
                                                total_period = (next_rebalance_datetime - last_rebal_datetime).total_seconds()
                                                elapsed_period = (datetime.now() - last_rebal_datetime).total_seconds()
                                                progress = min(max(elapsed_period / total_period, 0), 1)
                                                
                                                st.progress(progress, text=f"Progress to next rebalance: {progress:.1%}")
                                            
                                            # Create and store timer table figure for PDF export
                                            try:
                                                timer_data = [
                                                    ['Time Until Next Rebalance', format_time_until(time_until)],
                                                    ['Target Rebalance Date', next_date.strftime("%B %d, %Y")],
                                                    ['Rebalancing Frequency', rebalancing_frequency.replace('_', ' ').title()]
                                                ]
                                                
                                                fig_timer = go.Figure(data=[go.Table(
                                                    header=dict(
                                                        values=['Parameter', 'Value'],
                                                        fill_color='#2E86AB',
                                                        align='center',
                                                        font=dict(color='white', size=16, family='Arial Black')
                                                    ),
                                                    cells=dict(
                                                        values=[[row[0] for row in timer_data], [row[1] for row in timer_data]],
                                                        fill_color=[['#F8F9FA', '#FFFFFF'] * 2, ['#F8F9FA', '#FFFFFF'] * 2],
                                                        align='center',
                                                        font=dict(color='black', size=14, family='Arial'),
                                                        height=40
                                                    )
                                                )])
                                                
                                                fig_timer.update_layout(
                                                    title=dict(
                                                        text="‚è∞ Next Rebalance Timer",
                                                        x=0.5,
                                                        font=dict(size=18, color='#2E86AB', family='Arial Black')
                                                    ),
                                                    width=700,
                                                    height=250,
                                                    margin=dict(l=20, r=20, t=60, b=20)
                                                )
                                                
                                                # Store in session state for PDF export
                                                st.session_state[f'timer_table_{selected_portfolio_detail}'] = fig_timer
                                            except Exception as e:
                                                pass  # Silently ignore timer table creation errors
                                            
                                            # Also create timer tables for ALL portfolios for PDF export
                                            try:
                                                # Get all portfolio configs
                                                all_portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
                                                snapshot = st.session_state.get('multi_backtest_snapshot_data', {})
                                                last_rebalance_dates = snapshot.get('last_rebalance_dates', {})
                                                
                                                for portfolio_cfg in all_portfolio_configs:
                                                    portfolio_name = portfolio_cfg.get('name', 'Unknown')
                                                    
                                                    # Get rebalancing frequency for this portfolio
                                                    rebal_freq = portfolio_cfg.get('rebalancing_frequency', 'none')
                                                    rebal_freq = rebal_freq.lower()
                                                    rebal_freq = frequency_mapping.get(rebal_freq, rebal_freq)
                                                    
                                                    # Get last rebalance date for this portfolio
                                                    last_rebal_date = last_rebalance_dates.get(portfolio_name)
                                                    
                                                    if last_rebal_date and rebal_freq != 'none':
                                                        # Ensure last_rebal_date is a naive datetime object
                                                        if isinstance(last_rebal_date, str):
                                                            last_rebal_date = pd.to_datetime(last_rebal_date)
                                                        if hasattr(last_rebal_date, 'tzinfo') and last_rebal_date.tzinfo is not None:
                                                            last_rebal_date = last_rebal_date.replace(tzinfo=None)
                                                        
                                                        # Calculate next rebalance for this portfolio using the actual last rebalance date
                                                        # This matches the "Last Rebalance Allocation" date shown in the UI
                                                        if last_rebal_date:
                                                            # Calculate the next rebalance date from the last rebalance date
                                                            if rebal_freq == 'market_day':
                                                                next_date_port = last_rebal_date.date() + timedelta(days=1)
                                                            elif rebal_freq == 'calendar_day':
                                                                next_date_port = last_rebal_date.date() + timedelta(days=1)
                                                            elif rebal_freq == 'week':
                                                                next_date_port = last_rebal_date.date() + timedelta(weeks=1)
                                                            elif rebal_freq == '2weeks':
                                                                next_date_port = last_rebal_date.date() + timedelta(weeks=2)
                                                            elif rebal_freq == 'month':
                                                                if last_rebal_date.date().month == 12:
                                                                    next_date_port = last_rebal_date.date().replace(year=last_rebal_date.date().year + 1, month=1)
                                                                else:
                                                                    next_date_port = last_rebal_date.date().replace(month=last_rebal_date.date().month + 1)
                                                            elif rebal_freq == 'quarter':
                                                                new_month = last_rebal_date.date().month + 3
                                                                if new_month > 12:
                                                                    next_date_port = last_rebal_date.date().replace(year=last_rebal_date.date().year + 1, month=new_month - 12)
                                                                else:
                                                                    next_date_port = last_rebal_date.date().replace(month=new_month)
                                                            elif rebal_freq == 'semi':
                                                                new_month = last_rebal_date.date().month + 6
                                                                if new_month > 12:
                                                                    next_date_port = last_rebal_date.date().replace(year=last_rebal_date.date().year + 1, month=new_month - 12)
                                                                else:
                                                                    next_date_port = last_rebal_date.date().replace(month=new_month)
                                                            elif rebal_freq == 'year':
                                                                next_date_port = last_rebal_date.date().replace(year=last_rebal_date.date().year + 1)
                                                            else:
                                                                next_date_port = None
                                                            
                                                            if next_date_port:
                                                                time_diff = next_date_port - last_rebal_date.date()
                                                                time_until_port = time_diff.total_seconds() / (24 * 3600)
                                                                next_rebalance_datetime_port = datetime.combine(next_date_port, datetime.min.time())
                                                            else:
                                                                time_until_port = None
                                                                next_rebalance_datetime_port = None
                                                        else:
                                                            next_date_port = None
                                                            time_until_port = None
                                                            next_rebalance_datetime_port = None
                                                        
                                                        if next_date_port and time_until_port:
                                                            # Create timer data for this portfolio
                                                            timer_data_port = [
                                                                ['Time Until Next Rebalance', format_time_until(time_until_port)],
                                                                ['Target Rebalance Date', next_date_port.strftime("%B %d, %Y")],
                                                                ['Rebalancing Frequency', rebal_freq.replace('_', ' ').title()]
                                                            ]
                                                        else:
                                                            # Fallback timer data when calculation fails
                                                            timer_data_port = [
                                                                ['Last Rebalance Date', last_rebal_date.strftime("%B %d, %Y") if last_rebal_date else "Unknown"],
                                                                ['Rebalancing Frequency', rebal_freq.replace('_', ' ').title()],
                                                                ['Status', 'Timer calculation unavailable']
                                                            ]
                                                            
                                                            # Create timer table figure for this portfolio
                                                            fig_timer_port = go.Figure(data=[go.Table(
                                                                header=dict(
                                                                    values=['Parameter', 'Value'],
                                                                    fill_color='#2E86AB',
                                                                    align='center',
                                                                    font=dict(color='white', size=16, family='Arial Black')
                                                                ),
                                                                cells=dict(
                                                                    values=[[row[0] for row in timer_data_port], [row[1] for row in timer_data_port]],
                                                                    fill_color=[['#F8F9FA', '#FFFFFF'] * 2, ['#F8F9FA', '#FFFFFF'] * 2],
                                                                    align='center',
                                                                    font=dict(color='black', size=14, family='Arial'),
                                                                    height=40
                                                                )
                                                            )])
                                                            
                                                            fig_timer_port.update_layout(
                                                                title=dict(
                                                                    text=f"‚è∞ Next Rebalance Timer - {portfolio_name}",
                                                                    x=0.5,
                                                                    font=dict(size=18, color='#2E86AB', family='Arial Black')
                                                                ),
                                                                width=700,
                                                                height=250,
                                                                margin=dict(l=20, r=20, t=60, b=20)
                                                            )
                                                            
                                                            # Store in session state for PDF export
                                                            st.session_state[f'timer_table_{portfolio_name}'] = fig_timer_port
                                            except Exception as e:
                                                pass  # Silently ignore timer table creation errors
                                    else:
                                        st.write(f"  - last_rebal_date_for_timer: {last_rebal_date_for_timer}")
                                        st.write(f"  - rebalancing_frequency: {rebalancing_frequency}")
                                        st.write("  - Timer will not show")
                                        
                                except Exception as e:
                                    pass  # Silently ignore timer calculation errors

                                
                                # Table moved under the plot
                                # Add the "Rebalance as of today" table
                                try:
                                        # Get portfolio configuration for calculations
                                        portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
                                        portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == selected_portfolio_detail), None)
                                        
                                        if portfolio_cfg:
                                            # Use current portfolio value from backtest results instead of initial value
                                            portfolio_value = float(portfolio_cfg.get('initial_value', 0) or 0)  # fallback to initial value
                                            
                                            # Get current portfolio value from backtest results
                                            if 'multi_all_results' in st.session_state and st.session_state.multi_all_results:
                                                portfolio_results = st.session_state.multi_all_results.get(selected_portfolio_detail)
                                                if portfolio_results:
                                                    # Use the Final Value (with additions) for Multi Backtest - total portfolio value including all cash additions and compounding
                                                    if isinstance(portfolio_results, dict) and 'with_additions' in portfolio_results:
                                                        # Get the final value from the with_additions series (includes all cash additions and compounding)
                                                        final_value = portfolio_results['with_additions'].iloc[-1]
                                                        if not pd.isna(final_value) and final_value > 0:
                                                            portfolio_value = float(final_value)
                                                    elif isinstance(portfolio_results, dict) and 'no_additions' in portfolio_results:
                                                        # Fallback to no_additions if with_additions not available
                                                        final_value = portfolio_results['no_additions'].iloc[-1]
                                                        if not pd.isna(final_value) and final_value > 0:
                                                            portfolio_value = float(final_value)
                                                    elif isinstance(portfolio_results, pd.Series):
                                                        # Get the latest value from the series
                                                        latest_value = portfolio_results.iloc[-1]
                                                        if not pd.isna(latest_value) and latest_value > 0:
                                                            portfolio_value = float(latest_value)
                                            
                                            # Get raw data for price calculations
                                            raw_data = st.session_state.get('multi_backtest_raw_data', {})
                                            
                                            def _price_on_or_before(df, target_date):
                                                try:
                                                    idx = df.index[df.index <= pd.to_datetime(target_date)]
                                                    if len(idx) == 0:
                                                        return None
                                                    return float(df.loc[idx[-1], 'Close'])
                                                except Exception:
                                                    return None

                                            def build_table_from_alloc(alloc_dict, price_date, label):
                                                rows = []
                                                for tk in sorted(alloc_dict.keys()):
                                                    alloc_pct = float(alloc_dict.get(tk, 0))
                                                    if tk == 'CASH':
                                                        price = None
                                                        shares = 0.0
                                                        total_val = portfolio_value * alloc_pct
                                                    else:
                                                        df = raw_data.get(tk)
                                                        price = None
                                                        if isinstance(df, pd.DataFrame) and 'Close' in df.columns and not df['Close'].dropna().empty:
                                                            if price_date is None:
                                                                # use latest price
                                                                try:
                                                                    price = float(df['Close'].iloc[-1])
                                                                except Exception:
                                                                    price = None
                                                            else:
                                                                price = _price_on_or_before(df, price_date)
                                                        try:
                                                            if price and price > 0:
                                                                allocation_value = portfolio_value * alloc_pct
                                                                # allow fractional shares shown to 1 decimal place
                                                                shares = round(allocation_value / price, 1)
                                                                total_val = shares * price
                                                            else:
                                                                shares = 0.0
                                                                total_val = portfolio_value * alloc_pct
                                                        except Exception:
                                                            shares = 0.0
                                                            total_val = portfolio_value * alloc_pct

                                                    pct_of_port = (total_val / portfolio_value * 100) if portfolio_value > 0 else 0
                                                    rows.append({
                                                        'Ticker': tk,
                                                        'Allocation %': alloc_pct * 100,
                                                        'Price ($)': price if price is not None else float('nan'),
                                                        'Shares': float(shares) if shares is not None else 0.0,
                                                        'Total Value ($)': total_val,
                                                        '% of Portfolio': pct_of_port,
                                                    })

                                                df_table = pd.DataFrame(rows).set_index('Ticker')
                                                # Decide whether to show CASH row: hide if Total Value is zero or Shares zero/NaN
                                                df_display = df_table.copy()
                                                show_cash = False
                                                if 'CASH' in df_display.index:
                                                    cash_val = None
                                                    if 'Total Value ($)' in df_display.columns:
                                                        cash_val = df_display.at['CASH', 'Total Value ($)']
                                                    elif 'Shares' in df_display.columns:
                                                        cash_val = df_display.at['CASH', 'Shares']
                                                    try:
                                                        show_cash = bool(cash_val and not pd.isna(cash_val) and cash_val != 0)
                                                    except Exception:
                                                        show_cash = False
                                                    if not show_cash:
                                                        df_display = df_display.drop('CASH')

                                                # formatting for display
                                                fmt = {
                                                    'Allocation %': '{:,.1f}%',
                                                    'Price ($)': '${:,.2f}',
                                                    'Shares': '{:,.1f}',
                                                    'Total Value ($)': '${:,.2f}',
                                                    '% of Portfolio': '{:,.2f}%'
                                                }
                                                try:
                                                    st.markdown(f"**{label}**")
                                                    
                                                    # Add total row
                                                    total_alloc_pct = df_display['Allocation %'].sum()
                                                    total_value = df_display['Total Value ($)'].sum()
                                                    total_port_pct = df_display['% of Portfolio'].sum()

                                                    total_row = pd.DataFrame({
                                                        'Allocation %': [total_alloc_pct],
                                                        'Price ($)': [float('nan')],
                                                        'Shares': [float('nan')],
                                                        'Total Value ($)': [total_value],
                                                        '% of Portfolio': [total_port_pct]
                                                    }, index=['TOTAL'])

                                                    df_display = pd.concat([df_display, total_row])
                                                    
                                                    sty = df_display.style.format(fmt)
                                                    if 'CASH' in df_table.index and show_cash:
                                                        def _highlight_cash_row(s):
                                                            if s.name == 'CASH':
                                                                return ['background-color: #006400; color: white; font-weight: bold;' for _ in s]
                                                            return [''] * len(s)
                                                        sty = sty.apply(_highlight_cash_row, axis=1)

                                                    # Highlight TOTAL row
                                                    def _highlight_total_row(s):
                                                        if s.name == 'TOTAL':
                                                            return ['background-color: #1f4e79; color: white; font-weight: bold;' for _ in s]
                                                        return [''] * len(s)
                                                    sty = sty.apply(_highlight_total_row, axis=1)
                                                    
                                                    st.dataframe(sty, use_container_width=True)
                                                except Exception:
                                                    st.dataframe(df_display, use_container_width=True)
                                            
                                            # "Rebalance as of today" table (use momentum-based calculated weights)
                                            build_table_from_alloc(today_weights, None, f"Target Allocation if Rebalanced Today")
                                            
                                            # Store the table for PDF export AFTER the function call
                                            # Create a Plotly table figure for PDF export (EXACT same approach as fig_stats)
                                            try:
                                                # Get the DataFrame that was just created by build_table_from_alloc
                                                # We need to recreate it here since it's not returned by the function
                                                rows = []
                                                for tk in sorted(today_weights.keys()):
                                                    alloc_pct = float(today_weights.get(tk, 0))
                                                    if tk == 'CASH':
                                                        price = None
                                                        shares = 0.0
                                                        total_val = portfolio_value * alloc_pct
                                                    else:
                                                        df = raw_data.get(tk)
                                                        price = None
                                                        if isinstance(df, pd.DataFrame) and 'Close' in df.columns and not df['Close'].dropna().empty:
                                                            try:
                                                                price = float(df['Close'].iloc[-1])
                                                            except Exception:
                                                                price = None
                                                        try:
                                                            if price and price > 0:
                                                                allocation_value = portfolio_value * alloc_pct
                                                                shares = round(allocation_value / price, 1)
                                                                total_val = shares * price
                                                            else:
                                                                shares = 0.0
                                                                total_val = portfolio_value * alloc_pct
                                                        except Exception:
                                                            shares = 0.0
                                                            total_val = portfolio_value * alloc_pct

                                                    pct_of_port = (total_val / portfolio_value * 100) if portfolio_value > 0 else 0
                                                    rows.append({
                                                        'Ticker': tk,
                                                        'Allocation %': alloc_pct * 100,
                                                        'Price ($)': price if price is not None else float('nan'),
                                                        'Shares': float(shares) if shares is not None else 0.0,
                                                        'Total Value ($)': total_val,
                                                        '% of Portfolio': pct_of_port,
                                                    })

                                                df_table = pd.DataFrame(rows).set_index('Ticker')
                                                df_display = df_table.copy()
                                                
                                                # Remove CASH if it has zero value
                                                if 'CASH' in df_display.index:
                                                    cash_val = df_display.at['CASH', 'Total Value ($)']
                                                    if not (cash_val and not pd.isna(cash_val) and cash_val != 0):
                                                        df_display = df_display.drop('CASH')
                                                
                                                # Create Plotly table figure with ticker column included
                                                # Reset index to include ticker as a column
                                                df_display_with_ticker = df_display.reset_index()
                                                
                                                # Format the data to ensure 2 decimal places for display (same as PDF tables)
                                                formatted_values = []
                                                for col in df_display_with_ticker.columns:
                                                    if col in ['Price ($)', 'Total Value ($)', '% of Portfolio']:
                                                        # Format monetary and percentage values to 2 decimal places
                                                        formatted_values.append([f"{df_display_with_ticker[col][i]:.2f}" if pd.notna(df_display_with_ticker[col][i]) else "" for i in range(len(df_display_with_ticker))])
                                                    elif col == 'Shares':
                                                        # Format shares to 1 decimal place
                                                        formatted_values.append([f"{df_display_with_ticker[col][i]:.1f}" if pd.notna(df_display_with_ticker[col][i]) else "" for i in range(len(df_display_with_ticker))])
                                                    elif col == 'Allocation %':
                                                        # Format allocation to 2 decimal places
                                                        formatted_values.append([f"{df_display_with_ticker[col][i]:.2f}" if pd.notna(df_display_with_ticker[col][i]) else "" for i in range(len(df_display_with_ticker))])
                                                    else:
                                                        # Keep other columns as is
                                                        formatted_values.append([str(df_display_with_ticker[col][i]) if pd.notna(df_display_with_ticker[col][i]) else "" for i in range(len(df_display_with_ticker))])
                                                
                                                fig_alloc_table = go.Figure(data=[go.Table(
                                                    header=dict(values=list(df_display_with_ticker.columns),
                                                               fill_color='paleturquoise',
                                                               align='left',
                                                               font=dict(size=12)),
                                                    cells=dict(values=formatted_values,
                                                              fill_color='lavender',
                                                              align='left',
                                                              font=dict(size=11))
                                                )])
                                                fig_alloc_table.update_layout(
                                                    title=f"Target Allocation if Rebalanced Today - {selected_portfolio_detail}",
                                                    margin=dict(t=30, b=10, l=10, r=10),
                                                    height=400
                                                )
                                                table_key = f"alloc_table_{selected_portfolio_detail}"
                                                st.session_state[table_key] = fig_alloc_table
                                            except Exception as e:
                                                pass

                                except Exception as e:
                                    pass
                                
                                # Note: Allocation tables are now handled by the PDF generation function
                                # to avoid duplication. The tables are created automatically when needed.
                                
                                    
                        except Exception as e:
                            pass
                    else:
                        st.info("No allocation history available for this portfolio to show allocation plots.")
                else:
                    # Fallback: show table and plots based on last known allocations so UI stays visible
                    allocs_for_portfolio = st.session_state.multi_all_allocations.get(selected_portfolio_detail) if 'multi_all_allocations' in st.session_state else None
                    if not allocs_for_portfolio:
                        st.info("No allocation or momentum metrics available for this portfolio.")
                    else:
                        alloc_dates = sorted(list(allocs_for_portfolio.keys()))
                        last_date = alloc_dates[-1]
                        last_alloc = allocs_for_portfolio.get(last_date, {})
                        metrics_records_fb = []
                        for ticker, alloc in last_alloc.items():
                            record = {'Date': last_date, 'Ticker': ticker, 'Momentum': np.nan, 'Beta': np.nan, 'Volatility': np.nan, 'Calculated_Weight': alloc}
                            metrics_records_fb.append(record)

                        metrics_df = pd.DataFrame(metrics_records_fb)
                        metrics_df.set_index(['Date', 'Ticker'], inplace=True)
                        metrics_df_display = metrics_df.copy()
                        if 'Momentum' in metrics_df_display.columns:
                            metrics_df_display['Momentum'] = metrics_df_display['Momentum'].fillna(0) * 100
                        if 'Calculated_Weight' in metrics_df_display.columns:
                            metrics_df_display['Calculated_Weight'] = metrics_df_display['Calculated_Weight'].fillna(0) * 100
                            metrics_df_display['Volatility'] = metrics_df_display['Volatility'].fillna(np.nan) * 100

                        def color_momentum(val):
                            if isinstance(val, (int, float)):
                                color = 'green' if val > 0 else 'red'
                                return f'color: {color}'
                            return ''

                        def highlight_metrics_rows(s):
                            date_str = s.name[0]
                            if s.name[1] == 'CASH':
                                return ['background-color: #006400; color: white; font-weight: bold;' for _ in s]
                            unique_dates = list(metrics_df_display.index.get_level_values('Date').unique())
                            is_even = unique_dates.index(date_str) % 2 == 0
                            bg_color = 'background-color: #0e1117' if is_even else 'background-color: #262626'
                            return [bg_color] * len(s)

                        fmt_map = {}
                        if 'Momentum' in metrics_df_display.columns:
                            fmt_map['Momentum'] = '{:,.0f}%'
                        if 'Beta' in metrics_df_display.columns:
                            fmt_map['Beta'] = '{:,.2f}'
                        if 'Volatility' in metrics_df_display.columns:
                            fmt_map['Volatility'] = '{:,.2f}%'
                        if 'Calculated_Weight' in metrics_df_display.columns:
                            fmt_map['Calculated_Weight'] = '{:,.0f}%'

                        styler_metrics = metrics_df_display.style.apply(highlight_metrics_rows, axis=1)
                        if 'Momentum' in metrics_df_display.columns:
                            styler_metrics = styler_metrics.map(color_momentum, subset=['Momentum'])
                        if fmt_map:
                            styler_metrics = styler_metrics.format(fmt_map)
                        st.dataframe(styler_metrics, use_container_width=True)

                        # Also show allocation plots for the last allocation snapshot
                        try:
                            final_date = last_date
                            final_alloc = last_alloc
                            
                            # For fallback, we only have one allocation snapshot, so show it as both current and last rebalance
                            # This is a limitation when we don't have historical rebalancing data
                            # Use the same prepare_bar_data function as page 2 for consistency
                            def prepare_bar_data_fallback(d):
                                labels = []
                                values = []
                                for k, v in sorted(d.items(), key=lambda x: (-x[1], x[0])):
                                    try:
                                        val = float(v) * 100
                                        if val > 0:  # Only include tickers with allocation > 0%
                                            labels.append(k)
                                            values.append(val)
                                    except Exception:
                                        pass  # Skip invalid values
                                return labels, values
                            
                            labels_final, vals_final = prepare_bar_data_fallback(final_alloc)
                            
                            col_plot1, col_plot2 = st.columns(2)
                            with col_plot1:
                                st.markdown(f"**Target Allocation at Last Rebalance ({final_date.date()})**")
                                fig_rebal_small = go.Figure(data=[go.Pie(
                                    labels=labels_final,
                                    values=vals_final,
                                    hole=0.35
                                )])
                                fig_rebal_small.update_traces(textinfo='percent+label')
                                fig_rebal_small.update_layout(template='plotly_dark', margin=dict(t=10))
                                st.plotly_chart(fig_rebal_small, key=f"alloc_rebal_small_fallback_{selected_portfolio_detail}")
                            with col_plot2:
                                st.markdown(f"**Portfolio Evolution (Current Allocation)**")
                                fig_today_small = go.Figure(data=[go.Pie(
                                    labels=labels_final,
                                    values=vals_final,
                                    hole=0.35
                                )])
                                fig_today_small.update_traces(textinfo='percent+label')
                                fig_today_small.update_layout(template='plotly_dark', margin=dict(t=10))
                                st.plotly_chart(fig_today_small, key=f"alloc_today_small_fallback_{selected_portfolio_detail}")
                        except Exception as e:
                            pass

        else:
            st.info("Configuration is ready. Press 'Run Backtest' to see results.")
    
    # Console log UI removed
    
    # Performance Debug Section
    if st.session_state.get('multi_backtest_ran', False):
        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button("üîÑ Clear Cache", help="Clear all cached charts and data"):
                # Clear all cached data
                keys_to_clear = [key for key in st.session_state.keys() if key.startswith(('multi_allocation_evolution_chart_', 'processed_allocations_df_', 'processed_allocations_tickers_', 'pie_chart_'))]
                for key in keys_to_clear:
                    del st.session_state[key]
                st.success("Cache cleared. Charts will be recreated on next selection.")
                st.rerun()
        
        with col2:
            cached_charts = len([key for key in st.session_state.keys() if key.startswith('multi_allocation_evolution_chart_')])
            st.metric("Cached Charts", cached_charts)
        
        with col3:
            cached_dfs = len([key for key in st.session_state.keys() if key.startswith('processed_allocations_df_')])
            st.metric("Cached DataFrames", cached_dfs)
    
    # NEW: Individual Ticker Analysis with MA from Backtest - INDEPENDENT SECTION
    if 'multi_all_allocations' in st.session_state and st.session_state.multi_all_allocations:
        st.markdown("---")
        st.markdown("### üìà Individual Ticker Analysis")
        st.markdown("Analyze individual tickers with their MA data from the backtest.")
        
        # Get all available portfolio names
        available_portfolio_names = [cfg.get('name', 'Portfolio') for cfg in st.session_state.get('multi_backtest_portfolio_configs', [])]
        extra_names = [n for n in st.session_state.get('multi_all_results', {}).keys() if n not in available_portfolio_names]
        all_portfolio_names_ticker = available_portfolio_names + extra_names
        
        if all_portfolio_names_ticker:
            # Portfolio selector for ticker analysis
            selected_portfolio_ticker = st.selectbox(
                "Select portfolio for ticker analysis:",
                all_portfolio_names_ticker,
                key="ticker_analysis_portfolio_selector",
                help="Choose which portfolio to analyze tickers from"
            )
            
            # Get portfolio configuration to check MA settings
            portfolio_configs = st.session_state.get('multi_backtest_portfolio_configs', [])
            portfolio_cfg = next((cfg for cfg in portfolio_configs if cfg.get('name') == selected_portfolio_ticker), None)
            
            if portfolio_cfg:
                use_sma_filter = portfolio_cfg.get('use_sma_filter', False)
                sma_window = portfolio_cfg.get('sma_window', 200)
                ma_type = portfolio_cfg.get('ma_type', 'SMA')
                
                # Get available tickers from the portfolio
                portfolio_tickers = []
                if selected_portfolio_ticker in st.session_state.multi_all_allocations:
                    allocation_data = st.session_state.multi_all_allocations[selected_portfolio_ticker]
                    if allocation_data:
                        # Get all unique tickers from allocation data
                        all_tickers = set()
                        for date, allocs in allocation_data.items():
                            all_tickers.update(allocs.keys())
                        portfolio_tickers = sorted([t for t in all_tickers if t != 'CASH' and t])
                
                if portfolio_tickers:
                    # Ticker selector
                    selected_ticker = st.selectbox(
                        "Select Ticker to Analyze:",
                        options=portfolio_tickers,
                        key=f"ticker_selector_{selected_portfolio_ticker}",
                        help="Choose a ticker from this portfolio to see its price vs MA analysis"
                    )
                
                    if selected_ticker:
                        # Get raw data for this ticker
                        raw_data = st.session_state.get('multi_backtest_raw_data', {})
                        
                        if raw_data and selected_ticker in raw_data:
                            ticker_data = raw_data[selected_ticker]
                            
                            if isinstance(ticker_data, pd.DataFrame) and 'Close' in ticker_data.columns:
                                # Create the analysis chart
                                fig_ticker = go.Figure()
                                
                                # Add price line
                                fig_ticker.add_trace(go.Scatter(
                                    x=ticker_data.index,
                                    y=ticker_data['Close'],
                                    mode='lines',
                                    name=f'{selected_ticker} Price',
                                    line=dict(color='#00ff88', width=2),
                                    hovertemplate=f"<b>{selected_ticker}</b><br>Price: $%{{y:.2f}}<br>Date: %{{x|%Y-%m-%d}}<extra></extra>"
                                ))
                                
                                # Add MA line if MA filter is enabled and ticker is included in MA filter
                                if use_sma_filter:
                                    # Check if this ticker is included in MA filter
                                    ticker_included_in_sma = True  # Default
                                    for stock in portfolio_cfg.get('stocks', []):
                                        if stock.get('ticker') == selected_ticker:
                                            ticker_included_in_sma = stock.get('include_in_sma_filter', True)
                                            break
                                    
                                    if ticker_included_in_sma:
                                        # Calculate MA using the same type and window as backtest
                                        if ma_type == 'EMA':
                                            ma_data = calculate_ema(ticker_data, sma_window)
                                        else:
                                            ma_data = ticker_data['Close'].rolling(window=sma_window, min_periods=sma_window).mean()
                                        
                                        fig_ticker.add_trace(go.Scatter(
                                            x=ticker_data.index,
                                            y=ma_data,
                                            mode='lines',
                                            name=f'{sma_window}-day {ma_type}',
                                            line=dict(color='#ff6b6b', width=2, dash='dash'),
                                            hovertemplate=f"<b>{sma_window}-day {ma_type}</b><br>Value: $%{{y:.2f}}<br>Date: %{{x|%Y-%m-%d}}<extra></extra>"
                                        ))
                                        
                                        # Add MA status indicator
                                        latest_price = ticker_data['Close'].iloc[-1]
                                        latest_ma = ma_data.iloc[-1]
                                        status = "ABOVE" if latest_price >= latest_ma else "BELOW"
                                        status_color = "#00ff88" if status == "ABOVE" else "#ff6b6b"
                                        
                                        st.markdown(f"""
                                        <div style='padding:10px;background:#1a1a1a;border-radius:6px;margin:10px 0;'>
                                            <strong style='color:{status_color};'>{ma_type} Status: {status}</strong><br>
                                            <span style='color:#cccccc;'>Current Price: ${latest_price:.2f}</span><br>
                                            <span style='color:#cccccc;'>{sma_window}-day {ma_type}: ${latest_ma:.2f}</span><br>
                                            <span style='color:#cccccc;'>Difference: ${(latest_price - latest_ma):.2f} ({(latest_price/latest_ma - 1)*100:.1f}%)</span>
                                        </div>
                                        """, unsafe_allow_html=True)
                                    else:
                                        st.info(f"‚ÑπÔ∏è {selected_ticker} is excluded from MA filter in this portfolio.")
                                else:
                                    st.info("‚ÑπÔ∏è MA filter is not enabled for this portfolio.")
                            
                                # Update layout
                                fig_ticker.update_layout(
                                    title=f"{selected_ticker} Price Analysis",
                                    xaxis_title="Date",
                                    yaxis_title="Price ($)",
                                    template='plotly_dark',
                                    height=500,
                                    hovermode='x unified'
                                )
                                
                                # Add time range selector with 5Y option (no rangeslider for better zoom)
                                fig_ticker.update_layout(
                                    xaxis=dict(
                                        rangeselector=dict(
                                            buttons=list([
                                                dict(count=1, label="1M", step="month", stepmode="backward"),
                                                dict(count=3, label="3M", step="month", stepmode="backward"),
                                                dict(count=6, label="6M", step="month", stepmode="backward"),
                                                dict(count=1, label="1Y", step="year", stepmode="backward"),
                                                dict(count=5, label="5Y", step="year", stepmode="backward"),
                                                dict(step="all", label="All")
                                            ])
                                        ),
                                        rangeslider=dict(visible=False),
                                        type="date"
                                    )
                                )
                                
                                st.plotly_chart(fig_ticker, use_container_width=True, key=f"ticker_analysis_{selected_ticker}_{selected_portfolio_ticker}")
                                
                                # Add allocation info for this ticker
                                if selected_portfolio_ticker in st.session_state.multi_all_allocations:
                                    allocation_data = st.session_state.multi_all_allocations[selected_portfolio_ticker]
                                    if allocation_data:
                                        # Get latest allocation for this ticker
                                        latest_date = max(allocation_data.keys())
                                        latest_allocation = allocation_data[latest_date].get(selected_ticker, 0)
                                        
                                        st.markdown(f"""
                                        <div style='padding:8px;background:#2a2a2a;border-radius:4px;margin-top:10px;'>
                                            <strong style='color:#00ff88;'>Current Allocation:</strong> {latest_allocation*100:.1f}% of portfolio
                                        </div>
                                        """, unsafe_allow_html=True)
                            else:
                                st.warning(f"No price data available for {selected_ticker}.")
                        else:
                            st.warning(f"No raw data available for {selected_ticker}.")
                else:
                    st.info("No tickers found in this portfolio's allocation data.")
            else:
                st.warning("Portfolio configuration not found.")
    
    # Portfolio Allocation Evolution Chart Section - EXACTLY LIKE MAIN CHARTS
    if 'multi_all_allocations' in st.session_state and st.session_state.multi_all_allocations:
        st.markdown("---")
        st.markdown("**üìà Portfolio Allocation Evolution**")
        
        # Get all available portfolio names
        available_portfolio_names = [cfg.get('name', 'Portfolio') for cfg in st.session_state.get('multi_backtest_portfolio_configs', [])]
        extra_names = [n for n in st.session_state.get('multi_all_results', {}).keys() if n not in available_portfolio_names]
        all_portfolio_names = available_portfolio_names + extra_names
        
        if all_portfolio_names:
            # Show the selector first
            selected_portfolio_evolution = st.selectbox(
                "Select portfolio for allocation evolution chart",
                all_portfolio_names,
                key="allocation_evolution_portfolio_selector",
                help="Choose which portfolio to show allocation evolution over time"
            )
            
            # Hover mode option for allocation evolution chart - EXACTLY LIKE MAIN CHARTS
            try:
                show_closest_only_allocation = st.checkbox(
                    "Show Only Closest Allocation on Hover",
                    value=False,
                    help="When enabled, hovering will show only the allocation line closest to your cursor instead of all allocations.",
                    key="allocation_evolution_closest_hover"
                )
            except Exception as e:
                st.warning(f"Error with allocation hover checkbox: {e}")
                show_closest_only_allocation = False
            
            # Create allocation evolution chart - EXACTLY LIKE MAIN CHARTS
            if selected_portfolio_evolution and selected_portfolio_evolution in st.session_state.multi_all_allocations:
                allocs_data = st.session_state.multi_all_allocations[selected_portfolio_evolution]
                
                # Convert to DataFrame for easier processing
                alloc_df = pd.DataFrame(allocs_data).T
                alloc_df.index = pd.to_datetime(alloc_df.index)
                alloc_df = alloc_df.sort_index()
                
                # Get all unique tickers (excluding None)
                all_tickers = set()
                for date, allocs in allocs_data.items():
                    for ticker in allocs.keys():
                        if ticker is not None:
                            all_tickers.add(ticker)
                all_tickers = sorted(list(all_tickers))
                
                # Fill missing values with 0 for unavailable assets
                alloc_df = alloc_df.fillna(0)
                
                # Convert to percentages
                alloc_df = alloc_df * 100
                
                if all_tickers:
                    # Create figure - EXACTLY LIKE MAIN CHARTS
                    fig_evolution = go.Figure()
                    
                    # Color palette for different tickers
                    colors = [
                        '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',
                        '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf',
                        '#aec7e8', '#ffbb78', '#98df8a', '#ff9896', '#c5b0d5'
                    ]
                    
                    # Add traces - EXACTLY LIKE MAIN CHARTS
                    for i, ticker in enumerate(all_tickers):
                        if ticker in alloc_df.columns:
                            # Get the allocation data for this ticker
                            ticker_data = alloc_df[ticker].dropna()
                            
                            if not ticker_data.empty:  # Only add if we have data
                                # EXACTLY LIKE MAIN CHARTS - Set hover mode based on user preference with fallback
                                try:
                                    current_hover_mode_alloc = "closest" if show_closest_only_allocation else "x unified"
                                except NameError:
                                    current_hover_mode_alloc = "x unified"
                                
                                fig_evolution.add_trace(go.Scatter(
                                    x=ticker_data.index,
                                    y=ticker_data.values,
                                    mode='lines',
                                    name=ticker,
                                    line=dict(color=colors[i % len(colors)], width=2),
                                    hovertemplate=f"<b>{ticker}</b><br>Allocation: %{{y:.1f}}%<br>Date: %{{x|%Y-%m-%d}}<extra></extra>" if show_closest_only_allocation else f"<b>{ticker}</b><br>Allocation: %{{y:.1f}}%<br>Date: %{{x|%Y-%m-%d}}<extra></extra>",
                                    hoverinfo='text'
                                ))
                    
                    # Update layout - EXACTLY LIKE MAIN CHARTS
                    try:
                        hover_mode_alloc = "closest" if show_closest_only_allocation else "x unified"
                    except NameError:
                        hover_mode_alloc = "x unified"
                    
                    fig_evolution.update_layout(
                        title=f"Portfolio Allocation Evolution - {selected_portfolio_evolution}",
                        xaxis_title="Date",
                        yaxis_title="Allocation (%)",
                        template='plotly_dark',
                        height=600,
                        hovermode=hover_mode_alloc,
                        hoverdistance=20,
                        spikedistance=100,
                        # Improve legend layout to prevent name truncation
                        legend=dict(
                            orientation="v",
                            yanchor="top",
                            y=1,
                            xanchor="left",
                            x=1.02,
                            font=dict(size=10),
                            itemwidth=30
                        ),
                        margin=dict(t=120, l=80, r=80, b=80)  # Standardized margins for alignment
                    )
                    
                    # Add range selector
                    fig_evolution.update_layout(
                        xaxis=dict(
                            rangeselector=dict(
                                buttons=list([
                                    dict(count=1, label="1M", step="month", stepmode="backward"),
                                    dict(count=3, label="3M", step="month", stepmode="backward"),
                                    dict(count=6, label="6M", step="month", stepmode="backward"),
                                    dict(count=1, label="1Y", step="year", stepmode="backward"),
                                    dict(count=5, label="5Y", step="year", stepmode="backward"),
                                    dict(step="all")
                                ])
                            ),
                            rangeslider=dict(visible=False),
                            type="date"
                        )
                    )
                    
                    # Display the chart
                    st.plotly_chart(fig_evolution, use_container_width=True)
                else:
                    st.warning(f"No allocation data found for {selected_portfolio_evolution}")
            else:
                st.info("Please select a portfolio to view allocation evolution")
        else:
            st.info("No portfolios available for allocation evolution")
    
    # PE Ratio Evolution Chart Section
    if 'multi_all_allocations' in st.session_state and st.session_state.multi_all_allocations:
        st.markdown("---")
        st.markdown("**üìä Portfolio PE Ratio Evolution**")
        
        # Get all available portfolio names
        available_portfolio_names = [cfg.get('name', 'Portfolio') for cfg in st.session_state.get('multi_backtest_portfolio_configs', [])]
        extra_names = [n for n in st.session_state.get('multi_all_results', {}).keys() if n not in available_portfolio_names]
        all_portfolio_names = available_portfolio_names + extra_names
        
        if all_portfolio_names:
            selected_portfolio_pe = st.selectbox(
                "Select Portfolio for PE Ratio Analysis:",
                all_portfolio_names,
                key="multi_backtest_pe_portfolio_selector"
            )
            
            if selected_portfolio_pe:
                # Get allocation data for the selected portfolio
                allocs_data = st.session_state.multi_all_allocations.get(selected_portfolio_pe, {})
                
                if allocs_data:
                    try:
                        # Create PE ratio evolution chart
                        fig_pe = go.Figure()
                        
                        # Get all unique tickers and their allocations over time (exclude CASH)
                        all_tickers = set()
                        for date, allocs in allocs_data.items():
                            for ticker in allocs.keys():
                                if ticker is not None and ticker != 'CASH':
                                    all_tickers.add(ticker)
                        all_tickers = sorted(list(all_tickers))
                        
                        if all_tickers:
                            # Use batch download for PE data (much faster!)
                            pe_data = get_multiple_tickers_info_batch(all_tickers)
                            # Extract PE ratios from batch results
                            pe_data = {ticker: info.get('trailingPE', None) for ticker, info in pe_data.items() if info.get('trailingPE') is not None and info.get('trailingPE') > 0}
                            
                            # Initialize historical PE data as empty (placeholder for future implementation)
                            historical_pe_data = {}
                            
                            if pe_data:
                                # Calculate daily weighted PE ratio using the same approach as portfolio allocation evolution
                                dates = sorted(allocs_data.keys())
                                
                                # Show data range info
                                if dates:
                                    st.info(f"üìÖ **PE Data Range:** {dates[0].strftime('%Y-%m-%d')} to {dates[-1].strftime('%Y-%m-%d')}")
                                    
                                    # Check if data is recent
                                    last_date = dates[-1]
                                    current_date = pd.Timestamp.now()
                                    days_behind = (current_date - last_date).days
                                    
                                    if days_behind > 7:  # More than a week behind
                                        st.warning(f"‚ö†Ô∏è **Data is {days_behind} days behind current date.** To get the latest PE ratios, re-run your backtest to refresh the allocation data.")
                                
                                portfolio_pe_ratios = []
                                
                                for date in dates:
                                    allocs = allocs_data[date]
                                    weighted_pe = 0
                                    total_weight = 0
                                    
                                    # Check if portfolio is in cash (100% cash or no stock allocations)
                                    stock_allocation = sum(weight for ticker, weight in allocs.items() if ticker != 'CASH' and weight > 0)
                                    
                                    if stock_allocation == 0:
                                        # Portfolio is in cash - no PE ratio applicable
                                        portfolio_pe_ratios.append(None)
                                    else:
                                        # Calculate weighted PE only for stock allocations (daily precision)
                                        for ticker, weight in allocs.items():
                                            if ticker != 'CASH' and weight > 0:
                                                # Try to use historical PE data first, fallback to current PE
                                                ticker_pe = None
                                                if ticker in historical_pe_data:
                                                    # Find the closest historical PE date to current date
                                                    hist_dates = list(historical_pe_data[ticker].keys())
                                                    if hist_dates:
                                                        # Find the closest date before or on the current date
                                                        valid_dates = [d for d in hist_dates if d <= date]
                                                        if valid_dates:
                                                            closest_date = max(valid_dates)
                                                            ticker_pe = historical_pe_data[ticker][closest_date]
                                                
                                                # Fallback to current PE if no historical data
                                                if ticker_pe is None and ticker in pe_data:
                                                    ticker_pe = pe_data[ticker]
                                                
                                                if ticker_pe is not None and ticker_pe > 0:
                                                    weighted_pe += ticker_pe * weight
                                                    total_weight += weight
                                        
                                        if total_weight > 0:
                                            portfolio_pe_ratios.append(weighted_pe / total_weight)
                                        else:
                                            portfolio_pe_ratios.append(None)
                                
                                # Use all data including None values to show proper gaps for cash periods
                                if portfolio_pe_ratios:
                                    # Add PE ratio line with gaps for cash periods (smooth line, no markers)
                                    fig_pe.add_trace(go.Scatter(
                                        x=dates,
                                        y=portfolio_pe_ratios,  # Include None values to show gaps
                                        mode='lines',  # Smooth line only, no markers
                                        name=f'Portfolio PE Ratio',
                                        line=dict(color='#00ff88', width=3),  # Changed to bright green
                                        hovertemplate=(
                                            '<b>%{fullData.name}</b><br>' +
                                            'Date: %{x|%Y-%m-%d}<br>' +
                                            'PE Ratio: %{y:.2f}<br>' +
                                            '<extra></extra>'
                                        ),
                                        connectgaps=False  # Show gaps when in cash
                                    ))
                                    
                                    
                                    # Calculate statistical metrics (filter out None values for calculations)
                                    clean_pe_ratios = [pe for pe in portfolio_pe_ratios if pe is not None]
                                    if clean_pe_ratios:
                                        median_pe = np.median(clean_pe_ratios)
                                        std_pe = np.std(clean_pe_ratios)
                                        mean_pe = np.mean(clean_pe_ratios)
                                    else:
                                        median_pe = std_pe = mean_pe = 0
                                    
                                    # Add statistical reference lines
                                    fig_pe.add_hline(y=median_pe, line_dash="dash", line_color="blue", 
                                                   annotation_text=f"Median PE: {median_pe:.2f}", annotation_position="top right")
                                    fig_pe.add_hline(y=mean_pe, line_dash="dot", line_color="purple", 
                                                   annotation_text=f"Mean PE: {mean_pe:.2f}", annotation_position="top right")
                                    
                                    # Add multiple standard deviation lines
                                    fig_pe.add_hline(y=mean_pe + std_pe, line_dash="dash", line_color="cyan", 
                                                   annotation_text=f"+1œÉ: {mean_pe + std_pe:.2f}", annotation_position="top right")
                                    fig_pe.add_hline(y=mean_pe - std_pe, line_dash="dash", line_color="green", 
                                                   annotation_text=f"-1œÉ: {mean_pe - std_pe:.2f}", annotation_position="top right")
                                    
                                    # Add 2 standard deviation lines
                                    fig_pe.add_hline(y=mean_pe + 2*std_pe, line_dash="dot", line_color="red", 
                                                   annotation_text=f"+2œÉ: {mean_pe + 2*std_pe:.2f}", annotation_position="top right")
                                    fig_pe.add_hline(y=mean_pe - 2*std_pe, line_dash="dot", line_color="lightgreen", 
                                                   annotation_text=f"-2œÉ: {mean_pe - 2*std_pe:.2f}", annotation_position="top right")
                                    
                                    # Add 3 standard deviation lines
                                    fig_pe.add_hline(y=mean_pe + 3*std_pe, line_dash="dashdot", line_color="darkred", 
                                                   annotation_text=f"+3œÉ: {mean_pe + 3*std_pe:.2f}", annotation_position="top right")
                                    fig_pe.add_hline(y=mean_pe - 3*std_pe, line_dash="dashdot", line_color="darkgreen", 
                                                   annotation_text=f"-3œÉ: {mean_pe - 3*std_pe:.2f}", annotation_position="top right")
                                    
                                    # Update layout with proper date range
                                    fig_pe.update_layout(
                                        title=f"Portfolio PE Ratio Evolution - {selected_portfolio_pe}",
                                        xaxis_title="Date",
                                        yaxis_title="PE Ratio",
                                        template='plotly_dark',
                                        height=500,
                                        hovermode='x unified',
                                        showlegend=True,
                                        # Let Plotly handle margins automatically to prevent clipping
                                        xaxis=dict(
                                            type='date',
                                            automargin=True
                                        ),
                                        # Move legend to top
                                        legend=dict(
                                            orientation="h",
                                            yanchor="bottom",
                                            y=1.02,
                                            xanchor="right",
                                            x=1
                                        )
                                    )
                                    
                                    # Store in session state
                                    pe_chart_key = f"multi_backtest_pe_chart_{selected_portfolio_pe}"
                                    st.session_state[pe_chart_key] = fig_pe
                                    
                                    # Display chart
                                    st.plotly_chart(st.session_state[pe_chart_key], use_container_width=True)
                                    
                                    # Show PE data info
                                    st.warning("‚ö†Ô∏è **Work in Progress:** PE ratio calculations are currently using current PE ratios only. Historical PE evolution is not yet implemented and may not be fully accurate.")
                                    
                                    # Show cash periods warning outside the chart
                                    if len(clean_pe_ratios) < len(dates):
                                        st.info("üí° **Note:** Gaps in the chart indicate periods when the portfolio was in cash (no PE ratio applicable)")
                                    
                                    # Show PE data summary with statistical metrics
                                    if clean_pe_ratios:
                                        last_pe = clean_pe_ratios[-1]  # Today's PE (most recent)
                                        median_pe = np.median(clean_pe_ratios)
                                        std_pe = np.std(clean_pe_ratios)
                                        mean_pe = np.mean(clean_pe_ratios)
                                    else:
                                        last_pe = median_pe = std_pe = mean_pe = 0
                                    
                                    col1, col2, col3, col4 = st.columns(4)
                                    with col1:
                                        st.metric("Last PE (Today)", f"{last_pe:.2f}")
                                    with col2:
                                        st.metric("Median PE", f"{median_pe:.2f}")
                                    with col3:
                                        st.metric("Mean PE", f"{mean_pe:.2f}")
                                    with col4:
                                        st.metric("Std Deviation", f"{std_pe:.2f}")
                                    
                                    # Show individual ticker PE ratios
                                    st.info(f"üìä **Individual PE Ratios**: {len(pe_data)} tickers with PE data")
                                    pe_cols = st.columns(4)
                                    for i, (ticker, pe) in enumerate(pe_data.items()):
                                        with pe_cols[i % 4]:
                                            st.markdown(f"**{ticker}**: {pe:.2f}")
                                else:
                                    st.warning("No valid PE ratio data available for the selected period.")
                            else:
                                st.warning("No PE ratio data available for any tickers in this portfolio.")
                        else:
                            st.warning("No tickers found in allocation data.")
                    except Exception as e:
                        st.error(f"Error creating PE ratio chart: {str(e)}")
                else:
                    st.warning(f"No allocation data available for {selected_portfolio_pe}")
        else:
            st.info("No portfolios available for PE ratio analysis.")
    
    # PDF Export Section
    st.markdown("---")
    st.subheader("üìÑ PDF Export")
    
    # Optional custom PDF report name
    custom_report_name = st.text_input(
        "üìù Custom Report Name (optional):", 
        value="",
        placeholder="e.g., Tech Stocks Q4 Analysis, Conservative vs Aggressive, Monthly Performance Review",
        help="Leave empty to use automatic naming: 'Multi_Backtest_Report_[timestamp].pdf'",
        key="multi_backtest_custom_report_name"
    )
    
    if st.button("Generate PDF Report", type="primary", use_container_width=True):
        try:
            pdf_buffer = generate_simple_pdf_report(custom_report_name)
            if pdf_buffer:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                
                # Generate filename based on custom name or default
                if custom_report_name.strip():
                    clean_name = custom_report_name.strip().replace(' ', '_').replace('/', '_').replace('\\', '_')
                    filename = f"{clean_name}_{timestamp}.pdf"
                else:
                    filename = f"Multi_Backtest_Report_{timestamp}.pdf"
                
                st.success("‚úÖ PDF Report Generated Successfully!")
                st.download_button(
                    label="üì• Download PDF Report",
                    data=pdf_buffer.getvalue(),
                    file_name=filename,
                    mime="application/pdf",
                    use_container_width=True
                )
            else:
                st.error("‚ùå Failed to generate PDF report")
        except Exception as e:
            st.error(f"‚ùå Error generating PDF: {str(e)}")
            st.exception(e)
    
    # Footer - Always visible
    st.markdown("---")
    st.markdown("""
    <div style="
        text-align: center; 
        color: #666; 
        margin: 2rem 0; 
        padding: 1rem; 
        font-size: 0.9rem;
        font-weight: 500;
    ">
        Made by Nicolas Cool
    </div>
    """, unsafe_allow_html=True)
